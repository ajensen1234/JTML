\hypertarget{dataanalysis_8h_source}{}\doxysection{dataanalysis.\+h}
\label{dataanalysis_8h_source}\index{lib/alglib/dataanalysis.h@{lib/alglib/dataanalysis.h}}

\begin{DoxyCode}{0}
\DoxyCodeLine{1 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2 \textcolor{comment}{ALGLIB 3.18.0 (source code generated 2021-\/10-\/25)}}
\DoxyCodeLine{3 \textcolor{comment}{Copyright (c) Sergey Bochkanov (ALGLIB project).}}
\DoxyCodeLine{4 \textcolor{comment}{}}
\DoxyCodeLine{5 \textcolor{comment}{>>> SOURCE LICENSE >>>}}
\DoxyCodeLine{6 \textcolor{comment}{This program is free software; you can redistribute it and/or modify}}
\DoxyCodeLine{7 \textcolor{comment}{it under the terms of the GNU General Public License as published by}}
\DoxyCodeLine{8 \textcolor{comment}{the Free Software Foundation (www.fsf.org); either version 2 of the }}
\DoxyCodeLine{9 \textcolor{comment}{License, or (at your option) any later version.}}
\DoxyCodeLine{10 \textcolor{comment}{}}
\DoxyCodeLine{11 \textcolor{comment}{This program is distributed in the hope that it will be useful,}}
\DoxyCodeLine{12 \textcolor{comment}{but WITHOUT ANY WARRANTY; without even the implied warranty of}}
\DoxyCodeLine{13 \textcolor{comment}{MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the}}
\DoxyCodeLine{14 \textcolor{comment}{GNU General Public License for more details.}}
\DoxyCodeLine{15 \textcolor{comment}{}}
\DoxyCodeLine{16 \textcolor{comment}{A copy of the GNU General Public License is available at}}
\DoxyCodeLine{17 \textcolor{comment}{http://www.fsf.org/licensing/licenses}}
\DoxyCodeLine{18 \textcolor{comment}{>>> END OF LICENSE >>>}}
\DoxyCodeLine{19 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{20 \textcolor{preprocessor}{\#ifndef \_dataanalysis\_pkg\_h}}
\DoxyCodeLine{21 \textcolor{preprocessor}{\#define \_dataanalysis\_pkg\_h}}
\DoxyCodeLine{22 \textcolor{preprocessor}{\#include "{}ap.h"{}}}
\DoxyCodeLine{23 \textcolor{preprocessor}{\#include "{}alglibinternal.h"{}}}
\DoxyCodeLine{24 \textcolor{preprocessor}{\#include "{}alglibmisc.h"{}}}
\DoxyCodeLine{25 \textcolor{preprocessor}{\#include "{}linalg.h"{}}}
\DoxyCodeLine{26 \textcolor{preprocessor}{\#include "{}statistics.h"{}}}
\DoxyCodeLine{27 \textcolor{preprocessor}{\#include "{}specialfunctions.h"{}}}
\DoxyCodeLine{28 \textcolor{preprocessor}{\#include "{}optimization.h"{}}}
\DoxyCodeLine{29 \textcolor{preprocessor}{\#include "{}solvers.h"{}}}
\DoxyCodeLine{30 }
\DoxyCodeLine{32 \textcolor{comment}{//}}
\DoxyCodeLine{33 \textcolor{comment}{// THIS SECTION CONTAINS COMPUTATIONAL CORE DECLARATIONS (DATATYPES)}}
\DoxyCodeLine{34 \textcolor{comment}{//}}
\DoxyCodeLine{36 \textcolor{comment}{}\textcolor{keyword}{namespace }alglib\_impl}
\DoxyCodeLine{37 \{}
\DoxyCodeLine{38 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_PCA) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{39 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{40 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_BDSS) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{41 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{42 \{}
\DoxyCodeLine{43     \textcolor{keywordtype}{double} relclserror;}
\DoxyCodeLine{44     \textcolor{keywordtype}{double} avgce;}
\DoxyCodeLine{45     \textcolor{keywordtype}{double} rmserror;}
\DoxyCodeLine{46     \textcolor{keywordtype}{double} avgerror;}
\DoxyCodeLine{47     \textcolor{keywordtype}{double} avgrelerror;}
\DoxyCodeLine{48 \} \mbox{\hyperlink{structalglib__impl_1_1cvreport}{cvreport}};}
\DoxyCodeLine{49 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{50 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_MLPBASE) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{51 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{52 \{}
\DoxyCodeLine{53     \textcolor{keywordtype}{double} relclserror;}
\DoxyCodeLine{54     \textcolor{keywordtype}{double} avgce;}
\DoxyCodeLine{55     \textcolor{keywordtype}{double} rmserror;}
\DoxyCodeLine{56     \textcolor{keywordtype}{double} avgerror;}
\DoxyCodeLine{57     \textcolor{keywordtype}{double} avgrelerror;}
\DoxyCodeLine{58 \} \mbox{\hyperlink{structalglib__impl_1_1modelerrors}{modelerrors}};}
\DoxyCodeLine{59 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{60 \{}
\DoxyCodeLine{61     \textcolor{keywordtype}{double} f;}
\DoxyCodeLine{62     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} g;}
\DoxyCodeLine{63 \} \mbox{\hyperlink{structalglib__impl_1_1smlpgrad}{smlpgrad}};}
\DoxyCodeLine{64 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{65 \{}
\DoxyCodeLine{66     ae\_int\_t hlnetworktype;}
\DoxyCodeLine{67     ae\_int\_t hlnormtype;}
\DoxyCodeLine{68     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} hllayersizes;}
\DoxyCodeLine{69     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} hlconnections;}
\DoxyCodeLine{70     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} hlneurons;}
\DoxyCodeLine{71     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} structinfo;}
\DoxyCodeLine{72     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} weights;}
\DoxyCodeLine{73     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} columnmeans;}
\DoxyCodeLine{74     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} columnsigmas;}
\DoxyCodeLine{75     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} neurons;}
\DoxyCodeLine{76     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} dfdnet;}
\DoxyCodeLine{77     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} derror;}
\DoxyCodeLine{78     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} x;}
\DoxyCodeLine{79     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} y;}
\DoxyCodeLine{80     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} xy;}
\DoxyCodeLine{81     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} xyrow;}
\DoxyCodeLine{82     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} nwbuf;}
\DoxyCodeLine{83     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} integerbuf;}
\DoxyCodeLine{84     \mbox{\hyperlink{structalglib__impl_1_1modelerrors}{modelerrors}} err;}
\DoxyCodeLine{85     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} rndbuf;}
\DoxyCodeLine{86     \mbox{\hyperlink{structalglib__impl_1_1ae__shared__pool}{ae\_shared\_pool}} buf;}
\DoxyCodeLine{87     \mbox{\hyperlink{structalglib__impl_1_1ae__shared__pool}{ae\_shared\_pool}} gradbuf;}
\DoxyCodeLine{88     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} dummydxy;}
\DoxyCodeLine{89     \mbox{\hyperlink{structalglib__impl_1_1sparsematrix}{sparsematrix}} dummysxy;}
\DoxyCodeLine{90     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} dummyidx;}
\DoxyCodeLine{91     \mbox{\hyperlink{structalglib__impl_1_1ae__shared__pool}{ae\_shared\_pool}} dummypool;}
\DoxyCodeLine{92 \} \mbox{\hyperlink{structalglib__impl_1_1multilayerperceptron}{multilayerperceptron}};}
\DoxyCodeLine{93 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{94 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_MLPE) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{95 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{96 \{}
\DoxyCodeLine{97     ae\_int\_t ensemblesize;}
\DoxyCodeLine{98     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} weights;}
\DoxyCodeLine{99     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} columnmeans;}
\DoxyCodeLine{100     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} columnsigmas;}
\DoxyCodeLine{101     \mbox{\hyperlink{structalglib__impl_1_1multilayerperceptron}{multilayerperceptron}} network;}
\DoxyCodeLine{102     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} y;}
\DoxyCodeLine{103 \} \mbox{\hyperlink{structalglib__impl_1_1mlpensemble}{mlpensemble}};}
\DoxyCodeLine{104 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{105 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_CLUSTERING) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{106 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{107 \{}
\DoxyCodeLine{108     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} ct;}
\DoxyCodeLine{109     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} ctbest;}
\DoxyCodeLine{110     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} xycbest;}
\DoxyCodeLine{111     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} xycprev;}
\DoxyCodeLine{112     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} d2;}
\DoxyCodeLine{113     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} csizes;}
\DoxyCodeLine{114     \mbox{\hyperlink{structalglib__impl_1_1apbuffers}{apbuffers}} initbuf;}
\DoxyCodeLine{115     \mbox{\hyperlink{structalglib__impl_1_1ae__shared__pool}{ae\_shared\_pool}} updatepool;}
\DoxyCodeLine{116 \} \mbox{\hyperlink{structalglib__impl_1_1kmeansbuffers}{kmeansbuffers}};}
\DoxyCodeLine{117 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{118 \{}
\DoxyCodeLine{119     ae\_int\_t npoints;}
\DoxyCodeLine{120     ae\_int\_t nfeatures;}
\DoxyCodeLine{121     ae\_int\_t disttype;}
\DoxyCodeLine{122     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} xy;}
\DoxyCodeLine{123     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} d;}
\DoxyCodeLine{124     ae\_int\_t ahcalgo;}
\DoxyCodeLine{125     ae\_int\_t kmeansrestarts;}
\DoxyCodeLine{126     ae\_int\_t kmeansmaxits;}
\DoxyCodeLine{127     ae\_int\_t kmeansinitalgo;}
\DoxyCodeLine{128     ae\_bool kmeansdbgnoits;}
\DoxyCodeLine{129     ae\_int\_t seed;}
\DoxyCodeLine{130     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} tmpd;}
\DoxyCodeLine{131     \mbox{\hyperlink{structalglib__impl_1_1apbuffers}{apbuffers}} distbuf;}
\DoxyCodeLine{132     \mbox{\hyperlink{structalglib__impl_1_1kmeansbuffers}{kmeansbuffers}} kmeanstmp;}
\DoxyCodeLine{133 \} \mbox{\hyperlink{structalglib__impl_1_1clusterizerstate}{clusterizerstate}};}
\DoxyCodeLine{134 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{135 \{}
\DoxyCodeLine{136     ae\_int\_t terminationtype;}
\DoxyCodeLine{137     ae\_int\_t npoints;}
\DoxyCodeLine{138     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} p;}
\DoxyCodeLine{139     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} z;}
\DoxyCodeLine{140     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} pz;}
\DoxyCodeLine{141     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} pm;}
\DoxyCodeLine{142     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} mergedist;}
\DoxyCodeLine{143 \} \mbox{\hyperlink{structalglib__impl_1_1ahcreport}{ahcreport}};}
\DoxyCodeLine{144 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{145 \{}
\DoxyCodeLine{146     ae\_int\_t npoints;}
\DoxyCodeLine{147     ae\_int\_t nfeatures;}
\DoxyCodeLine{148     ae\_int\_t terminationtype;}
\DoxyCodeLine{149     ae\_int\_t iterationscount;}
\DoxyCodeLine{150     \textcolor{keywordtype}{double} energy;}
\DoxyCodeLine{151     ae\_int\_t k;}
\DoxyCodeLine{152     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} c;}
\DoxyCodeLine{153     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} cidx;}
\DoxyCodeLine{154 \} \mbox{\hyperlink{structalglib__impl_1_1kmeansreport}{kmeansreport}};}
\DoxyCodeLine{155 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{156 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_DFOREST) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{157 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{158 \{}
\DoxyCodeLine{159     ae\_int\_t dstype;}
\DoxyCodeLine{160     ae\_int\_t npoints;}
\DoxyCodeLine{161     ae\_int\_t nvars;}
\DoxyCodeLine{162     ae\_int\_t nclasses;}
\DoxyCodeLine{163     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} dsdata;}
\DoxyCodeLine{164     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} dsrval;}
\DoxyCodeLine{165     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} dsival;}
\DoxyCodeLine{166     ae\_int\_t rdfalgo;}
\DoxyCodeLine{167     \textcolor{keywordtype}{double} rdfratio;}
\DoxyCodeLine{168     \textcolor{keywordtype}{double} rdfvars;}
\DoxyCodeLine{169     ae\_int\_t rdfglobalseed;}
\DoxyCodeLine{170     ae\_int\_t rdfsplitstrength;}
\DoxyCodeLine{171     ae\_int\_t rdfimportance;}
\DoxyCodeLine{172     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} dsmin;}
\DoxyCodeLine{173     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} dsmax;}
\DoxyCodeLine{174     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} dsbinary;}
\DoxyCodeLine{175     \textcolor{keywordtype}{double} dsravg;}
\DoxyCodeLine{176     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} dsctotals;}
\DoxyCodeLine{177     ae\_int\_t rdfprogress;}
\DoxyCodeLine{178     ae\_int\_t rdftotal;}
\DoxyCodeLine{179     \mbox{\hyperlink{structalglib__impl_1_1ae__shared__pool}{ae\_shared\_pool}} workpool;}
\DoxyCodeLine{180     \mbox{\hyperlink{structalglib__impl_1_1ae__shared__pool}{ae\_shared\_pool}} votepool;}
\DoxyCodeLine{181     \mbox{\hyperlink{structalglib__impl_1_1ae__shared__pool}{ae\_shared\_pool}} treepool;}
\DoxyCodeLine{182     \mbox{\hyperlink{structalglib__impl_1_1ae__shared__pool}{ae\_shared\_pool}} treefactory;}
\DoxyCodeLine{183     ae\_bool neediobmatrix;}
\DoxyCodeLine{184     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} iobmatrix;}
\DoxyCodeLine{185     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} varimpshuffle2;}
\DoxyCodeLine{186 \} \mbox{\hyperlink{structalglib__impl_1_1decisionforestbuilder}{decisionforestbuilder}};}
\DoxyCodeLine{187 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{188 \{}
\DoxyCodeLine{189     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} classpriors;}
\DoxyCodeLine{190     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} varpool;}
\DoxyCodeLine{191     ae\_int\_t varpoolsize;}
\DoxyCodeLine{192     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} trnset;}
\DoxyCodeLine{193     ae\_int\_t trnsize;}
\DoxyCodeLine{194     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} trnlabelsr;}
\DoxyCodeLine{195     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} trnlabelsi;}
\DoxyCodeLine{196     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} oobset;}
\DoxyCodeLine{197     ae\_int\_t oobsize;}
\DoxyCodeLine{198     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} ooblabelsr;}
\DoxyCodeLine{199     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} ooblabelsi;}
\DoxyCodeLine{200     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} treebuf;}
\DoxyCodeLine{201     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} curvals;}
\DoxyCodeLine{202     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} bestvals;}
\DoxyCodeLine{203     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} tmp0i;}
\DoxyCodeLine{204     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} tmp1i;}
\DoxyCodeLine{205     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} tmp0r;}
\DoxyCodeLine{206     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} tmp1r;}
\DoxyCodeLine{207     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} tmp2r;}
\DoxyCodeLine{208     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} tmp3r;}
\DoxyCodeLine{209     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} tmpnrms2;}
\DoxyCodeLine{210     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} classtotals0;}
\DoxyCodeLine{211     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} classtotals1;}
\DoxyCodeLine{212     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} classtotals01;}
\DoxyCodeLine{213 \} \mbox{\hyperlink{structalglib__impl_1_1dfworkbuf}{dfworkbuf}};}
\DoxyCodeLine{214 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{215 \{}
\DoxyCodeLine{216     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} trntotals;}
\DoxyCodeLine{217     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} oobtotals;}
\DoxyCodeLine{218     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} trncounts;}
\DoxyCodeLine{219     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} oobcounts;}
\DoxyCodeLine{220     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} giniimportances;}
\DoxyCodeLine{221 \} \mbox{\hyperlink{structalglib__impl_1_1dfvotebuf}{dfvotebuf}};}
\DoxyCodeLine{222 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{223 \{}
\DoxyCodeLine{224     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} losses;}
\DoxyCodeLine{225     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} xraw;}
\DoxyCodeLine{226     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} xdist;}
\DoxyCodeLine{227     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} xcur;}
\DoxyCodeLine{228     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} y;}
\DoxyCodeLine{229     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} yv;}
\DoxyCodeLine{230     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} targety;}
\DoxyCodeLine{231     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} startnodes;}
\DoxyCodeLine{232 \} \mbox{\hyperlink{structalglib__impl_1_1dfpermimpbuf}{dfpermimpbuf}};}
\DoxyCodeLine{233 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{234 \{}
\DoxyCodeLine{235     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} treebuf;}
\DoxyCodeLine{236     ae\_int\_t treeidx;}
\DoxyCodeLine{237 \} \mbox{\hyperlink{structalglib__impl_1_1dftreebuf}{dftreebuf}};}
\DoxyCodeLine{238 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{239 \{}
\DoxyCodeLine{240     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} x;}
\DoxyCodeLine{241     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} y;}
\DoxyCodeLine{242 \} \mbox{\hyperlink{structalglib__impl_1_1decisionforestbuffer}{decisionforestbuffer}};}
\DoxyCodeLine{243 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{244 \{}
\DoxyCodeLine{245     ae\_int\_t forestformat;}
\DoxyCodeLine{246     ae\_bool usemantissa8;}
\DoxyCodeLine{247     ae\_int\_t nvars;}
\DoxyCodeLine{248     ae\_int\_t nclasses;}
\DoxyCodeLine{249     ae\_int\_t ntrees;}
\DoxyCodeLine{250     ae\_int\_t bufsize;}
\DoxyCodeLine{251     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} trees;}
\DoxyCodeLine{252     \mbox{\hyperlink{structalglib__impl_1_1decisionforestbuffer}{decisionforestbuffer}} buffer;}
\DoxyCodeLine{253     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} trees8;}
\DoxyCodeLine{254 \} \mbox{\hyperlink{structalglib__impl_1_1decisionforest}{decisionforest}};}
\DoxyCodeLine{255 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{256 \{}
\DoxyCodeLine{257     \textcolor{keywordtype}{double} relclserror;}
\DoxyCodeLine{258     \textcolor{keywordtype}{double} avgce;}
\DoxyCodeLine{259     \textcolor{keywordtype}{double} rmserror;}
\DoxyCodeLine{260     \textcolor{keywordtype}{double} avgerror;}
\DoxyCodeLine{261     \textcolor{keywordtype}{double} avgrelerror;}
\DoxyCodeLine{262     \textcolor{keywordtype}{double} oobrelclserror;}
\DoxyCodeLine{263     \textcolor{keywordtype}{double} oobavgce;}
\DoxyCodeLine{264     \textcolor{keywordtype}{double} oobrmserror;}
\DoxyCodeLine{265     \textcolor{keywordtype}{double} oobavgerror;}
\DoxyCodeLine{266     \textcolor{keywordtype}{double} oobavgrelerror;}
\DoxyCodeLine{267     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} topvars;}
\DoxyCodeLine{268     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} varimportances;}
\DoxyCodeLine{269 \} \mbox{\hyperlink{structalglib__impl_1_1dfreport}{dfreport}};}
\DoxyCodeLine{270 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{271 \{}
\DoxyCodeLine{272     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} treebuf;}
\DoxyCodeLine{273     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} idxbuf;}
\DoxyCodeLine{274     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} tmpbufr;}
\DoxyCodeLine{275     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} tmpbufr2;}
\DoxyCodeLine{276     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} tmpbufi;}
\DoxyCodeLine{277     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} classibuf;}
\DoxyCodeLine{278     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} sortrbuf;}
\DoxyCodeLine{279     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} sortrbuf2;}
\DoxyCodeLine{280     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} sortibuf;}
\DoxyCodeLine{281     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} varpool;}
\DoxyCodeLine{282     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} evsbin;}
\DoxyCodeLine{283     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} evssplits;}
\DoxyCodeLine{284 \} \mbox{\hyperlink{structalglib__impl_1_1dfinternalbuffers}{dfinternalbuffers}};}
\DoxyCodeLine{285 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{286 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_LINREG) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{287 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{288 \{}
\DoxyCodeLine{289     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} w;}
\DoxyCodeLine{290 \} \mbox{\hyperlink{structalglib__impl_1_1linearmodel}{linearmodel}};}
\DoxyCodeLine{291 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{292 \{}
\DoxyCodeLine{293     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} c;}
\DoxyCodeLine{294     \textcolor{keywordtype}{double} rmserror;}
\DoxyCodeLine{295     \textcolor{keywordtype}{double} avgerror;}
\DoxyCodeLine{296     \textcolor{keywordtype}{double} avgrelerror;}
\DoxyCodeLine{297     \textcolor{keywordtype}{double} cvrmserror;}
\DoxyCodeLine{298     \textcolor{keywordtype}{double} cvavgerror;}
\DoxyCodeLine{299     \textcolor{keywordtype}{double} cvavgrelerror;}
\DoxyCodeLine{300     ae\_int\_t ncvdefects;}
\DoxyCodeLine{301     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} cvdefects;}
\DoxyCodeLine{302 \} \mbox{\hyperlink{structalglib__impl_1_1lrreport}{lrreport}};}
\DoxyCodeLine{303 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{304 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_FILTERS) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{305 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{306 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_SSA) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{307 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{308 \{}
\DoxyCodeLine{309     ae\_int\_t nsequences;}
\DoxyCodeLine{310     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} sequenceidx;}
\DoxyCodeLine{311     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} sequencedata;}
\DoxyCodeLine{312     ae\_int\_t algotype;}
\DoxyCodeLine{313     ae\_int\_t windowwidth;}
\DoxyCodeLine{314     ae\_int\_t rtpowerup;}
\DoxyCodeLine{315     ae\_int\_t topk;}
\DoxyCodeLine{316     ae\_int\_t precomputedwidth;}
\DoxyCodeLine{317     ae\_int\_t precomputednbasis;}
\DoxyCodeLine{318     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} precomputedbasis;}
\DoxyCodeLine{319     ae\_int\_t defaultsubspaceits;}
\DoxyCodeLine{320     ae\_int\_t memorylimit;}
\DoxyCodeLine{321     ae\_bool arebasisandsolvervalid;}
\DoxyCodeLine{322     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} basis;}
\DoxyCodeLine{323     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} basist;}
\DoxyCodeLine{324     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} sv;}
\DoxyCodeLine{325     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} forecasta;}
\DoxyCodeLine{326     ae\_int\_t nbasis;}
\DoxyCodeLine{327     \mbox{\hyperlink{structalglib__impl_1_1eigsubspacestate}{eigsubspacestate}} solver;}
\DoxyCodeLine{328     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} xxt;}
\DoxyCodeLine{329     \mbox{\hyperlink{structalglib__impl_1_1hqrndstate}{hqrndstate}} rs;}
\DoxyCodeLine{330     ae\_int\_t rngseed;}
\DoxyCodeLine{331     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} rtqueue;}
\DoxyCodeLine{332     ae\_int\_t rtqueuecnt;}
\DoxyCodeLine{333     ae\_int\_t rtqueuechunk;}
\DoxyCodeLine{334     ae\_int\_t dbgcntevd;}
\DoxyCodeLine{335     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} tmp0;}
\DoxyCodeLine{336     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} tmp1;}
\DoxyCodeLine{337     \mbox{\hyperlink{structalglib__impl_1_1eigsubspacereport}{eigsubspacereport}} solverrep;}
\DoxyCodeLine{338     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} alongtrend;}
\DoxyCodeLine{339     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} alongnoise;}
\DoxyCodeLine{340     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} aseqtrajectory;}
\DoxyCodeLine{341     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} aseqtbproduct;}
\DoxyCodeLine{342     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} aseqcounts;}
\DoxyCodeLine{343     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} fctrend;}
\DoxyCodeLine{344     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} fcnoise;}
\DoxyCodeLine{345     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} fctrendm;}
\DoxyCodeLine{346     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} uxbatch;}
\DoxyCodeLine{347     ae\_int\_t uxbatchwidth;}
\DoxyCodeLine{348     ae\_int\_t uxbatchsize;}
\DoxyCodeLine{349     ae\_int\_t uxbatchlimit;}
\DoxyCodeLine{350 \} \mbox{\hyperlink{structalglib__impl_1_1ssamodel}{ssamodel}};}
\DoxyCodeLine{351 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{352 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_LDA) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{353 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{354 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_MCPD) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{355 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{356 \{}
\DoxyCodeLine{357     ae\_int\_t n;}
\DoxyCodeLine{358     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} states;}
\DoxyCodeLine{359     ae\_int\_t npairs;}
\DoxyCodeLine{360     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} data;}
\DoxyCodeLine{361     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} ec;}
\DoxyCodeLine{362     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} bndl;}
\DoxyCodeLine{363     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} bndu;}
\DoxyCodeLine{364     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} c;}
\DoxyCodeLine{365     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} ct;}
\DoxyCodeLine{366     ae\_int\_t ccnt;}
\DoxyCodeLine{367     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} pw;}
\DoxyCodeLine{368     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} priorp;}
\DoxyCodeLine{369     \textcolor{keywordtype}{double} regterm;}
\DoxyCodeLine{370     \mbox{\hyperlink{structalglib__impl_1_1minbleicstate}{minbleicstate}} bs;}
\DoxyCodeLine{371     ae\_int\_t repinneriterationscount;}
\DoxyCodeLine{372     ae\_int\_t repouteriterationscount;}
\DoxyCodeLine{373     ae\_int\_t repnfev;}
\DoxyCodeLine{374     ae\_int\_t repterminationtype;}
\DoxyCodeLine{375     \mbox{\hyperlink{structalglib__impl_1_1minbleicreport}{minbleicreport}} br;}
\DoxyCodeLine{376     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} tmpp;}
\DoxyCodeLine{377     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} effectivew;}
\DoxyCodeLine{378     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} effectivebndl;}
\DoxyCodeLine{379     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} effectivebndu;}
\DoxyCodeLine{380     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} effectivec;}
\DoxyCodeLine{381     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} effectivect;}
\DoxyCodeLine{382     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} h;}
\DoxyCodeLine{383     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} p;}
\DoxyCodeLine{384 \} \mbox{\hyperlink{structalglib__impl_1_1mcpdstate}{mcpdstate}};}
\DoxyCodeLine{385 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{386 \{}
\DoxyCodeLine{387     ae\_int\_t inneriterationscount;}
\DoxyCodeLine{388     ae\_int\_t outeriterationscount;}
\DoxyCodeLine{389     ae\_int\_t nfev;}
\DoxyCodeLine{390     ae\_int\_t terminationtype;}
\DoxyCodeLine{391 \} \mbox{\hyperlink{structalglib__impl_1_1mcpdreport}{mcpdreport}};}
\DoxyCodeLine{392 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{393 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_LOGIT) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{394 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{395 \{}
\DoxyCodeLine{396     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} w;}
\DoxyCodeLine{397 \} \mbox{\hyperlink{structalglib__impl_1_1logitmodel}{logitmodel}};}
\DoxyCodeLine{398 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{399 \{}
\DoxyCodeLine{400     ae\_bool brackt;}
\DoxyCodeLine{401     ae\_bool stage1;}
\DoxyCodeLine{402     ae\_int\_t infoc;}
\DoxyCodeLine{403     \textcolor{keywordtype}{double} dg;}
\DoxyCodeLine{404     \textcolor{keywordtype}{double} dgm;}
\DoxyCodeLine{405     \textcolor{keywordtype}{double} dginit;}
\DoxyCodeLine{406     \textcolor{keywordtype}{double} dgtest;}
\DoxyCodeLine{407     \textcolor{keywordtype}{double} dgx;}
\DoxyCodeLine{408     \textcolor{keywordtype}{double} dgxm;}
\DoxyCodeLine{409     \textcolor{keywordtype}{double} dgy;}
\DoxyCodeLine{410     \textcolor{keywordtype}{double} dgym;}
\DoxyCodeLine{411     \textcolor{keywordtype}{double} finit;}
\DoxyCodeLine{412     \textcolor{keywordtype}{double} ftest1;}
\DoxyCodeLine{413     \textcolor{keywordtype}{double} fm;}
\DoxyCodeLine{414     \textcolor{keywordtype}{double} fx;}
\DoxyCodeLine{415     \textcolor{keywordtype}{double} fxm;}
\DoxyCodeLine{416     \textcolor{keywordtype}{double} fy;}
\DoxyCodeLine{417     \textcolor{keywordtype}{double} fym;}
\DoxyCodeLine{418     \textcolor{keywordtype}{double} stx;}
\DoxyCodeLine{419     \textcolor{keywordtype}{double} sty;}
\DoxyCodeLine{420     \textcolor{keywordtype}{double} stmin;}
\DoxyCodeLine{421     \textcolor{keywordtype}{double} stmax;}
\DoxyCodeLine{422     \textcolor{keywordtype}{double} width;}
\DoxyCodeLine{423     \textcolor{keywordtype}{double} width1;}
\DoxyCodeLine{424     \textcolor{keywordtype}{double} xtrapf;}
\DoxyCodeLine{425 \} \mbox{\hyperlink{structalglib__impl_1_1logitmcstate}{logitmcstate}};}
\DoxyCodeLine{426 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{427 \{}
\DoxyCodeLine{428     ae\_int\_t ngrad;}
\DoxyCodeLine{429     ae\_int\_t nhess;}
\DoxyCodeLine{430 \} \mbox{\hyperlink{structalglib__impl_1_1mnlreport}{mnlreport}};}
\DoxyCodeLine{431 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{432 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_KNN) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{433 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{434 \{}
\DoxyCodeLine{435     \mbox{\hyperlink{structalglib__impl_1_1kdtreerequestbuffer}{kdtreerequestbuffer}} treebuf;}
\DoxyCodeLine{436     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} x;}
\DoxyCodeLine{437     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} y;}
\DoxyCodeLine{438     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} tags;}
\DoxyCodeLine{439     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} xy;}
\DoxyCodeLine{440 \} \mbox{\hyperlink{structalglib__impl_1_1knnbuffer}{knnbuffer}};}
\DoxyCodeLine{441 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{442 \{}
\DoxyCodeLine{443     ae\_int\_t dstype;}
\DoxyCodeLine{444     ae\_int\_t npoints;}
\DoxyCodeLine{445     ae\_int\_t nvars;}
\DoxyCodeLine{446     ae\_bool iscls;}
\DoxyCodeLine{447     ae\_int\_t nout;}
\DoxyCodeLine{448     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} dsdata;}
\DoxyCodeLine{449     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} dsrval;}
\DoxyCodeLine{450     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} dsival;}
\DoxyCodeLine{451     ae\_int\_t knnnrm;}
\DoxyCodeLine{452 \} \mbox{\hyperlink{structalglib__impl_1_1knnbuilder}{knnbuilder}};}
\DoxyCodeLine{453 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{454 \{}
\DoxyCodeLine{455     ae\_int\_t nvars;}
\DoxyCodeLine{456     ae\_int\_t nout;}
\DoxyCodeLine{457     ae\_int\_t k;}
\DoxyCodeLine{458     \textcolor{keywordtype}{double} eps;}
\DoxyCodeLine{459     ae\_bool iscls;}
\DoxyCodeLine{460     ae\_bool isdummy;}
\DoxyCodeLine{461     \mbox{\hyperlink{structalglib__impl_1_1kdtree}{kdtree}} tree;}
\DoxyCodeLine{462     \mbox{\hyperlink{structalglib__impl_1_1knnbuffer}{knnbuffer}} buffer;}
\DoxyCodeLine{463 \} \mbox{\hyperlink{structalglib__impl_1_1knnmodel}{knnmodel}};}
\DoxyCodeLine{464 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{465 \{}
\DoxyCodeLine{466     \textcolor{keywordtype}{double} relclserror;}
\DoxyCodeLine{467     \textcolor{keywordtype}{double} avgce;}
\DoxyCodeLine{468     \textcolor{keywordtype}{double} rmserror;}
\DoxyCodeLine{469     \textcolor{keywordtype}{double} avgerror;}
\DoxyCodeLine{470     \textcolor{keywordtype}{double} avgrelerror;}
\DoxyCodeLine{471 \} \mbox{\hyperlink{structalglib__impl_1_1knnreport}{knnreport}};}
\DoxyCodeLine{472 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{473 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_MLPTRAIN) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{474 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{475 \{}
\DoxyCodeLine{476     \textcolor{keywordtype}{double} relclserror;}
\DoxyCodeLine{477     \textcolor{keywordtype}{double} avgce;}
\DoxyCodeLine{478     \textcolor{keywordtype}{double} rmserror;}
\DoxyCodeLine{479     \textcolor{keywordtype}{double} avgerror;}
\DoxyCodeLine{480     \textcolor{keywordtype}{double} avgrelerror;}
\DoxyCodeLine{481     ae\_int\_t ngrad;}
\DoxyCodeLine{482     ae\_int\_t nhess;}
\DoxyCodeLine{483     ae\_int\_t ncholesky;}
\DoxyCodeLine{484 \} \mbox{\hyperlink{structalglib__impl_1_1mlpreport}{mlpreport}};}
\DoxyCodeLine{485 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{486 \{}
\DoxyCodeLine{487     \textcolor{keywordtype}{double} relclserror;}
\DoxyCodeLine{488     \textcolor{keywordtype}{double} avgce;}
\DoxyCodeLine{489     \textcolor{keywordtype}{double} rmserror;}
\DoxyCodeLine{490     \textcolor{keywordtype}{double} avgerror;}
\DoxyCodeLine{491     \textcolor{keywordtype}{double} avgrelerror;}
\DoxyCodeLine{492 \} \mbox{\hyperlink{structalglib__impl_1_1mlpcvreport}{mlpcvreport}};}
\DoxyCodeLine{493 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{494 \{}
\DoxyCodeLine{495     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} bestparameters;}
\DoxyCodeLine{496     \textcolor{keywordtype}{double} bestrmserror;}
\DoxyCodeLine{497     ae\_bool randomizenetwork;}
\DoxyCodeLine{498     \mbox{\hyperlink{structalglib__impl_1_1multilayerperceptron}{multilayerperceptron}} network;}
\DoxyCodeLine{499     \mbox{\hyperlink{structalglib__impl_1_1minlbfgsstate}{minlbfgsstate}} optimizer;}
\DoxyCodeLine{500     \mbox{\hyperlink{structalglib__impl_1_1minlbfgsreport}{minlbfgsreport}} optimizerrep;}
\DoxyCodeLine{501     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} wbuf0;}
\DoxyCodeLine{502     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} wbuf1;}
\DoxyCodeLine{503     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} allminibatches;}
\DoxyCodeLine{504     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} currentminibatch;}
\DoxyCodeLine{505     \mbox{\hyperlink{structalglib__impl_1_1rcommstate}{rcommstate}} rstate;}
\DoxyCodeLine{506     ae\_int\_t algoused;}
\DoxyCodeLine{507     ae\_int\_t minibatchsize;}
\DoxyCodeLine{508     \mbox{\hyperlink{structalglib__impl_1_1hqrndstate}{hqrndstate}} generator;}
\DoxyCodeLine{509 \} \mbox{\hyperlink{structalglib__impl_1_1smlptrnsession}{smlptrnsession}};}
\DoxyCodeLine{510 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{511 \{}
\DoxyCodeLine{512     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} trnsubset;}
\DoxyCodeLine{513     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} valsubset;}
\DoxyCodeLine{514     \mbox{\hyperlink{structalglib__impl_1_1ae__shared__pool}{ae\_shared\_pool}} mlpsessions;}
\DoxyCodeLine{515     \mbox{\hyperlink{structalglib__impl_1_1mlpreport}{mlpreport}} mlprep;}
\DoxyCodeLine{516     \mbox{\hyperlink{structalglib__impl_1_1multilayerperceptron}{multilayerperceptron}} network;}
\DoxyCodeLine{517 \} \mbox{\hyperlink{structalglib__impl_1_1mlpetrnsession}{mlpetrnsession}};}
\DoxyCodeLine{518 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{519 \{}
\DoxyCodeLine{520     ae\_int\_t nin;}
\DoxyCodeLine{521     ae\_int\_t nout;}
\DoxyCodeLine{522     ae\_bool rcpar;}
\DoxyCodeLine{523     ae\_int\_t lbfgsfactor;}
\DoxyCodeLine{524     \textcolor{keywordtype}{double} decay;}
\DoxyCodeLine{525     \textcolor{keywordtype}{double} wstep;}
\DoxyCodeLine{526     ae\_int\_t maxits;}
\DoxyCodeLine{527     ae\_int\_t datatype;}
\DoxyCodeLine{528     ae\_int\_t npoints;}
\DoxyCodeLine{529     \mbox{\hyperlink{structalglib__impl_1_1ae__matrix}{ae\_matrix}} densexy;}
\DoxyCodeLine{530     \mbox{\hyperlink{structalglib__impl_1_1sparsematrix}{sparsematrix}} sparsexy;}
\DoxyCodeLine{531     \mbox{\hyperlink{structalglib__impl_1_1smlptrnsession}{smlptrnsession}} session;}
\DoxyCodeLine{532     ae\_int\_t ngradbatch;}
\DoxyCodeLine{533     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} subset;}
\DoxyCodeLine{534     ae\_int\_t subsetsize;}
\DoxyCodeLine{535     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} valsubset;}
\DoxyCodeLine{536     ae\_int\_t valsubsetsize;}
\DoxyCodeLine{537     ae\_int\_t algokind;}
\DoxyCodeLine{538     ae\_int\_t minibatchsize;}
\DoxyCodeLine{539 \} \mbox{\hyperlink{structalglib__impl_1_1mlptrainer}{mlptrainer}};}
\DoxyCodeLine{540 \textcolor{keyword}{typedef} \textcolor{keyword}{struct}}
\DoxyCodeLine{541 \{}
\DoxyCodeLine{542     \mbox{\hyperlink{structalglib__impl_1_1multilayerperceptron}{multilayerperceptron}} network;}
\DoxyCodeLine{543     \mbox{\hyperlink{structalglib__impl_1_1mlpreport}{mlpreport}} rep;}
\DoxyCodeLine{544     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} subset;}
\DoxyCodeLine{545     ae\_int\_t subsetsize;}
\DoxyCodeLine{546     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} xyrow;}
\DoxyCodeLine{547     \mbox{\hyperlink{structalglib__impl_1_1ae__vector}{ae\_vector}} y;}
\DoxyCodeLine{548     ae\_int\_t ngrad;}
\DoxyCodeLine{549     \mbox{\hyperlink{structalglib__impl_1_1ae__shared__pool}{ae\_shared\_pool}} trnpool;}
\DoxyCodeLine{550 \} \mbox{\hyperlink{structalglib__impl_1_1mlpparallelizationcv}{mlpparallelizationcv}};}
\DoxyCodeLine{551 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{552 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_DATACOMP) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{553 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{554 }
\DoxyCodeLine{555 \}}
\DoxyCodeLine{556 }
\DoxyCodeLine{558 \textcolor{comment}{//}}
\DoxyCodeLine{559 \textcolor{comment}{// THIS SECTION CONTAINS C++ INTERFACE}}
\DoxyCodeLine{560 \textcolor{comment}{//}}
\DoxyCodeLine{562 \textcolor{comment}{}\textcolor{keyword}{namespace }alglib}
\DoxyCodeLine{563 \{}
\DoxyCodeLine{564 }
\DoxyCodeLine{565 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_PCA) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{566 }
\DoxyCodeLine{567 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{568 }
\DoxyCodeLine{569 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_BDSS) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{570 }
\DoxyCodeLine{571 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{572 }
\DoxyCodeLine{573 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_MLPBASE) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{574 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{575 \textcolor{comment}{Model's errors:}}
\DoxyCodeLine{576 \textcolor{comment}{    * RelCLSError   -\/   fraction of misclassified cases.}}
\DoxyCodeLine{577 \textcolor{comment}{    * AvgCE         -\/   acerage cross-\/entropy}}
\DoxyCodeLine{578 \textcolor{comment}{    * RMSError      -\/   root-\/mean-\/square error}}
\DoxyCodeLine{579 \textcolor{comment}{    * AvgError      -\/   average error}}
\DoxyCodeLine{580 \textcolor{comment}{    * AvgRelError   -\/   average relative error}}
\DoxyCodeLine{581 \textcolor{comment}{}}
\DoxyCodeLine{582 \textcolor{comment}{NOTE 1: RelCLSError/AvgCE are zero on regression problems.}}
\DoxyCodeLine{583 \textcolor{comment}{}}
\DoxyCodeLine{584 \textcolor{comment}{NOTE 2: on classification problems  RMSError/AvgError/AvgRelError  contain}}
\DoxyCodeLine{585 \textcolor{comment}{        errors in prediction of posterior probabilities}}
\DoxyCodeLine{586 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{587 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__modelerrors__owner}{\_modelerrors\_owner}}}
\DoxyCodeLine{588 \{}
\DoxyCodeLine{589 \textcolor{keyword}{public}:}
\DoxyCodeLine{590     \mbox{\hyperlink{classalglib_1_1__modelerrors__owner}{\_modelerrors\_owner}}();}
\DoxyCodeLine{591     \mbox{\hyperlink{classalglib_1_1__modelerrors__owner}{\_modelerrors\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__modelerrors__owner}{\_modelerrors\_owner}} \&rhs);}
\DoxyCodeLine{592     \mbox{\hyperlink{classalglib_1_1__modelerrors__owner}{\_modelerrors\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__modelerrors__owner}{\_modelerrors\_owner}} \&rhs);}
\DoxyCodeLine{593     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__modelerrors__owner}{\string~\_modelerrors\_owner}}();}
\DoxyCodeLine{594     \mbox{\hyperlink{structalglib__impl_1_1modelerrors}{alglib\_impl::modelerrors}}* c\_ptr();}
\DoxyCodeLine{595     \mbox{\hyperlink{structalglib__impl_1_1modelerrors}{alglib\_impl::modelerrors}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{596 \textcolor{keyword}{protected}:}
\DoxyCodeLine{597     \mbox{\hyperlink{structalglib__impl_1_1modelerrors}{alglib\_impl::modelerrors}} *p\_struct;}
\DoxyCodeLine{598 \};}
\DoxyCodeLine{599 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1modelerrors}{modelerrors}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__modelerrors__owner}{\_modelerrors\_owner}}}
\DoxyCodeLine{600 \{}
\DoxyCodeLine{601 \textcolor{keyword}{public}:}
\DoxyCodeLine{602     \mbox{\hyperlink{classalglib_1_1modelerrors}{modelerrors}}();}
\DoxyCodeLine{603     \mbox{\hyperlink{classalglib_1_1modelerrors}{modelerrors}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1modelerrors}{modelerrors}} \&rhs);}
\DoxyCodeLine{604     \mbox{\hyperlink{classalglib_1_1modelerrors}{modelerrors}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1modelerrors}{modelerrors}} \&rhs);}
\DoxyCodeLine{605     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1modelerrors}{\string~modelerrors}}();}
\DoxyCodeLine{606     \textcolor{keywordtype}{double} \&relclserror;}
\DoxyCodeLine{607     \textcolor{keywordtype}{double} \&avgce;}
\DoxyCodeLine{608     \textcolor{keywordtype}{double} \&rmserror;}
\DoxyCodeLine{609     \textcolor{keywordtype}{double} \&avgerror;}
\DoxyCodeLine{610     \textcolor{keywordtype}{double} \&avgrelerror;}
\DoxyCodeLine{611 }
\DoxyCodeLine{612 \};}
\DoxyCodeLine{613 }
\DoxyCodeLine{614 }
\DoxyCodeLine{615 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{616 \textcolor{comment}{}}
\DoxyCodeLine{617 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{618 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__multilayerperceptron__owner}{\_multilayerperceptron\_owner}}}
\DoxyCodeLine{619 \{}
\DoxyCodeLine{620 \textcolor{keyword}{public}:}
\DoxyCodeLine{621     \mbox{\hyperlink{classalglib_1_1__multilayerperceptron__owner}{\_multilayerperceptron\_owner}}();}
\DoxyCodeLine{622     \mbox{\hyperlink{classalglib_1_1__multilayerperceptron__owner}{\_multilayerperceptron\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__multilayerperceptron__owner}{\_multilayerperceptron\_owner}} \&rhs);}
\DoxyCodeLine{623     \mbox{\hyperlink{classalglib_1_1__multilayerperceptron__owner}{\_multilayerperceptron\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__multilayerperceptron__owner}{\_multilayerperceptron\_owner}} \&rhs);}
\DoxyCodeLine{624     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__multilayerperceptron__owner}{\string~\_multilayerperceptron\_owner}}();}
\DoxyCodeLine{625     \mbox{\hyperlink{structalglib__impl_1_1multilayerperceptron}{alglib\_impl::multilayerperceptron}}* c\_ptr();}
\DoxyCodeLine{626     \mbox{\hyperlink{structalglib__impl_1_1multilayerperceptron}{alglib\_impl::multilayerperceptron}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{627 \textcolor{keyword}{protected}:}
\DoxyCodeLine{628     \mbox{\hyperlink{structalglib__impl_1_1multilayerperceptron}{alglib\_impl::multilayerperceptron}} *p\_struct;}
\DoxyCodeLine{629 \};}
\DoxyCodeLine{630 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__multilayerperceptron__owner}{\_multilayerperceptron\_owner}}}
\DoxyCodeLine{631 \{}
\DoxyCodeLine{632 \textcolor{keyword}{public}:}
\DoxyCodeLine{633     \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}}();}
\DoxyCodeLine{634     \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&rhs);}
\DoxyCodeLine{635     \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&rhs);}
\DoxyCodeLine{636     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{\string~multilayerperceptron}}();}
\DoxyCodeLine{637 }
\DoxyCodeLine{638 \};}
\DoxyCodeLine{639 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{640 }
\DoxyCodeLine{641 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_MLPE) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{642 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{643 \textcolor{comment}{Neural networks ensemble}}
\DoxyCodeLine{644 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{645 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__mlpensemble__owner}{\_mlpensemble\_owner}}}
\DoxyCodeLine{646 \{}
\DoxyCodeLine{647 \textcolor{keyword}{public}:}
\DoxyCodeLine{648     \mbox{\hyperlink{classalglib_1_1__mlpensemble__owner}{\_mlpensemble\_owner}}();}
\DoxyCodeLine{649     \mbox{\hyperlink{classalglib_1_1__mlpensemble__owner}{\_mlpensemble\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__mlpensemble__owner}{\_mlpensemble\_owner}} \&rhs);}
\DoxyCodeLine{650     \mbox{\hyperlink{classalglib_1_1__mlpensemble__owner}{\_mlpensemble\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__mlpensemble__owner}{\_mlpensemble\_owner}} \&rhs);}
\DoxyCodeLine{651     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__mlpensemble__owner}{\string~\_mlpensemble\_owner}}();}
\DoxyCodeLine{652     \mbox{\hyperlink{structalglib__impl_1_1mlpensemble}{alglib\_impl::mlpensemble}}* c\_ptr();}
\DoxyCodeLine{653     \mbox{\hyperlink{structalglib__impl_1_1mlpensemble}{alglib\_impl::mlpensemble}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{654 \textcolor{keyword}{protected}:}
\DoxyCodeLine{655     \mbox{\hyperlink{structalglib__impl_1_1mlpensemble}{alglib\_impl::mlpensemble}} *p\_struct;}
\DoxyCodeLine{656 \};}
\DoxyCodeLine{657 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__mlpensemble__owner}{\_mlpensemble\_owner}}}
\DoxyCodeLine{658 \{}
\DoxyCodeLine{659 \textcolor{keyword}{public}:}
\DoxyCodeLine{660     \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}}();}
\DoxyCodeLine{661     \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&rhs);}
\DoxyCodeLine{662     \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&rhs);}
\DoxyCodeLine{663     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1mlpensemble}{\string~mlpensemble}}();}
\DoxyCodeLine{664 }
\DoxyCodeLine{665 \};}
\DoxyCodeLine{666 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{667 }
\DoxyCodeLine{668 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_CLUSTERING) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{669 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{670 \textcolor{comment}{This structure is a clusterization engine.}}
\DoxyCodeLine{671 \textcolor{comment}{}}
\DoxyCodeLine{672 \textcolor{comment}{You should not try to access its fields directly.}}
\DoxyCodeLine{673 \textcolor{comment}{Use ALGLIB functions in order to work with this object.}}
\DoxyCodeLine{674 \textcolor{comment}{}}
\DoxyCodeLine{675 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{676 \textcolor{comment}{     Copyright 10.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{677 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{678 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__clusterizerstate__owner}{\_clusterizerstate\_owner}}}
\DoxyCodeLine{679 \{}
\DoxyCodeLine{680 \textcolor{keyword}{public}:}
\DoxyCodeLine{681     \mbox{\hyperlink{classalglib_1_1__clusterizerstate__owner}{\_clusterizerstate\_owner}}();}
\DoxyCodeLine{682     \mbox{\hyperlink{classalglib_1_1__clusterizerstate__owner}{\_clusterizerstate\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__clusterizerstate__owner}{\_clusterizerstate\_owner}} \&rhs);}
\DoxyCodeLine{683     \mbox{\hyperlink{classalglib_1_1__clusterizerstate__owner}{\_clusterizerstate\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__clusterizerstate__owner}{\_clusterizerstate\_owner}} \&rhs);}
\DoxyCodeLine{684     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__clusterizerstate__owner}{\string~\_clusterizerstate\_owner}}();}
\DoxyCodeLine{685     \mbox{\hyperlink{structalglib__impl_1_1clusterizerstate}{alglib\_impl::clusterizerstate}}* c\_ptr();}
\DoxyCodeLine{686     \mbox{\hyperlink{structalglib__impl_1_1clusterizerstate}{alglib\_impl::clusterizerstate}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{687 \textcolor{keyword}{protected}:}
\DoxyCodeLine{688     \mbox{\hyperlink{structalglib__impl_1_1clusterizerstate}{alglib\_impl::clusterizerstate}} *p\_struct;}
\DoxyCodeLine{689 \};}
\DoxyCodeLine{690 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__clusterizerstate__owner}{\_clusterizerstate\_owner}}}
\DoxyCodeLine{691 \{}
\DoxyCodeLine{692 \textcolor{keyword}{public}:}
\DoxyCodeLine{693     \mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}}();}
\DoxyCodeLine{694     \mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}} \&rhs);}
\DoxyCodeLine{695     \mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}} \&rhs);}
\DoxyCodeLine{696     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1clusterizerstate}{\string~clusterizerstate}}();}
\DoxyCodeLine{697 }
\DoxyCodeLine{698 \};}
\DoxyCodeLine{699 }
\DoxyCodeLine{700 }
\DoxyCodeLine{701 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{702 \textcolor{comment}{This structure  is used to store results of the agglomerative hierarchical}}
\DoxyCodeLine{703 \textcolor{comment}{clustering (AHC).}}
\DoxyCodeLine{704 \textcolor{comment}{}}
\DoxyCodeLine{705 \textcolor{comment}{Following information is returned:}}
\DoxyCodeLine{706 \textcolor{comment}{}}
\DoxyCodeLine{707 \textcolor{comment}{* TerminationType -\/ completion code:}}
\DoxyCodeLine{708 \textcolor{comment}{  * 1   for successful completion of algorithm}}
\DoxyCodeLine{709 \textcolor{comment}{  * -\/5  inappropriate combination of  clustering  algorithm  and  distance}}
\DoxyCodeLine{710 \textcolor{comment}{        function was used. As for now, it  is  possible  only when  Ward's}}
\DoxyCodeLine{711 \textcolor{comment}{        method is called for dataset with non-\/Euclidean distance function.}}
\DoxyCodeLine{712 \textcolor{comment}{  In case negative completion code is returned,  other  fields  of  report}}
\DoxyCodeLine{713 \textcolor{comment}{  structure are invalid and should not be used.}}
\DoxyCodeLine{714 \textcolor{comment}{}}
\DoxyCodeLine{715 \textcolor{comment}{* NPoints contains number of points in the original dataset}}
\DoxyCodeLine{716 \textcolor{comment}{}}
\DoxyCodeLine{717 \textcolor{comment}{* Z contains information about merges performed  (see below).  Z  contains}}
\DoxyCodeLine{718 \textcolor{comment}{  indexes from the original (unsorted) dataset and it can be used when you}}
\DoxyCodeLine{719 \textcolor{comment}{  need to know what points were merged. However, it is not convenient when}}
\DoxyCodeLine{720 \textcolor{comment}{  you want to build a dendrograd (see below).}}
\DoxyCodeLine{721 \textcolor{comment}{}}
\DoxyCodeLine{722 \textcolor{comment}{* if  you  want  to  build  dendrogram, you  can use Z, but it is not good}}
\DoxyCodeLine{723 \textcolor{comment}{  option, because Z contains  indexes from  unsorted  dataset.  Dendrogram}}
\DoxyCodeLine{724 \textcolor{comment}{  built from such dataset is likely to have intersections. So, you have to}}
\DoxyCodeLine{725 \textcolor{comment}{  reorder you points before building dendrogram.}}
\DoxyCodeLine{726 \textcolor{comment}{  Permutation which reorders point is returned in P. Another representation}}
\DoxyCodeLine{727 \textcolor{comment}{  of  merges,  which  is  more  convenient for dendorgram construction, is}}
\DoxyCodeLine{728 \textcolor{comment}{  returned in PM.}}
\DoxyCodeLine{729 \textcolor{comment}{}}
\DoxyCodeLine{730 \textcolor{comment}{* more information on format of Z, P and PM can be found below and in the}}
\DoxyCodeLine{731 \textcolor{comment}{  examples from ALGLIB Reference Manual.}}
\DoxyCodeLine{732 \textcolor{comment}{}}
\DoxyCodeLine{733 \textcolor{comment}{FORMAL DESCRIPTION OF FIELDS:}}
\DoxyCodeLine{734 \textcolor{comment}{    NPoints         number of points}}
\DoxyCodeLine{735 \textcolor{comment}{    Z               array[NPoints-\/1,2],  contains   indexes   of  clusters}}
\DoxyCodeLine{736 \textcolor{comment}{                    linked in pairs to  form  clustering  tree.  I-\/th  row}}
\DoxyCodeLine{737 \textcolor{comment}{                    corresponds to I-\/th merge:}}
\DoxyCodeLine{738 \textcolor{comment}{                    * Z[I,0] -\/ index of the first cluster to merge}}
\DoxyCodeLine{739 \textcolor{comment}{                    * Z[I,1] -\/ index of the second cluster to merge}}
\DoxyCodeLine{740 \textcolor{comment}{                    * Z[I,0]<Z[I,1]}}
\DoxyCodeLine{741 \textcolor{comment}{                    * clusters are  numbered  from 0 to 2*NPoints-\/2,  with}}
\DoxyCodeLine{742 \textcolor{comment}{                      indexes from 0 to NPoints-\/1 corresponding to  points}}
\DoxyCodeLine{743 \textcolor{comment}{                      of the original dataset, and indexes from NPoints to}}
\DoxyCodeLine{744 \textcolor{comment}{                      2*NPoints-\/2  correspond  to  clusters  generated  by}}
\DoxyCodeLine{745 \textcolor{comment}{                      subsequent  merges  (I-\/th  row  of Z creates cluster}}
\DoxyCodeLine{746 \textcolor{comment}{                      with index NPoints+I).}}
\DoxyCodeLine{747 \textcolor{comment}{}}
\DoxyCodeLine{748 \textcolor{comment}{                    IMPORTANT: indexes in Z[] are indexes in the ORIGINAL,}}
\DoxyCodeLine{749 \textcolor{comment}{                    unsorted dataset. In addition to  Z algorithm  outputs}}
\DoxyCodeLine{750 \textcolor{comment}{                    permutation which rearranges points in such  way  that}}
\DoxyCodeLine{751 \textcolor{comment}{                    subsequent merges are  performed  on  adjacent  points}}
\DoxyCodeLine{752 \textcolor{comment}{                    (such order is needed if you want to build dendrogram).}}
\DoxyCodeLine{753 \textcolor{comment}{                    However,  indexes  in  Z  are  related  to   original,}}
\DoxyCodeLine{754 \textcolor{comment}{                    unrearranged sequence of points.}}
\DoxyCodeLine{755 \textcolor{comment}{}}
\DoxyCodeLine{756 \textcolor{comment}{    P               array[NPoints], permutation which reorders points  for}}
\DoxyCodeLine{757 \textcolor{comment}{                    dendrogram  construction.  P[i] contains  index of the}}
\DoxyCodeLine{758 \textcolor{comment}{                    position  where  we  should  move  I-\/th  point  of the}}
\DoxyCodeLine{759 \textcolor{comment}{                    original dataset in order to apply merges PZ/PM.}}
\DoxyCodeLine{760 \textcolor{comment}{}}
\DoxyCodeLine{761 \textcolor{comment}{    PZ              same as Z, but for permutation of points given  by  P.}}
\DoxyCodeLine{762 \textcolor{comment}{                    The  only  thing  which  changed  are  indexes  of the}}
\DoxyCodeLine{763 \textcolor{comment}{                    original points; indexes of clusters remained same.}}
\DoxyCodeLine{764 \textcolor{comment}{}}
\DoxyCodeLine{765 \textcolor{comment}{    MergeDist       array[NPoints-\/1], contains distances between  clusters}}
\DoxyCodeLine{766 \textcolor{comment}{                    being merged (MergeDist[i] correspond to merge  stored}}
\DoxyCodeLine{767 \textcolor{comment}{                    in Z[i,...]):}}
\DoxyCodeLine{768 \textcolor{comment}{                    * CLINK, SLINK and  average  linkage algorithms report}}
\DoxyCodeLine{769 \textcolor{comment}{                      "{}raw"{}, unmodified distance metric.}}
\DoxyCodeLine{770 \textcolor{comment}{                    * Ward's   method   reports   weighted   intra-\/cluster}}
\DoxyCodeLine{771 \textcolor{comment}{                      variance, which is equal to ||Ca-\/Cb||\string^2 * Sa*Sb/(Sa+Sb).}}
\DoxyCodeLine{772 \textcolor{comment}{                      Here  A  and  B  are  clusters being merged, Ca is a}}
\DoxyCodeLine{773 \textcolor{comment}{                      center of A, Cb is a center of B, Sa is a size of A,}}
\DoxyCodeLine{774 \textcolor{comment}{                      Sb is a size of B.}}
\DoxyCodeLine{775 \textcolor{comment}{}}
\DoxyCodeLine{776 \textcolor{comment}{    PM              array[NPoints-\/1,6], another representation of  merges,}}
\DoxyCodeLine{777 \textcolor{comment}{                    which is suited for dendrogram construction. It  deals}}
\DoxyCodeLine{778 \textcolor{comment}{                    with rearranged points (permutation P is applied)  and}}
\DoxyCodeLine{779 \textcolor{comment}{                    represents merges in a form which different  from  one}}
\DoxyCodeLine{780 \textcolor{comment}{                    used by Z.}}
\DoxyCodeLine{781 \textcolor{comment}{                    For each I from 0 to NPoints-\/2, I-\/th row of PM represents}}
\DoxyCodeLine{782 \textcolor{comment}{                    merge performed on two clusters C0 and C1. Here:}}
\DoxyCodeLine{783 \textcolor{comment}{                    * C0 contains points with indexes PM[I,0]...PM[I,1]}}
\DoxyCodeLine{784 \textcolor{comment}{                    * C1 contains points with indexes PM[I,2]...PM[I,3]}}
\DoxyCodeLine{785 \textcolor{comment}{                    * indexes stored in PM are given for dataset sorted}}
\DoxyCodeLine{786 \textcolor{comment}{                      according to permutation P}}
\DoxyCodeLine{787 \textcolor{comment}{                    * PM[I,1]=PM[I,2]-\/1 (only adjacent clusters are merged)}}
\DoxyCodeLine{788 \textcolor{comment}{                    * PM[I,0]<=PM[I,1], PM[I,2]<=PM[I,3], i.e. both}}
\DoxyCodeLine{789 \textcolor{comment}{                      clusters contain at least one point}}
\DoxyCodeLine{790 \textcolor{comment}{                    * heights of "{}subdendrograms"{} corresponding  to  C0/C1}}
\DoxyCodeLine{791 \textcolor{comment}{                      are stored in PM[I,4]  and  PM[I,5].  Subdendrograms}}
\DoxyCodeLine{792 \textcolor{comment}{                      corresponding   to   single-\/point   clusters    have}}
\DoxyCodeLine{793 \textcolor{comment}{                      height=0. Dendrogram of the merge result has  height}}
\DoxyCodeLine{794 \textcolor{comment}{                      H=max(H0,H1)+1.}}
\DoxyCodeLine{795 \textcolor{comment}{}}
\DoxyCodeLine{796 \textcolor{comment}{NOTE: there is one-\/to-\/one correspondence between merges described by Z and}}
\DoxyCodeLine{797 \textcolor{comment}{      PM. I-\/th row of Z describes same merge of clusters as I-\/th row of PM,}}
\DoxyCodeLine{798 \textcolor{comment}{      with "{}left"{} cluster from Z corresponding to the "{}left"{} one from PM.}}
\DoxyCodeLine{799 \textcolor{comment}{}}
\DoxyCodeLine{800 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{801 \textcolor{comment}{     Copyright 10.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{802 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{803 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__ahcreport__owner}{\_ahcreport\_owner}}}
\DoxyCodeLine{804 \{}
\DoxyCodeLine{805 \textcolor{keyword}{public}:}
\DoxyCodeLine{806     \mbox{\hyperlink{classalglib_1_1__ahcreport__owner}{\_ahcreport\_owner}}();}
\DoxyCodeLine{807     \mbox{\hyperlink{classalglib_1_1__ahcreport__owner}{\_ahcreport\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__ahcreport__owner}{\_ahcreport\_owner}} \&rhs);}
\DoxyCodeLine{808     \mbox{\hyperlink{classalglib_1_1__ahcreport__owner}{\_ahcreport\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__ahcreport__owner}{\_ahcreport\_owner}} \&rhs);}
\DoxyCodeLine{809     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__ahcreport__owner}{\string~\_ahcreport\_owner}}();}
\DoxyCodeLine{810     \mbox{\hyperlink{structalglib__impl_1_1ahcreport}{alglib\_impl::ahcreport}}* c\_ptr();}
\DoxyCodeLine{811     \mbox{\hyperlink{structalglib__impl_1_1ahcreport}{alglib\_impl::ahcreport}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{812 \textcolor{keyword}{protected}:}
\DoxyCodeLine{813     \mbox{\hyperlink{structalglib__impl_1_1ahcreport}{alglib\_impl::ahcreport}} *p\_struct;}
\DoxyCodeLine{814 \};}
\DoxyCodeLine{815 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1ahcreport}{ahcreport}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__ahcreport__owner}{\_ahcreport\_owner}}}
\DoxyCodeLine{816 \{}
\DoxyCodeLine{817 \textcolor{keyword}{public}:}
\DoxyCodeLine{818     \mbox{\hyperlink{classalglib_1_1ahcreport}{ahcreport}}();}
\DoxyCodeLine{819     \mbox{\hyperlink{classalglib_1_1ahcreport}{ahcreport}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ahcreport}{ahcreport}} \&rhs);}
\DoxyCodeLine{820     \mbox{\hyperlink{classalglib_1_1ahcreport}{ahcreport}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ahcreport}{ahcreport}} \&rhs);}
\DoxyCodeLine{821     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1ahcreport}{\string~ahcreport}}();}
\DoxyCodeLine{822     ae\_int\_t \&terminationtype;}
\DoxyCodeLine{823     ae\_int\_t \&npoints;}
\DoxyCodeLine{824     \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} p;}
\DoxyCodeLine{825     \mbox{\hyperlink{classalglib_1_1integer__2d__array}{integer\_2d\_array}} z;}
\DoxyCodeLine{826     \mbox{\hyperlink{classalglib_1_1integer__2d__array}{integer\_2d\_array}} pz;}
\DoxyCodeLine{827     \mbox{\hyperlink{classalglib_1_1integer__2d__array}{integer\_2d\_array}} pm;}
\DoxyCodeLine{828     \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} mergedist;}
\DoxyCodeLine{829 }
\DoxyCodeLine{830 \};}
\DoxyCodeLine{831 }
\DoxyCodeLine{832 }
\DoxyCodeLine{833 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{834 \textcolor{comment}{This  structure   is  used  to  store  results of the  k-\/means  clustering}}
\DoxyCodeLine{835 \textcolor{comment}{algorithm.}}
\DoxyCodeLine{836 \textcolor{comment}{}}
\DoxyCodeLine{837 \textcolor{comment}{Following information is always returned:}}
\DoxyCodeLine{838 \textcolor{comment}{* NPoints contains number of points in the original dataset}}
\DoxyCodeLine{839 \textcolor{comment}{* TerminationType contains completion code, negative on failure, positive}}
\DoxyCodeLine{840 \textcolor{comment}{  on success}}
\DoxyCodeLine{841 \textcolor{comment}{* K contains number of clusters}}
\DoxyCodeLine{842 \textcolor{comment}{}}
\DoxyCodeLine{843 \textcolor{comment}{For positive TerminationType we return:}}
\DoxyCodeLine{844 \textcolor{comment}{* NFeatures contains number of variables in the original dataset}}
\DoxyCodeLine{845 \textcolor{comment}{* C, which contains centers found by algorithm}}
\DoxyCodeLine{846 \textcolor{comment}{* CIdx, which maps points of the original dataset to clusters}}
\DoxyCodeLine{847 \textcolor{comment}{}}
\DoxyCodeLine{848 \textcolor{comment}{FORMAL DESCRIPTION OF FIELDS:}}
\DoxyCodeLine{849 \textcolor{comment}{    NPoints         number of points, >=0}}
\DoxyCodeLine{850 \textcolor{comment}{    NFeatures       number of variables, >=1}}
\DoxyCodeLine{851 \textcolor{comment}{    TerminationType completion code:}}
\DoxyCodeLine{852 \textcolor{comment}{                    * -\/5 if  distance  type  is  anything  different  from}}
\DoxyCodeLine{853 \textcolor{comment}{                         Euclidean metric}}
\DoxyCodeLine{854 \textcolor{comment}{                    * -\/3 for degenerate dataset: a) less  than  K  distinct}}
\DoxyCodeLine{855 \textcolor{comment}{                         points, b) K=0 for non-\/empty dataset.}}
\DoxyCodeLine{856 \textcolor{comment}{                    * +1 for successful completion}}
\DoxyCodeLine{857 \textcolor{comment}{    K               number of clusters}}
\DoxyCodeLine{858 \textcolor{comment}{    C               array[K,NFeatures], rows of the array store centers}}
\DoxyCodeLine{859 \textcolor{comment}{    CIdx            array[NPoints], which contains cluster indexes}}
\DoxyCodeLine{860 \textcolor{comment}{    IterationsCount actual number of iterations performed by clusterizer.}}
\DoxyCodeLine{861 \textcolor{comment}{                    If algorithm performed more than one random restart,}}
\DoxyCodeLine{862 \textcolor{comment}{                    total number of iterations is returned.}}
\DoxyCodeLine{863 \textcolor{comment}{    Energy          merit function, "{}energy"{}, sum  of  squared  deviations}}
\DoxyCodeLine{864 \textcolor{comment}{                    from cluster centers}}
\DoxyCodeLine{865 \textcolor{comment}{}}
\DoxyCodeLine{866 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{867 \textcolor{comment}{     Copyright 27.11.2012 by Bochkanov Sergey}}
\DoxyCodeLine{868 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{869 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__kmeansreport__owner}{\_kmeansreport\_owner}}}
\DoxyCodeLine{870 \{}
\DoxyCodeLine{871 \textcolor{keyword}{public}:}
\DoxyCodeLine{872     \mbox{\hyperlink{classalglib_1_1__kmeansreport__owner}{\_kmeansreport\_owner}}();}
\DoxyCodeLine{873     \mbox{\hyperlink{classalglib_1_1__kmeansreport__owner}{\_kmeansreport\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__kmeansreport__owner}{\_kmeansreport\_owner}} \&rhs);}
\DoxyCodeLine{874     \mbox{\hyperlink{classalglib_1_1__kmeansreport__owner}{\_kmeansreport\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__kmeansreport__owner}{\_kmeansreport\_owner}} \&rhs);}
\DoxyCodeLine{875     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__kmeansreport__owner}{\string~\_kmeansreport\_owner}}();}
\DoxyCodeLine{876     \mbox{\hyperlink{structalglib__impl_1_1kmeansreport}{alglib\_impl::kmeansreport}}* c\_ptr();}
\DoxyCodeLine{877     \mbox{\hyperlink{structalglib__impl_1_1kmeansreport}{alglib\_impl::kmeansreport}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{878 \textcolor{keyword}{protected}:}
\DoxyCodeLine{879     \mbox{\hyperlink{structalglib__impl_1_1kmeansreport}{alglib\_impl::kmeansreport}} *p\_struct;}
\DoxyCodeLine{880 \};}
\DoxyCodeLine{881 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1kmeansreport}{kmeansreport}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__kmeansreport__owner}{\_kmeansreport\_owner}}}
\DoxyCodeLine{882 \{}
\DoxyCodeLine{883 \textcolor{keyword}{public}:}
\DoxyCodeLine{884     \mbox{\hyperlink{classalglib_1_1kmeansreport}{kmeansreport}}();}
\DoxyCodeLine{885     \mbox{\hyperlink{classalglib_1_1kmeansreport}{kmeansreport}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1kmeansreport}{kmeansreport}} \&rhs);}
\DoxyCodeLine{886     \mbox{\hyperlink{classalglib_1_1kmeansreport}{kmeansreport}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1kmeansreport}{kmeansreport}} \&rhs);}
\DoxyCodeLine{887     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1kmeansreport}{\string~kmeansreport}}();}
\DoxyCodeLine{888     ae\_int\_t \&npoints;}
\DoxyCodeLine{889     ae\_int\_t \&nfeatures;}
\DoxyCodeLine{890     ae\_int\_t \&terminationtype;}
\DoxyCodeLine{891     ae\_int\_t \&iterationscount;}
\DoxyCodeLine{892     \textcolor{keywordtype}{double} \&energy;}
\DoxyCodeLine{893     ae\_int\_t \&k;}
\DoxyCodeLine{894     \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} c;}
\DoxyCodeLine{895     \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} cidx;}
\DoxyCodeLine{896 }
\DoxyCodeLine{897 \};}
\DoxyCodeLine{898 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{899 }
\DoxyCodeLine{900 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_DFOREST) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{901 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{902 \textcolor{comment}{A random forest (decision forest) builder object.}}
\DoxyCodeLine{903 \textcolor{comment}{}}
\DoxyCodeLine{904 \textcolor{comment}{Used to store dataset and specify decision forest training algorithm settings.}}
\DoxyCodeLine{905 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{906 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__decisionforestbuilder__owner}{\_decisionforestbuilder\_owner}}}
\DoxyCodeLine{907 \{}
\DoxyCodeLine{908 \textcolor{keyword}{public}:}
\DoxyCodeLine{909     \mbox{\hyperlink{classalglib_1_1__decisionforestbuilder__owner}{\_decisionforestbuilder\_owner}}();}
\DoxyCodeLine{910     \mbox{\hyperlink{classalglib_1_1__decisionforestbuilder__owner}{\_decisionforestbuilder\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__decisionforestbuilder__owner}{\_decisionforestbuilder\_owner}} \&rhs);}
\DoxyCodeLine{911     \mbox{\hyperlink{classalglib_1_1__decisionforestbuilder__owner}{\_decisionforestbuilder\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__decisionforestbuilder__owner}{\_decisionforestbuilder\_owner}} \&rhs);}
\DoxyCodeLine{912     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__decisionforestbuilder__owner}{\string~\_decisionforestbuilder\_owner}}();}
\DoxyCodeLine{913     \mbox{\hyperlink{structalglib__impl_1_1decisionforestbuilder}{alglib\_impl::decisionforestbuilder}}* c\_ptr();}
\DoxyCodeLine{914     \mbox{\hyperlink{structalglib__impl_1_1decisionforestbuilder}{alglib\_impl::decisionforestbuilder}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{915 \textcolor{keyword}{protected}:}
\DoxyCodeLine{916     \mbox{\hyperlink{structalglib__impl_1_1decisionforestbuilder}{alglib\_impl::decisionforestbuilder}} *p\_struct;}
\DoxyCodeLine{917 \};}
\DoxyCodeLine{918 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__decisionforestbuilder__owner}{\_decisionforestbuilder\_owner}}}
\DoxyCodeLine{919 \{}
\DoxyCodeLine{920 \textcolor{keyword}{public}:}
\DoxyCodeLine{921     \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}}();}
\DoxyCodeLine{922     \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&rhs);}
\DoxyCodeLine{923     \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&rhs);}
\DoxyCodeLine{924     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{\string~decisionforestbuilder}}();}
\DoxyCodeLine{925 }
\DoxyCodeLine{926 \};}
\DoxyCodeLine{927 }
\DoxyCodeLine{928 }
\DoxyCodeLine{929 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{930 \textcolor{comment}{Buffer object which is used to perform  various  requests  (usually  model}}
\DoxyCodeLine{931 \textcolor{comment}{inference) in the multithreaded mode (multiple threads working  with  same}}
\DoxyCodeLine{932 \textcolor{comment}{DF object).}}
\DoxyCodeLine{933 \textcolor{comment}{}}
\DoxyCodeLine{934 \textcolor{comment}{This object should be created with DFCreateBuffer().}}
\DoxyCodeLine{935 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{936 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__decisionforestbuffer__owner}{\_decisionforestbuffer\_owner}}}
\DoxyCodeLine{937 \{}
\DoxyCodeLine{938 \textcolor{keyword}{public}:}
\DoxyCodeLine{939     \mbox{\hyperlink{classalglib_1_1__decisionforestbuffer__owner}{\_decisionforestbuffer\_owner}}();}
\DoxyCodeLine{940     \mbox{\hyperlink{classalglib_1_1__decisionforestbuffer__owner}{\_decisionforestbuffer\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__decisionforestbuffer__owner}{\_decisionforestbuffer\_owner}} \&rhs);}
\DoxyCodeLine{941     \mbox{\hyperlink{classalglib_1_1__decisionforestbuffer__owner}{\_decisionforestbuffer\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__decisionforestbuffer__owner}{\_decisionforestbuffer\_owner}} \&rhs);}
\DoxyCodeLine{942     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__decisionforestbuffer__owner}{\string~\_decisionforestbuffer\_owner}}();}
\DoxyCodeLine{943     \mbox{\hyperlink{structalglib__impl_1_1decisionforestbuffer}{alglib\_impl::decisionforestbuffer}}* c\_ptr();}
\DoxyCodeLine{944     \mbox{\hyperlink{structalglib__impl_1_1decisionforestbuffer}{alglib\_impl::decisionforestbuffer}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{945 \textcolor{keyword}{protected}:}
\DoxyCodeLine{946     \mbox{\hyperlink{structalglib__impl_1_1decisionforestbuffer}{alglib\_impl::decisionforestbuffer}} *p\_struct;}
\DoxyCodeLine{947 \};}
\DoxyCodeLine{948 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1decisionforestbuffer}{decisionforestbuffer}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__decisionforestbuffer__owner}{\_decisionforestbuffer\_owner}}}
\DoxyCodeLine{949 \{}
\DoxyCodeLine{950 \textcolor{keyword}{public}:}
\DoxyCodeLine{951     \mbox{\hyperlink{classalglib_1_1decisionforestbuffer}{decisionforestbuffer}}();}
\DoxyCodeLine{952     \mbox{\hyperlink{classalglib_1_1decisionforestbuffer}{decisionforestbuffer}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuffer}{decisionforestbuffer}} \&rhs);}
\DoxyCodeLine{953     \mbox{\hyperlink{classalglib_1_1decisionforestbuffer}{decisionforestbuffer}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuffer}{decisionforestbuffer}} \&rhs);}
\DoxyCodeLine{954     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1decisionforestbuffer}{\string~decisionforestbuffer}}();}
\DoxyCodeLine{955 }
\DoxyCodeLine{956 \};}
\DoxyCodeLine{957 }
\DoxyCodeLine{958 }
\DoxyCodeLine{959 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{960 \textcolor{comment}{Decision forest (random forest) model.}}
\DoxyCodeLine{961 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{962 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__decisionforest__owner}{\_decisionforest\_owner}}}
\DoxyCodeLine{963 \{}
\DoxyCodeLine{964 \textcolor{keyword}{public}:}
\DoxyCodeLine{965     \mbox{\hyperlink{classalglib_1_1__decisionforest__owner}{\_decisionforest\_owner}}();}
\DoxyCodeLine{966     \mbox{\hyperlink{classalglib_1_1__decisionforest__owner}{\_decisionforest\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__decisionforest__owner}{\_decisionforest\_owner}} \&rhs);}
\DoxyCodeLine{967     \mbox{\hyperlink{classalglib_1_1__decisionforest__owner}{\_decisionforest\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__decisionforest__owner}{\_decisionforest\_owner}} \&rhs);}
\DoxyCodeLine{968     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__decisionforest__owner}{\string~\_decisionforest\_owner}}();}
\DoxyCodeLine{969     \mbox{\hyperlink{structalglib__impl_1_1decisionforest}{alglib\_impl::decisionforest}}* c\_ptr();}
\DoxyCodeLine{970     \mbox{\hyperlink{structalglib__impl_1_1decisionforest}{alglib\_impl::decisionforest}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{971 \textcolor{keyword}{protected}:}
\DoxyCodeLine{972     \mbox{\hyperlink{structalglib__impl_1_1decisionforest}{alglib\_impl::decisionforest}} *p\_struct;}
\DoxyCodeLine{973 \};}
\DoxyCodeLine{974 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__decisionforest__owner}{\_decisionforest\_owner}}}
\DoxyCodeLine{975 \{}
\DoxyCodeLine{976 \textcolor{keyword}{public}:}
\DoxyCodeLine{977     \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}}();}
\DoxyCodeLine{978     \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&rhs);}
\DoxyCodeLine{979     \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&rhs);}
\DoxyCodeLine{980     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1decisionforest}{\string~decisionforest}}();}
\DoxyCodeLine{981 }
\DoxyCodeLine{982 \};}
\DoxyCodeLine{983 }
\DoxyCodeLine{984 }
\DoxyCodeLine{985 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{986 \textcolor{comment}{Decision forest training report.}}
\DoxyCodeLine{987 \textcolor{comment}{}}
\DoxyCodeLine{988 \textcolor{comment}{=== training/oob errors ==================================================}}
\DoxyCodeLine{989 \textcolor{comment}{}}
\DoxyCodeLine{990 \textcolor{comment}{Following fields store training set errors:}}
\DoxyCodeLine{991 \textcolor{comment}{* relclserror           -\/   fraction of misclassified cases, [0,1]}}
\DoxyCodeLine{992 \textcolor{comment}{* avgce                 -\/   average cross-\/entropy in bits per symbol}}
\DoxyCodeLine{993 \textcolor{comment}{* rmserror              -\/   root-\/mean-\/square error}}
\DoxyCodeLine{994 \textcolor{comment}{* avgerror              -\/   average error}}
\DoxyCodeLine{995 \textcolor{comment}{* avgrelerror           -\/   average relative error}}
\DoxyCodeLine{996 \textcolor{comment}{}}
\DoxyCodeLine{997 \textcolor{comment}{Out-\/of-\/bag estimates are stored in fields with same names, but "{}oob"{} prefix.}}
\DoxyCodeLine{998 \textcolor{comment}{}}
\DoxyCodeLine{999 \textcolor{comment}{For classification problems:}}
\DoxyCodeLine{1000 \textcolor{comment}{* RMS, AVG and AVGREL errors are calculated for posterior probabilities}}
\DoxyCodeLine{1001 \textcolor{comment}{}}
\DoxyCodeLine{1002 \textcolor{comment}{For regression problems:}}
\DoxyCodeLine{1003 \textcolor{comment}{* RELCLS and AVGCE errors are zero}}
\DoxyCodeLine{1004 \textcolor{comment}{}}
\DoxyCodeLine{1005 \textcolor{comment}{=== variable importance ==================================================}}
\DoxyCodeLine{1006 \textcolor{comment}{}}
\DoxyCodeLine{1007 \textcolor{comment}{Following fields are used to store variable importance information:}}
\DoxyCodeLine{1008 \textcolor{comment}{}}
\DoxyCodeLine{1009 \textcolor{comment}{* topvars               -\/   variables ordered from the most  important  to}}
\DoxyCodeLine{1010 \textcolor{comment}{                            less  important  ones  (according  to  current}}
\DoxyCodeLine{1011 \textcolor{comment}{                            choice of importance raiting).}}
\DoxyCodeLine{1012 \textcolor{comment}{                            For example, topvars[0] contains index of  the}}
\DoxyCodeLine{1013 \textcolor{comment}{                            most important variable, and topvars[0:2]  are}}
\DoxyCodeLine{1014 \textcolor{comment}{                            indexes of 3 most important ones and so on.}}
\DoxyCodeLine{1015 \textcolor{comment}{}}
\DoxyCodeLine{1016 \textcolor{comment}{* varimportances        -\/   array[nvars], ratings (the  larger,  the  more}}
\DoxyCodeLine{1017 \textcolor{comment}{                            important the variable  is,  always  in  [0,1]}}
\DoxyCodeLine{1018 \textcolor{comment}{                            range).}}
\DoxyCodeLine{1019 \textcolor{comment}{                            By default, filled  by  zeros  (no  importance}}
\DoxyCodeLine{1020 \textcolor{comment}{                            ratings are  provided  unless  you  explicitly}}
\DoxyCodeLine{1021 \textcolor{comment}{                            request them).}}
\DoxyCodeLine{1022 \textcolor{comment}{                            Zero rating means that variable is not important,}}
\DoxyCodeLine{1023 \textcolor{comment}{                            however you will rarely encounter such a thing,}}
\DoxyCodeLine{1024 \textcolor{comment}{                            in many cases  unimportant  variables  produce}}
\DoxyCodeLine{1025 \textcolor{comment}{                            nearly-\/zero (but nonzero) ratings.}}
\DoxyCodeLine{1026 \textcolor{comment}{}}
\DoxyCodeLine{1027 \textcolor{comment}{Variable importance report must be EXPLICITLY requested by calling:}}
\DoxyCodeLine{1028 \textcolor{comment}{* dfbuildersetimportancegini() function, if you need out-\/of-\/bag Gini-\/based}}
\DoxyCodeLine{1029 \textcolor{comment}{  importance rating also known as MDI  (fast to  calculate,  resistant  to}}
\DoxyCodeLine{1030 \textcolor{comment}{  overfitting  issues,   but   has   some   bias  towards  continuous  and}}
\DoxyCodeLine{1031 \textcolor{comment}{  high-\/cardinality categorical variables)}}
\DoxyCodeLine{1032 \textcolor{comment}{* dfbuildersetimportancetrngini() function, if you need training set Gini-\/}}
\DoxyCodeLine{1033 \textcolor{comment}{  -\/based importance rating (what other packages typically report).}}
\DoxyCodeLine{1034 \textcolor{comment}{* dfbuildersetimportancepermutation() function, if you  need  permutation-\/}}
\DoxyCodeLine{1035 \textcolor{comment}{  based importance rating also known as MDA (slower to calculate, but less}}
\DoxyCodeLine{1036 \textcolor{comment}{  biased)}}
\DoxyCodeLine{1037 \textcolor{comment}{* dfbuildersetimportancenone() function,  if  you  do  not  need  importance}}
\DoxyCodeLine{1038 \textcolor{comment}{  ratings -\/ ratings will be zero, topvars[] will be [0,1,2,...]}}
\DoxyCodeLine{1039 \textcolor{comment}{}}
\DoxyCodeLine{1040 \textcolor{comment}{Different importance ratings (Gini or permutation) produce  non-\/comparable}}
\DoxyCodeLine{1041 \textcolor{comment}{values. Although in all cases rating values lie in [0,1] range, there  are}}
\DoxyCodeLine{1042 \textcolor{comment}{exist differences:}}
\DoxyCodeLine{1043 \textcolor{comment}{* informally speaking, Gini importance rating tends to divide "{}unit amount}}
\DoxyCodeLine{1044 \textcolor{comment}{  of importance"{}  between  several  important  variables, i.e. it produces}}
\DoxyCodeLine{1045 \textcolor{comment}{  estimates which roughly sum to 1.0 (or less than 1.0, if your  task  can}}
\DoxyCodeLine{1046 \textcolor{comment}{  not be solved exactly). If all variables  are  equally  important,  they}}
\DoxyCodeLine{1047 \textcolor{comment}{  will have same rating,  roughly  1/NVars,  even  if  every  variable  is}}
\DoxyCodeLine{1048 \textcolor{comment}{  critically important.}}
\DoxyCodeLine{1049 \textcolor{comment}{* from the other side, permutation importance tells us what percentage  of}}
\DoxyCodeLine{1050 \textcolor{comment}{  the model predictive power will be ruined  by  permuting  this  specific}}
\DoxyCodeLine{1051 \textcolor{comment}{  variable. It does not produce estimates which  sum  to  one.  Critically}}
\DoxyCodeLine{1052 \textcolor{comment}{  important variable will have rating close  to  1.0,  and  you  may  have}}
\DoxyCodeLine{1053 \textcolor{comment}{  multiple variables with such a rating.}}
\DoxyCodeLine{1054 \textcolor{comment}{}}
\DoxyCodeLine{1055 \textcolor{comment}{More information on variable importance ratings can be found  in  comments}}
\DoxyCodeLine{1056 \textcolor{comment}{on the dfbuildersetimportancegini() and dfbuildersetimportancepermutation()}}
\DoxyCodeLine{1057 \textcolor{comment}{functions.}}
\DoxyCodeLine{1058 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1059 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__dfreport__owner}{\_dfreport\_owner}}}
\DoxyCodeLine{1060 \{}
\DoxyCodeLine{1061 \textcolor{keyword}{public}:}
\DoxyCodeLine{1062     \mbox{\hyperlink{classalglib_1_1__dfreport__owner}{\_dfreport\_owner}}();}
\DoxyCodeLine{1063     \mbox{\hyperlink{classalglib_1_1__dfreport__owner}{\_dfreport\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__dfreport__owner}{\_dfreport\_owner}} \&rhs);}
\DoxyCodeLine{1064     \mbox{\hyperlink{classalglib_1_1__dfreport__owner}{\_dfreport\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__dfreport__owner}{\_dfreport\_owner}} \&rhs);}
\DoxyCodeLine{1065     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__dfreport__owner}{\string~\_dfreport\_owner}}();}
\DoxyCodeLine{1066     \mbox{\hyperlink{structalglib__impl_1_1dfreport}{alglib\_impl::dfreport}}* c\_ptr();}
\DoxyCodeLine{1067     \mbox{\hyperlink{structalglib__impl_1_1dfreport}{alglib\_impl::dfreport}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{1068 \textcolor{keyword}{protected}:}
\DoxyCodeLine{1069     \mbox{\hyperlink{structalglib__impl_1_1dfreport}{alglib\_impl::dfreport}} *p\_struct;}
\DoxyCodeLine{1070 \};}
\DoxyCodeLine{1071 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1dfreport}{dfreport}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__dfreport__owner}{\_dfreport\_owner}}}
\DoxyCodeLine{1072 \{}
\DoxyCodeLine{1073 \textcolor{keyword}{public}:}
\DoxyCodeLine{1074     \mbox{\hyperlink{classalglib_1_1dfreport}{dfreport}}();}
\DoxyCodeLine{1075     \mbox{\hyperlink{classalglib_1_1dfreport}{dfreport}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1dfreport}{dfreport}} \&rhs);}
\DoxyCodeLine{1076     \mbox{\hyperlink{classalglib_1_1dfreport}{dfreport}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1dfreport}{dfreport}} \&rhs);}
\DoxyCodeLine{1077     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1dfreport}{\string~dfreport}}();}
\DoxyCodeLine{1078     \textcolor{keywordtype}{double} \&relclserror;}
\DoxyCodeLine{1079     \textcolor{keywordtype}{double} \&avgce;}
\DoxyCodeLine{1080     \textcolor{keywordtype}{double} \&rmserror;}
\DoxyCodeLine{1081     \textcolor{keywordtype}{double} \&avgerror;}
\DoxyCodeLine{1082     \textcolor{keywordtype}{double} \&avgrelerror;}
\DoxyCodeLine{1083     \textcolor{keywordtype}{double} \&oobrelclserror;}
\DoxyCodeLine{1084     \textcolor{keywordtype}{double} \&oobavgce;}
\DoxyCodeLine{1085     \textcolor{keywordtype}{double} \&oobrmserror;}
\DoxyCodeLine{1086     \textcolor{keywordtype}{double} \&oobavgerror;}
\DoxyCodeLine{1087     \textcolor{keywordtype}{double} \&oobavgrelerror;}
\DoxyCodeLine{1088     \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} topvars;}
\DoxyCodeLine{1089     \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} varimportances;}
\DoxyCodeLine{1090 }
\DoxyCodeLine{1091 \};}
\DoxyCodeLine{1092 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{1093 }
\DoxyCodeLine{1094 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_LINREG) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{1095 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1096 \textcolor{comment}{}}
\DoxyCodeLine{1097 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1098 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__linearmodel__owner}{\_linearmodel\_owner}}}
\DoxyCodeLine{1099 \{}
\DoxyCodeLine{1100 \textcolor{keyword}{public}:}
\DoxyCodeLine{1101     \mbox{\hyperlink{classalglib_1_1__linearmodel__owner}{\_linearmodel\_owner}}();}
\DoxyCodeLine{1102     \mbox{\hyperlink{classalglib_1_1__linearmodel__owner}{\_linearmodel\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__linearmodel__owner}{\_linearmodel\_owner}} \&rhs);}
\DoxyCodeLine{1103     \mbox{\hyperlink{classalglib_1_1__linearmodel__owner}{\_linearmodel\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__linearmodel__owner}{\_linearmodel\_owner}} \&rhs);}
\DoxyCodeLine{1104     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__linearmodel__owner}{\string~\_linearmodel\_owner}}();}
\DoxyCodeLine{1105     \mbox{\hyperlink{structalglib__impl_1_1linearmodel}{alglib\_impl::linearmodel}}* c\_ptr();}
\DoxyCodeLine{1106     \mbox{\hyperlink{structalglib__impl_1_1linearmodel}{alglib\_impl::linearmodel}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{1107 \textcolor{keyword}{protected}:}
\DoxyCodeLine{1108     \mbox{\hyperlink{structalglib__impl_1_1linearmodel}{alglib\_impl::linearmodel}} *p\_struct;}
\DoxyCodeLine{1109 \};}
\DoxyCodeLine{1110 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1linearmodel}{linearmodel}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__linearmodel__owner}{\_linearmodel\_owner}}}
\DoxyCodeLine{1111 \{}
\DoxyCodeLine{1112 \textcolor{keyword}{public}:}
\DoxyCodeLine{1113     \mbox{\hyperlink{classalglib_1_1linearmodel}{linearmodel}}();}
\DoxyCodeLine{1114     \mbox{\hyperlink{classalglib_1_1linearmodel}{linearmodel}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1linearmodel}{linearmodel}} \&rhs);}
\DoxyCodeLine{1115     \mbox{\hyperlink{classalglib_1_1linearmodel}{linearmodel}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1linearmodel}{linearmodel}} \&rhs);}
\DoxyCodeLine{1116     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1linearmodel}{\string~linearmodel}}();}
\DoxyCodeLine{1117 }
\DoxyCodeLine{1118 \};}
\DoxyCodeLine{1119 }
\DoxyCodeLine{1120 }
\DoxyCodeLine{1121 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1122 \textcolor{comment}{LRReport structure contains additional information about linear model:}}
\DoxyCodeLine{1123 \textcolor{comment}{* C             -\/   covariation matrix,  array[0..NVars,0..NVars].}}
\DoxyCodeLine{1124 \textcolor{comment}{                    C[i,j] = Cov(A[i],A[j])}}
\DoxyCodeLine{1125 \textcolor{comment}{* RMSError      -\/   root mean square error on a training set}}
\DoxyCodeLine{1126 \textcolor{comment}{* AvgError      -\/   average error on a training set}}
\DoxyCodeLine{1127 \textcolor{comment}{* AvgRelError   -\/   average relative error on a training set (excluding}}
\DoxyCodeLine{1128 \textcolor{comment}{                    observations with zero function value).}}
\DoxyCodeLine{1129 \textcolor{comment}{* CVRMSError    -\/   leave-\/one-\/out cross-\/validation estimate of}}
\DoxyCodeLine{1130 \textcolor{comment}{                    generalization error. Calculated using fast algorithm}}
\DoxyCodeLine{1131 \textcolor{comment}{                    with O(NVars*NPoints) complexity.}}
\DoxyCodeLine{1132 \textcolor{comment}{* CVAvgError    -\/   cross-\/validation estimate of average error}}
\DoxyCodeLine{1133 \textcolor{comment}{* CVAvgRelError -\/   cross-\/validation estimate of average relative error}}
\DoxyCodeLine{1134 \textcolor{comment}{}}
\DoxyCodeLine{1135 \textcolor{comment}{All other fields of the structure are intended for internal use and should}}
\DoxyCodeLine{1136 \textcolor{comment}{not be used outside ALGLIB.}}
\DoxyCodeLine{1137 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1138 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__lrreport__owner}{\_lrreport\_owner}}}
\DoxyCodeLine{1139 \{}
\DoxyCodeLine{1140 \textcolor{keyword}{public}:}
\DoxyCodeLine{1141     \mbox{\hyperlink{classalglib_1_1__lrreport__owner}{\_lrreport\_owner}}();}
\DoxyCodeLine{1142     \mbox{\hyperlink{classalglib_1_1__lrreport__owner}{\_lrreport\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__lrreport__owner}{\_lrreport\_owner}} \&rhs);}
\DoxyCodeLine{1143     \mbox{\hyperlink{classalglib_1_1__lrreport__owner}{\_lrreport\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__lrreport__owner}{\_lrreport\_owner}} \&rhs);}
\DoxyCodeLine{1144     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__lrreport__owner}{\string~\_lrreport\_owner}}();}
\DoxyCodeLine{1145     \mbox{\hyperlink{structalglib__impl_1_1lrreport}{alglib\_impl::lrreport}}* c\_ptr();}
\DoxyCodeLine{1146     \mbox{\hyperlink{structalglib__impl_1_1lrreport}{alglib\_impl::lrreport}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{1147 \textcolor{keyword}{protected}:}
\DoxyCodeLine{1148     \mbox{\hyperlink{structalglib__impl_1_1lrreport}{alglib\_impl::lrreport}} *p\_struct;}
\DoxyCodeLine{1149 \};}
\DoxyCodeLine{1150 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1lrreport}{lrreport}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__lrreport__owner}{\_lrreport\_owner}}}
\DoxyCodeLine{1151 \{}
\DoxyCodeLine{1152 \textcolor{keyword}{public}:}
\DoxyCodeLine{1153     \mbox{\hyperlink{classalglib_1_1lrreport}{lrreport}}();}
\DoxyCodeLine{1154     \mbox{\hyperlink{classalglib_1_1lrreport}{lrreport}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1lrreport}{lrreport}} \&rhs);}
\DoxyCodeLine{1155     \mbox{\hyperlink{classalglib_1_1lrreport}{lrreport}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1lrreport}{lrreport}} \&rhs);}
\DoxyCodeLine{1156     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1lrreport}{\string~lrreport}}();}
\DoxyCodeLine{1157     \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} c;}
\DoxyCodeLine{1158     \textcolor{keywordtype}{double} \&rmserror;}
\DoxyCodeLine{1159     \textcolor{keywordtype}{double} \&avgerror;}
\DoxyCodeLine{1160     \textcolor{keywordtype}{double} \&avgrelerror;}
\DoxyCodeLine{1161     \textcolor{keywordtype}{double} \&cvrmserror;}
\DoxyCodeLine{1162     \textcolor{keywordtype}{double} \&cvavgerror;}
\DoxyCodeLine{1163     \textcolor{keywordtype}{double} \&cvavgrelerror;}
\DoxyCodeLine{1164     ae\_int\_t \&ncvdefects;}
\DoxyCodeLine{1165     \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} cvdefects;}
\DoxyCodeLine{1166 }
\DoxyCodeLine{1167 \};}
\DoxyCodeLine{1168 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{1169 }
\DoxyCodeLine{1170 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_FILTERS) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{1171 }
\DoxyCodeLine{1172 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{1173 }
\DoxyCodeLine{1174 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_SSA) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{1175 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1176 \textcolor{comment}{This object stores state of the SSA model.}}
\DoxyCodeLine{1177 \textcolor{comment}{}}
\DoxyCodeLine{1178 \textcolor{comment}{You should use ALGLIB functions to work with this object.}}
\DoxyCodeLine{1179 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1180 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__ssamodel__owner}{\_ssamodel\_owner}}}
\DoxyCodeLine{1181 \{}
\DoxyCodeLine{1182 \textcolor{keyword}{public}:}
\DoxyCodeLine{1183     \mbox{\hyperlink{classalglib_1_1__ssamodel__owner}{\_ssamodel\_owner}}();}
\DoxyCodeLine{1184     \mbox{\hyperlink{classalglib_1_1__ssamodel__owner}{\_ssamodel\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__ssamodel__owner}{\_ssamodel\_owner}} \&rhs);}
\DoxyCodeLine{1185     \mbox{\hyperlink{classalglib_1_1__ssamodel__owner}{\_ssamodel\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__ssamodel__owner}{\_ssamodel\_owner}} \&rhs);}
\DoxyCodeLine{1186     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__ssamodel__owner}{\string~\_ssamodel\_owner}}();}
\DoxyCodeLine{1187     \mbox{\hyperlink{structalglib__impl_1_1ssamodel}{alglib\_impl::ssamodel}}* c\_ptr();}
\DoxyCodeLine{1188     \mbox{\hyperlink{structalglib__impl_1_1ssamodel}{alglib\_impl::ssamodel}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{1189 \textcolor{keyword}{protected}:}
\DoxyCodeLine{1190     \mbox{\hyperlink{structalglib__impl_1_1ssamodel}{alglib\_impl::ssamodel}} *p\_struct;}
\DoxyCodeLine{1191 \};}
\DoxyCodeLine{1192 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__ssamodel__owner}{\_ssamodel\_owner}}}
\DoxyCodeLine{1193 \{}
\DoxyCodeLine{1194 \textcolor{keyword}{public}:}
\DoxyCodeLine{1195     \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}}();}
\DoxyCodeLine{1196     \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&rhs);}
\DoxyCodeLine{1197     \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&rhs);}
\DoxyCodeLine{1198     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1ssamodel}{\string~ssamodel}}();}
\DoxyCodeLine{1199 }
\DoxyCodeLine{1200 \};}
\DoxyCodeLine{1201 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{1202 }
\DoxyCodeLine{1203 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_LDA) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{1204 }
\DoxyCodeLine{1205 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{1206 }
\DoxyCodeLine{1207 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_MCPD) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{1208 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1209 \textcolor{comment}{This structure is a MCPD (Markov Chains for Population Data) solver.}}
\DoxyCodeLine{1210 \textcolor{comment}{}}
\DoxyCodeLine{1211 \textcolor{comment}{You should use ALGLIB functions in order to work with this object.}}
\DoxyCodeLine{1212 \textcolor{comment}{}}
\DoxyCodeLine{1213 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{1214 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{1215 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1216 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__mcpdstate__owner}{\_mcpdstate\_owner}}}
\DoxyCodeLine{1217 \{}
\DoxyCodeLine{1218 \textcolor{keyword}{public}:}
\DoxyCodeLine{1219     \mbox{\hyperlink{classalglib_1_1__mcpdstate__owner}{\_mcpdstate\_owner}}();}
\DoxyCodeLine{1220     \mbox{\hyperlink{classalglib_1_1__mcpdstate__owner}{\_mcpdstate\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__mcpdstate__owner}{\_mcpdstate\_owner}} \&rhs);}
\DoxyCodeLine{1221     \mbox{\hyperlink{classalglib_1_1__mcpdstate__owner}{\_mcpdstate\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__mcpdstate__owner}{\_mcpdstate\_owner}} \&rhs);}
\DoxyCodeLine{1222     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__mcpdstate__owner}{\string~\_mcpdstate\_owner}}();}
\DoxyCodeLine{1223     \mbox{\hyperlink{structalglib__impl_1_1mcpdstate}{alglib\_impl::mcpdstate}}* c\_ptr();}
\DoxyCodeLine{1224     \mbox{\hyperlink{structalglib__impl_1_1mcpdstate}{alglib\_impl::mcpdstate}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{1225 \textcolor{keyword}{protected}:}
\DoxyCodeLine{1226     \mbox{\hyperlink{structalglib__impl_1_1mcpdstate}{alglib\_impl::mcpdstate}} *p\_struct;}
\DoxyCodeLine{1227 \};}
\DoxyCodeLine{1228 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__mcpdstate__owner}{\_mcpdstate\_owner}}}
\DoxyCodeLine{1229 \{}
\DoxyCodeLine{1230 \textcolor{keyword}{public}:}
\DoxyCodeLine{1231     \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}}();}
\DoxyCodeLine{1232     \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&rhs);}
\DoxyCodeLine{1233     \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&rhs);}
\DoxyCodeLine{1234     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1mcpdstate}{\string~mcpdstate}}();}
\DoxyCodeLine{1235 }
\DoxyCodeLine{1236 \};}
\DoxyCodeLine{1237 }
\DoxyCodeLine{1238 }
\DoxyCodeLine{1239 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1240 \textcolor{comment}{This structure is a MCPD training report:}}
\DoxyCodeLine{1241 \textcolor{comment}{    InnerIterationsCount    -\/   number of inner iterations of the}}
\DoxyCodeLine{1242 \textcolor{comment}{                                underlying optimization algorithm}}
\DoxyCodeLine{1243 \textcolor{comment}{    OuterIterationsCount    -\/   number of outer iterations of the}}
\DoxyCodeLine{1244 \textcolor{comment}{                                underlying optimization algorithm}}
\DoxyCodeLine{1245 \textcolor{comment}{    NFEV                    -\/   number of merit function evaluations}}
\DoxyCodeLine{1246 \textcolor{comment}{    TerminationType         -\/   termination type}}
\DoxyCodeLine{1247 \textcolor{comment}{                                (same as for MinBLEIC optimizer, positive}}
\DoxyCodeLine{1248 \textcolor{comment}{                                values denote success, negative ones -\/}}
\DoxyCodeLine{1249 \textcolor{comment}{                                failure)}}
\DoxyCodeLine{1250 \textcolor{comment}{}}
\DoxyCodeLine{1251 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{1252 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{1253 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1254 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__mcpdreport__owner}{\_mcpdreport\_owner}}}
\DoxyCodeLine{1255 \{}
\DoxyCodeLine{1256 \textcolor{keyword}{public}:}
\DoxyCodeLine{1257     \mbox{\hyperlink{classalglib_1_1__mcpdreport__owner}{\_mcpdreport\_owner}}();}
\DoxyCodeLine{1258     \mbox{\hyperlink{classalglib_1_1__mcpdreport__owner}{\_mcpdreport\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__mcpdreport__owner}{\_mcpdreport\_owner}} \&rhs);}
\DoxyCodeLine{1259     \mbox{\hyperlink{classalglib_1_1__mcpdreport__owner}{\_mcpdreport\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__mcpdreport__owner}{\_mcpdreport\_owner}} \&rhs);}
\DoxyCodeLine{1260     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__mcpdreport__owner}{\string~\_mcpdreport\_owner}}();}
\DoxyCodeLine{1261     \mbox{\hyperlink{structalglib__impl_1_1mcpdreport}{alglib\_impl::mcpdreport}}* c\_ptr();}
\DoxyCodeLine{1262     \mbox{\hyperlink{structalglib__impl_1_1mcpdreport}{alglib\_impl::mcpdreport}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{1263 \textcolor{keyword}{protected}:}
\DoxyCodeLine{1264     \mbox{\hyperlink{structalglib__impl_1_1mcpdreport}{alglib\_impl::mcpdreport}} *p\_struct;}
\DoxyCodeLine{1265 \};}
\DoxyCodeLine{1266 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1mcpdreport}{mcpdreport}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__mcpdreport__owner}{\_mcpdreport\_owner}}}
\DoxyCodeLine{1267 \{}
\DoxyCodeLine{1268 \textcolor{keyword}{public}:}
\DoxyCodeLine{1269     \mbox{\hyperlink{classalglib_1_1mcpdreport}{mcpdreport}}();}
\DoxyCodeLine{1270     \mbox{\hyperlink{classalglib_1_1mcpdreport}{mcpdreport}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdreport}{mcpdreport}} \&rhs);}
\DoxyCodeLine{1271     \mbox{\hyperlink{classalglib_1_1mcpdreport}{mcpdreport}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdreport}{mcpdreport}} \&rhs);}
\DoxyCodeLine{1272     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1mcpdreport}{\string~mcpdreport}}();}
\DoxyCodeLine{1273     ae\_int\_t \&inneriterationscount;}
\DoxyCodeLine{1274     ae\_int\_t \&outeriterationscount;}
\DoxyCodeLine{1275     ae\_int\_t \&nfev;}
\DoxyCodeLine{1276     ae\_int\_t \&terminationtype;}
\DoxyCodeLine{1277 }
\DoxyCodeLine{1278 \};}
\DoxyCodeLine{1279 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{1280 }
\DoxyCodeLine{1281 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_LOGIT) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{1282 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1283 \textcolor{comment}{}}
\DoxyCodeLine{1284 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1285 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__logitmodel__owner}{\_logitmodel\_owner}}}
\DoxyCodeLine{1286 \{}
\DoxyCodeLine{1287 \textcolor{keyword}{public}:}
\DoxyCodeLine{1288     \mbox{\hyperlink{classalglib_1_1__logitmodel__owner}{\_logitmodel\_owner}}();}
\DoxyCodeLine{1289     \mbox{\hyperlink{classalglib_1_1__logitmodel__owner}{\_logitmodel\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__logitmodel__owner}{\_logitmodel\_owner}} \&rhs);}
\DoxyCodeLine{1290     \mbox{\hyperlink{classalglib_1_1__logitmodel__owner}{\_logitmodel\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__logitmodel__owner}{\_logitmodel\_owner}} \&rhs);}
\DoxyCodeLine{1291     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__logitmodel__owner}{\string~\_logitmodel\_owner}}();}
\DoxyCodeLine{1292     \mbox{\hyperlink{structalglib__impl_1_1logitmodel}{alglib\_impl::logitmodel}}* c\_ptr();}
\DoxyCodeLine{1293     \mbox{\hyperlink{structalglib__impl_1_1logitmodel}{alglib\_impl::logitmodel}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{1294 \textcolor{keyword}{protected}:}
\DoxyCodeLine{1295     \mbox{\hyperlink{structalglib__impl_1_1logitmodel}{alglib\_impl::logitmodel}} *p\_struct;}
\DoxyCodeLine{1296 \};}
\DoxyCodeLine{1297 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__logitmodel__owner}{\_logitmodel\_owner}}}
\DoxyCodeLine{1298 \{}
\DoxyCodeLine{1299 \textcolor{keyword}{public}:}
\DoxyCodeLine{1300     \mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}}();}
\DoxyCodeLine{1301     \mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}} \&rhs);}
\DoxyCodeLine{1302     \mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}} \&rhs);}
\DoxyCodeLine{1303     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1logitmodel}{\string~logitmodel}}();}
\DoxyCodeLine{1304 }
\DoxyCodeLine{1305 \};}
\DoxyCodeLine{1306 }
\DoxyCodeLine{1307 }
\DoxyCodeLine{1308 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1309 \textcolor{comment}{MNLReport structure contains information about training process:}}
\DoxyCodeLine{1310 \textcolor{comment}{* NGrad     -\/   number of gradient calculations}}
\DoxyCodeLine{1311 \textcolor{comment}{* NHess     -\/   number of Hessian calculations}}
\DoxyCodeLine{1312 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1313 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__mnlreport__owner}{\_mnlreport\_owner}}}
\DoxyCodeLine{1314 \{}
\DoxyCodeLine{1315 \textcolor{keyword}{public}:}
\DoxyCodeLine{1316     \mbox{\hyperlink{classalglib_1_1__mnlreport__owner}{\_mnlreport\_owner}}();}
\DoxyCodeLine{1317     \mbox{\hyperlink{classalglib_1_1__mnlreport__owner}{\_mnlreport\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__mnlreport__owner}{\_mnlreport\_owner}} \&rhs);}
\DoxyCodeLine{1318     \mbox{\hyperlink{classalglib_1_1__mnlreport__owner}{\_mnlreport\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__mnlreport__owner}{\_mnlreport\_owner}} \&rhs);}
\DoxyCodeLine{1319     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__mnlreport__owner}{\string~\_mnlreport\_owner}}();}
\DoxyCodeLine{1320     \mbox{\hyperlink{structalglib__impl_1_1mnlreport}{alglib\_impl::mnlreport}}* c\_ptr();}
\DoxyCodeLine{1321     \mbox{\hyperlink{structalglib__impl_1_1mnlreport}{alglib\_impl::mnlreport}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{1322 \textcolor{keyword}{protected}:}
\DoxyCodeLine{1323     \mbox{\hyperlink{structalglib__impl_1_1mnlreport}{alglib\_impl::mnlreport}} *p\_struct;}
\DoxyCodeLine{1324 \};}
\DoxyCodeLine{1325 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1mnlreport}{mnlreport}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__mnlreport__owner}{\_mnlreport\_owner}}}
\DoxyCodeLine{1326 \{}
\DoxyCodeLine{1327 \textcolor{keyword}{public}:}
\DoxyCodeLine{1328     \mbox{\hyperlink{classalglib_1_1mnlreport}{mnlreport}}();}
\DoxyCodeLine{1329     \mbox{\hyperlink{classalglib_1_1mnlreport}{mnlreport}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mnlreport}{mnlreport}} \&rhs);}
\DoxyCodeLine{1330     \mbox{\hyperlink{classalglib_1_1mnlreport}{mnlreport}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mnlreport}{mnlreport}} \&rhs);}
\DoxyCodeLine{1331     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1mnlreport}{\string~mnlreport}}();}
\DoxyCodeLine{1332     ae\_int\_t \&ngrad;}
\DoxyCodeLine{1333     ae\_int\_t \&nhess;}
\DoxyCodeLine{1334 }
\DoxyCodeLine{1335 \};}
\DoxyCodeLine{1336 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{1337 }
\DoxyCodeLine{1338 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_KNN) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{1339 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1340 \textcolor{comment}{Buffer object which is used to perform  various  requests  (usually  model}}
\DoxyCodeLine{1341 \textcolor{comment}{inference) in the multithreaded mode (multiple threads working  with  same}}
\DoxyCodeLine{1342 \textcolor{comment}{KNN object).}}
\DoxyCodeLine{1343 \textcolor{comment}{}}
\DoxyCodeLine{1344 \textcolor{comment}{This object should be created with KNNCreateBuffer().}}
\DoxyCodeLine{1345 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1346 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__knnbuffer__owner}{\_knnbuffer\_owner}}}
\DoxyCodeLine{1347 \{}
\DoxyCodeLine{1348 \textcolor{keyword}{public}:}
\DoxyCodeLine{1349     \mbox{\hyperlink{classalglib_1_1__knnbuffer__owner}{\_knnbuffer\_owner}}();}
\DoxyCodeLine{1350     \mbox{\hyperlink{classalglib_1_1__knnbuffer__owner}{\_knnbuffer\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__knnbuffer__owner}{\_knnbuffer\_owner}} \&rhs);}
\DoxyCodeLine{1351     \mbox{\hyperlink{classalglib_1_1__knnbuffer__owner}{\_knnbuffer\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__knnbuffer__owner}{\_knnbuffer\_owner}} \&rhs);}
\DoxyCodeLine{1352     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__knnbuffer__owner}{\string~\_knnbuffer\_owner}}();}
\DoxyCodeLine{1353     \mbox{\hyperlink{structalglib__impl_1_1knnbuffer}{alglib\_impl::knnbuffer}}* c\_ptr();}
\DoxyCodeLine{1354     \mbox{\hyperlink{structalglib__impl_1_1knnbuffer}{alglib\_impl::knnbuffer}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{1355 \textcolor{keyword}{protected}:}
\DoxyCodeLine{1356     \mbox{\hyperlink{structalglib__impl_1_1knnbuffer}{alglib\_impl::knnbuffer}} *p\_struct;}
\DoxyCodeLine{1357 \};}
\DoxyCodeLine{1358 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1knnbuffer}{knnbuffer}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__knnbuffer__owner}{\_knnbuffer\_owner}}}
\DoxyCodeLine{1359 \{}
\DoxyCodeLine{1360 \textcolor{keyword}{public}:}
\DoxyCodeLine{1361     \mbox{\hyperlink{classalglib_1_1knnbuffer}{knnbuffer}}();}
\DoxyCodeLine{1362     \mbox{\hyperlink{classalglib_1_1knnbuffer}{knnbuffer}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnbuffer}{knnbuffer}} \&rhs);}
\DoxyCodeLine{1363     \mbox{\hyperlink{classalglib_1_1knnbuffer}{knnbuffer}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnbuffer}{knnbuffer}} \&rhs);}
\DoxyCodeLine{1364     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1knnbuffer}{\string~knnbuffer}}();}
\DoxyCodeLine{1365 }
\DoxyCodeLine{1366 \};}
\DoxyCodeLine{1367 }
\DoxyCodeLine{1368 }
\DoxyCodeLine{1369 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1370 \textcolor{comment}{A KNN builder object; this object encapsulates  dataset  and  all  related}}
\DoxyCodeLine{1371 \textcolor{comment}{settings, it is used to create an actual instance of KNN model.}}
\DoxyCodeLine{1372 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1373 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__knnbuilder__owner}{\_knnbuilder\_owner}}}
\DoxyCodeLine{1374 \{}
\DoxyCodeLine{1375 \textcolor{keyword}{public}:}
\DoxyCodeLine{1376     \mbox{\hyperlink{classalglib_1_1__knnbuilder__owner}{\_knnbuilder\_owner}}();}
\DoxyCodeLine{1377     \mbox{\hyperlink{classalglib_1_1__knnbuilder__owner}{\_knnbuilder\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__knnbuilder__owner}{\_knnbuilder\_owner}} \&rhs);}
\DoxyCodeLine{1378     \mbox{\hyperlink{classalglib_1_1__knnbuilder__owner}{\_knnbuilder\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__knnbuilder__owner}{\_knnbuilder\_owner}} \&rhs);}
\DoxyCodeLine{1379     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__knnbuilder__owner}{\string~\_knnbuilder\_owner}}();}
\DoxyCodeLine{1380     \mbox{\hyperlink{structalglib__impl_1_1knnbuilder}{alglib\_impl::knnbuilder}}* c\_ptr();}
\DoxyCodeLine{1381     \mbox{\hyperlink{structalglib__impl_1_1knnbuilder}{alglib\_impl::knnbuilder}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{1382 \textcolor{keyword}{protected}:}
\DoxyCodeLine{1383     \mbox{\hyperlink{structalglib__impl_1_1knnbuilder}{alglib\_impl::knnbuilder}} *p\_struct;}
\DoxyCodeLine{1384 \};}
\DoxyCodeLine{1385 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1knnbuilder}{knnbuilder}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__knnbuilder__owner}{\_knnbuilder\_owner}}}
\DoxyCodeLine{1386 \{}
\DoxyCodeLine{1387 \textcolor{keyword}{public}:}
\DoxyCodeLine{1388     \mbox{\hyperlink{classalglib_1_1knnbuilder}{knnbuilder}}();}
\DoxyCodeLine{1389     \mbox{\hyperlink{classalglib_1_1knnbuilder}{knnbuilder}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnbuilder}{knnbuilder}} \&rhs);}
\DoxyCodeLine{1390     \mbox{\hyperlink{classalglib_1_1knnbuilder}{knnbuilder}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnbuilder}{knnbuilder}} \&rhs);}
\DoxyCodeLine{1391     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1knnbuilder}{\string~knnbuilder}}();}
\DoxyCodeLine{1392 }
\DoxyCodeLine{1393 \};}
\DoxyCodeLine{1394 }
\DoxyCodeLine{1395 }
\DoxyCodeLine{1396 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1397 \textcolor{comment}{KNN model, can be used for classification or regression}}
\DoxyCodeLine{1398 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1399 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__knnmodel__owner}{\_knnmodel\_owner}}}
\DoxyCodeLine{1400 \{}
\DoxyCodeLine{1401 \textcolor{keyword}{public}:}
\DoxyCodeLine{1402     \mbox{\hyperlink{classalglib_1_1__knnmodel__owner}{\_knnmodel\_owner}}();}
\DoxyCodeLine{1403     \mbox{\hyperlink{classalglib_1_1__knnmodel__owner}{\_knnmodel\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__knnmodel__owner}{\_knnmodel\_owner}} \&rhs);}
\DoxyCodeLine{1404     \mbox{\hyperlink{classalglib_1_1__knnmodel__owner}{\_knnmodel\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__knnmodel__owner}{\_knnmodel\_owner}} \&rhs);}
\DoxyCodeLine{1405     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__knnmodel__owner}{\string~\_knnmodel\_owner}}();}
\DoxyCodeLine{1406     \mbox{\hyperlink{structalglib__impl_1_1knnmodel}{alglib\_impl::knnmodel}}* c\_ptr();}
\DoxyCodeLine{1407     \mbox{\hyperlink{structalglib__impl_1_1knnmodel}{alglib\_impl::knnmodel}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{1408 \textcolor{keyword}{protected}:}
\DoxyCodeLine{1409     \mbox{\hyperlink{structalglib__impl_1_1knnmodel}{alglib\_impl::knnmodel}} *p\_struct;}
\DoxyCodeLine{1410 \};}
\DoxyCodeLine{1411 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__knnmodel__owner}{\_knnmodel\_owner}}}
\DoxyCodeLine{1412 \{}
\DoxyCodeLine{1413 \textcolor{keyword}{public}:}
\DoxyCodeLine{1414     \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}}();}
\DoxyCodeLine{1415     \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&rhs);}
\DoxyCodeLine{1416     \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&rhs);}
\DoxyCodeLine{1417     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1knnmodel}{\string~knnmodel}}();}
\DoxyCodeLine{1418 }
\DoxyCodeLine{1419 \};}
\DoxyCodeLine{1420 }
\DoxyCodeLine{1421 }
\DoxyCodeLine{1422 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1423 \textcolor{comment}{KNN training report.}}
\DoxyCodeLine{1424 \textcolor{comment}{}}
\DoxyCodeLine{1425 \textcolor{comment}{Following fields store training set errors:}}
\DoxyCodeLine{1426 \textcolor{comment}{* relclserror       -\/   fraction of misclassified cases, [0,1]}}
\DoxyCodeLine{1427 \textcolor{comment}{* avgce             -\/   average cross-\/entropy in bits per symbol}}
\DoxyCodeLine{1428 \textcolor{comment}{* rmserror          -\/   root-\/mean-\/square error}}
\DoxyCodeLine{1429 \textcolor{comment}{* avgerror          -\/   average error}}
\DoxyCodeLine{1430 \textcolor{comment}{* avgrelerror       -\/   average relative error}}
\DoxyCodeLine{1431 \textcolor{comment}{}}
\DoxyCodeLine{1432 \textcolor{comment}{For classification problems:}}
\DoxyCodeLine{1433 \textcolor{comment}{* RMS, AVG and AVGREL errors are calculated for posterior probabilities}}
\DoxyCodeLine{1434 \textcolor{comment}{}}
\DoxyCodeLine{1435 \textcolor{comment}{For regression problems:}}
\DoxyCodeLine{1436 \textcolor{comment}{* RELCLS and AVGCE errors are zero}}
\DoxyCodeLine{1437 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1438 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__knnreport__owner}{\_knnreport\_owner}}}
\DoxyCodeLine{1439 \{}
\DoxyCodeLine{1440 \textcolor{keyword}{public}:}
\DoxyCodeLine{1441     \mbox{\hyperlink{classalglib_1_1__knnreport__owner}{\_knnreport\_owner}}();}
\DoxyCodeLine{1442     \mbox{\hyperlink{classalglib_1_1__knnreport__owner}{\_knnreport\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__knnreport__owner}{\_knnreport\_owner}} \&rhs);}
\DoxyCodeLine{1443     \mbox{\hyperlink{classalglib_1_1__knnreport__owner}{\_knnreport\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__knnreport__owner}{\_knnreport\_owner}} \&rhs);}
\DoxyCodeLine{1444     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__knnreport__owner}{\string~\_knnreport\_owner}}();}
\DoxyCodeLine{1445     \mbox{\hyperlink{structalglib__impl_1_1knnreport}{alglib\_impl::knnreport}}* c\_ptr();}
\DoxyCodeLine{1446     \mbox{\hyperlink{structalglib__impl_1_1knnreport}{alglib\_impl::knnreport}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{1447 \textcolor{keyword}{protected}:}
\DoxyCodeLine{1448     \mbox{\hyperlink{structalglib__impl_1_1knnreport}{alglib\_impl::knnreport}} *p\_struct;}
\DoxyCodeLine{1449 \};}
\DoxyCodeLine{1450 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1knnreport}{knnreport}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__knnreport__owner}{\_knnreport\_owner}}}
\DoxyCodeLine{1451 \{}
\DoxyCodeLine{1452 \textcolor{keyword}{public}:}
\DoxyCodeLine{1453     \mbox{\hyperlink{classalglib_1_1knnreport}{knnreport}}();}
\DoxyCodeLine{1454     \mbox{\hyperlink{classalglib_1_1knnreport}{knnreport}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnreport}{knnreport}} \&rhs);}
\DoxyCodeLine{1455     \mbox{\hyperlink{classalglib_1_1knnreport}{knnreport}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnreport}{knnreport}} \&rhs);}
\DoxyCodeLine{1456     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1knnreport}{\string~knnreport}}();}
\DoxyCodeLine{1457     \textcolor{keywordtype}{double} \&relclserror;}
\DoxyCodeLine{1458     \textcolor{keywordtype}{double} \&avgce;}
\DoxyCodeLine{1459     \textcolor{keywordtype}{double} \&rmserror;}
\DoxyCodeLine{1460     \textcolor{keywordtype}{double} \&avgerror;}
\DoxyCodeLine{1461     \textcolor{keywordtype}{double} \&avgrelerror;}
\DoxyCodeLine{1462 }
\DoxyCodeLine{1463 \};}
\DoxyCodeLine{1464 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{1465 }
\DoxyCodeLine{1466 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_MLPTRAIN) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{1467 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1468 \textcolor{comment}{Training report:}}
\DoxyCodeLine{1469 \textcolor{comment}{    * RelCLSError   -\/   fraction of misclassified cases.}}
\DoxyCodeLine{1470 \textcolor{comment}{    * AvgCE         -\/   acerage cross-\/entropy}}
\DoxyCodeLine{1471 \textcolor{comment}{    * RMSError      -\/   root-\/mean-\/square error}}
\DoxyCodeLine{1472 \textcolor{comment}{    * AvgError      -\/   average error}}
\DoxyCodeLine{1473 \textcolor{comment}{    * AvgRelError   -\/   average relative error}}
\DoxyCodeLine{1474 \textcolor{comment}{    * NGrad         -\/   number of gradient calculations}}
\DoxyCodeLine{1475 \textcolor{comment}{    * NHess         -\/   number of Hessian calculations}}
\DoxyCodeLine{1476 \textcolor{comment}{    * NCholesky     -\/   number of Cholesky decompositions}}
\DoxyCodeLine{1477 \textcolor{comment}{}}
\DoxyCodeLine{1478 \textcolor{comment}{NOTE 1: RelCLSError/AvgCE are zero on regression problems.}}
\DoxyCodeLine{1479 \textcolor{comment}{}}
\DoxyCodeLine{1480 \textcolor{comment}{NOTE 2: on classification problems  RMSError/AvgError/AvgRelError  contain}}
\DoxyCodeLine{1481 \textcolor{comment}{        errors in prediction of posterior probabilities}}
\DoxyCodeLine{1482 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1483 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__mlpreport__owner}{\_mlpreport\_owner}}}
\DoxyCodeLine{1484 \{}
\DoxyCodeLine{1485 \textcolor{keyword}{public}:}
\DoxyCodeLine{1486     \mbox{\hyperlink{classalglib_1_1__mlpreport__owner}{\_mlpreport\_owner}}();}
\DoxyCodeLine{1487     \mbox{\hyperlink{classalglib_1_1__mlpreport__owner}{\_mlpreport\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__mlpreport__owner}{\_mlpreport\_owner}} \&rhs);}
\DoxyCodeLine{1488     \mbox{\hyperlink{classalglib_1_1__mlpreport__owner}{\_mlpreport\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__mlpreport__owner}{\_mlpreport\_owner}} \&rhs);}
\DoxyCodeLine{1489     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__mlpreport__owner}{\string~\_mlpreport\_owner}}();}
\DoxyCodeLine{1490     \mbox{\hyperlink{structalglib__impl_1_1mlpreport}{alglib\_impl::mlpreport}}* c\_ptr();}
\DoxyCodeLine{1491     \mbox{\hyperlink{structalglib__impl_1_1mlpreport}{alglib\_impl::mlpreport}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{1492 \textcolor{keyword}{protected}:}
\DoxyCodeLine{1493     \mbox{\hyperlink{structalglib__impl_1_1mlpreport}{alglib\_impl::mlpreport}} *p\_struct;}
\DoxyCodeLine{1494 \};}
\DoxyCodeLine{1495 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__mlpreport__owner}{\_mlpreport\_owner}}}
\DoxyCodeLine{1496 \{}
\DoxyCodeLine{1497 \textcolor{keyword}{public}:}
\DoxyCodeLine{1498     \mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}}();}
\DoxyCodeLine{1499     \mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}} \&rhs);}
\DoxyCodeLine{1500     \mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}} \&rhs);}
\DoxyCodeLine{1501     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1mlpreport}{\string~mlpreport}}();}
\DoxyCodeLine{1502     \textcolor{keywordtype}{double} \&relclserror;}
\DoxyCodeLine{1503     \textcolor{keywordtype}{double} \&avgce;}
\DoxyCodeLine{1504     \textcolor{keywordtype}{double} \&rmserror;}
\DoxyCodeLine{1505     \textcolor{keywordtype}{double} \&avgerror;}
\DoxyCodeLine{1506     \textcolor{keywordtype}{double} \&avgrelerror;}
\DoxyCodeLine{1507     ae\_int\_t \&ngrad;}
\DoxyCodeLine{1508     ae\_int\_t \&nhess;}
\DoxyCodeLine{1509     ae\_int\_t \&ncholesky;}
\DoxyCodeLine{1510 }
\DoxyCodeLine{1511 \};}
\DoxyCodeLine{1512 }
\DoxyCodeLine{1513 }
\DoxyCodeLine{1514 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1515 \textcolor{comment}{Cross-\/validation estimates of generalization error}}
\DoxyCodeLine{1516 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1517 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__mlpcvreport__owner}{\_mlpcvreport\_owner}}}
\DoxyCodeLine{1518 \{}
\DoxyCodeLine{1519 \textcolor{keyword}{public}:}
\DoxyCodeLine{1520     \mbox{\hyperlink{classalglib_1_1__mlpcvreport__owner}{\_mlpcvreport\_owner}}();}
\DoxyCodeLine{1521     \mbox{\hyperlink{classalglib_1_1__mlpcvreport__owner}{\_mlpcvreport\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__mlpcvreport__owner}{\_mlpcvreport\_owner}} \&rhs);}
\DoxyCodeLine{1522     \mbox{\hyperlink{classalglib_1_1__mlpcvreport__owner}{\_mlpcvreport\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__mlpcvreport__owner}{\_mlpcvreport\_owner}} \&rhs);}
\DoxyCodeLine{1523     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__mlpcvreport__owner}{\string~\_mlpcvreport\_owner}}();}
\DoxyCodeLine{1524     \mbox{\hyperlink{structalglib__impl_1_1mlpcvreport}{alglib\_impl::mlpcvreport}}* c\_ptr();}
\DoxyCodeLine{1525     \mbox{\hyperlink{structalglib__impl_1_1mlpcvreport}{alglib\_impl::mlpcvreport}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{1526 \textcolor{keyword}{protected}:}
\DoxyCodeLine{1527     \mbox{\hyperlink{structalglib__impl_1_1mlpcvreport}{alglib\_impl::mlpcvreport}} *p\_struct;}
\DoxyCodeLine{1528 \};}
\DoxyCodeLine{1529 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1mlpcvreport}{mlpcvreport}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__mlpcvreport__owner}{\_mlpcvreport\_owner}}}
\DoxyCodeLine{1530 \{}
\DoxyCodeLine{1531 \textcolor{keyword}{public}:}
\DoxyCodeLine{1532     \mbox{\hyperlink{classalglib_1_1mlpcvreport}{mlpcvreport}}();}
\DoxyCodeLine{1533     \mbox{\hyperlink{classalglib_1_1mlpcvreport}{mlpcvreport}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpcvreport}{mlpcvreport}} \&rhs);}
\DoxyCodeLine{1534     \mbox{\hyperlink{classalglib_1_1mlpcvreport}{mlpcvreport}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpcvreport}{mlpcvreport}} \&rhs);}
\DoxyCodeLine{1535     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1mlpcvreport}{\string~mlpcvreport}}();}
\DoxyCodeLine{1536     \textcolor{keywordtype}{double} \&relclserror;}
\DoxyCodeLine{1537     \textcolor{keywordtype}{double} \&avgce;}
\DoxyCodeLine{1538     \textcolor{keywordtype}{double} \&rmserror;}
\DoxyCodeLine{1539     \textcolor{keywordtype}{double} \&avgerror;}
\DoxyCodeLine{1540     \textcolor{keywordtype}{double} \&avgrelerror;}
\DoxyCodeLine{1541 }
\DoxyCodeLine{1542 \};}
\DoxyCodeLine{1543 }
\DoxyCodeLine{1544 }
\DoxyCodeLine{1545 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1546 \textcolor{comment}{Trainer object for neural network.}}
\DoxyCodeLine{1547 \textcolor{comment}{}}
\DoxyCodeLine{1548 \textcolor{comment}{You should not try to access fields of this object directly -\/  use  ALGLIB}}
\DoxyCodeLine{1549 \textcolor{comment}{functions to work with this object.}}
\DoxyCodeLine{1550 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1551 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1__mlptrainer__owner}{\_mlptrainer\_owner}}}
\DoxyCodeLine{1552 \{}
\DoxyCodeLine{1553 \textcolor{keyword}{public}:}
\DoxyCodeLine{1554     \mbox{\hyperlink{classalglib_1_1__mlptrainer__owner}{\_mlptrainer\_owner}}();}
\DoxyCodeLine{1555     \mbox{\hyperlink{classalglib_1_1__mlptrainer__owner}{\_mlptrainer\_owner}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__mlptrainer__owner}{\_mlptrainer\_owner}} \&rhs);}
\DoxyCodeLine{1556     \mbox{\hyperlink{classalglib_1_1__mlptrainer__owner}{\_mlptrainer\_owner}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1__mlptrainer__owner}{\_mlptrainer\_owner}} \&rhs);}
\DoxyCodeLine{1557     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1__mlptrainer__owner}{\string~\_mlptrainer\_owner}}();}
\DoxyCodeLine{1558     \mbox{\hyperlink{structalglib__impl_1_1mlptrainer}{alglib\_impl::mlptrainer}}* c\_ptr();}
\DoxyCodeLine{1559     \mbox{\hyperlink{structalglib__impl_1_1mlptrainer}{alglib\_impl::mlptrainer}}* c\_ptr() \textcolor{keyword}{const};}
\DoxyCodeLine{1560 \textcolor{keyword}{protected}:}
\DoxyCodeLine{1561     \mbox{\hyperlink{structalglib__impl_1_1mlptrainer}{alglib\_impl::mlptrainer}} *p\_struct;}
\DoxyCodeLine{1562 \};}
\DoxyCodeLine{1563 \textcolor{keyword}{class }\mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}} : \textcolor{keyword}{public} \mbox{\hyperlink{classalglib_1_1__mlptrainer__owner}{\_mlptrainer\_owner}}}
\DoxyCodeLine{1564 \{}
\DoxyCodeLine{1565 \textcolor{keyword}{public}:}
\DoxyCodeLine{1566     \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}}();}
\DoxyCodeLine{1567     \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}}(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}} \&rhs);}
\DoxyCodeLine{1568     \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}}\& operator=(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}} \&rhs);}
\DoxyCodeLine{1569     \textcolor{keyword}{virtual} \mbox{\hyperlink{classalglib_1_1mlptrainer}{\string~mlptrainer}}();}
\DoxyCodeLine{1570 }
\DoxyCodeLine{1571 \};}
\DoxyCodeLine{1572 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{1573 }
\DoxyCodeLine{1574 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_DATACOMP) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{1575 }
\DoxyCodeLine{1576 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{1577 }
\DoxyCodeLine{1578 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_PCA) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{1579 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1580 \textcolor{comment}{Principal components analysis}}
\DoxyCodeLine{1581 \textcolor{comment}{}}
\DoxyCodeLine{1582 \textcolor{comment}{This function builds orthogonal basis  where  first  axis  corresponds  to}}
\DoxyCodeLine{1583 \textcolor{comment}{direction with maximum variance, second axis  maximizes  variance  in  the}}
\DoxyCodeLine{1584 \textcolor{comment}{subspace orthogonal to first axis and so on.}}
\DoxyCodeLine{1585 \textcolor{comment}{}}
\DoxyCodeLine{1586 \textcolor{comment}{This function builds FULL basis, i.e. returns N vectors  corresponding  to}}
\DoxyCodeLine{1587 \textcolor{comment}{ALL directions, no matter how informative. If you need  just a  few  (say,}}
\DoxyCodeLine{1588 \textcolor{comment}{10 or 50) of the most important directions, you may find it faster to  use}}
\DoxyCodeLine{1589 \textcolor{comment}{one of the reduced versions:}}
\DoxyCodeLine{1590 \textcolor{comment}{* pcatruncatedsubspace() -\/ for subspace iteration based method}}
\DoxyCodeLine{1591 \textcolor{comment}{}}
\DoxyCodeLine{1592 \textcolor{comment}{It should be noted that, unlike LDA, PCA does not use class labels.}}
\DoxyCodeLine{1593 \textcolor{comment}{}}
\DoxyCodeLine{1594 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{1595 \textcolor{comment}{    X           -\/   dataset, array[0..NPoints-\/1,0..NVars-\/1].}}
\DoxyCodeLine{1596 \textcolor{comment}{                    matrix contains ONLY INDEPENDENT VARIABLES.}}
\DoxyCodeLine{1597 \textcolor{comment}{    NPoints     -\/   dataset size, NPoints>=0}}
\DoxyCodeLine{1598 \textcolor{comment}{    NVars       -\/   number of independent variables, NVars>=1}}
\DoxyCodeLine{1599 \textcolor{comment}{}}
\DoxyCodeLine{1600 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{1601 \textcolor{comment}{    Info        -\/   return code:}}
\DoxyCodeLine{1602 \textcolor{comment}{                    * -\/4, if SVD subroutine haven't converged}}
\DoxyCodeLine{1603 \textcolor{comment}{                    * -\/1, if wrong parameters has been passed (NPoints<0,}}
\DoxyCodeLine{1604 \textcolor{comment}{                          NVars<1)}}
\DoxyCodeLine{1605 \textcolor{comment}{                    *  1, if task is solved}}
\DoxyCodeLine{1606 \textcolor{comment}{    S2          -\/   array[0..NVars-\/1]. variance values corresponding}}
\DoxyCodeLine{1607 \textcolor{comment}{                    to basis vectors.}}
\DoxyCodeLine{1608 \textcolor{comment}{    V           -\/   array[0..NVars-\/1,0..NVars-\/1]}}
\DoxyCodeLine{1609 \textcolor{comment}{                    matrix, whose columns store basis vectors.}}
\DoxyCodeLine{1610 \textcolor{comment}{}}
\DoxyCodeLine{1611 \textcolor{comment}{  ! FREE EDITION OF ALGLIB:}}
\DoxyCodeLine{1612 \textcolor{comment}{  !}}
\DoxyCodeLine{1613 \textcolor{comment}{  ! Free Edition of ALGLIB supports following important features for  this}}
\DoxyCodeLine{1614 \textcolor{comment}{  ! function:}}
\DoxyCodeLine{1615 \textcolor{comment}{  ! * C++ version: x64 SIMD support using C++ intrinsics}}
\DoxyCodeLine{1616 \textcolor{comment}{  ! * C\#  version: x64 SIMD support using NET5/NetCore hardware intrinsics}}
\DoxyCodeLine{1617 \textcolor{comment}{  !}}
\DoxyCodeLine{1618 \textcolor{comment}{  ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB}}
\DoxyCodeLine{1619 \textcolor{comment}{  ! Reference Manual in order  to  find  out  how to activate SIMD support}}
\DoxyCodeLine{1620 \textcolor{comment}{  ! in ALGLIB.}}
\DoxyCodeLine{1621 \textcolor{comment}{}}
\DoxyCodeLine{1622 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{1623 \textcolor{comment}{  !}}
\DoxyCodeLine{1624 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{1625 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{1626 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{1627 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{1628 \textcolor{comment}{  ! * hardware vendor (Intel) implementations of linear algebra primitives}}
\DoxyCodeLine{1629 \textcolor{comment}{  !   (C++ and C\# versions, x86/x64 platform)}}
\DoxyCodeLine{1630 \textcolor{comment}{  !}}
\DoxyCodeLine{1631 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{1632 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{1633 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{1634 \textcolor{comment}{}}
\DoxyCodeLine{1635 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{1636 \textcolor{comment}{     Copyright 25.08.2008 by Bochkanov Sergey}}
\DoxyCodeLine{1637 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1638 \textcolor{keywordtype}{void} pcabuildbasis(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&x, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nvars, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&s2, \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&v, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{1639 }
\DoxyCodeLine{1640 }
\DoxyCodeLine{1641 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1642 \textcolor{comment}{Principal components analysis}}
\DoxyCodeLine{1643 \textcolor{comment}{}}
\DoxyCodeLine{1644 \textcolor{comment}{This function performs truncated PCA, i.e. returns just a few most important}}
\DoxyCodeLine{1645 \textcolor{comment}{directions.}}
\DoxyCodeLine{1646 \textcolor{comment}{}}
\DoxyCodeLine{1647 \textcolor{comment}{Internally it uses iterative eigensolver which is very efficient when only}}
\DoxyCodeLine{1648 \textcolor{comment}{a minor fraction of full basis is required. Thus, if you need full  basis,}}
\DoxyCodeLine{1649 \textcolor{comment}{it is better to use pcabuildbasis() function.}}
\DoxyCodeLine{1650 \textcolor{comment}{}}
\DoxyCodeLine{1651 \textcolor{comment}{It should be noted that, unlike LDA, PCA does not use class labels.}}
\DoxyCodeLine{1652 \textcolor{comment}{}}
\DoxyCodeLine{1653 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{1654 \textcolor{comment}{    X           -\/   dataset, array[0..NPoints-\/1,0..NVars-\/1].}}
\DoxyCodeLine{1655 \textcolor{comment}{                    matrix contains ONLY INDEPENDENT VARIABLES.}}
\DoxyCodeLine{1656 \textcolor{comment}{    NPoints     -\/   dataset size, NPoints>=0}}
\DoxyCodeLine{1657 \textcolor{comment}{    NVars       -\/   number of independent variables, NVars>=1}}
\DoxyCodeLine{1658 \textcolor{comment}{    NNeeded     -\/   number of requested components, in [1,NVars] range;}}
\DoxyCodeLine{1659 \textcolor{comment}{                    this function is efficient only for NNeeded<<NVars.}}
\DoxyCodeLine{1660 \textcolor{comment}{    Eps         -\/   desired  precision  of  vectors  returned;  underlying}}
\DoxyCodeLine{1661 \textcolor{comment}{                    solver will stop iterations as soon as absolute  error}}
\DoxyCodeLine{1662 \textcolor{comment}{                    in corresponding singular values  reduces  to  roughly}}
\DoxyCodeLine{1663 \textcolor{comment}{                    eps*MAX(lambda[]), with lambda[] being array of  eigen}}
\DoxyCodeLine{1664 \textcolor{comment}{                    values.}}
\DoxyCodeLine{1665 \textcolor{comment}{                    Zero value means that  algorithm  performs  number  of}}
\DoxyCodeLine{1666 \textcolor{comment}{                    iterations  specified  by  maxits  parameter,  without}}
\DoxyCodeLine{1667 \textcolor{comment}{                    paying attention to precision.}}
\DoxyCodeLine{1668 \textcolor{comment}{    MaxIts      -\/   number of iterations performed by  subspace  iteration}}
\DoxyCodeLine{1669 \textcolor{comment}{                    method. Zero value means that no  limit  on  iteration}}
\DoxyCodeLine{1670 \textcolor{comment}{                    count is placed (eps-\/based stopping condition is used).}}
\DoxyCodeLine{1671 \textcolor{comment}{}}
\DoxyCodeLine{1672 \textcolor{comment}{}}
\DoxyCodeLine{1673 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{1674 \textcolor{comment}{    S2          -\/   array[NNeeded]. Variance values corresponding}}
\DoxyCodeLine{1675 \textcolor{comment}{                    to basis vectors.}}
\DoxyCodeLine{1676 \textcolor{comment}{    V           -\/   array[NVars,NNeeded]}}
\DoxyCodeLine{1677 \textcolor{comment}{                    matrix, whose columns store basis vectors.}}
\DoxyCodeLine{1678 \textcolor{comment}{}}
\DoxyCodeLine{1679 \textcolor{comment}{NOTE: passing eps=0 and maxits=0 results in small eps  being  selected  as}}
\DoxyCodeLine{1680 \textcolor{comment}{stopping condition. Exact value of automatically selected eps is  version-\/}}
\DoxyCodeLine{1681 \textcolor{comment}{-\/dependent.}}
\DoxyCodeLine{1682 \textcolor{comment}{}}
\DoxyCodeLine{1683 \textcolor{comment}{  ! FREE EDITION OF ALGLIB:}}
\DoxyCodeLine{1684 \textcolor{comment}{  !}}
\DoxyCodeLine{1685 \textcolor{comment}{  ! Free Edition of ALGLIB supports following important features for  this}}
\DoxyCodeLine{1686 \textcolor{comment}{  ! function:}}
\DoxyCodeLine{1687 \textcolor{comment}{  ! * C++ version: x64 SIMD support using C++ intrinsics}}
\DoxyCodeLine{1688 \textcolor{comment}{  ! * C\#  version: x64 SIMD support using NET5/NetCore hardware intrinsics}}
\DoxyCodeLine{1689 \textcolor{comment}{  !}}
\DoxyCodeLine{1690 \textcolor{comment}{  ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB}}
\DoxyCodeLine{1691 \textcolor{comment}{  ! Reference Manual in order  to  find  out  how to activate SIMD support}}
\DoxyCodeLine{1692 \textcolor{comment}{  ! in ALGLIB.}}
\DoxyCodeLine{1693 \textcolor{comment}{}}
\DoxyCodeLine{1694 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{1695 \textcolor{comment}{  !}}
\DoxyCodeLine{1696 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{1697 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{1698 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{1699 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{1700 \textcolor{comment}{  ! * hardware vendor (Intel) implementations of linear algebra primitives}}
\DoxyCodeLine{1701 \textcolor{comment}{  !   (C++ and C\# versions, x86/x64 platform)}}
\DoxyCodeLine{1702 \textcolor{comment}{  !}}
\DoxyCodeLine{1703 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{1704 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{1705 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{1706 \textcolor{comment}{}}
\DoxyCodeLine{1707 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{1708 \textcolor{comment}{     Copyright 10.01.2017 by Bochkanov Sergey}}
\DoxyCodeLine{1709 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1710 \textcolor{keywordtype}{void} pcatruncatedsubspace(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&x, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nvars, \textcolor{keyword}{const} ae\_int\_t nneeded, \textcolor{keyword}{const} \textcolor{keywordtype}{double} eps, \textcolor{keyword}{const} ae\_int\_t maxits, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&s2, \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&v, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{1711 }
\DoxyCodeLine{1712 }
\DoxyCodeLine{1713 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1714 \textcolor{comment}{Sparse truncated principal components analysis}}
\DoxyCodeLine{1715 \textcolor{comment}{}}
\DoxyCodeLine{1716 \textcolor{comment}{This function performs sparse truncated PCA, i.e. returns just a few  most}}
\DoxyCodeLine{1717 \textcolor{comment}{important principal components for a sparse input X.}}
\DoxyCodeLine{1718 \textcolor{comment}{}}
\DoxyCodeLine{1719 \textcolor{comment}{Internally it uses iterative eigensolver which is very efficient when only}}
\DoxyCodeLine{1720 \textcolor{comment}{a minor fraction of full basis is required.}}
\DoxyCodeLine{1721 \textcolor{comment}{}}
\DoxyCodeLine{1722 \textcolor{comment}{It should be noted that, unlike LDA, PCA does not use class labels.}}
\DoxyCodeLine{1723 \textcolor{comment}{}}
\DoxyCodeLine{1724 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{1725 \textcolor{comment}{    X           -\/   sparse dataset, sparse  npoints*nvars  matrix.  It  is}}
\DoxyCodeLine{1726 \textcolor{comment}{                    recommended to use CRS sparse storage format;  non-\/CRS}}
\DoxyCodeLine{1727 \textcolor{comment}{                    input will be internally converted to CRS.}}
\DoxyCodeLine{1728 \textcolor{comment}{                    Matrix contains ONLY INDEPENDENT VARIABLES,  and  must}}
\DoxyCodeLine{1729 \textcolor{comment}{                    be EXACTLY npoints*nvars.}}
\DoxyCodeLine{1730 \textcolor{comment}{    NPoints     -\/   dataset size, NPoints>=0}}
\DoxyCodeLine{1731 \textcolor{comment}{    NVars       -\/   number of independent variables, NVars>=1}}
\DoxyCodeLine{1732 \textcolor{comment}{    NNeeded     -\/   number of requested components, in [1,NVars] range;}}
\DoxyCodeLine{1733 \textcolor{comment}{                    this function is efficient only for NNeeded<<NVars.}}
\DoxyCodeLine{1734 \textcolor{comment}{    Eps         -\/   desired  precision  of  vectors  returned;  underlying}}
\DoxyCodeLine{1735 \textcolor{comment}{                    solver will stop iterations as soon as absolute  error}}
\DoxyCodeLine{1736 \textcolor{comment}{                    in corresponding singular values  reduces  to  roughly}}
\DoxyCodeLine{1737 \textcolor{comment}{                    eps*MAX(lambda[]), with lambda[] being array of  eigen}}
\DoxyCodeLine{1738 \textcolor{comment}{                    values.}}
\DoxyCodeLine{1739 \textcolor{comment}{                    Zero value means that  algorithm  performs  number  of}}
\DoxyCodeLine{1740 \textcolor{comment}{                    iterations  specified  by  maxits  parameter,  without}}
\DoxyCodeLine{1741 \textcolor{comment}{                    paying attention to precision.}}
\DoxyCodeLine{1742 \textcolor{comment}{    MaxIts      -\/   number of iterations performed by  subspace  iteration}}
\DoxyCodeLine{1743 \textcolor{comment}{                    method. Zero value means that no  limit  on  iteration}}
\DoxyCodeLine{1744 \textcolor{comment}{                    count is placed (eps-\/based stopping condition is used).}}
\DoxyCodeLine{1745 \textcolor{comment}{}}
\DoxyCodeLine{1746 \textcolor{comment}{}}
\DoxyCodeLine{1747 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{1748 \textcolor{comment}{    S2          -\/   array[NNeeded]. Variance values corresponding}}
\DoxyCodeLine{1749 \textcolor{comment}{                    to basis vectors.}}
\DoxyCodeLine{1750 \textcolor{comment}{    V           -\/   array[NVars,NNeeded]}}
\DoxyCodeLine{1751 \textcolor{comment}{                    matrix, whose columns store basis vectors.}}
\DoxyCodeLine{1752 \textcolor{comment}{}}
\DoxyCodeLine{1753 \textcolor{comment}{NOTE: passing eps=0 and maxits=0 results in small eps  being  selected  as}}
\DoxyCodeLine{1754 \textcolor{comment}{      a stopping condition. Exact value of automatically selected  eps  is}}
\DoxyCodeLine{1755 \textcolor{comment}{      version-\/dependent.}}
\DoxyCodeLine{1756 \textcolor{comment}{}}
\DoxyCodeLine{1757 \textcolor{comment}{NOTE: zero  MaxIts  is  silently  replaced  by some reasonable value which}}
\DoxyCodeLine{1758 \textcolor{comment}{      prevents eternal loops (possible when inputs are degenerate and  too}}
\DoxyCodeLine{1759 \textcolor{comment}{      stringent stopping criteria are specified). In  current  version  it}}
\DoxyCodeLine{1760 \textcolor{comment}{      is 50+2*NVars.}}
\DoxyCodeLine{1761 \textcolor{comment}{}}
\DoxyCodeLine{1762 \textcolor{comment}{  ! FREE EDITION OF ALGLIB:}}
\DoxyCodeLine{1763 \textcolor{comment}{  !}}
\DoxyCodeLine{1764 \textcolor{comment}{  ! Free Edition of ALGLIB supports following important features for  this}}
\DoxyCodeLine{1765 \textcolor{comment}{  ! function:}}
\DoxyCodeLine{1766 \textcolor{comment}{  ! * C++ version: x64 SIMD support using C++ intrinsics}}
\DoxyCodeLine{1767 \textcolor{comment}{  ! * C\#  version: x64 SIMD support using NET5/NetCore hardware intrinsics}}
\DoxyCodeLine{1768 \textcolor{comment}{  !}}
\DoxyCodeLine{1769 \textcolor{comment}{  ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB}}
\DoxyCodeLine{1770 \textcolor{comment}{  ! Reference Manual in order  to  find  out  how to activate SIMD support}}
\DoxyCodeLine{1771 \textcolor{comment}{  ! in ALGLIB.}}
\DoxyCodeLine{1772 \textcolor{comment}{}}
\DoxyCodeLine{1773 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{1774 \textcolor{comment}{  !}}
\DoxyCodeLine{1775 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{1776 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{1777 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{1778 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{1779 \textcolor{comment}{  ! * hardware vendor (Intel) implementations of linear algebra primitives}}
\DoxyCodeLine{1780 \textcolor{comment}{  !   (C++ and C\# versions, x86/x64 platform)}}
\DoxyCodeLine{1781 \textcolor{comment}{  !}}
\DoxyCodeLine{1782 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{1783 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{1784 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{1785 \textcolor{comment}{}}
\DoxyCodeLine{1786 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{1787 \textcolor{comment}{     Copyright 10.01.2017 by Bochkanov Sergey}}
\DoxyCodeLine{1788 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1789 \textcolor{keywordtype}{void} pcatruncatedsubspacesparse(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1sparsematrix}{sparsematrix}} \&x, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nvars, \textcolor{keyword}{const} ae\_int\_t nneeded, \textcolor{keyword}{const} \textcolor{keywordtype}{double} eps, \textcolor{keyword}{const} ae\_int\_t maxits, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&s2, \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&v, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{1790 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{1791 }
\DoxyCodeLine{1792 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_BDSS) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{1793 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1794 \textcolor{comment}{Optimal binary classification}}
\DoxyCodeLine{1795 \textcolor{comment}{}}
\DoxyCodeLine{1796 \textcolor{comment}{Algorithms finds optimal (=with minimal cross-\/entropy) binary partition.}}
\DoxyCodeLine{1797 \textcolor{comment}{Internal subroutine.}}
\DoxyCodeLine{1798 \textcolor{comment}{}}
\DoxyCodeLine{1799 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{1800 \textcolor{comment}{    A       -\/   array[0..N-\/1], variable}}
\DoxyCodeLine{1801 \textcolor{comment}{    C       -\/   array[0..N-\/1], class numbers (0 or 1).}}
\DoxyCodeLine{1802 \textcolor{comment}{    N       -\/   array size}}
\DoxyCodeLine{1803 \textcolor{comment}{}}
\DoxyCodeLine{1804 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{1805 \textcolor{comment}{    Info    -\/   completetion code:}}
\DoxyCodeLine{1806 \textcolor{comment}{                * -\/3, all values of A[] are same (partition is impossible)}}
\DoxyCodeLine{1807 \textcolor{comment}{                * -\/2, one of C[] is incorrect (<0, >1)}}
\DoxyCodeLine{1808 \textcolor{comment}{                * -\/1, incorrect pararemets were passed (N<=0).}}
\DoxyCodeLine{1809 \textcolor{comment}{                *  1, OK}}
\DoxyCodeLine{1810 \textcolor{comment}{    Threshold-\/  partiton boundary. Left part contains values which are}}
\DoxyCodeLine{1811 \textcolor{comment}{                strictly less than Threshold. Right part contains values}}
\DoxyCodeLine{1812 \textcolor{comment}{                which are greater than or equal to Threshold.}}
\DoxyCodeLine{1813 \textcolor{comment}{    PAL, PBL-\/   probabilities P(0|v<Threshold) and P(1|v<Threshold)}}
\DoxyCodeLine{1814 \textcolor{comment}{    PAR, PBR-\/   probabilities P(0|v>=Threshold) and P(1|v>=Threshold)}}
\DoxyCodeLine{1815 \textcolor{comment}{    CVE     -\/   cross-\/validation estimate of cross-\/entropy}}
\DoxyCodeLine{1816 \textcolor{comment}{}}
\DoxyCodeLine{1817 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{1818 \textcolor{comment}{     Copyright 22.05.2008 by Bochkanov Sergey}}
\DoxyCodeLine{1819 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1820 \textcolor{keywordtype}{void} dsoptimalsplit2(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&a, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&c, \textcolor{keyword}{const} ae\_int\_t n, ae\_int\_t \&info, \textcolor{keywordtype}{double} \&threshold, \textcolor{keywordtype}{double} \&pal, \textcolor{keywordtype}{double} \&pbl, \textcolor{keywordtype}{double} \&par, \textcolor{keywordtype}{double} \&pbr, \textcolor{keywordtype}{double} \&cve, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{1821 }
\DoxyCodeLine{1822 }
\DoxyCodeLine{1823 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1824 \textcolor{comment}{Optimal partition, internal subroutine. Fast version.}}
\DoxyCodeLine{1825 \textcolor{comment}{}}
\DoxyCodeLine{1826 \textcolor{comment}{Accepts:}}
\DoxyCodeLine{1827 \textcolor{comment}{    A       array[0..N-\/1]       array of attributes     array[0..N-\/1]}}
\DoxyCodeLine{1828 \textcolor{comment}{    C       array[0..N-\/1]       array of class labels}}
\DoxyCodeLine{1829 \textcolor{comment}{    TiesBuf array[0..N]         temporaries (ties)}}
\DoxyCodeLine{1830 \textcolor{comment}{    CntBuf  array[0..2*NC-\/1]    temporaries (counts)}}
\DoxyCodeLine{1831 \textcolor{comment}{    Alpha                       centering factor (0<=alpha<=1, recommended value -\/ 0.05)}}
\DoxyCodeLine{1832 \textcolor{comment}{    BufR    array[0..N-\/1]       temporaries}}
\DoxyCodeLine{1833 \textcolor{comment}{    BufI    array[0..N-\/1]       temporaries}}
\DoxyCodeLine{1834 \textcolor{comment}{}}
\DoxyCodeLine{1835 \textcolor{comment}{Output:}}
\DoxyCodeLine{1836 \textcolor{comment}{    Info    error code ("{}>0"{}=OK, "{}<0"{}=bad)}}
\DoxyCodeLine{1837 \textcolor{comment}{    RMS     training set RMS error}}
\DoxyCodeLine{1838 \textcolor{comment}{    CVRMS   leave-\/one-\/out RMS error}}
\DoxyCodeLine{1839 \textcolor{comment}{}}
\DoxyCodeLine{1840 \textcolor{comment}{Note:}}
\DoxyCodeLine{1841 \textcolor{comment}{    content of all arrays is changed by subroutine;}}
\DoxyCodeLine{1842 \textcolor{comment}{    it doesn't allocate temporaries.}}
\DoxyCodeLine{1843 \textcolor{comment}{}}
\DoxyCodeLine{1844 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{1845 \textcolor{comment}{     Copyright 11.12.2008 by Bochkanov Sergey}}
\DoxyCodeLine{1846 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1847 \textcolor{keywordtype}{void} dsoptimalsplit2fast(\mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&a, \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&c, \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&tiesbuf, \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&cntbuf, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&bufr, \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&bufi, \textcolor{keyword}{const} ae\_int\_t n, \textcolor{keyword}{const} ae\_int\_t nc, \textcolor{keyword}{const} \textcolor{keywordtype}{double} alpha, ae\_int\_t \&info, \textcolor{keywordtype}{double} \&threshold, \textcolor{keywordtype}{double} \&rms, \textcolor{keywordtype}{double} \&cvrms, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{1848 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{1849 }
\DoxyCodeLine{1850 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_MLPBASE) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{1851 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1852 \textcolor{comment}{This function serializes data structure to string.}}
\DoxyCodeLine{1853 \textcolor{comment}{}}
\DoxyCodeLine{1854 \textcolor{comment}{Important properties of s\_out:}}
\DoxyCodeLine{1855 \textcolor{comment}{* it contains alphanumeric characters, dots, underscores, minus signs}}
\DoxyCodeLine{1856 \textcolor{comment}{* these symbols are grouped into words, which are separated by spaces}}
\DoxyCodeLine{1857 \textcolor{comment}{  and Windows-\/style (CR+LF) newlines}}
\DoxyCodeLine{1858 \textcolor{comment}{* although  serializer  uses  spaces and CR+LF as separators, you can }}
\DoxyCodeLine{1859 \textcolor{comment}{  replace any separator character by arbitrary combination of spaces,}}
\DoxyCodeLine{1860 \textcolor{comment}{  tabs, Windows or Unix newlines. It allows flexible reformatting  of}}
\DoxyCodeLine{1861 \textcolor{comment}{  the  string  in  case you want to include it into text or XML file. }}
\DoxyCodeLine{1862 \textcolor{comment}{  But you should not insert separators into the middle of the "{}words"{}}}
\DoxyCodeLine{1863 \textcolor{comment}{  nor you should change case of letters.}}
\DoxyCodeLine{1864 \textcolor{comment}{* s\_out can be freely moved between 32-\/bit and 64-\/bit systems, little}}
\DoxyCodeLine{1865 \textcolor{comment}{  and big endian machines, and so on. You can serialize structure  on}}
\DoxyCodeLine{1866 \textcolor{comment}{  32-\/bit machine and unserialize it on 64-\/bit one (or vice versa), or}}
\DoxyCodeLine{1867 \textcolor{comment}{  serialize  it  on  SPARC  and  unserialize  on  x86.  You  can also }}
\DoxyCodeLine{1868 \textcolor{comment}{  serialize  it  in  C++ version of ALGLIB and unserialize in C\# one, }}
\DoxyCodeLine{1869 \textcolor{comment}{  and vice versa.}}
\DoxyCodeLine{1870 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1871 \textcolor{keywordtype}{void} mlpserialize(\mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&obj, std::string \&s\_out);}
\DoxyCodeLine{1872 }
\DoxyCodeLine{1873 }
\DoxyCodeLine{1874 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1875 \textcolor{comment}{This function unserializes data structure from string.}}
\DoxyCodeLine{1876 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1877 \textcolor{keywordtype}{void} mlpunserialize(\textcolor{keyword}{const} std::string \&s\_in, \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&obj);}
\DoxyCodeLine{1878 }
\DoxyCodeLine{1879 }
\DoxyCodeLine{1880 }
\DoxyCodeLine{1881 }
\DoxyCodeLine{1882 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1883 \textcolor{comment}{This function serializes data structure to C++ stream.}}
\DoxyCodeLine{1884 \textcolor{comment}{}}
\DoxyCodeLine{1885 \textcolor{comment}{Data stream generated by this function is same as  string  representation}}
\DoxyCodeLine{1886 \textcolor{comment}{generated  by  string  version  of  serializer -\/ alphanumeric characters,}}
\DoxyCodeLine{1887 \textcolor{comment}{dots, underscores, minus signs, which are grouped into words separated by}}
\DoxyCodeLine{1888 \textcolor{comment}{spaces and CR+LF.}}
\DoxyCodeLine{1889 \textcolor{comment}{}}
\DoxyCodeLine{1890 \textcolor{comment}{We recommend you to read comments on string version of serializer to find}}
\DoxyCodeLine{1891 \textcolor{comment}{out more about serialization of AlGLIB objects.}}
\DoxyCodeLine{1892 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1893 \textcolor{keywordtype}{void} mlpserialize(\mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&obj, std::ostream \&s\_out);}
\DoxyCodeLine{1894 }
\DoxyCodeLine{1895 }
\DoxyCodeLine{1896 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1897 \textcolor{comment}{This function unserializes data structure from stream.}}
\DoxyCodeLine{1898 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1899 \textcolor{keywordtype}{void} mlpunserialize(\textcolor{keyword}{const} std::istream \&s\_in, \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&obj);}
\DoxyCodeLine{1900 }
\DoxyCodeLine{1901 }
\DoxyCodeLine{1902 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1903 \textcolor{comment}{Creates  neural  network  with  NIn  inputs,  NOut outputs, without hidden}}
\DoxyCodeLine{1904 \textcolor{comment}{layers, with linear output layer. Network weights are  filled  with  small}}
\DoxyCodeLine{1905 \textcolor{comment}{random values.}}
\DoxyCodeLine{1906 \textcolor{comment}{}}
\DoxyCodeLine{1907 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{1908 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{1909 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1910 \textcolor{keywordtype}{void} mlpcreate0(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nout, \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{1911 }
\DoxyCodeLine{1912 }
\DoxyCodeLine{1913 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1914 \textcolor{comment}{Same  as  MLPCreate0,  but  with  one  hidden  layer  (NHid  neurons) with}}
\DoxyCodeLine{1915 \textcolor{comment}{non-\/linear activation function. Output layer is linear.}}
\DoxyCodeLine{1916 \textcolor{comment}{}}
\DoxyCodeLine{1917 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{1918 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{1919 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1920 \textcolor{keywordtype}{void} mlpcreate1(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nhid, \textcolor{keyword}{const} ae\_int\_t nout, \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{1921 }
\DoxyCodeLine{1922 }
\DoxyCodeLine{1923 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1924 \textcolor{comment}{Same as MLPCreate0, but with two hidden layers (NHid1 and  NHid2  neurons)}}
\DoxyCodeLine{1925 \textcolor{comment}{with non-\/linear activation function. Output layer is linear.}}
\DoxyCodeLine{1926 \textcolor{comment}{ \$ALL}}
\DoxyCodeLine{1927 \textcolor{comment}{}}
\DoxyCodeLine{1928 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{1929 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{1930 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1931 \textcolor{keywordtype}{void} mlpcreate2(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nhid1, \textcolor{keyword}{const} ae\_int\_t nhid2, \textcolor{keyword}{const} ae\_int\_t nout, \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{1932 }
\DoxyCodeLine{1933 }
\DoxyCodeLine{1934 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1935 \textcolor{comment}{Creates  neural  network  with  NIn  inputs,  NOut outputs, without hidden}}
\DoxyCodeLine{1936 \textcolor{comment}{layers with non-\/linear output layer. Network weights are filled with small}}
\DoxyCodeLine{1937 \textcolor{comment}{random values.}}
\DoxyCodeLine{1938 \textcolor{comment}{}}
\DoxyCodeLine{1939 \textcolor{comment}{Activation function of the output layer takes values:}}
\DoxyCodeLine{1940 \textcolor{comment}{}}
\DoxyCodeLine{1941 \textcolor{comment}{    (B, +INF), if D>=0}}
\DoxyCodeLine{1942 \textcolor{comment}{}}
\DoxyCodeLine{1943 \textcolor{comment}{or}}
\DoxyCodeLine{1944 \textcolor{comment}{}}
\DoxyCodeLine{1945 \textcolor{comment}{    (-\/INF, B), if D<0.}}
\DoxyCodeLine{1946 \textcolor{comment}{}}
\DoxyCodeLine{1947 \textcolor{comment}{}}
\DoxyCodeLine{1948 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{1949 \textcolor{comment}{     Copyright 30.03.2008 by Bochkanov Sergey}}
\DoxyCodeLine{1950 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1951 \textcolor{keywordtype}{void} mlpcreateb0(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} \textcolor{keywordtype}{double} b, \textcolor{keyword}{const} \textcolor{keywordtype}{double} d, \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{1952 }
\DoxyCodeLine{1953 }
\DoxyCodeLine{1954 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1955 \textcolor{comment}{Same as MLPCreateB0 but with non-\/linear hidden layer.}}
\DoxyCodeLine{1956 \textcolor{comment}{}}
\DoxyCodeLine{1957 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{1958 \textcolor{comment}{     Copyright 30.03.2008 by Bochkanov Sergey}}
\DoxyCodeLine{1959 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1960 \textcolor{keywordtype}{void} mlpcreateb1(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nhid, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} \textcolor{keywordtype}{double} b, \textcolor{keyword}{const} \textcolor{keywordtype}{double} d, \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{1961 }
\DoxyCodeLine{1962 }
\DoxyCodeLine{1963 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1964 \textcolor{comment}{Same as MLPCreateB0 but with two non-\/linear hidden layers.}}
\DoxyCodeLine{1965 \textcolor{comment}{}}
\DoxyCodeLine{1966 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{1967 \textcolor{comment}{     Copyright 30.03.2008 by Bochkanov Sergey}}
\DoxyCodeLine{1968 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1969 \textcolor{keywordtype}{void} mlpcreateb2(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nhid1, \textcolor{keyword}{const} ae\_int\_t nhid2, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} \textcolor{keywordtype}{double} b, \textcolor{keyword}{const} \textcolor{keywordtype}{double} d, \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{1970 }
\DoxyCodeLine{1971 }
\DoxyCodeLine{1972 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1973 \textcolor{comment}{Creates  neural  network  with  NIn  inputs,  NOut outputs, without hidden}}
\DoxyCodeLine{1974 \textcolor{comment}{layers with non-\/linear output layer. Network weights are filled with small}}
\DoxyCodeLine{1975 \textcolor{comment}{random values. Activation function of the output layer takes values [A,B].}}
\DoxyCodeLine{1976 \textcolor{comment}{}}
\DoxyCodeLine{1977 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{1978 \textcolor{comment}{     Copyright 30.03.2008 by Bochkanov Sergey}}
\DoxyCodeLine{1979 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1980 \textcolor{keywordtype}{void} mlpcreater0(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} \textcolor{keywordtype}{double} a, \textcolor{keyword}{const} \textcolor{keywordtype}{double} b, \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{1981 }
\DoxyCodeLine{1982 }
\DoxyCodeLine{1983 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1984 \textcolor{comment}{Same as MLPCreateR0, but with non-\/linear hidden layer.}}
\DoxyCodeLine{1985 \textcolor{comment}{}}
\DoxyCodeLine{1986 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{1987 \textcolor{comment}{     Copyright 30.03.2008 by Bochkanov Sergey}}
\DoxyCodeLine{1988 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1989 \textcolor{keywordtype}{void} mlpcreater1(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nhid, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} \textcolor{keywordtype}{double} a, \textcolor{keyword}{const} \textcolor{keywordtype}{double} b, \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{1990 }
\DoxyCodeLine{1991 }
\DoxyCodeLine{1992 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{1993 \textcolor{comment}{Same as MLPCreateR0, but with two non-\/linear hidden layers.}}
\DoxyCodeLine{1994 \textcolor{comment}{}}
\DoxyCodeLine{1995 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{1996 \textcolor{comment}{     Copyright 30.03.2008 by Bochkanov Sergey}}
\DoxyCodeLine{1997 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{1998 \textcolor{keywordtype}{void} mlpcreater2(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nhid1, \textcolor{keyword}{const} ae\_int\_t nhid2, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} \textcolor{keywordtype}{double} a, \textcolor{keyword}{const} \textcolor{keywordtype}{double} b, \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{1999 }
\DoxyCodeLine{2000 }
\DoxyCodeLine{2001 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2002 \textcolor{comment}{Creates classifier network with NIn  inputs  and  NOut  possible  classes.}}
\DoxyCodeLine{2003 \textcolor{comment}{Network contains no hidden layers and linear output  layer  with  SOFTMAX-\/}}
\DoxyCodeLine{2004 \textcolor{comment}{normalization  (so  outputs  sums  up  to  1.0  and  converge to posterior}}
\DoxyCodeLine{2005 \textcolor{comment}{probabilities).}}
\DoxyCodeLine{2006 \textcolor{comment}{}}
\DoxyCodeLine{2007 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2008 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{2009 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2010 \textcolor{keywordtype}{void} mlpcreatec0(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nout, \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2011 }
\DoxyCodeLine{2012 }
\DoxyCodeLine{2013 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2014 \textcolor{comment}{Same as MLPCreateC0, but with one non-\/linear hidden layer.}}
\DoxyCodeLine{2015 \textcolor{comment}{}}
\DoxyCodeLine{2016 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2017 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{2018 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2019 \textcolor{keywordtype}{void} mlpcreatec1(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nhid, \textcolor{keyword}{const} ae\_int\_t nout, \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2020 }
\DoxyCodeLine{2021 }
\DoxyCodeLine{2022 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2023 \textcolor{comment}{Same as MLPCreateC0, but with two non-\/linear hidden layers.}}
\DoxyCodeLine{2024 \textcolor{comment}{}}
\DoxyCodeLine{2025 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2026 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{2027 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2028 \textcolor{keywordtype}{void} mlpcreatec2(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nhid1, \textcolor{keyword}{const} ae\_int\_t nhid2, \textcolor{keyword}{const} ae\_int\_t nout, \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2029 }
\DoxyCodeLine{2030 }
\DoxyCodeLine{2031 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2032 \textcolor{comment}{Copying of neural network}}
\DoxyCodeLine{2033 \textcolor{comment}{}}
\DoxyCodeLine{2034 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2035 \textcolor{comment}{    Network1 -\/   original}}
\DoxyCodeLine{2036 \textcolor{comment}{}}
\DoxyCodeLine{2037 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{2038 \textcolor{comment}{    Network2 -\/   copy}}
\DoxyCodeLine{2039 \textcolor{comment}{}}
\DoxyCodeLine{2040 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2041 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{2042 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2043 \textcolor{keywordtype}{void} mlpcopy(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network1, \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network2, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2044 }
\DoxyCodeLine{2045 }
\DoxyCodeLine{2046 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2047 \textcolor{comment}{This function copies tunable  parameters (weights/means/sigmas)  from  one}}
\DoxyCodeLine{2048 \textcolor{comment}{network to another with same architecture. It  performs  some  rudimentary}}
\DoxyCodeLine{2049 \textcolor{comment}{checks that architectures are same, and throws exception if check fails.}}
\DoxyCodeLine{2050 \textcolor{comment}{}}
\DoxyCodeLine{2051 \textcolor{comment}{It is intended for fast copying of states between two  network  which  are}}
\DoxyCodeLine{2052 \textcolor{comment}{known to have same geometry.}}
\DoxyCodeLine{2053 \textcolor{comment}{}}
\DoxyCodeLine{2054 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2055 \textcolor{comment}{    Network1 -\/   source, must be correctly initialized}}
\DoxyCodeLine{2056 \textcolor{comment}{    Network2 -\/   target, must have same architecture}}
\DoxyCodeLine{2057 \textcolor{comment}{}}
\DoxyCodeLine{2058 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{2059 \textcolor{comment}{    Network2 -\/   network state is copied from source to target}}
\DoxyCodeLine{2060 \textcolor{comment}{}}
\DoxyCodeLine{2061 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2062 \textcolor{comment}{     Copyright 20.06.2013 by Bochkanov Sergey}}
\DoxyCodeLine{2063 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2064 \textcolor{keywordtype}{void} mlpcopytunableparameters(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network1, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network2, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2065 }
\DoxyCodeLine{2066 }
\DoxyCodeLine{2067 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2068 \textcolor{comment}{Randomization of neural network weights}}
\DoxyCodeLine{2069 \textcolor{comment}{}}
\DoxyCodeLine{2070 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2071 \textcolor{comment}{     Copyright 06.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{2072 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2073 \textcolor{keywordtype}{void} mlprandomize(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2074 }
\DoxyCodeLine{2075 }
\DoxyCodeLine{2076 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2077 \textcolor{comment}{Randomization of neural network weights and standartisator}}
\DoxyCodeLine{2078 \textcolor{comment}{}}
\DoxyCodeLine{2079 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2080 \textcolor{comment}{     Copyright 10.03.2008 by Bochkanov Sergey}}
\DoxyCodeLine{2081 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2082 \textcolor{keywordtype}{void} mlprandomizefull(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2083 }
\DoxyCodeLine{2084 }
\DoxyCodeLine{2085 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2086 \textcolor{comment}{Internal subroutine.}}
\DoxyCodeLine{2087 \textcolor{comment}{}}
\DoxyCodeLine{2088 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2089 \textcolor{comment}{     Copyright 30.03.2008 by Bochkanov Sergey}}
\DoxyCodeLine{2090 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2091 \textcolor{keywordtype}{void} mlpinitpreprocessor(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t ssize, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2092 }
\DoxyCodeLine{2093 }
\DoxyCodeLine{2094 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2095 \textcolor{comment}{Returns information about initialized network: number of inputs, outputs,}}
\DoxyCodeLine{2096 \textcolor{comment}{weights.}}
\DoxyCodeLine{2097 \textcolor{comment}{}}
\DoxyCodeLine{2098 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2099 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{2100 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2101 \textcolor{keywordtype}{void} mlpproperties(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, ae\_int\_t \&nin, ae\_int\_t \&nout, ae\_int\_t \&wcount, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2102 }
\DoxyCodeLine{2103 }
\DoxyCodeLine{2104 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2105 \textcolor{comment}{Returns number of inputs.}}
\DoxyCodeLine{2106 \textcolor{comment}{}}
\DoxyCodeLine{2107 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2108 \textcolor{comment}{     Copyright 19.10.2011 by Bochkanov Sergey}}
\DoxyCodeLine{2109 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2110 ae\_int\_t mlpgetinputscount(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2111 }
\DoxyCodeLine{2112 }
\DoxyCodeLine{2113 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2114 \textcolor{comment}{Returns number of outputs.}}
\DoxyCodeLine{2115 \textcolor{comment}{}}
\DoxyCodeLine{2116 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2117 \textcolor{comment}{     Copyright 19.10.2011 by Bochkanov Sergey}}
\DoxyCodeLine{2118 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2119 ae\_int\_t mlpgetoutputscount(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2120 }
\DoxyCodeLine{2121 }
\DoxyCodeLine{2122 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2123 \textcolor{comment}{Returns number of weights.}}
\DoxyCodeLine{2124 \textcolor{comment}{}}
\DoxyCodeLine{2125 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2126 \textcolor{comment}{     Copyright 19.10.2011 by Bochkanov Sergey}}
\DoxyCodeLine{2127 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2128 ae\_int\_t mlpgetweightscount(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2129 }
\DoxyCodeLine{2130 }
\DoxyCodeLine{2131 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2132 \textcolor{comment}{Tells whether network is SOFTMAX-\/normalized (i.e. classifier) or not.}}
\DoxyCodeLine{2133 \textcolor{comment}{}}
\DoxyCodeLine{2134 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2135 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{2136 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2137 \textcolor{keywordtype}{bool} mlpissoftmax(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2138 }
\DoxyCodeLine{2139 }
\DoxyCodeLine{2140 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2141 \textcolor{comment}{This function returns total number of layers (including input, hidden and}}
\DoxyCodeLine{2142 \textcolor{comment}{output layers).}}
\DoxyCodeLine{2143 \textcolor{comment}{}}
\DoxyCodeLine{2144 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2145 \textcolor{comment}{     Copyright 25.03.2011 by Bochkanov Sergey}}
\DoxyCodeLine{2146 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2147 ae\_int\_t mlpgetlayerscount(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2148 }
\DoxyCodeLine{2149 }
\DoxyCodeLine{2150 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2151 \textcolor{comment}{This function returns size of K-\/th layer.}}
\DoxyCodeLine{2152 \textcolor{comment}{}}
\DoxyCodeLine{2153 \textcolor{comment}{K=0 corresponds to input layer, K=CNT-\/1 corresponds to output layer.}}
\DoxyCodeLine{2154 \textcolor{comment}{}}
\DoxyCodeLine{2155 \textcolor{comment}{Size of the output layer is always equal to the number of outputs, although}}
\DoxyCodeLine{2156 \textcolor{comment}{when we have softmax-\/normalized network, last neuron doesn't have any}}
\DoxyCodeLine{2157 \textcolor{comment}{connections -\/ it is just zero.}}
\DoxyCodeLine{2158 \textcolor{comment}{}}
\DoxyCodeLine{2159 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2160 \textcolor{comment}{     Copyright 25.03.2011 by Bochkanov Sergey}}
\DoxyCodeLine{2161 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2162 ae\_int\_t mlpgetlayersize(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} ae\_int\_t k, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2163 }
\DoxyCodeLine{2164 }
\DoxyCodeLine{2165 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2166 \textcolor{comment}{This function returns offset/scaling coefficients for I-\/th input of the}}
\DoxyCodeLine{2167 \textcolor{comment}{network.}}
\DoxyCodeLine{2168 \textcolor{comment}{}}
\DoxyCodeLine{2169 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2170 \textcolor{comment}{    Network     -\/   network}}
\DoxyCodeLine{2171 \textcolor{comment}{    I           -\/   input index}}
\DoxyCodeLine{2172 \textcolor{comment}{}}
\DoxyCodeLine{2173 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{2174 \textcolor{comment}{    Mean        -\/   mean term}}
\DoxyCodeLine{2175 \textcolor{comment}{    Sigma       -\/   sigma term, guaranteed to be nonzero.}}
\DoxyCodeLine{2176 \textcolor{comment}{}}
\DoxyCodeLine{2177 \textcolor{comment}{I-\/th input is passed through linear transformation}}
\DoxyCodeLine{2178 \textcolor{comment}{    IN[i] = (IN[i]-\/Mean)/Sigma}}
\DoxyCodeLine{2179 \textcolor{comment}{before feeding to the network}}
\DoxyCodeLine{2180 \textcolor{comment}{}}
\DoxyCodeLine{2181 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2182 \textcolor{comment}{     Copyright 25.03.2011 by Bochkanov Sergey}}
\DoxyCodeLine{2183 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2184 \textcolor{keywordtype}{void} mlpgetinputscaling(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} ae\_int\_t i, \textcolor{keywordtype}{double} \&mean, \textcolor{keywordtype}{double} \&sigma, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2185 }
\DoxyCodeLine{2186 }
\DoxyCodeLine{2187 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2188 \textcolor{comment}{This function returns offset/scaling coefficients for I-\/th output of the}}
\DoxyCodeLine{2189 \textcolor{comment}{network.}}
\DoxyCodeLine{2190 \textcolor{comment}{}}
\DoxyCodeLine{2191 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2192 \textcolor{comment}{    Network     -\/   network}}
\DoxyCodeLine{2193 \textcolor{comment}{    I           -\/   input index}}
\DoxyCodeLine{2194 \textcolor{comment}{}}
\DoxyCodeLine{2195 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{2196 \textcolor{comment}{    Mean        -\/   mean term}}
\DoxyCodeLine{2197 \textcolor{comment}{    Sigma       -\/   sigma term, guaranteed to be nonzero.}}
\DoxyCodeLine{2198 \textcolor{comment}{}}
\DoxyCodeLine{2199 \textcolor{comment}{I-\/th output is passed through linear transformation}}
\DoxyCodeLine{2200 \textcolor{comment}{    OUT[i] = OUT[i]*Sigma+Mean}}
\DoxyCodeLine{2201 \textcolor{comment}{before returning it to user. In case we have SOFTMAX-\/normalized network,}}
\DoxyCodeLine{2202 \textcolor{comment}{we return (Mean,Sigma)=(0.0,1.0).}}
\DoxyCodeLine{2203 \textcolor{comment}{}}
\DoxyCodeLine{2204 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2205 \textcolor{comment}{     Copyright 25.03.2011 by Bochkanov Sergey}}
\DoxyCodeLine{2206 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2207 \textcolor{keywordtype}{void} mlpgetoutputscaling(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} ae\_int\_t i, \textcolor{keywordtype}{double} \&mean, \textcolor{keywordtype}{double} \&sigma, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2208 }
\DoxyCodeLine{2209 }
\DoxyCodeLine{2210 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2211 \textcolor{comment}{This function returns information about Ith neuron of Kth layer}}
\DoxyCodeLine{2212 \textcolor{comment}{}}
\DoxyCodeLine{2213 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2214 \textcolor{comment}{    Network     -\/   network}}
\DoxyCodeLine{2215 \textcolor{comment}{    K           -\/   layer index}}
\DoxyCodeLine{2216 \textcolor{comment}{    I           -\/   neuron index (within layer)}}
\DoxyCodeLine{2217 \textcolor{comment}{}}
\DoxyCodeLine{2218 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{2219 \textcolor{comment}{    FKind       -\/   activation function type (used by MLPActivationFunction())}}
\DoxyCodeLine{2220 \textcolor{comment}{                    this value is zero for input or linear neurons}}
\DoxyCodeLine{2221 \textcolor{comment}{    Threshold   -\/   also called offset, bias}}
\DoxyCodeLine{2222 \textcolor{comment}{                    zero for input neurons}}
\DoxyCodeLine{2223 \textcolor{comment}{}}
\DoxyCodeLine{2224 \textcolor{comment}{NOTE: this function throws exception if layer or neuron with  given  index}}
\DoxyCodeLine{2225 \textcolor{comment}{do not exists.}}
\DoxyCodeLine{2226 \textcolor{comment}{}}
\DoxyCodeLine{2227 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2228 \textcolor{comment}{     Copyright 25.03.2011 by Bochkanov Sergey}}
\DoxyCodeLine{2229 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2230 \textcolor{keywordtype}{void} mlpgetneuroninfo(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} ae\_int\_t k, \textcolor{keyword}{const} ae\_int\_t i, ae\_int\_t \&fkind, \textcolor{keywordtype}{double} \&threshold, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2231 }
\DoxyCodeLine{2232 }
\DoxyCodeLine{2233 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2234 \textcolor{comment}{This function returns information about connection from I0-\/th neuron of}}
\DoxyCodeLine{2235 \textcolor{comment}{K0-\/th layer to I1-\/th neuron of K1-\/th layer.}}
\DoxyCodeLine{2236 \textcolor{comment}{}}
\DoxyCodeLine{2237 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2238 \textcolor{comment}{    Network     -\/   network}}
\DoxyCodeLine{2239 \textcolor{comment}{    K0          -\/   layer index}}
\DoxyCodeLine{2240 \textcolor{comment}{    I0          -\/   neuron index (within layer)}}
\DoxyCodeLine{2241 \textcolor{comment}{    K1          -\/   layer index}}
\DoxyCodeLine{2242 \textcolor{comment}{    I1          -\/   neuron index (within layer)}}
\DoxyCodeLine{2243 \textcolor{comment}{}}
\DoxyCodeLine{2244 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{2245 \textcolor{comment}{    connection weight (zero for non-\/existent connections)}}
\DoxyCodeLine{2246 \textcolor{comment}{}}
\DoxyCodeLine{2247 \textcolor{comment}{This function:}}
\DoxyCodeLine{2248 \textcolor{comment}{1. throws exception if layer or neuron with given index do not exists.}}
\DoxyCodeLine{2249 \textcolor{comment}{2. returns zero if neurons exist, but there is no connection between them}}
\DoxyCodeLine{2250 \textcolor{comment}{}}
\DoxyCodeLine{2251 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2252 \textcolor{comment}{     Copyright 25.03.2011 by Bochkanov Sergey}}
\DoxyCodeLine{2253 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2254 \textcolor{keywordtype}{double} mlpgetweight(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} ae\_int\_t k0, \textcolor{keyword}{const} ae\_int\_t i0, \textcolor{keyword}{const} ae\_int\_t k1, \textcolor{keyword}{const} ae\_int\_t i1, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2255 }
\DoxyCodeLine{2256 }
\DoxyCodeLine{2257 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2258 \textcolor{comment}{This function sets offset/scaling coefficients for I-\/th input of the}}
\DoxyCodeLine{2259 \textcolor{comment}{network.}}
\DoxyCodeLine{2260 \textcolor{comment}{}}
\DoxyCodeLine{2261 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2262 \textcolor{comment}{    Network     -\/   network}}
\DoxyCodeLine{2263 \textcolor{comment}{    I           -\/   input index}}
\DoxyCodeLine{2264 \textcolor{comment}{    Mean        -\/   mean term}}
\DoxyCodeLine{2265 \textcolor{comment}{    Sigma       -\/   sigma term (if zero, will be replaced by 1.0)}}
\DoxyCodeLine{2266 \textcolor{comment}{}}
\DoxyCodeLine{2267 \textcolor{comment}{NTE: I-\/th input is passed through linear transformation}}
\DoxyCodeLine{2268 \textcolor{comment}{    IN[i] = (IN[i]-\/Mean)/Sigma}}
\DoxyCodeLine{2269 \textcolor{comment}{before feeding to the network. This function sets Mean and Sigma.}}
\DoxyCodeLine{2270 \textcolor{comment}{}}
\DoxyCodeLine{2271 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2272 \textcolor{comment}{     Copyright 25.03.2011 by Bochkanov Sergey}}
\DoxyCodeLine{2273 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2274 \textcolor{keywordtype}{void} mlpsetinputscaling(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} ae\_int\_t i, \textcolor{keyword}{const} \textcolor{keywordtype}{double} mean, \textcolor{keyword}{const} \textcolor{keywordtype}{double} sigma, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2275 }
\DoxyCodeLine{2276 }
\DoxyCodeLine{2277 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2278 \textcolor{comment}{This function sets offset/scaling coefficients for I-\/th output of the}}
\DoxyCodeLine{2279 \textcolor{comment}{network.}}
\DoxyCodeLine{2280 \textcolor{comment}{}}
\DoxyCodeLine{2281 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2282 \textcolor{comment}{    Network     -\/   network}}
\DoxyCodeLine{2283 \textcolor{comment}{    I           -\/   input index}}
\DoxyCodeLine{2284 \textcolor{comment}{    Mean        -\/   mean term}}
\DoxyCodeLine{2285 \textcolor{comment}{    Sigma       -\/   sigma term (if zero, will be replaced by 1.0)}}
\DoxyCodeLine{2286 \textcolor{comment}{}}
\DoxyCodeLine{2287 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{2288 \textcolor{comment}{}}
\DoxyCodeLine{2289 \textcolor{comment}{NOTE: I-\/th output is passed through linear transformation}}
\DoxyCodeLine{2290 \textcolor{comment}{    OUT[i] = OUT[i]*Sigma+Mean}}
\DoxyCodeLine{2291 \textcolor{comment}{before returning it to user. This function sets Sigma/Mean. In case we}}
\DoxyCodeLine{2292 \textcolor{comment}{have SOFTMAX-\/normalized network, you can not set (Sigma,Mean) to anything}}
\DoxyCodeLine{2293 \textcolor{comment}{other than(0.0,1.0) -\/ this function will throw exception.}}
\DoxyCodeLine{2294 \textcolor{comment}{}}
\DoxyCodeLine{2295 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2296 \textcolor{comment}{     Copyright 25.03.2011 by Bochkanov Sergey}}
\DoxyCodeLine{2297 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2298 \textcolor{keywordtype}{void} mlpsetoutputscaling(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} ae\_int\_t i, \textcolor{keyword}{const} \textcolor{keywordtype}{double} mean, \textcolor{keyword}{const} \textcolor{keywordtype}{double} sigma, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2299 }
\DoxyCodeLine{2300 }
\DoxyCodeLine{2301 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2302 \textcolor{comment}{This function modifies information about Ith neuron of Kth layer}}
\DoxyCodeLine{2303 \textcolor{comment}{}}
\DoxyCodeLine{2304 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2305 \textcolor{comment}{    Network     -\/   network}}
\DoxyCodeLine{2306 \textcolor{comment}{    K           -\/   layer index}}
\DoxyCodeLine{2307 \textcolor{comment}{    I           -\/   neuron index (within layer)}}
\DoxyCodeLine{2308 \textcolor{comment}{    FKind       -\/   activation function type (used by MLPActivationFunction())}}
\DoxyCodeLine{2309 \textcolor{comment}{                    this value must be zero for input neurons}}
\DoxyCodeLine{2310 \textcolor{comment}{                    (you can not set activation function for input neurons)}}
\DoxyCodeLine{2311 \textcolor{comment}{    Threshold   -\/   also called offset, bias}}
\DoxyCodeLine{2312 \textcolor{comment}{                    this value must be zero for input neurons}}
\DoxyCodeLine{2313 \textcolor{comment}{                    (you can not set threshold for input neurons)}}
\DoxyCodeLine{2314 \textcolor{comment}{}}
\DoxyCodeLine{2315 \textcolor{comment}{NOTES:}}
\DoxyCodeLine{2316 \textcolor{comment}{1. this function throws exception if layer or neuron with given index do}}
\DoxyCodeLine{2317 \textcolor{comment}{   not exists.}}
\DoxyCodeLine{2318 \textcolor{comment}{2. this function also throws exception when you try to set non-\/linear}}
\DoxyCodeLine{2319 \textcolor{comment}{   activation function for input neurons (any kind of network) or for output}}
\DoxyCodeLine{2320 \textcolor{comment}{   neurons of classifier network.}}
\DoxyCodeLine{2321 \textcolor{comment}{3. this function throws exception when you try to set non-\/zero threshold for}}
\DoxyCodeLine{2322 \textcolor{comment}{   input neurons (any kind of network).}}
\DoxyCodeLine{2323 \textcolor{comment}{}}
\DoxyCodeLine{2324 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2325 \textcolor{comment}{     Copyright 25.03.2011 by Bochkanov Sergey}}
\DoxyCodeLine{2326 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2327 \textcolor{keywordtype}{void} mlpsetneuroninfo(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} ae\_int\_t k, \textcolor{keyword}{const} ae\_int\_t i, \textcolor{keyword}{const} ae\_int\_t fkind, \textcolor{keyword}{const} \textcolor{keywordtype}{double} threshold, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2328 }
\DoxyCodeLine{2329 }
\DoxyCodeLine{2330 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2331 \textcolor{comment}{This function modifies information about connection from I0-\/th neuron of}}
\DoxyCodeLine{2332 \textcolor{comment}{K0-\/th layer to I1-\/th neuron of K1-\/th layer.}}
\DoxyCodeLine{2333 \textcolor{comment}{}}
\DoxyCodeLine{2334 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2335 \textcolor{comment}{    Network     -\/   network}}
\DoxyCodeLine{2336 \textcolor{comment}{    K0          -\/   layer index}}
\DoxyCodeLine{2337 \textcolor{comment}{    I0          -\/   neuron index (within layer)}}
\DoxyCodeLine{2338 \textcolor{comment}{    K1          -\/   layer index}}
\DoxyCodeLine{2339 \textcolor{comment}{    I1          -\/   neuron index (within layer)}}
\DoxyCodeLine{2340 \textcolor{comment}{    W           -\/   connection weight (must be zero for non-\/existent}}
\DoxyCodeLine{2341 \textcolor{comment}{                    connections)}}
\DoxyCodeLine{2342 \textcolor{comment}{}}
\DoxyCodeLine{2343 \textcolor{comment}{This function:}}
\DoxyCodeLine{2344 \textcolor{comment}{1. throws exception if layer or neuron with given index do not exists.}}
\DoxyCodeLine{2345 \textcolor{comment}{2. throws exception if you try to set non-\/zero weight for non-\/existent}}
\DoxyCodeLine{2346 \textcolor{comment}{   connection}}
\DoxyCodeLine{2347 \textcolor{comment}{}}
\DoxyCodeLine{2348 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2349 \textcolor{comment}{     Copyright 25.03.2011 by Bochkanov Sergey}}
\DoxyCodeLine{2350 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2351 \textcolor{keywordtype}{void} mlpsetweight(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} ae\_int\_t k0, \textcolor{keyword}{const} ae\_int\_t i0, \textcolor{keyword}{const} ae\_int\_t k1, \textcolor{keyword}{const} ae\_int\_t i1, \textcolor{keyword}{const} \textcolor{keywordtype}{double} w, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2352 }
\DoxyCodeLine{2353 }
\DoxyCodeLine{2354 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2355 \textcolor{comment}{Neural network activation function}}
\DoxyCodeLine{2356 \textcolor{comment}{}}
\DoxyCodeLine{2357 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2358 \textcolor{comment}{    NET         -\/   neuron input}}
\DoxyCodeLine{2359 \textcolor{comment}{    K           -\/   function index (zero for linear function)}}
\DoxyCodeLine{2360 \textcolor{comment}{}}
\DoxyCodeLine{2361 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{2362 \textcolor{comment}{    F           -\/   function}}
\DoxyCodeLine{2363 \textcolor{comment}{    DF          -\/   its derivative}}
\DoxyCodeLine{2364 \textcolor{comment}{    D2F         -\/   its second derivative}}
\DoxyCodeLine{2365 \textcolor{comment}{}}
\DoxyCodeLine{2366 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2367 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{2368 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2369 \textcolor{keywordtype}{void} mlpactivationfunction(\textcolor{keyword}{const} \textcolor{keywordtype}{double} net, \textcolor{keyword}{const} ae\_int\_t k, \textcolor{keywordtype}{double} \&f, \textcolor{keywordtype}{double} \&df, \textcolor{keywordtype}{double} \&d2f, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2370 }
\DoxyCodeLine{2371 }
\DoxyCodeLine{2372 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2373 \textcolor{comment}{Procesing}}
\DoxyCodeLine{2374 \textcolor{comment}{}}
\DoxyCodeLine{2375 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2376 \textcolor{comment}{    Network -\/   neural network}}
\DoxyCodeLine{2377 \textcolor{comment}{    X       -\/   input vector,  array[0..NIn-\/1].}}
\DoxyCodeLine{2378 \textcolor{comment}{}}
\DoxyCodeLine{2379 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{2380 \textcolor{comment}{    Y       -\/   result. Regression estimate when solving regression  task,}}
\DoxyCodeLine{2381 \textcolor{comment}{                vector of posterior probabilities for classification task.}}
\DoxyCodeLine{2382 \textcolor{comment}{}}
\DoxyCodeLine{2383 \textcolor{comment}{See also MLPProcessI}}
\DoxyCodeLine{2384 \textcolor{comment}{}}
\DoxyCodeLine{2385 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2386 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{2387 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2388 \textcolor{keywordtype}{void} mlpprocess(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&y, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2389 }
\DoxyCodeLine{2390 }
\DoxyCodeLine{2391 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2392 \textcolor{comment}{'interactive'  variant  of  MLPProcess  for  languages  like  Python which}}
\DoxyCodeLine{2393 \textcolor{comment}{support constructs like "{}Y = MLPProcess(NN,X)"{} and interactive mode of the}}
\DoxyCodeLine{2394 \textcolor{comment}{interpreter}}
\DoxyCodeLine{2395 \textcolor{comment}{}}
\DoxyCodeLine{2396 \textcolor{comment}{This function allocates new array on each call,  so  it  is  significantly}}
\DoxyCodeLine{2397 \textcolor{comment}{slower than its 'non-\/interactive' counterpart, but it is  more  convenient}}
\DoxyCodeLine{2398 \textcolor{comment}{when you call it from command line.}}
\DoxyCodeLine{2399 \textcolor{comment}{}}
\DoxyCodeLine{2400 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2401 \textcolor{comment}{     Copyright 21.09.2010 by Bochkanov Sergey}}
\DoxyCodeLine{2402 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2403 \textcolor{keywordtype}{void} mlpprocessi(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&y, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2404 }
\DoxyCodeLine{2405 }
\DoxyCodeLine{2406 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2407 \textcolor{comment}{Error of the neural network on dataset.}}
\DoxyCodeLine{2408 \textcolor{comment}{}}
\DoxyCodeLine{2409 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{2410 \textcolor{comment}{  !}}
\DoxyCodeLine{2411 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{2412 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{2413 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{2414 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{2415 \textcolor{comment}{  !}}
\DoxyCodeLine{2416 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{2417 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{2418 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{2419 \textcolor{comment}{}}
\DoxyCodeLine{2420 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2421 \textcolor{comment}{    Network     -\/   neural network;}}
\DoxyCodeLine{2422 \textcolor{comment}{    XY          -\/   training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{2423 \textcolor{comment}{                    training set format;}}
\DoxyCodeLine{2424 \textcolor{comment}{    NPoints     -\/   points count.}}
\DoxyCodeLine{2425 \textcolor{comment}{}}
\DoxyCodeLine{2426 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{2427 \textcolor{comment}{    sum-\/of-\/squares error, SUM(sqr(y[i]-\/desired\_y[i])/2)}}
\DoxyCodeLine{2428 \textcolor{comment}{}}
\DoxyCodeLine{2429 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{2430 \textcolor{comment}{}}
\DoxyCodeLine{2431 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{2432 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{2433 \textcolor{comment}{}}
\DoxyCodeLine{2434 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{2435 \textcolor{comment}{format is used:}}
\DoxyCodeLine{2436 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{2437 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2438 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{2439 \textcolor{comment}{}}
\DoxyCodeLine{2440 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{2441 \textcolor{comment}{dataset format is used:}}
\DoxyCodeLine{2442 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{2443 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2444 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{2445 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{2446 \textcolor{comment}{}}
\DoxyCodeLine{2447 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2448 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{2449 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2450 \textcolor{keywordtype}{double} mlperror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2451 }
\DoxyCodeLine{2452 }
\DoxyCodeLine{2453 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2454 \textcolor{comment}{Error of the neural network on dataset given by sparse matrix.}}
\DoxyCodeLine{2455 \textcolor{comment}{}}
\DoxyCodeLine{2456 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{2457 \textcolor{comment}{  !}}
\DoxyCodeLine{2458 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{2459 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{2460 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{2461 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{2462 \textcolor{comment}{  !}}
\DoxyCodeLine{2463 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{2464 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{2465 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{2466 \textcolor{comment}{}}
\DoxyCodeLine{2467 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2468 \textcolor{comment}{    Network     -\/   neural network}}
\DoxyCodeLine{2469 \textcolor{comment}{    XY          -\/   training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{2470 \textcolor{comment}{                    training set format. This function checks  correctness}}
\DoxyCodeLine{2471 \textcolor{comment}{                    of  the  dataset  (no  NANs/INFs,  class  numbers  are}}
\DoxyCodeLine{2472 \textcolor{comment}{                    correct) and throws exception when  incorrect  dataset}}
\DoxyCodeLine{2473 \textcolor{comment}{                    is passed.  Sparse  matrix  must  use  CRS  format for}}
\DoxyCodeLine{2474 \textcolor{comment}{                    storage.}}
\DoxyCodeLine{2475 \textcolor{comment}{    NPoints     -\/   points count, >=0}}
\DoxyCodeLine{2476 \textcolor{comment}{}}
\DoxyCodeLine{2477 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{2478 \textcolor{comment}{    sum-\/of-\/squares error, SUM(sqr(y[i]-\/desired\_y[i])/2)}}
\DoxyCodeLine{2479 \textcolor{comment}{}}
\DoxyCodeLine{2480 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{2481 \textcolor{comment}{}}
\DoxyCodeLine{2482 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{2483 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{2484 \textcolor{comment}{}}
\DoxyCodeLine{2485 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{2486 \textcolor{comment}{format is used:}}
\DoxyCodeLine{2487 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{2488 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2489 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{2490 \textcolor{comment}{}}
\DoxyCodeLine{2491 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{2492 \textcolor{comment}{dataset format is used:}}
\DoxyCodeLine{2493 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{2494 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2495 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{2496 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{2497 \textcolor{comment}{}}
\DoxyCodeLine{2498 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2499 \textcolor{comment}{     Copyright 23.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{2500 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2501 \textcolor{keywordtype}{double} mlperrorsparse(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1sparsematrix}{sparsematrix}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2502 }
\DoxyCodeLine{2503 }
\DoxyCodeLine{2504 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2505 \textcolor{comment}{Natural error function for neural network, internal subroutine.}}
\DoxyCodeLine{2506 \textcolor{comment}{}}
\DoxyCodeLine{2507 \textcolor{comment}{NOTE: this function is single-\/threaded. Unlike other  error  function,  it}}
\DoxyCodeLine{2508 \textcolor{comment}{receives no speed-\/up from being executed in SMP mode.}}
\DoxyCodeLine{2509 \textcolor{comment}{}}
\DoxyCodeLine{2510 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2511 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{2512 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2513 \textcolor{keywordtype}{double} mlperrorn(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t ssize, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2514 }
\DoxyCodeLine{2515 }
\DoxyCodeLine{2516 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2517 \textcolor{comment}{Classification error of the neural network on dataset.}}
\DoxyCodeLine{2518 \textcolor{comment}{}}
\DoxyCodeLine{2519 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{2520 \textcolor{comment}{  !}}
\DoxyCodeLine{2521 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{2522 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{2523 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{2524 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{2525 \textcolor{comment}{  !}}
\DoxyCodeLine{2526 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{2527 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{2528 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{2529 \textcolor{comment}{}}
\DoxyCodeLine{2530 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2531 \textcolor{comment}{    Network     -\/   neural network;}}
\DoxyCodeLine{2532 \textcolor{comment}{    XY          -\/   training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{2533 \textcolor{comment}{                    training set format;}}
\DoxyCodeLine{2534 \textcolor{comment}{    NPoints     -\/   points count.}}
\DoxyCodeLine{2535 \textcolor{comment}{}}
\DoxyCodeLine{2536 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{2537 \textcolor{comment}{    classification error (number of misclassified cases)}}
\DoxyCodeLine{2538 \textcolor{comment}{}}
\DoxyCodeLine{2539 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{2540 \textcolor{comment}{}}
\DoxyCodeLine{2541 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{2542 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{2543 \textcolor{comment}{}}
\DoxyCodeLine{2544 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{2545 \textcolor{comment}{format is used:}}
\DoxyCodeLine{2546 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{2547 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2548 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{2549 \textcolor{comment}{}}
\DoxyCodeLine{2550 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{2551 \textcolor{comment}{dataset format is used:}}
\DoxyCodeLine{2552 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{2553 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2554 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{2555 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{2556 \textcolor{comment}{}}
\DoxyCodeLine{2557 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2558 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{2559 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2560 ae\_int\_t mlpclserror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2561 }
\DoxyCodeLine{2562 }
\DoxyCodeLine{2563 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2564 \textcolor{comment}{Relative classification error on the test set.}}
\DoxyCodeLine{2565 \textcolor{comment}{}}
\DoxyCodeLine{2566 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{2567 \textcolor{comment}{  !}}
\DoxyCodeLine{2568 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{2569 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{2570 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{2571 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{2572 \textcolor{comment}{  !}}
\DoxyCodeLine{2573 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{2574 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{2575 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{2576 \textcolor{comment}{}}
\DoxyCodeLine{2577 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2578 \textcolor{comment}{    Network     -\/   neural network;}}
\DoxyCodeLine{2579 \textcolor{comment}{    XY          -\/   training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{2580 \textcolor{comment}{                    training set format;}}
\DoxyCodeLine{2581 \textcolor{comment}{    NPoints     -\/   points count.}}
\DoxyCodeLine{2582 \textcolor{comment}{}}
\DoxyCodeLine{2583 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{2584 \textcolor{comment}{Percent   of incorrectly   classified  cases.  Works  both  for classifier}}
\DoxyCodeLine{2585 \textcolor{comment}{networks and general purpose networks used as classifiers.}}
\DoxyCodeLine{2586 \textcolor{comment}{}}
\DoxyCodeLine{2587 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{2588 \textcolor{comment}{}}
\DoxyCodeLine{2589 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{2590 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{2591 \textcolor{comment}{}}
\DoxyCodeLine{2592 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{2593 \textcolor{comment}{format is used:}}
\DoxyCodeLine{2594 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{2595 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2596 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{2597 \textcolor{comment}{}}
\DoxyCodeLine{2598 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{2599 \textcolor{comment}{dataset format is used:}}
\DoxyCodeLine{2600 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{2601 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2602 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{2603 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{2604 \textcolor{comment}{}}
\DoxyCodeLine{2605 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2606 \textcolor{comment}{     Copyright 25.12.2008 by Bochkanov Sergey}}
\DoxyCodeLine{2607 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2608 \textcolor{keywordtype}{double} mlprelclserror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2609 }
\DoxyCodeLine{2610 }
\DoxyCodeLine{2611 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2612 \textcolor{comment}{Relative classification error on the test set given by sparse matrix.}}
\DoxyCodeLine{2613 \textcolor{comment}{}}
\DoxyCodeLine{2614 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{2615 \textcolor{comment}{  !}}
\DoxyCodeLine{2616 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{2617 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{2618 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{2619 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{2620 \textcolor{comment}{  !}}
\DoxyCodeLine{2621 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{2622 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{2623 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{2624 \textcolor{comment}{}}
\DoxyCodeLine{2625 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2626 \textcolor{comment}{    Network     -\/   neural network;}}
\DoxyCodeLine{2627 \textcolor{comment}{    XY          -\/   training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{2628 \textcolor{comment}{                    training set format. Sparse matrix must use CRS format}}
\DoxyCodeLine{2629 \textcolor{comment}{                    for storage.}}
\DoxyCodeLine{2630 \textcolor{comment}{    NPoints     -\/   points count, >=0.}}
\DoxyCodeLine{2631 \textcolor{comment}{}}
\DoxyCodeLine{2632 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{2633 \textcolor{comment}{Percent   of incorrectly   classified  cases.  Works  both  for classifier}}
\DoxyCodeLine{2634 \textcolor{comment}{networks and general purpose networks used as classifiers.}}
\DoxyCodeLine{2635 \textcolor{comment}{}}
\DoxyCodeLine{2636 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{2637 \textcolor{comment}{}}
\DoxyCodeLine{2638 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{2639 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{2640 \textcolor{comment}{}}
\DoxyCodeLine{2641 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{2642 \textcolor{comment}{format is used:}}
\DoxyCodeLine{2643 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{2644 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2645 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{2646 \textcolor{comment}{}}
\DoxyCodeLine{2647 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{2648 \textcolor{comment}{dataset format is used:}}
\DoxyCodeLine{2649 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{2650 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2651 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{2652 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{2653 \textcolor{comment}{}}
\DoxyCodeLine{2654 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2655 \textcolor{comment}{     Copyright 09.08.2012 by Bochkanov Sergey}}
\DoxyCodeLine{2656 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2657 \textcolor{keywordtype}{double} mlprelclserrorsparse(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1sparsematrix}{sparsematrix}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2658 }
\DoxyCodeLine{2659 }
\DoxyCodeLine{2660 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2661 \textcolor{comment}{Average cross-\/entropy  (in bits  per element) on the test set.}}
\DoxyCodeLine{2662 \textcolor{comment}{}}
\DoxyCodeLine{2663 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{2664 \textcolor{comment}{  !}}
\DoxyCodeLine{2665 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{2666 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{2667 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{2668 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{2669 \textcolor{comment}{  !}}
\DoxyCodeLine{2670 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{2671 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{2672 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{2673 \textcolor{comment}{}}
\DoxyCodeLine{2674 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2675 \textcolor{comment}{    Network     -\/   neural network;}}
\DoxyCodeLine{2676 \textcolor{comment}{    XY          -\/   training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{2677 \textcolor{comment}{                    training set format;}}
\DoxyCodeLine{2678 \textcolor{comment}{    NPoints     -\/   points count.}}
\DoxyCodeLine{2679 \textcolor{comment}{}}
\DoxyCodeLine{2680 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{2681 \textcolor{comment}{CrossEntropy/(NPoints*LN(2)).}}
\DoxyCodeLine{2682 \textcolor{comment}{Zero if network solves regression task.}}
\DoxyCodeLine{2683 \textcolor{comment}{}}
\DoxyCodeLine{2684 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{2685 \textcolor{comment}{}}
\DoxyCodeLine{2686 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{2687 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{2688 \textcolor{comment}{}}
\DoxyCodeLine{2689 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{2690 \textcolor{comment}{format is used:}}
\DoxyCodeLine{2691 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{2692 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2693 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{2694 \textcolor{comment}{}}
\DoxyCodeLine{2695 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{2696 \textcolor{comment}{dataset format is used:}}
\DoxyCodeLine{2697 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{2698 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2699 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{2700 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{2701 \textcolor{comment}{}}
\DoxyCodeLine{2702 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2703 \textcolor{comment}{     Copyright 08.01.2009 by Bochkanov Sergey}}
\DoxyCodeLine{2704 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2705 \textcolor{keywordtype}{double} mlpavgce(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2706 }
\DoxyCodeLine{2707 }
\DoxyCodeLine{2708 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2709 \textcolor{comment}{Average  cross-\/entropy  (in bits  per element)  on the  test set  given by}}
\DoxyCodeLine{2710 \textcolor{comment}{sparse matrix.}}
\DoxyCodeLine{2711 \textcolor{comment}{}}
\DoxyCodeLine{2712 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{2713 \textcolor{comment}{  !}}
\DoxyCodeLine{2714 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{2715 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{2716 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{2717 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{2718 \textcolor{comment}{  !}}
\DoxyCodeLine{2719 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{2720 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{2721 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{2722 \textcolor{comment}{}}
\DoxyCodeLine{2723 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2724 \textcolor{comment}{    Network     -\/   neural network;}}
\DoxyCodeLine{2725 \textcolor{comment}{    XY          -\/   training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{2726 \textcolor{comment}{                    training set format. This function checks  correctness}}
\DoxyCodeLine{2727 \textcolor{comment}{                    of  the  dataset  (no  NANs/INFs,  class  numbers  are}}
\DoxyCodeLine{2728 \textcolor{comment}{                    correct) and throws exception when  incorrect  dataset}}
\DoxyCodeLine{2729 \textcolor{comment}{                    is passed.  Sparse  matrix  must  use  CRS  format for}}
\DoxyCodeLine{2730 \textcolor{comment}{                    storage.}}
\DoxyCodeLine{2731 \textcolor{comment}{    NPoints     -\/   points count, >=0.}}
\DoxyCodeLine{2732 \textcolor{comment}{}}
\DoxyCodeLine{2733 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{2734 \textcolor{comment}{CrossEntropy/(NPoints*LN(2)).}}
\DoxyCodeLine{2735 \textcolor{comment}{Zero if network solves regression task.}}
\DoxyCodeLine{2736 \textcolor{comment}{}}
\DoxyCodeLine{2737 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{2738 \textcolor{comment}{}}
\DoxyCodeLine{2739 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{2740 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{2741 \textcolor{comment}{}}
\DoxyCodeLine{2742 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{2743 \textcolor{comment}{format is used:}}
\DoxyCodeLine{2744 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{2745 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2746 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{2747 \textcolor{comment}{}}
\DoxyCodeLine{2748 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{2749 \textcolor{comment}{dataset format is used:}}
\DoxyCodeLine{2750 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{2751 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2752 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{2753 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{2754 \textcolor{comment}{}}
\DoxyCodeLine{2755 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2756 \textcolor{comment}{     Copyright 9.08.2012 by Bochkanov Sergey}}
\DoxyCodeLine{2757 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2758 \textcolor{keywordtype}{double} mlpavgcesparse(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1sparsematrix}{sparsematrix}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2759 }
\DoxyCodeLine{2760 }
\DoxyCodeLine{2761 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2762 \textcolor{comment}{RMS error on the test set given.}}
\DoxyCodeLine{2763 \textcolor{comment}{}}
\DoxyCodeLine{2764 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{2765 \textcolor{comment}{  !}}
\DoxyCodeLine{2766 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{2767 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{2768 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{2769 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{2770 \textcolor{comment}{  !}}
\DoxyCodeLine{2771 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{2772 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{2773 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{2774 \textcolor{comment}{}}
\DoxyCodeLine{2775 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2776 \textcolor{comment}{    Network     -\/   neural network;}}
\DoxyCodeLine{2777 \textcolor{comment}{    XY          -\/   training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{2778 \textcolor{comment}{                    training set format;}}
\DoxyCodeLine{2779 \textcolor{comment}{    NPoints     -\/   points count.}}
\DoxyCodeLine{2780 \textcolor{comment}{}}
\DoxyCodeLine{2781 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{2782 \textcolor{comment}{Root mean  square error. Its meaning for regression task is obvious. As for}}
\DoxyCodeLine{2783 \textcolor{comment}{classification  task,  RMS  error  means  error  when estimating  posterior}}
\DoxyCodeLine{2784 \textcolor{comment}{probabilities.}}
\DoxyCodeLine{2785 \textcolor{comment}{}}
\DoxyCodeLine{2786 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{2787 \textcolor{comment}{}}
\DoxyCodeLine{2788 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{2789 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{2790 \textcolor{comment}{}}
\DoxyCodeLine{2791 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{2792 \textcolor{comment}{format is used:}}
\DoxyCodeLine{2793 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{2794 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2795 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{2796 \textcolor{comment}{}}
\DoxyCodeLine{2797 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{2798 \textcolor{comment}{dataset format is used:}}
\DoxyCodeLine{2799 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{2800 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2801 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{2802 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{2803 \textcolor{comment}{}}
\DoxyCodeLine{2804 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2805 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{2806 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2807 \textcolor{keywordtype}{double} mlprmserror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2808 }
\DoxyCodeLine{2809 }
\DoxyCodeLine{2810 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2811 \textcolor{comment}{RMS error on the test set given by sparse matrix.}}
\DoxyCodeLine{2812 \textcolor{comment}{}}
\DoxyCodeLine{2813 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{2814 \textcolor{comment}{  !}}
\DoxyCodeLine{2815 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{2816 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{2817 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{2818 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{2819 \textcolor{comment}{  !}}
\DoxyCodeLine{2820 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{2821 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{2822 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{2823 \textcolor{comment}{}}
\DoxyCodeLine{2824 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2825 \textcolor{comment}{    Network     -\/   neural network;}}
\DoxyCodeLine{2826 \textcolor{comment}{    XY          -\/   training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{2827 \textcolor{comment}{                    training set format. This function checks  correctness}}
\DoxyCodeLine{2828 \textcolor{comment}{                    of  the  dataset  (no  NANs/INFs,  class  numbers  are}}
\DoxyCodeLine{2829 \textcolor{comment}{                    correct) and throws exception when  incorrect  dataset}}
\DoxyCodeLine{2830 \textcolor{comment}{                    is passed.  Sparse  matrix  must  use  CRS  format for}}
\DoxyCodeLine{2831 \textcolor{comment}{                    storage.}}
\DoxyCodeLine{2832 \textcolor{comment}{    NPoints     -\/   points count, >=0.}}
\DoxyCodeLine{2833 \textcolor{comment}{}}
\DoxyCodeLine{2834 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{2835 \textcolor{comment}{Root mean  square error. Its meaning for regression task is obvious. As for}}
\DoxyCodeLine{2836 \textcolor{comment}{classification  task,  RMS  error  means  error  when estimating  posterior}}
\DoxyCodeLine{2837 \textcolor{comment}{probabilities.}}
\DoxyCodeLine{2838 \textcolor{comment}{}}
\DoxyCodeLine{2839 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{2840 \textcolor{comment}{}}
\DoxyCodeLine{2841 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{2842 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{2843 \textcolor{comment}{}}
\DoxyCodeLine{2844 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{2845 \textcolor{comment}{format is used:}}
\DoxyCodeLine{2846 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{2847 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2848 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{2849 \textcolor{comment}{}}
\DoxyCodeLine{2850 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{2851 \textcolor{comment}{dataset format is used:}}
\DoxyCodeLine{2852 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{2853 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2854 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{2855 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{2856 \textcolor{comment}{}}
\DoxyCodeLine{2857 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2858 \textcolor{comment}{     Copyright 09.08.2012 by Bochkanov Sergey}}
\DoxyCodeLine{2859 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2860 \textcolor{keywordtype}{double} mlprmserrorsparse(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1sparsematrix}{sparsematrix}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2861 }
\DoxyCodeLine{2862 }
\DoxyCodeLine{2863 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2864 \textcolor{comment}{Average absolute error on the test set.}}
\DoxyCodeLine{2865 \textcolor{comment}{}}
\DoxyCodeLine{2866 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{2867 \textcolor{comment}{  !}}
\DoxyCodeLine{2868 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{2869 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{2870 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{2871 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{2872 \textcolor{comment}{  !}}
\DoxyCodeLine{2873 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{2874 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{2875 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{2876 \textcolor{comment}{}}
\DoxyCodeLine{2877 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2878 \textcolor{comment}{    Network     -\/   neural network;}}
\DoxyCodeLine{2879 \textcolor{comment}{    XY          -\/   training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{2880 \textcolor{comment}{                    training set format;}}
\DoxyCodeLine{2881 \textcolor{comment}{    NPoints     -\/   points count.}}
\DoxyCodeLine{2882 \textcolor{comment}{}}
\DoxyCodeLine{2883 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{2884 \textcolor{comment}{Its meaning for regression task is obvious. As for classification task, it}}
\DoxyCodeLine{2885 \textcolor{comment}{means average error when estimating posterior probabilities.}}
\DoxyCodeLine{2886 \textcolor{comment}{}}
\DoxyCodeLine{2887 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{2888 \textcolor{comment}{}}
\DoxyCodeLine{2889 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{2890 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{2891 \textcolor{comment}{}}
\DoxyCodeLine{2892 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{2893 \textcolor{comment}{format is used:}}
\DoxyCodeLine{2894 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{2895 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2896 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{2897 \textcolor{comment}{}}
\DoxyCodeLine{2898 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{2899 \textcolor{comment}{dataset format is used:}}
\DoxyCodeLine{2900 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{2901 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2902 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{2903 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{2904 \textcolor{comment}{}}
\DoxyCodeLine{2905 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2906 \textcolor{comment}{     Copyright 11.03.2008 by Bochkanov Sergey}}
\DoxyCodeLine{2907 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2908 \textcolor{keywordtype}{double} mlpavgerror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2909 }
\DoxyCodeLine{2910 }
\DoxyCodeLine{2911 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2912 \textcolor{comment}{Average absolute error on the test set given by sparse matrix.}}
\DoxyCodeLine{2913 \textcolor{comment}{}}
\DoxyCodeLine{2914 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{2915 \textcolor{comment}{  !}}
\DoxyCodeLine{2916 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{2917 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{2918 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{2919 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{2920 \textcolor{comment}{  !}}
\DoxyCodeLine{2921 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{2922 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{2923 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{2924 \textcolor{comment}{}}
\DoxyCodeLine{2925 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2926 \textcolor{comment}{    Network     -\/   neural network;}}
\DoxyCodeLine{2927 \textcolor{comment}{    XY          -\/   training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{2928 \textcolor{comment}{                    training set format. This function checks  correctness}}
\DoxyCodeLine{2929 \textcolor{comment}{                    of  the  dataset  (no  NANs/INFs,  class  numbers  are}}
\DoxyCodeLine{2930 \textcolor{comment}{                    correct) and throws exception when  incorrect  dataset}}
\DoxyCodeLine{2931 \textcolor{comment}{                    is passed.  Sparse  matrix  must  use  CRS  format for}}
\DoxyCodeLine{2932 \textcolor{comment}{                    storage.}}
\DoxyCodeLine{2933 \textcolor{comment}{    NPoints     -\/   points count, >=0.}}
\DoxyCodeLine{2934 \textcolor{comment}{}}
\DoxyCodeLine{2935 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{2936 \textcolor{comment}{Its meaning for regression task is obvious. As for classification task, it}}
\DoxyCodeLine{2937 \textcolor{comment}{means average error when estimating posterior probabilities.}}
\DoxyCodeLine{2938 \textcolor{comment}{}}
\DoxyCodeLine{2939 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{2940 \textcolor{comment}{}}
\DoxyCodeLine{2941 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{2942 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{2943 \textcolor{comment}{}}
\DoxyCodeLine{2944 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{2945 \textcolor{comment}{format is used:}}
\DoxyCodeLine{2946 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{2947 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2948 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{2949 \textcolor{comment}{}}
\DoxyCodeLine{2950 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{2951 \textcolor{comment}{dataset format is used:}}
\DoxyCodeLine{2952 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{2953 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2954 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{2955 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{2956 \textcolor{comment}{}}
\DoxyCodeLine{2957 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{2958 \textcolor{comment}{     Copyright 09.08.2012 by Bochkanov Sergey}}
\DoxyCodeLine{2959 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{2960 \textcolor{keywordtype}{double} mlpavgerrorsparse(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1sparsematrix}{sparsematrix}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{2961 }
\DoxyCodeLine{2962 }
\DoxyCodeLine{2963 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{2964 \textcolor{comment}{Average relative error on the test set.}}
\DoxyCodeLine{2965 \textcolor{comment}{}}
\DoxyCodeLine{2966 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{2967 \textcolor{comment}{  !}}
\DoxyCodeLine{2968 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{2969 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{2970 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{2971 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{2972 \textcolor{comment}{  !}}
\DoxyCodeLine{2973 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{2974 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{2975 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{2976 \textcolor{comment}{}}
\DoxyCodeLine{2977 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{2978 \textcolor{comment}{    Network     -\/   neural network;}}
\DoxyCodeLine{2979 \textcolor{comment}{    XY          -\/   training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{2980 \textcolor{comment}{                    training set format;}}
\DoxyCodeLine{2981 \textcolor{comment}{    NPoints     -\/   points count.}}
\DoxyCodeLine{2982 \textcolor{comment}{}}
\DoxyCodeLine{2983 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{2984 \textcolor{comment}{Its meaning for regression task is obvious. As for classification task, it}}
\DoxyCodeLine{2985 \textcolor{comment}{means  average  relative  error  when  estimating posterior probability of}}
\DoxyCodeLine{2986 \textcolor{comment}{belonging to the correct class.}}
\DoxyCodeLine{2987 \textcolor{comment}{}}
\DoxyCodeLine{2988 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{2989 \textcolor{comment}{}}
\DoxyCodeLine{2990 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{2991 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{2992 \textcolor{comment}{}}
\DoxyCodeLine{2993 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{2994 \textcolor{comment}{format is used:}}
\DoxyCodeLine{2995 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{2996 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{2997 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{2998 \textcolor{comment}{}}
\DoxyCodeLine{2999 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{3000 \textcolor{comment}{dataset format is used:}}
\DoxyCodeLine{3001 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{3002 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{3003 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{3004 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{3005 \textcolor{comment}{}}
\DoxyCodeLine{3006 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3007 \textcolor{comment}{     Copyright 11.03.2008 by Bochkanov Sergey}}
\DoxyCodeLine{3008 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3009 \textcolor{keywordtype}{double} mlpavgrelerror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3010 }
\DoxyCodeLine{3011 }
\DoxyCodeLine{3012 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3013 \textcolor{comment}{Average relative error on the test set given by sparse matrix.}}
\DoxyCodeLine{3014 \textcolor{comment}{}}
\DoxyCodeLine{3015 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{3016 \textcolor{comment}{  !}}
\DoxyCodeLine{3017 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{3018 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{3019 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{3020 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{3021 \textcolor{comment}{  !}}
\DoxyCodeLine{3022 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{3023 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{3024 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{3025 \textcolor{comment}{}}
\DoxyCodeLine{3026 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3027 \textcolor{comment}{    Network     -\/   neural network;}}
\DoxyCodeLine{3028 \textcolor{comment}{    XY          -\/   training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{3029 \textcolor{comment}{                    training set format. This function checks  correctness}}
\DoxyCodeLine{3030 \textcolor{comment}{                    of  the  dataset  (no  NANs/INFs,  class  numbers  are}}
\DoxyCodeLine{3031 \textcolor{comment}{                    correct) and throws exception when  incorrect  dataset}}
\DoxyCodeLine{3032 \textcolor{comment}{                    is passed.  Sparse  matrix  must  use  CRS  format for}}
\DoxyCodeLine{3033 \textcolor{comment}{                    storage.}}
\DoxyCodeLine{3034 \textcolor{comment}{    NPoints     -\/   points count, >=0.}}
\DoxyCodeLine{3035 \textcolor{comment}{}}
\DoxyCodeLine{3036 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{3037 \textcolor{comment}{Its meaning for regression task is obvious. As for classification task, it}}
\DoxyCodeLine{3038 \textcolor{comment}{means  average  relative  error  when  estimating posterior probability of}}
\DoxyCodeLine{3039 \textcolor{comment}{belonging to the correct class.}}
\DoxyCodeLine{3040 \textcolor{comment}{}}
\DoxyCodeLine{3041 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{3042 \textcolor{comment}{}}
\DoxyCodeLine{3043 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{3044 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{3045 \textcolor{comment}{}}
\DoxyCodeLine{3046 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{3047 \textcolor{comment}{format is used:}}
\DoxyCodeLine{3048 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{3049 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{3050 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{3051 \textcolor{comment}{}}
\DoxyCodeLine{3052 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{3053 \textcolor{comment}{dataset format is used:}}
\DoxyCodeLine{3054 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{3055 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{3056 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{3057 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{3058 \textcolor{comment}{}}
\DoxyCodeLine{3059 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3060 \textcolor{comment}{     Copyright 09.08.2012 by Bochkanov Sergey}}
\DoxyCodeLine{3061 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3062 \textcolor{keywordtype}{double} mlpavgrelerrorsparse(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1sparsematrix}{sparsematrix}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3063 }
\DoxyCodeLine{3064 }
\DoxyCodeLine{3065 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3066 \textcolor{comment}{Gradient calculation}}
\DoxyCodeLine{3067 \textcolor{comment}{}}
\DoxyCodeLine{3068 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3069 \textcolor{comment}{    Network -\/   network initialized with one of the network creation funcs}}
\DoxyCodeLine{3070 \textcolor{comment}{    X       -\/   input vector, length of array must be at least NIn}}
\DoxyCodeLine{3071 \textcolor{comment}{    DesiredY-\/   desired outputs, length of array must be at least NOut}}
\DoxyCodeLine{3072 \textcolor{comment}{    Grad    -\/   possibly preallocated array. If size of array is smaller}}
\DoxyCodeLine{3073 \textcolor{comment}{                than WCount, it will be reallocated. It is recommended to}}
\DoxyCodeLine{3074 \textcolor{comment}{                reuse previously allocated array to reduce allocation}}
\DoxyCodeLine{3075 \textcolor{comment}{                overhead.}}
\DoxyCodeLine{3076 \textcolor{comment}{}}
\DoxyCodeLine{3077 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{3078 \textcolor{comment}{    E       -\/   error function, SUM(sqr(y[i]-\/desiredy[i])/2,i)}}
\DoxyCodeLine{3079 \textcolor{comment}{    Grad    -\/   gradient of E with respect to weights of network, array[WCount]}}
\DoxyCodeLine{3080 \textcolor{comment}{}}
\DoxyCodeLine{3081 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3082 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{3083 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3084 \textcolor{keywordtype}{void} mlpgrad(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&desiredy, \textcolor{keywordtype}{double} \&e, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&grad, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3085 }
\DoxyCodeLine{3086 }
\DoxyCodeLine{3087 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3088 \textcolor{comment}{Gradient calculation (natural error function is used)}}
\DoxyCodeLine{3089 \textcolor{comment}{}}
\DoxyCodeLine{3090 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3091 \textcolor{comment}{    Network -\/   network initialized with one of the network creation funcs}}
\DoxyCodeLine{3092 \textcolor{comment}{    X       -\/   input vector, length of array must be at least NIn}}
\DoxyCodeLine{3093 \textcolor{comment}{    DesiredY-\/   desired outputs, length of array must be at least NOut}}
\DoxyCodeLine{3094 \textcolor{comment}{    Grad    -\/   possibly preallocated array. If size of array is smaller}}
\DoxyCodeLine{3095 \textcolor{comment}{                than WCount, it will be reallocated. It is recommended to}}
\DoxyCodeLine{3096 \textcolor{comment}{                reuse previously allocated array to reduce allocation}}
\DoxyCodeLine{3097 \textcolor{comment}{                overhead.}}
\DoxyCodeLine{3098 \textcolor{comment}{}}
\DoxyCodeLine{3099 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{3100 \textcolor{comment}{    E       -\/   error function, sum-\/of-\/squares for regression networks,}}
\DoxyCodeLine{3101 \textcolor{comment}{                cross-\/entropy for classification networks.}}
\DoxyCodeLine{3102 \textcolor{comment}{    Grad    -\/   gradient of E with respect to weights of network, array[WCount]}}
\DoxyCodeLine{3103 \textcolor{comment}{}}
\DoxyCodeLine{3104 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3105 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{3106 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3107 \textcolor{keywordtype}{void} mlpgradn(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&desiredy, \textcolor{keywordtype}{double} \&e, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&grad, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3108 }
\DoxyCodeLine{3109 }
\DoxyCodeLine{3110 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3111 \textcolor{comment}{Batch gradient calculation for a set of inputs/outputs}}
\DoxyCodeLine{3112 \textcolor{comment}{}}
\DoxyCodeLine{3113 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{3114 \textcolor{comment}{  !}}
\DoxyCodeLine{3115 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{3116 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{3117 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{3118 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{3119 \textcolor{comment}{  !}}
\DoxyCodeLine{3120 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{3121 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{3122 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{3123 \textcolor{comment}{}}
\DoxyCodeLine{3124 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3125 \textcolor{comment}{    Network -\/   network initialized with one of the network creation funcs}}
\DoxyCodeLine{3126 \textcolor{comment}{    XY      -\/   original dataset in dense format; one sample = one row:}}
\DoxyCodeLine{3127 \textcolor{comment}{                * first NIn columns contain inputs,}}
\DoxyCodeLine{3128 \textcolor{comment}{                * for regression problem, next NOut columns store}}
\DoxyCodeLine{3129 \textcolor{comment}{                  desired outputs.}}
\DoxyCodeLine{3130 \textcolor{comment}{                * for classification problem, next column (just one!)}}
\DoxyCodeLine{3131 \textcolor{comment}{                  stores class number.}}
\DoxyCodeLine{3132 \textcolor{comment}{    SSize   -\/   number of elements in XY}}
\DoxyCodeLine{3133 \textcolor{comment}{    Grad    -\/   possibly preallocated array. If size of array is smaller}}
\DoxyCodeLine{3134 \textcolor{comment}{                than WCount, it will be reallocated. It is recommended to}}
\DoxyCodeLine{3135 \textcolor{comment}{                reuse previously allocated array to reduce allocation}}
\DoxyCodeLine{3136 \textcolor{comment}{                overhead.}}
\DoxyCodeLine{3137 \textcolor{comment}{}}
\DoxyCodeLine{3138 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{3139 \textcolor{comment}{    E       -\/   error function, SUM(sqr(y[i]-\/desiredy[i])/2,i)}}
\DoxyCodeLine{3140 \textcolor{comment}{    Grad    -\/   gradient of E with respect to weights of network, array[WCount]}}
\DoxyCodeLine{3141 \textcolor{comment}{}}
\DoxyCodeLine{3142 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3143 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{3144 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3145 \textcolor{keywordtype}{void} mlpgradbatch(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t ssize, \textcolor{keywordtype}{double} \&e, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&grad, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3146 }
\DoxyCodeLine{3147 }
\DoxyCodeLine{3148 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3149 \textcolor{comment}{Batch gradient calculation for a set  of inputs/outputs  given  by  sparse}}
\DoxyCodeLine{3150 \textcolor{comment}{matrices}}
\DoxyCodeLine{3151 \textcolor{comment}{}}
\DoxyCodeLine{3152 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{3153 \textcolor{comment}{  !}}
\DoxyCodeLine{3154 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{3155 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{3156 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{3157 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{3158 \textcolor{comment}{  !}}
\DoxyCodeLine{3159 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{3160 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{3161 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{3162 \textcolor{comment}{}}
\DoxyCodeLine{3163 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3164 \textcolor{comment}{    Network -\/   network initialized with one of the network creation funcs}}
\DoxyCodeLine{3165 \textcolor{comment}{    XY      -\/   original dataset in sparse format; one sample = one row:}}
\DoxyCodeLine{3166 \textcolor{comment}{                * MATRIX MUST BE STORED IN CRS FORMAT}}
\DoxyCodeLine{3167 \textcolor{comment}{                * first NIn columns contain inputs.}}
\DoxyCodeLine{3168 \textcolor{comment}{                * for regression problem, next NOut columns store}}
\DoxyCodeLine{3169 \textcolor{comment}{                  desired outputs.}}
\DoxyCodeLine{3170 \textcolor{comment}{                * for classification problem, next column (just one!)}}
\DoxyCodeLine{3171 \textcolor{comment}{                  stores class number.}}
\DoxyCodeLine{3172 \textcolor{comment}{    SSize   -\/   number of elements in XY}}
\DoxyCodeLine{3173 \textcolor{comment}{    Grad    -\/   possibly preallocated array. If size of array is smaller}}
\DoxyCodeLine{3174 \textcolor{comment}{                than WCount, it will be reallocated. It is recommended to}}
\DoxyCodeLine{3175 \textcolor{comment}{                reuse previously allocated array to reduce allocation}}
\DoxyCodeLine{3176 \textcolor{comment}{                overhead.}}
\DoxyCodeLine{3177 \textcolor{comment}{}}
\DoxyCodeLine{3178 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{3179 \textcolor{comment}{    E       -\/   error function, SUM(sqr(y[i]-\/desiredy[i])/2,i)}}
\DoxyCodeLine{3180 \textcolor{comment}{    Grad    -\/   gradient of E with respect to weights of network, array[WCount]}}
\DoxyCodeLine{3181 \textcolor{comment}{}}
\DoxyCodeLine{3182 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3183 \textcolor{comment}{     Copyright 26.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{3184 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3185 \textcolor{keywordtype}{void} mlpgradbatchsparse(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1sparsematrix}{sparsematrix}} \&xy, \textcolor{keyword}{const} ae\_int\_t ssize, \textcolor{keywordtype}{double} \&e, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&grad, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3186 }
\DoxyCodeLine{3187 }
\DoxyCodeLine{3188 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3189 \textcolor{comment}{Batch gradient calculation for a subset of dataset}}
\DoxyCodeLine{3190 \textcolor{comment}{}}
\DoxyCodeLine{3191 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{3192 \textcolor{comment}{  !}}
\DoxyCodeLine{3193 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{3194 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{3195 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{3196 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{3197 \textcolor{comment}{  !}}
\DoxyCodeLine{3198 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{3199 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{3200 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{3201 \textcolor{comment}{}}
\DoxyCodeLine{3202 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3203 \textcolor{comment}{    Network -\/   network initialized with one of the network creation funcs}}
\DoxyCodeLine{3204 \textcolor{comment}{    XY      -\/   original dataset in dense format; one sample = one row:}}
\DoxyCodeLine{3205 \textcolor{comment}{                * first NIn columns contain inputs,}}
\DoxyCodeLine{3206 \textcolor{comment}{                * for regression problem, next NOut columns store}}
\DoxyCodeLine{3207 \textcolor{comment}{                  desired outputs.}}
\DoxyCodeLine{3208 \textcolor{comment}{                * for classification problem, next column (just one!)}}
\DoxyCodeLine{3209 \textcolor{comment}{                  stores class number.}}
\DoxyCodeLine{3210 \textcolor{comment}{    SetSize -\/   real size of XY, SetSize>=0;}}
\DoxyCodeLine{3211 \textcolor{comment}{    Idx     -\/   subset of SubsetSize elements, array[SubsetSize]:}}
\DoxyCodeLine{3212 \textcolor{comment}{                * Idx[I] stores row index in the original dataset which is}}
\DoxyCodeLine{3213 \textcolor{comment}{                  given by XY. Gradient is calculated with respect to rows}}
\DoxyCodeLine{3214 \textcolor{comment}{                  whose indexes are stored in Idx[].}}
\DoxyCodeLine{3215 \textcolor{comment}{                * Idx[]  must store correct indexes; this function  throws}}
\DoxyCodeLine{3216 \textcolor{comment}{                  an  exception  in  case  incorrect index (less than 0 or}}
\DoxyCodeLine{3217 \textcolor{comment}{                  larger than rows(XY)) is given}}
\DoxyCodeLine{3218 \textcolor{comment}{                * Idx[]  may  store  indexes  in  any  order and even with}}
\DoxyCodeLine{3219 \textcolor{comment}{                  repetitions.}}
\DoxyCodeLine{3220 \textcolor{comment}{    SubsetSize-\/ number of elements in Idx[] array:}}
\DoxyCodeLine{3221 \textcolor{comment}{                * positive value means that subset given by Idx[] is processed}}
\DoxyCodeLine{3222 \textcolor{comment}{                * zero value results in zero gradient}}
\DoxyCodeLine{3223 \textcolor{comment}{                * negative value means that full dataset is processed}}
\DoxyCodeLine{3224 \textcolor{comment}{    Grad      -\/ possibly  preallocated array. If size of array is  smaller}}
\DoxyCodeLine{3225 \textcolor{comment}{                than WCount, it will be reallocated. It is  recommended to}}
\DoxyCodeLine{3226 \textcolor{comment}{                reuse  previously  allocated  array  to  reduce allocation}}
\DoxyCodeLine{3227 \textcolor{comment}{                overhead.}}
\DoxyCodeLine{3228 \textcolor{comment}{}}
\DoxyCodeLine{3229 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{3230 \textcolor{comment}{    E         -\/ error function, SUM(sqr(y[i]-\/desiredy[i])/2,i)}}
\DoxyCodeLine{3231 \textcolor{comment}{    Grad      -\/ gradient  of  E  with  respect   to  weights  of  network,}}
\DoxyCodeLine{3232 \textcolor{comment}{                array[WCount]}}
\DoxyCodeLine{3233 \textcolor{comment}{}}
\DoxyCodeLine{3234 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3235 \textcolor{comment}{     Copyright 26.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{3236 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3237 \textcolor{keywordtype}{void} mlpgradbatchsubset(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t setsize, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&idx, \textcolor{keyword}{const} ae\_int\_t subsetsize, \textcolor{keywordtype}{double} \&e, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&grad, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3238 }
\DoxyCodeLine{3239 }
\DoxyCodeLine{3240 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3241 \textcolor{comment}{Batch gradient calculation for a set of inputs/outputs  for  a  subset  of}}
\DoxyCodeLine{3242 \textcolor{comment}{dataset given by set of indexes.}}
\DoxyCodeLine{3243 \textcolor{comment}{}}
\DoxyCodeLine{3244 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{3245 \textcolor{comment}{  !}}
\DoxyCodeLine{3246 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{3247 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{3248 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{3249 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{3250 \textcolor{comment}{  !}}
\DoxyCodeLine{3251 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{3252 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{3253 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{3254 \textcolor{comment}{}}
\DoxyCodeLine{3255 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3256 \textcolor{comment}{    Network -\/   network initialized with one of the network creation funcs}}
\DoxyCodeLine{3257 \textcolor{comment}{    XY      -\/   original dataset in sparse format; one sample = one row:}}
\DoxyCodeLine{3258 \textcolor{comment}{                * MATRIX MUST BE STORED IN CRS FORMAT}}
\DoxyCodeLine{3259 \textcolor{comment}{                * first NIn columns contain inputs,}}
\DoxyCodeLine{3260 \textcolor{comment}{                * for regression problem, next NOut columns store}}
\DoxyCodeLine{3261 \textcolor{comment}{                  desired outputs.}}
\DoxyCodeLine{3262 \textcolor{comment}{                * for classification problem, next column (just one!)}}
\DoxyCodeLine{3263 \textcolor{comment}{                  stores class number.}}
\DoxyCodeLine{3264 \textcolor{comment}{    SetSize -\/   real size of XY, SetSize>=0;}}
\DoxyCodeLine{3265 \textcolor{comment}{    Idx     -\/   subset of SubsetSize elements, array[SubsetSize]:}}
\DoxyCodeLine{3266 \textcolor{comment}{                * Idx[I] stores row index in the original dataset which is}}
\DoxyCodeLine{3267 \textcolor{comment}{                  given by XY. Gradient is calculated with respect to rows}}
\DoxyCodeLine{3268 \textcolor{comment}{                  whose indexes are stored in Idx[].}}
\DoxyCodeLine{3269 \textcolor{comment}{                * Idx[]  must store correct indexes; this function  throws}}
\DoxyCodeLine{3270 \textcolor{comment}{                  an  exception  in  case  incorrect index (less than 0 or}}
\DoxyCodeLine{3271 \textcolor{comment}{                  larger than rows(XY)) is given}}
\DoxyCodeLine{3272 \textcolor{comment}{                * Idx[]  may  store  indexes  in  any  order and even with}}
\DoxyCodeLine{3273 \textcolor{comment}{                  repetitions.}}
\DoxyCodeLine{3274 \textcolor{comment}{    SubsetSize-\/ number of elements in Idx[] array:}}
\DoxyCodeLine{3275 \textcolor{comment}{                * positive value means that subset given by Idx[] is processed}}
\DoxyCodeLine{3276 \textcolor{comment}{                * zero value results in zero gradient}}
\DoxyCodeLine{3277 \textcolor{comment}{                * negative value means that full dataset is processed}}
\DoxyCodeLine{3278 \textcolor{comment}{    Grad      -\/ possibly  preallocated array. If size of array is  smaller}}
\DoxyCodeLine{3279 \textcolor{comment}{                than WCount, it will be reallocated. It is  recommended to}}
\DoxyCodeLine{3280 \textcolor{comment}{                reuse  previously  allocated  array  to  reduce allocation}}
\DoxyCodeLine{3281 \textcolor{comment}{                overhead.}}
\DoxyCodeLine{3282 \textcolor{comment}{}}
\DoxyCodeLine{3283 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{3284 \textcolor{comment}{    E       -\/   error function, SUM(sqr(y[i]-\/desiredy[i])/2,i)}}
\DoxyCodeLine{3285 \textcolor{comment}{    Grad    -\/   gradient  of  E  with  respect   to  weights  of  network,}}
\DoxyCodeLine{3286 \textcolor{comment}{                array[WCount]}}
\DoxyCodeLine{3287 \textcolor{comment}{}}
\DoxyCodeLine{3288 \textcolor{comment}{NOTE: when  SubsetSize<0 is used full dataset by call MLPGradBatchSparse}}
\DoxyCodeLine{3289 \textcolor{comment}{      function.}}
\DoxyCodeLine{3290 \textcolor{comment}{}}
\DoxyCodeLine{3291 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3292 \textcolor{comment}{     Copyright 26.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{3293 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3294 \textcolor{keywordtype}{void} mlpgradbatchsparsesubset(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1sparsematrix}{sparsematrix}} \&xy, \textcolor{keyword}{const} ae\_int\_t setsize, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&idx, \textcolor{keyword}{const} ae\_int\_t subsetsize, \textcolor{keywordtype}{double} \&e, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&grad, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3295 }
\DoxyCodeLine{3296 }
\DoxyCodeLine{3297 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3298 \textcolor{comment}{Batch gradient calculation for a set of inputs/outputs}}
\DoxyCodeLine{3299 \textcolor{comment}{(natural error function is used)}}
\DoxyCodeLine{3300 \textcolor{comment}{}}
\DoxyCodeLine{3301 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3302 \textcolor{comment}{    Network -\/   network initialized with one of the network creation funcs}}
\DoxyCodeLine{3303 \textcolor{comment}{    XY      -\/   set of inputs/outputs; one sample = one row;}}
\DoxyCodeLine{3304 \textcolor{comment}{                first NIn columns contain inputs,}}
\DoxyCodeLine{3305 \textcolor{comment}{                next NOut columns -\/ desired outputs.}}
\DoxyCodeLine{3306 \textcolor{comment}{    SSize   -\/   number of elements in XY}}
\DoxyCodeLine{3307 \textcolor{comment}{    Grad    -\/   possibly preallocated array. If size of array is smaller}}
\DoxyCodeLine{3308 \textcolor{comment}{                than WCount, it will be reallocated. It is recommended to}}
\DoxyCodeLine{3309 \textcolor{comment}{                reuse previously allocated array to reduce allocation}}
\DoxyCodeLine{3310 \textcolor{comment}{                overhead.}}
\DoxyCodeLine{3311 \textcolor{comment}{}}
\DoxyCodeLine{3312 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{3313 \textcolor{comment}{    E       -\/   error function, sum-\/of-\/squares for regression networks,}}
\DoxyCodeLine{3314 \textcolor{comment}{                cross-\/entropy for classification networks.}}
\DoxyCodeLine{3315 \textcolor{comment}{    Grad    -\/   gradient of E with respect to weights of network, array[WCount]}}
\DoxyCodeLine{3316 \textcolor{comment}{}}
\DoxyCodeLine{3317 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3318 \textcolor{comment}{     Copyright 04.11.2007 by Bochkanov Sergey}}
\DoxyCodeLine{3319 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3320 \textcolor{keywordtype}{void} mlpgradnbatch(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t ssize, \textcolor{keywordtype}{double} \&e, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&grad, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3321 }
\DoxyCodeLine{3322 }
\DoxyCodeLine{3323 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3324 \textcolor{comment}{Batch Hessian calculation (natural error function) using R-\/algorithm.}}
\DoxyCodeLine{3325 \textcolor{comment}{Internal subroutine.}}
\DoxyCodeLine{3326 \textcolor{comment}{}}
\DoxyCodeLine{3327 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3328 \textcolor{comment}{     Copyright 26.01.2008 by Bochkanov Sergey.}}
\DoxyCodeLine{3329 \textcolor{comment}{}}
\DoxyCodeLine{3330 \textcolor{comment}{     Hessian calculation based on R-\/algorithm described in}}
\DoxyCodeLine{3331 \textcolor{comment}{     "{}Fast Exact Multiplication by the Hessian"{},}}
\DoxyCodeLine{3332 \textcolor{comment}{     B. A. Pearlmutter,}}
\DoxyCodeLine{3333 \textcolor{comment}{     Neural Computation, 1994.}}
\DoxyCodeLine{3334 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3335 \textcolor{keywordtype}{void} mlphessiannbatch(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t ssize, \textcolor{keywordtype}{double} \&e, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&grad, \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&h, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3336 }
\DoxyCodeLine{3337 }
\DoxyCodeLine{3338 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3339 \textcolor{comment}{Batch Hessian calculation using R-\/algorithm.}}
\DoxyCodeLine{3340 \textcolor{comment}{Internal subroutine.}}
\DoxyCodeLine{3341 \textcolor{comment}{}}
\DoxyCodeLine{3342 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3343 \textcolor{comment}{     Copyright 26.01.2008 by Bochkanov Sergey.}}
\DoxyCodeLine{3344 \textcolor{comment}{}}
\DoxyCodeLine{3345 \textcolor{comment}{     Hessian calculation based on R-\/algorithm described in}}
\DoxyCodeLine{3346 \textcolor{comment}{     "{}Fast Exact Multiplication by the Hessian"{},}}
\DoxyCodeLine{3347 \textcolor{comment}{     B. A. Pearlmutter,}}
\DoxyCodeLine{3348 \textcolor{comment}{     Neural Computation, 1994.}}
\DoxyCodeLine{3349 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3350 \textcolor{keywordtype}{void} mlphessianbatch(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t ssize, \textcolor{keywordtype}{double} \&e, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&grad, \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&h, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3351 }
\DoxyCodeLine{3352 }
\DoxyCodeLine{3353 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3354 \textcolor{comment}{Calculation of all types of errors on subset of dataset.}}
\DoxyCodeLine{3355 \textcolor{comment}{}}
\DoxyCodeLine{3356 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{3357 \textcolor{comment}{  !}}
\DoxyCodeLine{3358 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{3359 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{3360 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{3361 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{3362 \textcolor{comment}{  !}}
\DoxyCodeLine{3363 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{3364 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{3365 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{3366 \textcolor{comment}{}}
\DoxyCodeLine{3367 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3368 \textcolor{comment}{    Network -\/   network initialized with one of the network creation funcs}}
\DoxyCodeLine{3369 \textcolor{comment}{    XY      -\/   original dataset; one sample = one row;}}
\DoxyCodeLine{3370 \textcolor{comment}{                first NIn columns contain inputs,}}
\DoxyCodeLine{3371 \textcolor{comment}{                next NOut columns -\/ desired outputs.}}
\DoxyCodeLine{3372 \textcolor{comment}{    SetSize -\/   real size of XY, SetSize>=0;}}
\DoxyCodeLine{3373 \textcolor{comment}{    Subset  -\/   subset of SubsetSize elements, array[SubsetSize];}}
\DoxyCodeLine{3374 \textcolor{comment}{    SubsetSize-\/ number of elements in Subset[] array:}}
\DoxyCodeLine{3375 \textcolor{comment}{                * if SubsetSize>0, rows of XY with indices Subset[0]...}}
\DoxyCodeLine{3376 \textcolor{comment}{                  ...Subset[SubsetSize-\/1] are processed}}
\DoxyCodeLine{3377 \textcolor{comment}{                * if SubsetSize=0, zeros are returned}}
\DoxyCodeLine{3378 \textcolor{comment}{                * if SubsetSize<0, entire dataset is  processed;  Subset[]}}
\DoxyCodeLine{3379 \textcolor{comment}{                  array is ignored in this case.}}
\DoxyCodeLine{3380 \textcolor{comment}{}}
\DoxyCodeLine{3381 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{3382 \textcolor{comment}{    Rep     -\/   it contains all type of errors.}}
\DoxyCodeLine{3383 \textcolor{comment}{}}
\DoxyCodeLine{3384 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3385 \textcolor{comment}{     Copyright 04.09.2012 by Bochkanov Sergey}}
\DoxyCodeLine{3386 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3387 \textcolor{keywordtype}{void} mlpallerrorssubset(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t setsize, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&subset, \textcolor{keyword}{const} ae\_int\_t subsetsize, \mbox{\hyperlink{classalglib_1_1modelerrors}{modelerrors}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3388 }
\DoxyCodeLine{3389 }
\DoxyCodeLine{3390 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3391 \textcolor{comment}{Calculation of all types of errors on subset of dataset.}}
\DoxyCodeLine{3392 \textcolor{comment}{}}
\DoxyCodeLine{3393 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{3394 \textcolor{comment}{  !}}
\DoxyCodeLine{3395 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{3396 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{3397 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{3398 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{3399 \textcolor{comment}{  !}}
\DoxyCodeLine{3400 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{3401 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{3402 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{3403 \textcolor{comment}{}}
\DoxyCodeLine{3404 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3405 \textcolor{comment}{    Network -\/   network initialized with one of the network creation funcs}}
\DoxyCodeLine{3406 \textcolor{comment}{    XY      -\/   original dataset given by sparse matrix;}}
\DoxyCodeLine{3407 \textcolor{comment}{                one sample = one row;}}
\DoxyCodeLine{3408 \textcolor{comment}{                first NIn columns contain inputs,}}
\DoxyCodeLine{3409 \textcolor{comment}{                next NOut columns -\/ desired outputs.}}
\DoxyCodeLine{3410 \textcolor{comment}{    SetSize -\/   real size of XY, SetSize>=0;}}
\DoxyCodeLine{3411 \textcolor{comment}{    Subset  -\/   subset of SubsetSize elements, array[SubsetSize];}}
\DoxyCodeLine{3412 \textcolor{comment}{    SubsetSize-\/ number of elements in Subset[] array:}}
\DoxyCodeLine{3413 \textcolor{comment}{                * if SubsetSize>0, rows of XY with indices Subset[0]...}}
\DoxyCodeLine{3414 \textcolor{comment}{                  ...Subset[SubsetSize-\/1] are processed}}
\DoxyCodeLine{3415 \textcolor{comment}{                * if SubsetSize=0, zeros are returned}}
\DoxyCodeLine{3416 \textcolor{comment}{                * if SubsetSize<0, entire dataset is  processed;  Subset[]}}
\DoxyCodeLine{3417 \textcolor{comment}{                  array is ignored in this case.}}
\DoxyCodeLine{3418 \textcolor{comment}{}}
\DoxyCodeLine{3419 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{3420 \textcolor{comment}{    Rep     -\/   it contains all type of errors.}}
\DoxyCodeLine{3421 \textcolor{comment}{}}
\DoxyCodeLine{3422 \textcolor{comment}{}}
\DoxyCodeLine{3423 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3424 \textcolor{comment}{     Copyright 04.09.2012 by Bochkanov Sergey}}
\DoxyCodeLine{3425 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3426 \textcolor{keywordtype}{void} mlpallerrorssparsesubset(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1sparsematrix}{sparsematrix}} \&xy, \textcolor{keyword}{const} ae\_int\_t setsize, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&subset, \textcolor{keyword}{const} ae\_int\_t subsetsize, \mbox{\hyperlink{classalglib_1_1modelerrors}{modelerrors}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3427 }
\DoxyCodeLine{3428 }
\DoxyCodeLine{3429 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3430 \textcolor{comment}{Error of the neural network on subset of dataset.}}
\DoxyCodeLine{3431 \textcolor{comment}{}}
\DoxyCodeLine{3432 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{3433 \textcolor{comment}{  !}}
\DoxyCodeLine{3434 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{3435 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{3436 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{3437 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{3438 \textcolor{comment}{  !}}
\DoxyCodeLine{3439 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{3440 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{3441 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{3442 \textcolor{comment}{}}
\DoxyCodeLine{3443 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3444 \textcolor{comment}{    Network   -\/     neural network;}}
\DoxyCodeLine{3445 \textcolor{comment}{    XY        -\/     training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{3446 \textcolor{comment}{                    training set format;}}
\DoxyCodeLine{3447 \textcolor{comment}{    SetSize   -\/     real size of XY, SetSize>=0;}}
\DoxyCodeLine{3448 \textcolor{comment}{    Subset    -\/     subset of SubsetSize elements, array[SubsetSize];}}
\DoxyCodeLine{3449 \textcolor{comment}{    SubsetSize-\/     number of elements in Subset[] array:}}
\DoxyCodeLine{3450 \textcolor{comment}{                    * if SubsetSize>0, rows of XY with indices Subset[0]...}}
\DoxyCodeLine{3451 \textcolor{comment}{                      ...Subset[SubsetSize-\/1] are processed}}
\DoxyCodeLine{3452 \textcolor{comment}{                    * if SubsetSize=0, zeros are returned}}
\DoxyCodeLine{3453 \textcolor{comment}{                    * if SubsetSize<0, entire dataset is  processed;  Subset[]}}
\DoxyCodeLine{3454 \textcolor{comment}{                      array is ignored in this case.}}
\DoxyCodeLine{3455 \textcolor{comment}{}}
\DoxyCodeLine{3456 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{3457 \textcolor{comment}{    sum-\/of-\/squares error, SUM(sqr(y[i]-\/desired\_y[i])/2)}}
\DoxyCodeLine{3458 \textcolor{comment}{}}
\DoxyCodeLine{3459 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{3460 \textcolor{comment}{}}
\DoxyCodeLine{3461 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{3462 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{3463 \textcolor{comment}{}}
\DoxyCodeLine{3464 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{3465 \textcolor{comment}{format is used:}}
\DoxyCodeLine{3466 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{3467 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{3468 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{3469 \textcolor{comment}{}}
\DoxyCodeLine{3470 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{3471 \textcolor{comment}{dataset format is used:}}
\DoxyCodeLine{3472 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{3473 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{3474 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{3475 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{3476 \textcolor{comment}{}}
\DoxyCodeLine{3477 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3478 \textcolor{comment}{     Copyright 04.09.2012 by Bochkanov Sergey}}
\DoxyCodeLine{3479 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3480 \textcolor{keywordtype}{double} mlperrorsubset(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t setsize, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&subset, \textcolor{keyword}{const} ae\_int\_t subsetsize, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3481 }
\DoxyCodeLine{3482 }
\DoxyCodeLine{3483 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3484 \textcolor{comment}{Error of the neural network on subset of sparse dataset.}}
\DoxyCodeLine{3485 \textcolor{comment}{}}
\DoxyCodeLine{3486 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{3487 \textcolor{comment}{  !}}
\DoxyCodeLine{3488 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{3489 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{3490 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{3491 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{3492 \textcolor{comment}{  !}}
\DoxyCodeLine{3493 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{3494 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{3495 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{3496 \textcolor{comment}{}}
\DoxyCodeLine{3497 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3498 \textcolor{comment}{    Network   -\/     neural network;}}
\DoxyCodeLine{3499 \textcolor{comment}{    XY        -\/     training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{3500 \textcolor{comment}{                    training set format. This function checks  correctness}}
\DoxyCodeLine{3501 \textcolor{comment}{                    of  the  dataset  (no  NANs/INFs,  class  numbers  are}}
\DoxyCodeLine{3502 \textcolor{comment}{                    correct) and throws exception when  incorrect  dataset}}
\DoxyCodeLine{3503 \textcolor{comment}{                    is passed.  Sparse  matrix  must  use  CRS  format for}}
\DoxyCodeLine{3504 \textcolor{comment}{                    storage.}}
\DoxyCodeLine{3505 \textcolor{comment}{    SetSize   -\/     real size of XY, SetSize>=0;}}
\DoxyCodeLine{3506 \textcolor{comment}{                    it is used when SubsetSize<0;}}
\DoxyCodeLine{3507 \textcolor{comment}{    Subset    -\/     subset of SubsetSize elements, array[SubsetSize];}}
\DoxyCodeLine{3508 \textcolor{comment}{    SubsetSize-\/     number of elements in Subset[] array:}}
\DoxyCodeLine{3509 \textcolor{comment}{                    * if SubsetSize>0, rows of XY with indices Subset[0]...}}
\DoxyCodeLine{3510 \textcolor{comment}{                      ...Subset[SubsetSize-\/1] are processed}}
\DoxyCodeLine{3511 \textcolor{comment}{                    * if SubsetSize=0, zeros are returned}}
\DoxyCodeLine{3512 \textcolor{comment}{                    * if SubsetSize<0, entire dataset is  processed;  Subset[]}}
\DoxyCodeLine{3513 \textcolor{comment}{                      array is ignored in this case.}}
\DoxyCodeLine{3514 \textcolor{comment}{}}
\DoxyCodeLine{3515 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{3516 \textcolor{comment}{    sum-\/of-\/squares error, SUM(sqr(y[i]-\/desired\_y[i])/2)}}
\DoxyCodeLine{3517 \textcolor{comment}{}}
\DoxyCodeLine{3518 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{3519 \textcolor{comment}{}}
\DoxyCodeLine{3520 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{3521 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{3522 \textcolor{comment}{}}
\DoxyCodeLine{3523 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{3524 \textcolor{comment}{format is used:}}
\DoxyCodeLine{3525 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{3526 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{3527 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{3528 \textcolor{comment}{}}
\DoxyCodeLine{3529 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{3530 \textcolor{comment}{dataset format is used:}}
\DoxyCodeLine{3531 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{3532 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{3533 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{3534 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{3535 \textcolor{comment}{}}
\DoxyCodeLine{3536 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3537 \textcolor{comment}{     Copyright 04.09.2012 by Bochkanov Sergey}}
\DoxyCodeLine{3538 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3539 \textcolor{keywordtype}{double} mlperrorsparsesubset(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1sparsematrix}{sparsematrix}} \&xy, \textcolor{keyword}{const} ae\_int\_t setsize, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&subset, \textcolor{keyword}{const} ae\_int\_t subsetsize, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3540 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{3541 }
\DoxyCodeLine{3542 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_MLPE) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{3543 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3544 \textcolor{comment}{This function serializes data structure to string.}}
\DoxyCodeLine{3545 \textcolor{comment}{}}
\DoxyCodeLine{3546 \textcolor{comment}{Important properties of s\_out:}}
\DoxyCodeLine{3547 \textcolor{comment}{* it contains alphanumeric characters, dots, underscores, minus signs}}
\DoxyCodeLine{3548 \textcolor{comment}{* these symbols are grouped into words, which are separated by spaces}}
\DoxyCodeLine{3549 \textcolor{comment}{  and Windows-\/style (CR+LF) newlines}}
\DoxyCodeLine{3550 \textcolor{comment}{* although  serializer  uses  spaces and CR+LF as separators, you can }}
\DoxyCodeLine{3551 \textcolor{comment}{  replace any separator character by arbitrary combination of spaces,}}
\DoxyCodeLine{3552 \textcolor{comment}{  tabs, Windows or Unix newlines. It allows flexible reformatting  of}}
\DoxyCodeLine{3553 \textcolor{comment}{  the  string  in  case you want to include it into text or XML file. }}
\DoxyCodeLine{3554 \textcolor{comment}{  But you should not insert separators into the middle of the "{}words"{}}}
\DoxyCodeLine{3555 \textcolor{comment}{  nor you should change case of letters.}}
\DoxyCodeLine{3556 \textcolor{comment}{* s\_out can be freely moved between 32-\/bit and 64-\/bit systems, little}}
\DoxyCodeLine{3557 \textcolor{comment}{  and big endian machines, and so on. You can serialize structure  on}}
\DoxyCodeLine{3558 \textcolor{comment}{  32-\/bit machine and unserialize it on 64-\/bit one (or vice versa), or}}
\DoxyCodeLine{3559 \textcolor{comment}{  serialize  it  on  SPARC  and  unserialize  on  x86.  You  can also }}
\DoxyCodeLine{3560 \textcolor{comment}{  serialize  it  in  C++ version of ALGLIB and unserialize in C\# one, }}
\DoxyCodeLine{3561 \textcolor{comment}{  and vice versa.}}
\DoxyCodeLine{3562 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3563 \textcolor{keywordtype}{void} mlpeserialize(\mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&obj, std::string \&s\_out);}
\DoxyCodeLine{3564 }
\DoxyCodeLine{3565 }
\DoxyCodeLine{3566 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3567 \textcolor{comment}{This function unserializes data structure from string.}}
\DoxyCodeLine{3568 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3569 \textcolor{keywordtype}{void} mlpeunserialize(\textcolor{keyword}{const} std::string \&s\_in, \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&obj);}
\DoxyCodeLine{3570 }
\DoxyCodeLine{3571 }
\DoxyCodeLine{3572 }
\DoxyCodeLine{3573 }
\DoxyCodeLine{3574 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3575 \textcolor{comment}{This function serializes data structure to C++ stream.}}
\DoxyCodeLine{3576 \textcolor{comment}{}}
\DoxyCodeLine{3577 \textcolor{comment}{Data stream generated by this function is same as  string  representation}}
\DoxyCodeLine{3578 \textcolor{comment}{generated  by  string  version  of  serializer -\/ alphanumeric characters,}}
\DoxyCodeLine{3579 \textcolor{comment}{dots, underscores, minus signs, which are grouped into words separated by}}
\DoxyCodeLine{3580 \textcolor{comment}{spaces and CR+LF.}}
\DoxyCodeLine{3581 \textcolor{comment}{}}
\DoxyCodeLine{3582 \textcolor{comment}{We recommend you to read comments on string version of serializer to find}}
\DoxyCodeLine{3583 \textcolor{comment}{out more about serialization of AlGLIB objects.}}
\DoxyCodeLine{3584 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3585 \textcolor{keywordtype}{void} mlpeserialize(\mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&obj, std::ostream \&s\_out);}
\DoxyCodeLine{3586 }
\DoxyCodeLine{3587 }
\DoxyCodeLine{3588 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3589 \textcolor{comment}{This function unserializes data structure from stream.}}
\DoxyCodeLine{3590 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3591 \textcolor{keywordtype}{void} mlpeunserialize(\textcolor{keyword}{const} std::istream \&s\_in, \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&obj);}
\DoxyCodeLine{3592 }
\DoxyCodeLine{3593 }
\DoxyCodeLine{3594 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3595 \textcolor{comment}{Like MLPCreate0, but for ensembles.}}
\DoxyCodeLine{3596 \textcolor{comment}{}}
\DoxyCodeLine{3597 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3598 \textcolor{comment}{     Copyright 18.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3599 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3600 \textcolor{keywordtype}{void} mlpecreate0(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} ae\_int\_t ensemblesize, \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3601 }
\DoxyCodeLine{3602 }
\DoxyCodeLine{3603 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3604 \textcolor{comment}{Like MLPCreate1, but for ensembles.}}
\DoxyCodeLine{3605 \textcolor{comment}{}}
\DoxyCodeLine{3606 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3607 \textcolor{comment}{     Copyright 18.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3608 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3609 \textcolor{keywordtype}{void} mlpecreate1(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nhid, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} ae\_int\_t ensemblesize, \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3610 }
\DoxyCodeLine{3611 }
\DoxyCodeLine{3612 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3613 \textcolor{comment}{Like MLPCreate2, but for ensembles.}}
\DoxyCodeLine{3614 \textcolor{comment}{}}
\DoxyCodeLine{3615 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3616 \textcolor{comment}{     Copyright 18.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3617 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3618 \textcolor{keywordtype}{void} mlpecreate2(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nhid1, \textcolor{keyword}{const} ae\_int\_t nhid2, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} ae\_int\_t ensemblesize, \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3619 }
\DoxyCodeLine{3620 }
\DoxyCodeLine{3621 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3622 \textcolor{comment}{Like MLPCreateB0, but for ensembles.}}
\DoxyCodeLine{3623 \textcolor{comment}{}}
\DoxyCodeLine{3624 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3625 \textcolor{comment}{     Copyright 18.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3626 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3627 \textcolor{keywordtype}{void} mlpecreateb0(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} \textcolor{keywordtype}{double} b, \textcolor{keyword}{const} \textcolor{keywordtype}{double} d, \textcolor{keyword}{const} ae\_int\_t ensemblesize, \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3628 }
\DoxyCodeLine{3629 }
\DoxyCodeLine{3630 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3631 \textcolor{comment}{Like MLPCreateB1, but for ensembles.}}
\DoxyCodeLine{3632 \textcolor{comment}{}}
\DoxyCodeLine{3633 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3634 \textcolor{comment}{     Copyright 18.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3635 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3636 \textcolor{keywordtype}{void} mlpecreateb1(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nhid, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} \textcolor{keywordtype}{double} b, \textcolor{keyword}{const} \textcolor{keywordtype}{double} d, \textcolor{keyword}{const} ae\_int\_t ensemblesize, \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3637 }
\DoxyCodeLine{3638 }
\DoxyCodeLine{3639 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3640 \textcolor{comment}{Like MLPCreateB2, but for ensembles.}}
\DoxyCodeLine{3641 \textcolor{comment}{}}
\DoxyCodeLine{3642 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3643 \textcolor{comment}{     Copyright 18.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3644 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3645 \textcolor{keywordtype}{void} mlpecreateb2(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nhid1, \textcolor{keyword}{const} ae\_int\_t nhid2, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} \textcolor{keywordtype}{double} b, \textcolor{keyword}{const} \textcolor{keywordtype}{double} d, \textcolor{keyword}{const} ae\_int\_t ensemblesize, \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3646 }
\DoxyCodeLine{3647 }
\DoxyCodeLine{3648 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3649 \textcolor{comment}{Like MLPCreateR0, but for ensembles.}}
\DoxyCodeLine{3650 \textcolor{comment}{}}
\DoxyCodeLine{3651 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3652 \textcolor{comment}{     Copyright 18.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3653 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3654 \textcolor{keywordtype}{void} mlpecreater0(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} \textcolor{keywordtype}{double} a, \textcolor{keyword}{const} \textcolor{keywordtype}{double} b, \textcolor{keyword}{const} ae\_int\_t ensemblesize, \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3655 }
\DoxyCodeLine{3656 }
\DoxyCodeLine{3657 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3658 \textcolor{comment}{Like MLPCreateR1, but for ensembles.}}
\DoxyCodeLine{3659 \textcolor{comment}{}}
\DoxyCodeLine{3660 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3661 \textcolor{comment}{     Copyright 18.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3662 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3663 \textcolor{keywordtype}{void} mlpecreater1(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nhid, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} \textcolor{keywordtype}{double} a, \textcolor{keyword}{const} \textcolor{keywordtype}{double} b, \textcolor{keyword}{const} ae\_int\_t ensemblesize, \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3664 }
\DoxyCodeLine{3665 }
\DoxyCodeLine{3666 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3667 \textcolor{comment}{Like MLPCreateR2, but for ensembles.}}
\DoxyCodeLine{3668 \textcolor{comment}{}}
\DoxyCodeLine{3669 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3670 \textcolor{comment}{     Copyright 18.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3671 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3672 \textcolor{keywordtype}{void} mlpecreater2(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nhid1, \textcolor{keyword}{const} ae\_int\_t nhid2, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} \textcolor{keywordtype}{double} a, \textcolor{keyword}{const} \textcolor{keywordtype}{double} b, \textcolor{keyword}{const} ae\_int\_t ensemblesize, \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3673 }
\DoxyCodeLine{3674 }
\DoxyCodeLine{3675 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3676 \textcolor{comment}{Like MLPCreateC0, but for ensembles.}}
\DoxyCodeLine{3677 \textcolor{comment}{}}
\DoxyCodeLine{3678 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3679 \textcolor{comment}{     Copyright 18.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3680 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3681 \textcolor{keywordtype}{void} mlpecreatec0(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} ae\_int\_t ensemblesize, \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3682 }
\DoxyCodeLine{3683 }
\DoxyCodeLine{3684 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3685 \textcolor{comment}{Like MLPCreateC1, but for ensembles.}}
\DoxyCodeLine{3686 \textcolor{comment}{}}
\DoxyCodeLine{3687 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3688 \textcolor{comment}{     Copyright 18.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3689 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3690 \textcolor{keywordtype}{void} mlpecreatec1(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nhid, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} ae\_int\_t ensemblesize, \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3691 }
\DoxyCodeLine{3692 }
\DoxyCodeLine{3693 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3694 \textcolor{comment}{Like MLPCreateC2, but for ensembles.}}
\DoxyCodeLine{3695 \textcolor{comment}{}}
\DoxyCodeLine{3696 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3697 \textcolor{comment}{     Copyright 18.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3698 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3699 \textcolor{keywordtype}{void} mlpecreatec2(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nhid1, \textcolor{keyword}{const} ae\_int\_t nhid2, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} ae\_int\_t ensemblesize, \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3700 }
\DoxyCodeLine{3701 }
\DoxyCodeLine{3702 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3703 \textcolor{comment}{Creates ensemble from network. Only network geometry is copied.}}
\DoxyCodeLine{3704 \textcolor{comment}{}}
\DoxyCodeLine{3705 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3706 \textcolor{comment}{     Copyright 17.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3707 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3708 \textcolor{keywordtype}{void} mlpecreatefromnetwork(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} ae\_int\_t ensemblesize, \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3709 }
\DoxyCodeLine{3710 }
\DoxyCodeLine{3711 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3712 \textcolor{comment}{Randomization of MLP ensemble}}
\DoxyCodeLine{3713 \textcolor{comment}{}}
\DoxyCodeLine{3714 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3715 \textcolor{comment}{     Copyright 17.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3716 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3717 \textcolor{keywordtype}{void} mlperandomize(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3718 }
\DoxyCodeLine{3719 }
\DoxyCodeLine{3720 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3721 \textcolor{comment}{Return ensemble properties (number of inputs and outputs).}}
\DoxyCodeLine{3722 \textcolor{comment}{}}
\DoxyCodeLine{3723 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3724 \textcolor{comment}{     Copyright 17.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3725 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3726 \textcolor{keywordtype}{void} mlpeproperties(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, ae\_int\_t \&nin, ae\_int\_t \&nout, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3727 }
\DoxyCodeLine{3728 }
\DoxyCodeLine{3729 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3730 \textcolor{comment}{Return normalization type (whether ensemble is SOFTMAX-\/normalized or not).}}
\DoxyCodeLine{3731 \textcolor{comment}{}}
\DoxyCodeLine{3732 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3733 \textcolor{comment}{     Copyright 17.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3734 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3735 \textcolor{keywordtype}{bool} mlpeissoftmax(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3736 }
\DoxyCodeLine{3737 }
\DoxyCodeLine{3738 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3739 \textcolor{comment}{Procesing}}
\DoxyCodeLine{3740 \textcolor{comment}{}}
\DoxyCodeLine{3741 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3742 \textcolor{comment}{    Ensemble-\/   neural networks ensemble}}
\DoxyCodeLine{3743 \textcolor{comment}{    X       -\/   input vector,  array[0..NIn-\/1].}}
\DoxyCodeLine{3744 \textcolor{comment}{    Y       -\/   (possibly) preallocated buffer; if size of Y is less than}}
\DoxyCodeLine{3745 \textcolor{comment}{                NOut, it will be reallocated. If it is large enough, it}}
\DoxyCodeLine{3746 \textcolor{comment}{                is NOT reallocated, so we can save some time on reallocation.}}
\DoxyCodeLine{3747 \textcolor{comment}{}}
\DoxyCodeLine{3748 \textcolor{comment}{}}
\DoxyCodeLine{3749 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{3750 \textcolor{comment}{    Y       -\/   result. Regression estimate when solving regression  task,}}
\DoxyCodeLine{3751 \textcolor{comment}{                vector of posterior probabilities for classification task.}}
\DoxyCodeLine{3752 \textcolor{comment}{}}
\DoxyCodeLine{3753 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3754 \textcolor{comment}{     Copyright 17.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3755 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3756 \textcolor{keywordtype}{void} mlpeprocess(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&y, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3757 }
\DoxyCodeLine{3758 }
\DoxyCodeLine{3759 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3760 \textcolor{comment}{'interactive'  variant  of  MLPEProcess  for  languages  like Python which}}
\DoxyCodeLine{3761 \textcolor{comment}{support constructs like "{}Y = MLPEProcess(LM,X)"{} and interactive mode of the}}
\DoxyCodeLine{3762 \textcolor{comment}{interpreter}}
\DoxyCodeLine{3763 \textcolor{comment}{}}
\DoxyCodeLine{3764 \textcolor{comment}{This function allocates new array on each call,  so  it  is  significantly}}
\DoxyCodeLine{3765 \textcolor{comment}{slower than its 'non-\/interactive' counterpart, but it is  more  convenient}}
\DoxyCodeLine{3766 \textcolor{comment}{when you call it from command line.}}
\DoxyCodeLine{3767 \textcolor{comment}{}}
\DoxyCodeLine{3768 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3769 \textcolor{comment}{     Copyright 17.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3770 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3771 \textcolor{keywordtype}{void} mlpeprocessi(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&y, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3772 }
\DoxyCodeLine{3773 }
\DoxyCodeLine{3774 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3775 \textcolor{comment}{Relative classification error on the test set}}
\DoxyCodeLine{3776 \textcolor{comment}{}}
\DoxyCodeLine{3777 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3778 \textcolor{comment}{    Ensemble-\/   ensemble}}
\DoxyCodeLine{3779 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{3780 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{3781 \textcolor{comment}{}}
\DoxyCodeLine{3782 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{3783 \textcolor{comment}{    percent of incorrectly classified cases.}}
\DoxyCodeLine{3784 \textcolor{comment}{    Works both for classifier betwork and for regression networks which}}
\DoxyCodeLine{3785 \textcolor{comment}{are used as classifiers.}}
\DoxyCodeLine{3786 \textcolor{comment}{}}
\DoxyCodeLine{3787 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3788 \textcolor{comment}{     Copyright 17.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3789 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3790 \textcolor{keywordtype}{double} mlperelclserror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3791 }
\DoxyCodeLine{3792 }
\DoxyCodeLine{3793 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3794 \textcolor{comment}{Average cross-\/entropy (in bits per element) on the test set}}
\DoxyCodeLine{3795 \textcolor{comment}{}}
\DoxyCodeLine{3796 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3797 \textcolor{comment}{    Ensemble-\/   ensemble}}
\DoxyCodeLine{3798 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{3799 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{3800 \textcolor{comment}{}}
\DoxyCodeLine{3801 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{3802 \textcolor{comment}{    CrossEntropy/(NPoints*LN(2)).}}
\DoxyCodeLine{3803 \textcolor{comment}{    Zero if ensemble solves regression task.}}
\DoxyCodeLine{3804 \textcolor{comment}{}}
\DoxyCodeLine{3805 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3806 \textcolor{comment}{     Copyright 17.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3807 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3808 \textcolor{keywordtype}{double} mlpeavgce(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3809 }
\DoxyCodeLine{3810 }
\DoxyCodeLine{3811 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3812 \textcolor{comment}{RMS error on the test set}}
\DoxyCodeLine{3813 \textcolor{comment}{}}
\DoxyCodeLine{3814 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3815 \textcolor{comment}{    Ensemble-\/   ensemble}}
\DoxyCodeLine{3816 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{3817 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{3818 \textcolor{comment}{}}
\DoxyCodeLine{3819 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{3820 \textcolor{comment}{    root mean square error.}}
\DoxyCodeLine{3821 \textcolor{comment}{    Its meaning for regression task is obvious. As for classification task}}
\DoxyCodeLine{3822 \textcolor{comment}{RMS error means error when estimating posterior probabilities.}}
\DoxyCodeLine{3823 \textcolor{comment}{}}
\DoxyCodeLine{3824 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3825 \textcolor{comment}{     Copyright 17.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3826 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3827 \textcolor{keywordtype}{double} mlpermserror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3828 }
\DoxyCodeLine{3829 }
\DoxyCodeLine{3830 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3831 \textcolor{comment}{Average error on the test set}}
\DoxyCodeLine{3832 \textcolor{comment}{}}
\DoxyCodeLine{3833 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3834 \textcolor{comment}{    Ensemble-\/   ensemble}}
\DoxyCodeLine{3835 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{3836 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{3837 \textcolor{comment}{}}
\DoxyCodeLine{3838 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{3839 \textcolor{comment}{    Its meaning for regression task is obvious. As for classification task}}
\DoxyCodeLine{3840 \textcolor{comment}{it means average error when estimating posterior probabilities.}}
\DoxyCodeLine{3841 \textcolor{comment}{}}
\DoxyCodeLine{3842 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3843 \textcolor{comment}{     Copyright 17.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3844 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3845 \textcolor{keywordtype}{double} mlpeavgerror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3846 }
\DoxyCodeLine{3847 }
\DoxyCodeLine{3848 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3849 \textcolor{comment}{Average relative error on the test set}}
\DoxyCodeLine{3850 \textcolor{comment}{}}
\DoxyCodeLine{3851 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3852 \textcolor{comment}{    Ensemble-\/   ensemble}}
\DoxyCodeLine{3853 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{3854 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{3855 \textcolor{comment}{}}
\DoxyCodeLine{3856 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{3857 \textcolor{comment}{    Its meaning for regression task is obvious. As for classification task}}
\DoxyCodeLine{3858 \textcolor{comment}{it means average relative error when estimating posterior probabilities.}}
\DoxyCodeLine{3859 \textcolor{comment}{}}
\DoxyCodeLine{3860 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3861 \textcolor{comment}{     Copyright 17.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{3862 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3863 \textcolor{keywordtype}{double} mlpeavgrelerror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3864 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{3865 }
\DoxyCodeLine{3866 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_CLUSTERING) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{3867 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3868 \textcolor{comment}{This function initializes clusterizer object. Newly initialized object  is}}
\DoxyCodeLine{3869 \textcolor{comment}{empty, i.e. it does not contain dataset. You should use it as follows:}}
\DoxyCodeLine{3870 \textcolor{comment}{1. creation}}
\DoxyCodeLine{3871 \textcolor{comment}{2. dataset is added with ClusterizerSetPoints()}}
\DoxyCodeLine{3872 \textcolor{comment}{3. additional parameters are set}}
\DoxyCodeLine{3873 \textcolor{comment}{3. clusterization is performed with one of the clustering functions}}
\DoxyCodeLine{3874 \textcolor{comment}{}}
\DoxyCodeLine{3875 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3876 \textcolor{comment}{     Copyright 10.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{3877 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3878 \textcolor{keywordtype}{void} clusterizercreate(\mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3879 }
\DoxyCodeLine{3880 }
\DoxyCodeLine{3881 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3882 \textcolor{comment}{This function adds dataset to the clusterizer structure.}}
\DoxyCodeLine{3883 \textcolor{comment}{}}
\DoxyCodeLine{3884 \textcolor{comment}{This function overrides all previous calls  of  ClusterizerSetPoints()  or}}
\DoxyCodeLine{3885 \textcolor{comment}{ClusterizerSetDistances().}}
\DoxyCodeLine{3886 \textcolor{comment}{}}
\DoxyCodeLine{3887 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3888 \textcolor{comment}{    S       -\/   clusterizer state, initialized by ClusterizerCreate()}}
\DoxyCodeLine{3889 \textcolor{comment}{    XY      -\/   array[NPoints,NFeatures], dataset}}
\DoxyCodeLine{3890 \textcolor{comment}{    NPoints -\/   number of points, >=0}}
\DoxyCodeLine{3891 \textcolor{comment}{    NFeatures-\/  number of features, >=1}}
\DoxyCodeLine{3892 \textcolor{comment}{    DistType-\/   distance function:}}
\DoxyCodeLine{3893 \textcolor{comment}{                *  0    Chebyshev distance  (L-\/inf norm)}}
\DoxyCodeLine{3894 \textcolor{comment}{                *  1    city block distance (L1 norm)}}
\DoxyCodeLine{3895 \textcolor{comment}{                *  2    Euclidean distance  (L2 norm), non-\/squared}}
\DoxyCodeLine{3896 \textcolor{comment}{                * 10    Pearson correlation:}}
\DoxyCodeLine{3897 \textcolor{comment}{                        dist(a,b) = 1-\/corr(a,b)}}
\DoxyCodeLine{3898 \textcolor{comment}{                * 11    Absolute Pearson correlation:}}
\DoxyCodeLine{3899 \textcolor{comment}{                        dist(a,b) = 1-\/|corr(a,b)|}}
\DoxyCodeLine{3900 \textcolor{comment}{                * 12    Uncentered Pearson correlation (cosine of the angle):}}
\DoxyCodeLine{3901 \textcolor{comment}{                        dist(a,b) = a'*b/(|a|*|b|)}}
\DoxyCodeLine{3902 \textcolor{comment}{                * 13    Absolute uncentered Pearson correlation}}
\DoxyCodeLine{3903 \textcolor{comment}{                        dist(a,b) = |a'*b|/(|a|*|b|)}}
\DoxyCodeLine{3904 \textcolor{comment}{                * 20    Spearman rank correlation:}}
\DoxyCodeLine{3905 \textcolor{comment}{                        dist(a,b) = 1-\/rankcorr(a,b)}}
\DoxyCodeLine{3906 \textcolor{comment}{                * 21    Absolute Spearman rank correlation}}
\DoxyCodeLine{3907 \textcolor{comment}{                        dist(a,b) = 1-\/|rankcorr(a,b)|}}
\DoxyCodeLine{3908 \textcolor{comment}{}}
\DoxyCodeLine{3909 \textcolor{comment}{NOTE 1: different distance functions have different performance penalty:}}
\DoxyCodeLine{3910 \textcolor{comment}{        * Euclidean or Pearson correlation distances are the fastest ones}}
\DoxyCodeLine{3911 \textcolor{comment}{        * Spearman correlation distance function is a bit slower}}
\DoxyCodeLine{3912 \textcolor{comment}{        * city block and Chebyshev distances are order of magnitude slower}}
\DoxyCodeLine{3913 \textcolor{comment}{}}
\DoxyCodeLine{3914 \textcolor{comment}{        The reason behing difference in performance is that correlation-\/based}}
\DoxyCodeLine{3915 \textcolor{comment}{        distance functions are computed using optimized linear algebra kernels,}}
\DoxyCodeLine{3916 \textcolor{comment}{        while Chebyshev and city block distance functions are computed using}}
\DoxyCodeLine{3917 \textcolor{comment}{        simple nested loops with two branches at each iteration.}}
\DoxyCodeLine{3918 \textcolor{comment}{}}
\DoxyCodeLine{3919 \textcolor{comment}{NOTE 2: different clustering algorithms have different limitations:}}
\DoxyCodeLine{3920 \textcolor{comment}{        * agglomerative hierarchical clustering algorithms may be used with}}
\DoxyCodeLine{3921 \textcolor{comment}{          any kind of distance metric}}
\DoxyCodeLine{3922 \textcolor{comment}{        * k-\/means++ clustering algorithm may be used only  with  Euclidean}}
\DoxyCodeLine{3923 \textcolor{comment}{          distance function}}
\DoxyCodeLine{3924 \textcolor{comment}{        Thus, list of specific clustering algorithms you may  use  depends}}
\DoxyCodeLine{3925 \textcolor{comment}{        on distance function you specify when you set your dataset.}}
\DoxyCodeLine{3926 \textcolor{comment}{}}
\DoxyCodeLine{3927 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3928 \textcolor{comment}{     Copyright 10.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{3929 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3930 \textcolor{keywordtype}{void} clusterizersetpoints(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nfeatures, \textcolor{keyword}{const} ae\_int\_t disttype, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3931 \textcolor{keywordtype}{void} clusterizersetpoints(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t disttype, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3932 }
\DoxyCodeLine{3933 }
\DoxyCodeLine{3934 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3935 \textcolor{comment}{This function adds dataset given by distance  matrix  to  the  clusterizer}}
\DoxyCodeLine{3936 \textcolor{comment}{structure. It is important that dataset is not  given  explicitly  -\/  only}}
\DoxyCodeLine{3937 \textcolor{comment}{distance matrix is given.}}
\DoxyCodeLine{3938 \textcolor{comment}{}}
\DoxyCodeLine{3939 \textcolor{comment}{This function overrides all previous calls  of  ClusterizerSetPoints()  or}}
\DoxyCodeLine{3940 \textcolor{comment}{ClusterizerSetDistances().}}
\DoxyCodeLine{3941 \textcolor{comment}{}}
\DoxyCodeLine{3942 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3943 \textcolor{comment}{    S       -\/   clusterizer state, initialized by ClusterizerCreate()}}
\DoxyCodeLine{3944 \textcolor{comment}{    D       -\/   array[NPoints,NPoints], distance matrix given by its upper}}
\DoxyCodeLine{3945 \textcolor{comment}{                or lower triangle (main diagonal is  ignored  because  its}}
\DoxyCodeLine{3946 \textcolor{comment}{                entries are expected to be zero).}}
\DoxyCodeLine{3947 \textcolor{comment}{    NPoints -\/   number of points}}
\DoxyCodeLine{3948 \textcolor{comment}{    IsUpper -\/   whether upper or lower triangle of D is given.}}
\DoxyCodeLine{3949 \textcolor{comment}{}}
\DoxyCodeLine{3950 \textcolor{comment}{NOTE 1: different clustering algorithms have different limitations:}}
\DoxyCodeLine{3951 \textcolor{comment}{        * agglomerative hierarchical clustering algorithms may be used with}}
\DoxyCodeLine{3952 \textcolor{comment}{          any kind of distance metric, including one  which  is  given  by}}
\DoxyCodeLine{3953 \textcolor{comment}{          distance matrix}}
\DoxyCodeLine{3954 \textcolor{comment}{        * k-\/means++ clustering algorithm may be used only  with  Euclidean}}
\DoxyCodeLine{3955 \textcolor{comment}{          distance function and explicitly given points -\/ it  can  not  be}}
\DoxyCodeLine{3956 \textcolor{comment}{          used with dataset given by distance matrix}}
\DoxyCodeLine{3957 \textcolor{comment}{        Thus, if you call this function, you will be unable to use k-\/means}}
\DoxyCodeLine{3958 \textcolor{comment}{        clustering algorithm to process your problem.}}
\DoxyCodeLine{3959 \textcolor{comment}{}}
\DoxyCodeLine{3960 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3961 \textcolor{comment}{     Copyright 10.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{3962 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3963 \textcolor{keywordtype}{void} clusterizersetdistances(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&d, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \textcolor{keywordtype}{bool} isupper, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3964 \textcolor{keywordtype}{void} clusterizersetdistances(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&d, \textcolor{keyword}{const} \textcolor{keywordtype}{bool} isupper, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3965 }
\DoxyCodeLine{3966 }
\DoxyCodeLine{3967 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3968 \textcolor{comment}{This function sets agglomerative hierarchical clustering algorithm}}
\DoxyCodeLine{3969 \textcolor{comment}{}}
\DoxyCodeLine{3970 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3971 \textcolor{comment}{    S       -\/   clusterizer state, initialized by ClusterizerCreate()}}
\DoxyCodeLine{3972 \textcolor{comment}{    Algo    -\/   algorithm type:}}
\DoxyCodeLine{3973 \textcolor{comment}{                * 0     complete linkage (default algorithm)}}
\DoxyCodeLine{3974 \textcolor{comment}{                * 1     single linkage}}
\DoxyCodeLine{3975 \textcolor{comment}{                * 2     unweighted average linkage}}
\DoxyCodeLine{3976 \textcolor{comment}{                * 3     weighted average linkage}}
\DoxyCodeLine{3977 \textcolor{comment}{                * 4     Ward's method}}
\DoxyCodeLine{3978 \textcolor{comment}{}}
\DoxyCodeLine{3979 \textcolor{comment}{NOTE: Ward's method works correctly only with Euclidean  distance,  that's}}
\DoxyCodeLine{3980 \textcolor{comment}{      why algorithm will return negative termination  code  (failure)  for}}
\DoxyCodeLine{3981 \textcolor{comment}{      any other distance type.}}
\DoxyCodeLine{3982 \textcolor{comment}{}}
\DoxyCodeLine{3983 \textcolor{comment}{      It is possible, however,  to  use  this  method  with  user-\/supplied}}
\DoxyCodeLine{3984 \textcolor{comment}{      distance matrix. It  is  your  responsibility  to pass one which was}}
\DoxyCodeLine{3985 \textcolor{comment}{      calculated with Euclidean distance function.}}
\DoxyCodeLine{3986 \textcolor{comment}{}}
\DoxyCodeLine{3987 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{3988 \textcolor{comment}{     Copyright 10.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{3989 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{3990 \textcolor{keywordtype}{void} clusterizersetahcalgo(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}} \&s, \textcolor{keyword}{const} ae\_int\_t algo, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{3991 }
\DoxyCodeLine{3992 }
\DoxyCodeLine{3993 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{3994 \textcolor{comment}{This  function  sets k-\/means properties:  number  of  restarts and maximum}}
\DoxyCodeLine{3995 \textcolor{comment}{number of iterations per one run.}}
\DoxyCodeLine{3996 \textcolor{comment}{}}
\DoxyCodeLine{3997 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{3998 \textcolor{comment}{    S       -\/   clusterizer state, initialized by ClusterizerCreate()}}
\DoxyCodeLine{3999 \textcolor{comment}{    Restarts-\/   restarts count, >=1.}}
\DoxyCodeLine{4000 \textcolor{comment}{                k-\/means++ algorithm performs several restarts and  chooses}}
\DoxyCodeLine{4001 \textcolor{comment}{                best set of centers (one with minimum squared distance).}}
\DoxyCodeLine{4002 \textcolor{comment}{    MaxIts  -\/   maximum number of k-\/means iterations performed during  one}}
\DoxyCodeLine{4003 \textcolor{comment}{                run. >=0, zero value means that algorithm performs unlimited}}
\DoxyCodeLine{4004 \textcolor{comment}{                number of iterations.}}
\DoxyCodeLine{4005 \textcolor{comment}{}}
\DoxyCodeLine{4006 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4007 \textcolor{comment}{     Copyright 10.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{4008 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4009 \textcolor{keywordtype}{void} clusterizersetkmeanslimits(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}} \&s, \textcolor{keyword}{const} ae\_int\_t restarts, \textcolor{keyword}{const} ae\_int\_t maxits, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4010 }
\DoxyCodeLine{4011 }
\DoxyCodeLine{4012 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4013 \textcolor{comment}{This function sets k-\/means  initialization  algorithm.  Several  different}}
\DoxyCodeLine{4014 \textcolor{comment}{algorithms can be chosen, including k-\/means++.}}
\DoxyCodeLine{4015 \textcolor{comment}{}}
\DoxyCodeLine{4016 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4017 \textcolor{comment}{    S       -\/   clusterizer state, initialized by ClusterizerCreate()}}
\DoxyCodeLine{4018 \textcolor{comment}{    InitAlgo-\/   initialization algorithm:}}
\DoxyCodeLine{4019 \textcolor{comment}{                * 0  automatic selection ( different  versions  of  ALGLIB}}
\DoxyCodeLine{4020 \textcolor{comment}{                     may select different algorithms)}}
\DoxyCodeLine{4021 \textcolor{comment}{                * 1  random initialization}}
\DoxyCodeLine{4022 \textcolor{comment}{                * 2  k-\/means++ initialization  (best  quality  of  initial}}
\DoxyCodeLine{4023 \textcolor{comment}{                     centers, but long  non-\/parallelizable  initialization}}
\DoxyCodeLine{4024 \textcolor{comment}{                     phase with bad cache locality)}}
\DoxyCodeLine{4025 \textcolor{comment}{                * 3  "{}fast-\/greedy"{}  algorithm  with  efficient,  easy   to}}
\DoxyCodeLine{4026 \textcolor{comment}{                     parallelize initialization. Quality of initial centers}}
\DoxyCodeLine{4027 \textcolor{comment}{                     is  somewhat  worse  than  that  of  k-\/means++.  This}}
\DoxyCodeLine{4028 \textcolor{comment}{                     algorithm is a default one in the current version  of}}
\DoxyCodeLine{4029 \textcolor{comment}{                     ALGLIB.}}
\DoxyCodeLine{4030 \textcolor{comment}{                *-\/1  "{}debug"{} algorithm which always selects first  K  rows}}
\DoxyCodeLine{4031 \textcolor{comment}{                     of dataset; this algorithm is used for debug purposes}}
\DoxyCodeLine{4032 \textcolor{comment}{                     only. Do not use it in the industrial code!}}
\DoxyCodeLine{4033 \textcolor{comment}{}}
\DoxyCodeLine{4034 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4035 \textcolor{comment}{     Copyright 21.01.2015 by Bochkanov Sergey}}
\DoxyCodeLine{4036 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4037 \textcolor{keywordtype}{void} clusterizersetkmeansinit(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}} \&s, \textcolor{keyword}{const} ae\_int\_t initalgo, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4038 }
\DoxyCodeLine{4039 }
\DoxyCodeLine{4040 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4041 \textcolor{comment}{This  function  sets  seed  which  is  used to initialize internal RNG. By}}
\DoxyCodeLine{4042 \textcolor{comment}{default, deterministic seed is used -\/ same for each run of clusterizer. If}}
\DoxyCodeLine{4043 \textcolor{comment}{you specify non-\/deterministic  seed  value,  then  some  algorithms  which}}
\DoxyCodeLine{4044 \textcolor{comment}{depend on random initialization (in current version: k-\/means)  may  return}}
\DoxyCodeLine{4045 \textcolor{comment}{slightly different results after each run.}}
\DoxyCodeLine{4046 \textcolor{comment}{}}
\DoxyCodeLine{4047 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4048 \textcolor{comment}{    S       -\/   clusterizer state, initialized by ClusterizerCreate()}}
\DoxyCodeLine{4049 \textcolor{comment}{    Seed    -\/   seed:}}
\DoxyCodeLine{4050 \textcolor{comment}{                * positive values = use deterministic seed for each run of}}
\DoxyCodeLine{4051 \textcolor{comment}{                  algorithms which depend on random initialization}}
\DoxyCodeLine{4052 \textcolor{comment}{                * zero or negative values = use non-\/deterministic seed}}
\DoxyCodeLine{4053 \textcolor{comment}{}}
\DoxyCodeLine{4054 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4055 \textcolor{comment}{     Copyright 08.06.2017 by Bochkanov Sergey}}
\DoxyCodeLine{4056 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4057 \textcolor{keywordtype}{void} clusterizersetseed(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}} \&s, \textcolor{keyword}{const} ae\_int\_t seed, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4058 }
\DoxyCodeLine{4059 }
\DoxyCodeLine{4060 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4061 \textcolor{comment}{This function performs agglomerative hierarchical clustering}}
\DoxyCodeLine{4062 \textcolor{comment}{}}
\DoxyCodeLine{4063 \textcolor{comment}{NOTE: Agglomerative  hierarchical  clustering  algorithm  has two  phases:}}
\DoxyCodeLine{4064 \textcolor{comment}{      distance matrix calculation and clustering  itself. Only first phase}}
\DoxyCodeLine{4065 \textcolor{comment}{      (distance matrix calculation) is accelerated by SIMD and SMP.  Thus,}}
\DoxyCodeLine{4066 \textcolor{comment}{      acceleration is significant  only  for  medium  or  high-\/dimensional}}
\DoxyCodeLine{4067 \textcolor{comment}{      problems.}}
\DoxyCodeLine{4068 \textcolor{comment}{}}
\DoxyCodeLine{4069 \textcolor{comment}{      Although activating multithreading gives some speedup  over  single-\/}}
\DoxyCodeLine{4070 \textcolor{comment}{      threaded execution, you  should  not  expect  nearly-\/linear  scaling}}
\DoxyCodeLine{4071 \textcolor{comment}{      with respect to cores count.}}
\DoxyCodeLine{4072 \textcolor{comment}{}}
\DoxyCodeLine{4073 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4074 \textcolor{comment}{    S       -\/   clusterizer state, initialized by ClusterizerCreate()}}
\DoxyCodeLine{4075 \textcolor{comment}{}}
\DoxyCodeLine{4076 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4077 \textcolor{comment}{    Rep     -\/   clustering results; see description of AHCReport}}
\DoxyCodeLine{4078 \textcolor{comment}{                structure for more information.}}
\DoxyCodeLine{4079 \textcolor{comment}{}}
\DoxyCodeLine{4080 \textcolor{comment}{NOTE 1: hierarchical clustering algorithms require large amounts of memory.}}
\DoxyCodeLine{4081 \textcolor{comment}{        In particular, this implementation needs  sizeof(double)*NPoints\string^2}}
\DoxyCodeLine{4082 \textcolor{comment}{        bytes, which are used to store distance matrix. In  case  we  work}}
\DoxyCodeLine{4083 \textcolor{comment}{        with user-\/supplied matrix, this amount is multiplied by 2 (we have}}
\DoxyCodeLine{4084 \textcolor{comment}{        to store original matrix and to work with its copy).}}
\DoxyCodeLine{4085 \textcolor{comment}{}}
\DoxyCodeLine{4086 \textcolor{comment}{        For example, problem with 10000 points  would require 800M of RAM,}}
\DoxyCodeLine{4087 \textcolor{comment}{        even when working in a 1-\/dimensional space.}}
\DoxyCodeLine{4088 \textcolor{comment}{}}
\DoxyCodeLine{4089 \textcolor{comment}{  ! FREE EDITION OF ALGLIB:}}
\DoxyCodeLine{4090 \textcolor{comment}{  !}}
\DoxyCodeLine{4091 \textcolor{comment}{  ! Free Edition of ALGLIB supports following important features for  this}}
\DoxyCodeLine{4092 \textcolor{comment}{  ! function:}}
\DoxyCodeLine{4093 \textcolor{comment}{  ! * C++ version: x64 SIMD support using C++ intrinsics}}
\DoxyCodeLine{4094 \textcolor{comment}{  ! * C\#  version: x64 SIMD support using NET5/NetCore hardware intrinsics}}
\DoxyCodeLine{4095 \textcolor{comment}{  !}}
\DoxyCodeLine{4096 \textcolor{comment}{  ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB}}
\DoxyCodeLine{4097 \textcolor{comment}{  ! Reference Manual in order  to  find  out  how to activate SIMD support}}
\DoxyCodeLine{4098 \textcolor{comment}{  ! in ALGLIB.}}
\DoxyCodeLine{4099 \textcolor{comment}{}}
\DoxyCodeLine{4100 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{4101 \textcolor{comment}{  !}}
\DoxyCodeLine{4102 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{4103 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{4104 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{4105 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{4106 \textcolor{comment}{  ! * hardware vendor (Intel) implementations of linear algebra primitives}}
\DoxyCodeLine{4107 \textcolor{comment}{  !   (C++ and C\# versions, x86/x64 platform)}}
\DoxyCodeLine{4108 \textcolor{comment}{  !}}
\DoxyCodeLine{4109 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{4110 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{4111 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{4112 \textcolor{comment}{}}
\DoxyCodeLine{4113 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4114 \textcolor{comment}{     Copyright 10.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{4115 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4116 \textcolor{keywordtype}{void} clusterizerrunahc(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}} \&s, \mbox{\hyperlink{classalglib_1_1ahcreport}{ahcreport}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4117 }
\DoxyCodeLine{4118 }
\DoxyCodeLine{4119 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4120 \textcolor{comment}{This function performs clustering by k-\/means++ algorithm.}}
\DoxyCodeLine{4121 \textcolor{comment}{}}
\DoxyCodeLine{4122 \textcolor{comment}{You may change algorithm properties by calling:}}
\DoxyCodeLine{4123 \textcolor{comment}{* ClusterizerSetKMeansLimits() to change number of restarts or iterations}}
\DoxyCodeLine{4124 \textcolor{comment}{* ClusterizerSetKMeansInit() to change initialization algorithm}}
\DoxyCodeLine{4125 \textcolor{comment}{}}
\DoxyCodeLine{4126 \textcolor{comment}{By  default,  one  restart  and  unlimited number of iterations are  used.}}
\DoxyCodeLine{4127 \textcolor{comment}{Initialization algorithm is chosen automatically.}}
\DoxyCodeLine{4128 \textcolor{comment}{}}
\DoxyCodeLine{4129 \textcolor{comment}{NOTE: k-\/means clustering  algorithm has two  phases:  selection of initial}}
\DoxyCodeLine{4130 \textcolor{comment}{      centers and clustering  itself.  ALGLIB  parallelizes  both  phases.}}
\DoxyCodeLine{4131 \textcolor{comment}{      Parallel version is optimized for the following  scenario: medium or}}
\DoxyCodeLine{4132 \textcolor{comment}{      high-\/dimensional problem (8 or more dimensions) with large number of}}
\DoxyCodeLine{4133 \textcolor{comment}{      points and clusters. However, some speed-\/up  can  be  obtained  even}}
\DoxyCodeLine{4134 \textcolor{comment}{      when assumptions above are violated.}}
\DoxyCodeLine{4135 \textcolor{comment}{}}
\DoxyCodeLine{4136 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4137 \textcolor{comment}{    S       -\/   clusterizer state, initialized by ClusterizerCreate()}}
\DoxyCodeLine{4138 \textcolor{comment}{    K       -\/   number of clusters, K>=0.}}
\DoxyCodeLine{4139 \textcolor{comment}{                K  can  be  zero only when algorithm is called  for  empty}}
\DoxyCodeLine{4140 \textcolor{comment}{                dataset,  in   this   case   completion  code  is  set  to}}
\DoxyCodeLine{4141 \textcolor{comment}{                success (+1).}}
\DoxyCodeLine{4142 \textcolor{comment}{                If  K=0  and  dataset  size  is  non-\/zero,  we   can   not}}
\DoxyCodeLine{4143 \textcolor{comment}{                meaningfully assign points to some center  (there  are  no}}
\DoxyCodeLine{4144 \textcolor{comment}{                centers because K=0) and  return  -\/3  as  completion  code}}
\DoxyCodeLine{4145 \textcolor{comment}{                (failure).}}
\DoxyCodeLine{4146 \textcolor{comment}{}}
\DoxyCodeLine{4147 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4148 \textcolor{comment}{    Rep     -\/   clustering results; see description of KMeansReport}}
\DoxyCodeLine{4149 \textcolor{comment}{                structure for more information.}}
\DoxyCodeLine{4150 \textcolor{comment}{}}
\DoxyCodeLine{4151 \textcolor{comment}{NOTE 1: k-\/means  clustering  can  be  performed  only  for  datasets  with}}
\DoxyCodeLine{4152 \textcolor{comment}{        Euclidean  distance  function.  Algorithm  will  return   negative}}
\DoxyCodeLine{4153 \textcolor{comment}{        completion code in Rep.TerminationType in case dataset  was  added}}
\DoxyCodeLine{4154 \textcolor{comment}{        to clusterizer with DistType other than Euclidean (or dataset  was}}
\DoxyCodeLine{4155 \textcolor{comment}{        specified by distance matrix instead of explicitly given points).}}
\DoxyCodeLine{4156 \textcolor{comment}{}}
\DoxyCodeLine{4157 \textcolor{comment}{NOTE 2: by default, k-\/means uses non-\/deterministic seed to initialize  RNG}}
\DoxyCodeLine{4158 \textcolor{comment}{        which is used to select initial centers. As  result,  each  run of}}
\DoxyCodeLine{4159 \textcolor{comment}{        algorithm may return different values. If you  need  deterministic}}
\DoxyCodeLine{4160 \textcolor{comment}{        behavior, use ClusterizerSetSeed() function.}}
\DoxyCodeLine{4161 \textcolor{comment}{}}
\DoxyCodeLine{4162 \textcolor{comment}{  ! FREE EDITION OF ALGLIB:}}
\DoxyCodeLine{4163 \textcolor{comment}{  !}}
\DoxyCodeLine{4164 \textcolor{comment}{  ! Free Edition of ALGLIB supports following important features for  this}}
\DoxyCodeLine{4165 \textcolor{comment}{  ! function:}}
\DoxyCodeLine{4166 \textcolor{comment}{  ! * C++ version: x64 SIMD support using C++ intrinsics}}
\DoxyCodeLine{4167 \textcolor{comment}{  ! * C\#  version: x64 SIMD support using NET5/NetCore hardware intrinsics}}
\DoxyCodeLine{4168 \textcolor{comment}{  !}}
\DoxyCodeLine{4169 \textcolor{comment}{  ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB}}
\DoxyCodeLine{4170 \textcolor{comment}{  ! Reference Manual in order  to  find  out  how to activate SIMD support}}
\DoxyCodeLine{4171 \textcolor{comment}{  ! in ALGLIB.}}
\DoxyCodeLine{4172 \textcolor{comment}{}}
\DoxyCodeLine{4173 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{4174 \textcolor{comment}{  !}}
\DoxyCodeLine{4175 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{4176 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{4177 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{4178 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{4179 \textcolor{comment}{  ! * hardware vendor (Intel) implementations of linear algebra primitives}}
\DoxyCodeLine{4180 \textcolor{comment}{  !   (C++ and C\# versions, x86/x64 platform)}}
\DoxyCodeLine{4181 \textcolor{comment}{  !}}
\DoxyCodeLine{4182 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{4183 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{4184 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{4185 \textcolor{comment}{}}
\DoxyCodeLine{4186 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4187 \textcolor{comment}{     Copyright 10.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{4188 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4189 \textcolor{keywordtype}{void} clusterizerrunkmeans(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1clusterizerstate}{clusterizerstate}} \&s, \textcolor{keyword}{const} ae\_int\_t k, \mbox{\hyperlink{classalglib_1_1kmeansreport}{kmeansreport}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4190 }
\DoxyCodeLine{4191 }
\DoxyCodeLine{4192 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4193 \textcolor{comment}{This function returns distance matrix for dataset}}
\DoxyCodeLine{4194 \textcolor{comment}{}}
\DoxyCodeLine{4195 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4196 \textcolor{comment}{    XY      -\/   array[NPoints,NFeatures], dataset}}
\DoxyCodeLine{4197 \textcolor{comment}{    NPoints -\/   number of points, >=0}}
\DoxyCodeLine{4198 \textcolor{comment}{    NFeatures-\/  number of features, >=1}}
\DoxyCodeLine{4199 \textcolor{comment}{    DistType-\/   distance function:}}
\DoxyCodeLine{4200 \textcolor{comment}{                *  0    Chebyshev distance  (L-\/inf norm)}}
\DoxyCodeLine{4201 \textcolor{comment}{                *  1    city block distance (L1 norm)}}
\DoxyCodeLine{4202 \textcolor{comment}{                *  2    Euclidean distance  (L2 norm, non-\/squared)}}
\DoxyCodeLine{4203 \textcolor{comment}{                * 10    Pearson correlation:}}
\DoxyCodeLine{4204 \textcolor{comment}{                        dist(a,b) = 1-\/corr(a,b)}}
\DoxyCodeLine{4205 \textcolor{comment}{                * 11    Absolute Pearson correlation:}}
\DoxyCodeLine{4206 \textcolor{comment}{                        dist(a,b) = 1-\/|corr(a,b)|}}
\DoxyCodeLine{4207 \textcolor{comment}{                * 12    Uncentered Pearson correlation (cosine of the angle):}}
\DoxyCodeLine{4208 \textcolor{comment}{                        dist(a,b) = a'*b/(|a|*|b|)}}
\DoxyCodeLine{4209 \textcolor{comment}{                * 13    Absolute uncentered Pearson correlation}}
\DoxyCodeLine{4210 \textcolor{comment}{                        dist(a,b) = |a'*b|/(|a|*|b|)}}
\DoxyCodeLine{4211 \textcolor{comment}{                * 20    Spearman rank correlation:}}
\DoxyCodeLine{4212 \textcolor{comment}{                        dist(a,b) = 1-\/rankcorr(a,b)}}
\DoxyCodeLine{4213 \textcolor{comment}{                * 21    Absolute Spearman rank correlation}}
\DoxyCodeLine{4214 \textcolor{comment}{                        dist(a,b) = 1-\/|rankcorr(a,b)|}}
\DoxyCodeLine{4215 \textcolor{comment}{}}
\DoxyCodeLine{4216 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4217 \textcolor{comment}{    D       -\/   array[NPoints,NPoints], distance matrix}}
\DoxyCodeLine{4218 \textcolor{comment}{                (full matrix is returned, with lower and upper triangles)}}
\DoxyCodeLine{4219 \textcolor{comment}{}}
\DoxyCodeLine{4220 \textcolor{comment}{NOTE:  different distance functions have different performance penalty:}}
\DoxyCodeLine{4221 \textcolor{comment}{       * Euclidean or Pearson correlation distances are the fastest ones}}
\DoxyCodeLine{4222 \textcolor{comment}{       * Spearman correlation distance function is a bit slower}}
\DoxyCodeLine{4223 \textcolor{comment}{       * city block and Chebyshev distances are order of magnitude slower}}
\DoxyCodeLine{4224 \textcolor{comment}{}}
\DoxyCodeLine{4225 \textcolor{comment}{       The reason behing difference in performance is that correlation-\/based}}
\DoxyCodeLine{4226 \textcolor{comment}{       distance functions are computed using optimized linear algebra kernels,}}
\DoxyCodeLine{4227 \textcolor{comment}{       while Chebyshev and city block distance functions are computed using}}
\DoxyCodeLine{4228 \textcolor{comment}{       simple nested loops with two branches at each iteration.}}
\DoxyCodeLine{4229 \textcolor{comment}{}}
\DoxyCodeLine{4230 \textcolor{comment}{  ! FREE EDITION OF ALGLIB:}}
\DoxyCodeLine{4231 \textcolor{comment}{  !}}
\DoxyCodeLine{4232 \textcolor{comment}{  ! Free Edition of ALGLIB supports following important features for  this}}
\DoxyCodeLine{4233 \textcolor{comment}{  ! function:}}
\DoxyCodeLine{4234 \textcolor{comment}{  ! * C++ version: x64 SIMD support using C++ intrinsics}}
\DoxyCodeLine{4235 \textcolor{comment}{  ! * C\#  version: x64 SIMD support using NET5/NetCore hardware intrinsics}}
\DoxyCodeLine{4236 \textcolor{comment}{  !}}
\DoxyCodeLine{4237 \textcolor{comment}{  ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB}}
\DoxyCodeLine{4238 \textcolor{comment}{  ! Reference Manual in order  to  find  out  how to activate SIMD support}}
\DoxyCodeLine{4239 \textcolor{comment}{  ! in ALGLIB.}}
\DoxyCodeLine{4240 \textcolor{comment}{}}
\DoxyCodeLine{4241 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{4242 \textcolor{comment}{  !}}
\DoxyCodeLine{4243 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{4244 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{4245 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{4246 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{4247 \textcolor{comment}{  ! * hardware vendor (Intel) implementations of linear algebra primitives}}
\DoxyCodeLine{4248 \textcolor{comment}{  !   (C++ and C\# versions, x86/x64 platform)}}
\DoxyCodeLine{4249 \textcolor{comment}{  !}}
\DoxyCodeLine{4250 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{4251 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{4252 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{4253 \textcolor{comment}{}}
\DoxyCodeLine{4254 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4255 \textcolor{comment}{     Copyright 10.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{4256 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4257 \textcolor{keywordtype}{void} clusterizergetdistances(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nfeatures, \textcolor{keyword}{const} ae\_int\_t disttype, \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&d, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4258 }
\DoxyCodeLine{4259 }
\DoxyCodeLine{4260 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4261 \textcolor{comment}{This function takes as input clusterization report Rep,  desired  clusters}}
\DoxyCodeLine{4262 \textcolor{comment}{count K, and builds top K clusters from hierarchical clusterization  tree.}}
\DoxyCodeLine{4263 \textcolor{comment}{It returns assignment of points to clusters (array of cluster indexes).}}
\DoxyCodeLine{4264 \textcolor{comment}{}}
\DoxyCodeLine{4265 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4266 \textcolor{comment}{    Rep     -\/   report from ClusterizerRunAHC() performed on XY}}
\DoxyCodeLine{4267 \textcolor{comment}{    K       -\/   desired number of clusters, 1<=K<=NPoints.}}
\DoxyCodeLine{4268 \textcolor{comment}{                K can be zero only when NPoints=0.}}
\DoxyCodeLine{4269 \textcolor{comment}{}}
\DoxyCodeLine{4270 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4271 \textcolor{comment}{    CIdx    -\/   array[NPoints], I-\/th element contains cluster index  (from}}
\DoxyCodeLine{4272 \textcolor{comment}{                0 to K-\/1) for I-\/th point of the dataset.}}
\DoxyCodeLine{4273 \textcolor{comment}{    CZ      -\/   array[K]. This array allows  to  convert  cluster  indexes}}
\DoxyCodeLine{4274 \textcolor{comment}{                returned by this function to indexes used by  Rep.Z.  J-\/th}}
\DoxyCodeLine{4275 \textcolor{comment}{                cluster returned by this function corresponds to  CZ[J]-\/th}}
\DoxyCodeLine{4276 \textcolor{comment}{                cluster stored in Rep.Z/PZ/PM.}}
\DoxyCodeLine{4277 \textcolor{comment}{                It is guaranteed that CZ[I]<CZ[I+1].}}
\DoxyCodeLine{4278 \textcolor{comment}{}}
\DoxyCodeLine{4279 \textcolor{comment}{NOTE: K clusters built by this subroutine are assumed to have no hierarchy.}}
\DoxyCodeLine{4280 \textcolor{comment}{      Although  they  were  obtained  by  manipulation with top K nodes of}}
\DoxyCodeLine{4281 \textcolor{comment}{      dendrogram  (i.e.  hierarchical  decomposition  of  dataset),   this}}
\DoxyCodeLine{4282 \textcolor{comment}{      function does not return information about hierarchy.  Each  of  the}}
\DoxyCodeLine{4283 \textcolor{comment}{      clusters stand on its own.}}
\DoxyCodeLine{4284 \textcolor{comment}{}}
\DoxyCodeLine{4285 \textcolor{comment}{NOTE: Cluster indexes returned by this function  does  not  correspond  to}}
\DoxyCodeLine{4286 \textcolor{comment}{      indexes returned in Rep.Z/PZ/PM. Either you work  with  hierarchical}}
\DoxyCodeLine{4287 \textcolor{comment}{      representation of the dataset (dendrogram), or you work with  "{}flat"{}}}
\DoxyCodeLine{4288 \textcolor{comment}{      representation returned by this function.  Each  of  representations}}
\DoxyCodeLine{4289 \textcolor{comment}{      has its own clusters indexing system (former uses [0, 2*NPoints-\/2]),}}
\DoxyCodeLine{4290 \textcolor{comment}{      while latter uses [0..K-\/1]), although  it  is  possible  to  perform}}
\DoxyCodeLine{4291 \textcolor{comment}{      conversion from one system to another by means of CZ array, returned}}
\DoxyCodeLine{4292 \textcolor{comment}{      by this function, which allows you to convert indexes stored in CIdx}}
\DoxyCodeLine{4293 \textcolor{comment}{      to the numeration system used by Rep.Z.}}
\DoxyCodeLine{4294 \textcolor{comment}{}}
\DoxyCodeLine{4295 \textcolor{comment}{NOTE: this subroutine is optimized for moderate values of K. Say, for  K=5}}
\DoxyCodeLine{4296 \textcolor{comment}{      it will perform many times faster than  for  K=100.  Its  worst-\/case}}
\DoxyCodeLine{4297 \textcolor{comment}{      performance is O(N*K), although in average case  it  perform  better}}
\DoxyCodeLine{4298 \textcolor{comment}{      (up to O(N*log(K))).}}
\DoxyCodeLine{4299 \textcolor{comment}{}}
\DoxyCodeLine{4300 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4301 \textcolor{comment}{     Copyright 10.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{4302 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4303 \textcolor{keywordtype}{void} clusterizergetkclusters(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ahcreport}{ahcreport}} \&rep, \textcolor{keyword}{const} ae\_int\_t k, \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&cidx, \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&cz, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4304 }
\DoxyCodeLine{4305 }
\DoxyCodeLine{4306 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4307 \textcolor{comment}{This  function  accepts  AHC  report  Rep,  desired  minimum  intercluster}}
\DoxyCodeLine{4308 \textcolor{comment}{distance and returns top clusters from  hierarchical  clusterization  tree}}
\DoxyCodeLine{4309 \textcolor{comment}{which are separated by distance R or HIGHER.}}
\DoxyCodeLine{4310 \textcolor{comment}{}}
\DoxyCodeLine{4311 \textcolor{comment}{It returns assignment of points to clusters (array of cluster indexes).}}
\DoxyCodeLine{4312 \textcolor{comment}{}}
\DoxyCodeLine{4313 \textcolor{comment}{There is one more function with similar name -\/ ClusterizerSeparatedByCorr,}}
\DoxyCodeLine{4314 \textcolor{comment}{which returns clusters with intercluster correlation equal to R  or  LOWER}}
\DoxyCodeLine{4315 \textcolor{comment}{(note: higher for distance, lower for correlation).}}
\DoxyCodeLine{4316 \textcolor{comment}{}}
\DoxyCodeLine{4317 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4318 \textcolor{comment}{    Rep     -\/   report from ClusterizerRunAHC() performed on XY}}
\DoxyCodeLine{4319 \textcolor{comment}{    R       -\/   desired minimum intercluster distance, R>=0}}
\DoxyCodeLine{4320 \textcolor{comment}{}}
\DoxyCodeLine{4321 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4322 \textcolor{comment}{    K       -\/   number of clusters, 1<=K<=NPoints}}
\DoxyCodeLine{4323 \textcolor{comment}{    CIdx    -\/   array[NPoints], I-\/th element contains cluster index  (from}}
\DoxyCodeLine{4324 \textcolor{comment}{                0 to K-\/1) for I-\/th point of the dataset.}}
\DoxyCodeLine{4325 \textcolor{comment}{    CZ      -\/   array[K]. This array allows  to  convert  cluster  indexes}}
\DoxyCodeLine{4326 \textcolor{comment}{                returned by this function to indexes used by  Rep.Z.  J-\/th}}
\DoxyCodeLine{4327 \textcolor{comment}{                cluster returned by this function corresponds to  CZ[J]-\/th}}
\DoxyCodeLine{4328 \textcolor{comment}{                cluster stored in Rep.Z/PZ/PM.}}
\DoxyCodeLine{4329 \textcolor{comment}{                It is guaranteed that CZ[I]<CZ[I+1].}}
\DoxyCodeLine{4330 \textcolor{comment}{}}
\DoxyCodeLine{4331 \textcolor{comment}{NOTE: K clusters built by this subroutine are assumed to have no hierarchy.}}
\DoxyCodeLine{4332 \textcolor{comment}{      Although  they  were  obtained  by  manipulation with top K nodes of}}
\DoxyCodeLine{4333 \textcolor{comment}{      dendrogram  (i.e.  hierarchical  decomposition  of  dataset),   this}}
\DoxyCodeLine{4334 \textcolor{comment}{      function does not return information about hierarchy.  Each  of  the}}
\DoxyCodeLine{4335 \textcolor{comment}{      clusters stand on its own.}}
\DoxyCodeLine{4336 \textcolor{comment}{}}
\DoxyCodeLine{4337 \textcolor{comment}{NOTE: Cluster indexes returned by this function  does  not  correspond  to}}
\DoxyCodeLine{4338 \textcolor{comment}{      indexes returned in Rep.Z/PZ/PM. Either you work  with  hierarchical}}
\DoxyCodeLine{4339 \textcolor{comment}{      representation of the dataset (dendrogram), or you work with  "{}flat"{}}}
\DoxyCodeLine{4340 \textcolor{comment}{      representation returned by this function.  Each  of  representations}}
\DoxyCodeLine{4341 \textcolor{comment}{      has its own clusters indexing system (former uses [0, 2*NPoints-\/2]),}}
\DoxyCodeLine{4342 \textcolor{comment}{      while latter uses [0..K-\/1]), although  it  is  possible  to  perform}}
\DoxyCodeLine{4343 \textcolor{comment}{      conversion from one system to another by means of CZ array, returned}}
\DoxyCodeLine{4344 \textcolor{comment}{      by this function, which allows you to convert indexes stored in CIdx}}
\DoxyCodeLine{4345 \textcolor{comment}{      to the numeration system used by Rep.Z.}}
\DoxyCodeLine{4346 \textcolor{comment}{}}
\DoxyCodeLine{4347 \textcolor{comment}{NOTE: this subroutine is optimized for moderate values of K. Say, for  K=5}}
\DoxyCodeLine{4348 \textcolor{comment}{      it will perform many times faster than  for  K=100.  Its  worst-\/case}}
\DoxyCodeLine{4349 \textcolor{comment}{      performance is O(N*K), although in average case  it  perform  better}}
\DoxyCodeLine{4350 \textcolor{comment}{      (up to O(N*log(K))).}}
\DoxyCodeLine{4351 \textcolor{comment}{}}
\DoxyCodeLine{4352 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4353 \textcolor{comment}{     Copyright 10.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{4354 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4355 \textcolor{keywordtype}{void} clusterizerseparatedbydist(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ahcreport}{ahcreport}} \&rep, \textcolor{keyword}{const} \textcolor{keywordtype}{double} r, ae\_int\_t \&k, \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&cidx, \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&cz, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4356 }
\DoxyCodeLine{4357 }
\DoxyCodeLine{4358 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4359 \textcolor{comment}{This  function  accepts  AHC  report  Rep,  desired  maximum  intercluster}}
\DoxyCodeLine{4360 \textcolor{comment}{correlation and returns top clusters from hierarchical clusterization tree}}
\DoxyCodeLine{4361 \textcolor{comment}{which are separated by correlation R or LOWER.}}
\DoxyCodeLine{4362 \textcolor{comment}{}}
\DoxyCodeLine{4363 \textcolor{comment}{It returns assignment of points to clusters (array of cluster indexes).}}
\DoxyCodeLine{4364 \textcolor{comment}{}}
\DoxyCodeLine{4365 \textcolor{comment}{There is one more function with similar name -\/ ClusterizerSeparatedByDist,}}
\DoxyCodeLine{4366 \textcolor{comment}{which returns clusters with intercluster distance equal  to  R  or  HIGHER}}
\DoxyCodeLine{4367 \textcolor{comment}{(note: higher for distance, lower for correlation).}}
\DoxyCodeLine{4368 \textcolor{comment}{}}
\DoxyCodeLine{4369 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4370 \textcolor{comment}{    Rep     -\/   report from ClusterizerRunAHC() performed on XY}}
\DoxyCodeLine{4371 \textcolor{comment}{    R       -\/   desired maximum intercluster correlation, -\/1<=R<=+1}}
\DoxyCodeLine{4372 \textcolor{comment}{}}
\DoxyCodeLine{4373 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4374 \textcolor{comment}{    K       -\/   number of clusters, 1<=K<=NPoints}}
\DoxyCodeLine{4375 \textcolor{comment}{    CIdx    -\/   array[NPoints], I-\/th element contains cluster index  (from}}
\DoxyCodeLine{4376 \textcolor{comment}{                0 to K-\/1) for I-\/th point of the dataset.}}
\DoxyCodeLine{4377 \textcolor{comment}{    CZ      -\/   array[K]. This array allows  to  convert  cluster  indexes}}
\DoxyCodeLine{4378 \textcolor{comment}{                returned by this function to indexes used by  Rep.Z.  J-\/th}}
\DoxyCodeLine{4379 \textcolor{comment}{                cluster returned by this function corresponds to  CZ[J]-\/th}}
\DoxyCodeLine{4380 \textcolor{comment}{                cluster stored in Rep.Z/PZ/PM.}}
\DoxyCodeLine{4381 \textcolor{comment}{                It is guaranteed that CZ[I]<CZ[I+1].}}
\DoxyCodeLine{4382 \textcolor{comment}{}}
\DoxyCodeLine{4383 \textcolor{comment}{NOTE: K clusters built by this subroutine are assumed to have no hierarchy.}}
\DoxyCodeLine{4384 \textcolor{comment}{      Although  they  were  obtained  by  manipulation with top K nodes of}}
\DoxyCodeLine{4385 \textcolor{comment}{      dendrogram  (i.e.  hierarchical  decomposition  of  dataset),   this}}
\DoxyCodeLine{4386 \textcolor{comment}{      function does not return information about hierarchy.  Each  of  the}}
\DoxyCodeLine{4387 \textcolor{comment}{      clusters stand on its own.}}
\DoxyCodeLine{4388 \textcolor{comment}{}}
\DoxyCodeLine{4389 \textcolor{comment}{NOTE: Cluster indexes returned by this function  does  not  correspond  to}}
\DoxyCodeLine{4390 \textcolor{comment}{      indexes returned in Rep.Z/PZ/PM. Either you work  with  hierarchical}}
\DoxyCodeLine{4391 \textcolor{comment}{      representation of the dataset (dendrogram), or you work with  "{}flat"{}}}
\DoxyCodeLine{4392 \textcolor{comment}{      representation returned by this function.  Each  of  representations}}
\DoxyCodeLine{4393 \textcolor{comment}{      has its own clusters indexing system (former uses [0, 2*NPoints-\/2]),}}
\DoxyCodeLine{4394 \textcolor{comment}{      while latter uses [0..K-\/1]), although  it  is  possible  to  perform}}
\DoxyCodeLine{4395 \textcolor{comment}{      conversion from one system to another by means of CZ array, returned}}
\DoxyCodeLine{4396 \textcolor{comment}{      by this function, which allows you to convert indexes stored in CIdx}}
\DoxyCodeLine{4397 \textcolor{comment}{      to the numeration system used by Rep.Z.}}
\DoxyCodeLine{4398 \textcolor{comment}{}}
\DoxyCodeLine{4399 \textcolor{comment}{NOTE: this subroutine is optimized for moderate values of K. Say, for  K=5}}
\DoxyCodeLine{4400 \textcolor{comment}{      it will perform many times faster than  for  K=100.  Its  worst-\/case}}
\DoxyCodeLine{4401 \textcolor{comment}{      performance is O(N*K), although in average case  it  perform  better}}
\DoxyCodeLine{4402 \textcolor{comment}{      (up to O(N*log(K))).}}
\DoxyCodeLine{4403 \textcolor{comment}{}}
\DoxyCodeLine{4404 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4405 \textcolor{comment}{     Copyright 10.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{4406 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4407 \textcolor{keywordtype}{void} clusterizerseparatedbycorr(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ahcreport}{ahcreport}} \&rep, \textcolor{keyword}{const} \textcolor{keywordtype}{double} r, ae\_int\_t \&k, \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&cidx, \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&cz, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4408 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{4409 }
\DoxyCodeLine{4410 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_DFOREST) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{4411 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4412 \textcolor{comment}{This function serializes data structure to string.}}
\DoxyCodeLine{4413 \textcolor{comment}{}}
\DoxyCodeLine{4414 \textcolor{comment}{Important properties of s\_out:}}
\DoxyCodeLine{4415 \textcolor{comment}{* it contains alphanumeric characters, dots, underscores, minus signs}}
\DoxyCodeLine{4416 \textcolor{comment}{* these symbols are grouped into words, which are separated by spaces}}
\DoxyCodeLine{4417 \textcolor{comment}{  and Windows-\/style (CR+LF) newlines}}
\DoxyCodeLine{4418 \textcolor{comment}{* although  serializer  uses  spaces and CR+LF as separators, you can }}
\DoxyCodeLine{4419 \textcolor{comment}{  replace any separator character by arbitrary combination of spaces,}}
\DoxyCodeLine{4420 \textcolor{comment}{  tabs, Windows or Unix newlines. It allows flexible reformatting  of}}
\DoxyCodeLine{4421 \textcolor{comment}{  the  string  in  case you want to include it into text or XML file. }}
\DoxyCodeLine{4422 \textcolor{comment}{  But you should not insert separators into the middle of the "{}words"{}}}
\DoxyCodeLine{4423 \textcolor{comment}{  nor you should change case of letters.}}
\DoxyCodeLine{4424 \textcolor{comment}{* s\_out can be freely moved between 32-\/bit and 64-\/bit systems, little}}
\DoxyCodeLine{4425 \textcolor{comment}{  and big endian machines, and so on. You can serialize structure  on}}
\DoxyCodeLine{4426 \textcolor{comment}{  32-\/bit machine and unserialize it on 64-\/bit one (or vice versa), or}}
\DoxyCodeLine{4427 \textcolor{comment}{  serialize  it  on  SPARC  and  unserialize  on  x86.  You  can also }}
\DoxyCodeLine{4428 \textcolor{comment}{  serialize  it  in  C++ version of ALGLIB and unserialize in C\# one, }}
\DoxyCodeLine{4429 \textcolor{comment}{  and vice versa.}}
\DoxyCodeLine{4430 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4431 \textcolor{keywordtype}{void} dfserialize(\mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&obj, std::string \&s\_out);}
\DoxyCodeLine{4432 }
\DoxyCodeLine{4433 }
\DoxyCodeLine{4434 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4435 \textcolor{comment}{This function unserializes data structure from string.}}
\DoxyCodeLine{4436 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4437 \textcolor{keywordtype}{void} dfunserialize(\textcolor{keyword}{const} std::string \&s\_in, \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&obj);}
\DoxyCodeLine{4438 }
\DoxyCodeLine{4439 }
\DoxyCodeLine{4440 }
\DoxyCodeLine{4441 }
\DoxyCodeLine{4442 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4443 \textcolor{comment}{This function serializes data structure to C++ stream.}}
\DoxyCodeLine{4444 \textcolor{comment}{}}
\DoxyCodeLine{4445 \textcolor{comment}{Data stream generated by this function is same as  string  representation}}
\DoxyCodeLine{4446 \textcolor{comment}{generated  by  string  version  of  serializer -\/ alphanumeric characters,}}
\DoxyCodeLine{4447 \textcolor{comment}{dots, underscores, minus signs, which are grouped into words separated by}}
\DoxyCodeLine{4448 \textcolor{comment}{spaces and CR+LF.}}
\DoxyCodeLine{4449 \textcolor{comment}{}}
\DoxyCodeLine{4450 \textcolor{comment}{We recommend you to read comments on string version of serializer to find}}
\DoxyCodeLine{4451 \textcolor{comment}{out more about serialization of AlGLIB objects.}}
\DoxyCodeLine{4452 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4453 \textcolor{keywordtype}{void} dfserialize(\mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&obj, std::ostream \&s\_out);}
\DoxyCodeLine{4454 }
\DoxyCodeLine{4455 }
\DoxyCodeLine{4456 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4457 \textcolor{comment}{This function unserializes data structure from stream.}}
\DoxyCodeLine{4458 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4459 \textcolor{keywordtype}{void} dfunserialize(\textcolor{keyword}{const} std::istream \&s\_in, \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&obj);}
\DoxyCodeLine{4460 }
\DoxyCodeLine{4461 }
\DoxyCodeLine{4462 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4463 \textcolor{comment}{This function creates buffer  structure  which  can  be  used  to  perform}}
\DoxyCodeLine{4464 \textcolor{comment}{parallel inference requests.}}
\DoxyCodeLine{4465 \textcolor{comment}{}}
\DoxyCodeLine{4466 \textcolor{comment}{DF subpackage  provides two sets of computing functions -\/ ones  which  use}}
\DoxyCodeLine{4467 \textcolor{comment}{internal buffer of DF model  (these  functions are single-\/threaded because}}
\DoxyCodeLine{4468 \textcolor{comment}{they use same buffer, which can not  shared  between  threads),  and  ones}}
\DoxyCodeLine{4469 \textcolor{comment}{which use external buffer.}}
\DoxyCodeLine{4470 \textcolor{comment}{}}
\DoxyCodeLine{4471 \textcolor{comment}{This function is used to initialize external buffer.}}
\DoxyCodeLine{4472 \textcolor{comment}{}}
\DoxyCodeLine{4473 \textcolor{comment}{INPUT PARAMETERS}}
\DoxyCodeLine{4474 \textcolor{comment}{    Model       -\/   DF model which is associated with newly created buffer}}
\DoxyCodeLine{4475 \textcolor{comment}{}}
\DoxyCodeLine{4476 \textcolor{comment}{OUTPUT PARAMETERS}}
\DoxyCodeLine{4477 \textcolor{comment}{    Buf         -\/   external buffer.}}
\DoxyCodeLine{4478 \textcolor{comment}{}}
\DoxyCodeLine{4479 \textcolor{comment}{}}
\DoxyCodeLine{4480 \textcolor{comment}{IMPORTANT: buffer object should be used only with model which was used  to}}
\DoxyCodeLine{4481 \textcolor{comment}{           initialize buffer. Any attempt to  use  buffer  with  different}}
\DoxyCodeLine{4482 \textcolor{comment}{           object is dangerous -\/ you  may   get  integrity  check  failure}}
\DoxyCodeLine{4483 \textcolor{comment}{           (exception) because sizes of internal  arrays  do  not  fit  to}}
\DoxyCodeLine{4484 \textcolor{comment}{           dimensions of the model structure.}}
\DoxyCodeLine{4485 \textcolor{comment}{}}
\DoxyCodeLine{4486 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4487 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{4488 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4489 \textcolor{keywordtype}{void} dfcreatebuffer(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&model, \mbox{\hyperlink{classalglib_1_1decisionforestbuffer}{decisionforestbuffer}} \&buf, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4490 }
\DoxyCodeLine{4491 }
\DoxyCodeLine{4492 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4493 \textcolor{comment}{This subroutine creates DecisionForestBuilder  object  which  is  used  to}}
\DoxyCodeLine{4494 \textcolor{comment}{train decision forests.}}
\DoxyCodeLine{4495 \textcolor{comment}{}}
\DoxyCodeLine{4496 \textcolor{comment}{By default, new builder stores empty dataset and some  reasonable  default}}
\DoxyCodeLine{4497 \textcolor{comment}{settings. At the very least, you should specify dataset prior to  building}}
\DoxyCodeLine{4498 \textcolor{comment}{decision forest. You can also tweak settings of  the  forest  construction}}
\DoxyCodeLine{4499 \textcolor{comment}{algorithm (recommended, although default setting should work well).}}
\DoxyCodeLine{4500 \textcolor{comment}{}}
\DoxyCodeLine{4501 \textcolor{comment}{Following actions are mandatory:}}
\DoxyCodeLine{4502 \textcolor{comment}{* calling dfbuildersetdataset() to specify dataset}}
\DoxyCodeLine{4503 \textcolor{comment}{* calling dfbuilderbuildrandomforest()  to  build  decision  forest  using}}
\DoxyCodeLine{4504 \textcolor{comment}{  current dataset and default settings}}
\DoxyCodeLine{4505 \textcolor{comment}{}}
\DoxyCodeLine{4506 \textcolor{comment}{Additionally, you may call:}}
\DoxyCodeLine{4507 \textcolor{comment}{* dfbuildersetrndvars() or dfbuildersetrndvarsratio() to specify number of}}
\DoxyCodeLine{4508 \textcolor{comment}{  variables randomly chosen for each split}}
\DoxyCodeLine{4509 \textcolor{comment}{* dfbuildersetsubsampleratio() to specify fraction of the dataset randomly}}
\DoxyCodeLine{4510 \textcolor{comment}{  subsampled to build each tree}}
\DoxyCodeLine{4511 \textcolor{comment}{* dfbuildersetseed() to control random seed chosen for tree construction}}
\DoxyCodeLine{4512 \textcolor{comment}{}}
\DoxyCodeLine{4513 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4514 \textcolor{comment}{    none}}
\DoxyCodeLine{4515 \textcolor{comment}{}}
\DoxyCodeLine{4516 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4517 \textcolor{comment}{    S           -\/   decision forest builder}}
\DoxyCodeLine{4518 \textcolor{comment}{}}
\DoxyCodeLine{4519 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4520 \textcolor{comment}{     Copyright 21.05.2018 by Bochkanov Sergey}}
\DoxyCodeLine{4521 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4522 \textcolor{keywordtype}{void} dfbuildercreate(\mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4523 }
\DoxyCodeLine{4524 }
\DoxyCodeLine{4525 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4526 \textcolor{comment}{This subroutine adds dense dataset to the internal storage of the  builder}}
\DoxyCodeLine{4527 \textcolor{comment}{object. Specifying your dataset in the dense format means that  the  dense}}
\DoxyCodeLine{4528 \textcolor{comment}{version of the forest construction algorithm will be invoked.}}
\DoxyCodeLine{4529 \textcolor{comment}{}}
\DoxyCodeLine{4530 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4531 \textcolor{comment}{    S           -\/   decision forest builder object}}
\DoxyCodeLine{4532 \textcolor{comment}{    XY          -\/   array[NPoints,NVars+1] (minimum size; actual size  can}}
\DoxyCodeLine{4533 \textcolor{comment}{                    be larger, only leading part is used anyway), dataset:}}
\DoxyCodeLine{4534 \textcolor{comment}{                    * first NVars elements of each row store values of the}}
\DoxyCodeLine{4535 \textcolor{comment}{                      independent variables}}
\DoxyCodeLine{4536 \textcolor{comment}{                    * last  column  store class number (in 0...NClasses-\/1)}}
\DoxyCodeLine{4537 \textcolor{comment}{                      or real value of the dependent variable}}
\DoxyCodeLine{4538 \textcolor{comment}{    NPoints     -\/   number of rows in the dataset, NPoints>=1}}
\DoxyCodeLine{4539 \textcolor{comment}{    NVars       -\/   number of independent variables, NVars>=1}}
\DoxyCodeLine{4540 \textcolor{comment}{    NClasses    -\/   indicates type of the problem being solved:}}
\DoxyCodeLine{4541 \textcolor{comment}{                    * NClasses>=2 means  that  classification  problem  is}}
\DoxyCodeLine{4542 \textcolor{comment}{                      solved  (last  column  of  the  dataset stores class}}
\DoxyCodeLine{4543 \textcolor{comment}{                      number)}}
\DoxyCodeLine{4544 \textcolor{comment}{                    * NClasses=1 means that regression problem  is  solved}}
\DoxyCodeLine{4545 \textcolor{comment}{                      (last column of the dataset stores variable value)}}
\DoxyCodeLine{4546 \textcolor{comment}{}}
\DoxyCodeLine{4547 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4548 \textcolor{comment}{    S           -\/   decision forest builder}}
\DoxyCodeLine{4549 \textcolor{comment}{}}
\DoxyCodeLine{4550 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4551 \textcolor{comment}{     Copyright 21.05.2018 by Bochkanov Sergey}}
\DoxyCodeLine{4552 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4553 \textcolor{keywordtype}{void} dfbuildersetdataset(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nvars, \textcolor{keyword}{const} ae\_int\_t nclasses, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4554 }
\DoxyCodeLine{4555 }
\DoxyCodeLine{4556 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4557 \textcolor{comment}{This function sets number  of  variables  (in  [1,NVars]  range)  used  by}}
\DoxyCodeLine{4558 \textcolor{comment}{decision forest construction algorithm.}}
\DoxyCodeLine{4559 \textcolor{comment}{}}
\DoxyCodeLine{4560 \textcolor{comment}{The default option is to use roughly sqrt(NVars) variables.}}
\DoxyCodeLine{4561 \textcolor{comment}{}}
\DoxyCodeLine{4562 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4563 \textcolor{comment}{    S           -\/   decision forest builder object}}
\DoxyCodeLine{4564 \textcolor{comment}{    RndVars     -\/   number of randomly selected variables; values  outside}}
\DoxyCodeLine{4565 \textcolor{comment}{                    of [1,NVars] range are silently clipped.}}
\DoxyCodeLine{4566 \textcolor{comment}{}}
\DoxyCodeLine{4567 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4568 \textcolor{comment}{    S           -\/   decision forest builder}}
\DoxyCodeLine{4569 \textcolor{comment}{}}
\DoxyCodeLine{4570 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4571 \textcolor{comment}{     Copyright 21.05.2018 by Bochkanov Sergey}}
\DoxyCodeLine{4572 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4573 \textcolor{keywordtype}{void} dfbuildersetrndvars(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&s, \textcolor{keyword}{const} ae\_int\_t rndvars, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4574 }
\DoxyCodeLine{4575 }
\DoxyCodeLine{4576 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4577 \textcolor{comment}{This function sets number of variables used by decision forest construction}}
\DoxyCodeLine{4578 \textcolor{comment}{algorithm as a fraction of total variable count (0,1) range.}}
\DoxyCodeLine{4579 \textcolor{comment}{}}
\DoxyCodeLine{4580 \textcolor{comment}{The default option is to use roughly sqrt(NVars) variables.}}
\DoxyCodeLine{4581 \textcolor{comment}{}}
\DoxyCodeLine{4582 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4583 \textcolor{comment}{    S           -\/   decision forest builder object}}
\DoxyCodeLine{4584 \textcolor{comment}{    F           -\/   round(NVars*F) variables are selected}}
\DoxyCodeLine{4585 \textcolor{comment}{}}
\DoxyCodeLine{4586 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4587 \textcolor{comment}{    S           -\/   decision forest builder}}
\DoxyCodeLine{4588 \textcolor{comment}{}}
\DoxyCodeLine{4589 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4590 \textcolor{comment}{     Copyright 21.05.2018 by Bochkanov Sergey}}
\DoxyCodeLine{4591 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4592 \textcolor{keywordtype}{void} dfbuildersetrndvarsratio(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&s, \textcolor{keyword}{const} \textcolor{keywordtype}{double} f, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4593 }
\DoxyCodeLine{4594 }
\DoxyCodeLine{4595 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4596 \textcolor{comment}{This function tells decision forest builder to automatically choose number}}
\DoxyCodeLine{4597 \textcolor{comment}{of  variables  used  by  decision forest construction  algorithm.  Roughly}}
\DoxyCodeLine{4598 \textcolor{comment}{sqrt(NVars) variables will be used.}}
\DoxyCodeLine{4599 \textcolor{comment}{}}
\DoxyCodeLine{4600 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4601 \textcolor{comment}{    S           -\/   decision forest builder object}}
\DoxyCodeLine{4602 \textcolor{comment}{}}
\DoxyCodeLine{4603 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4604 \textcolor{comment}{    S           -\/   decision forest builder}}
\DoxyCodeLine{4605 \textcolor{comment}{}}
\DoxyCodeLine{4606 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4607 \textcolor{comment}{     Copyright 21.05.2018 by Bochkanov Sergey}}
\DoxyCodeLine{4608 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4609 \textcolor{keywordtype}{void} dfbuildersetrndvarsauto(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4610 }
\DoxyCodeLine{4611 }
\DoxyCodeLine{4612 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4613 \textcolor{comment}{This function sets size of dataset subsample generated the decision forest}}
\DoxyCodeLine{4614 \textcolor{comment}{construction algorithm. Size is specified as a fraction of  total  dataset}}
\DoxyCodeLine{4615 \textcolor{comment}{size.}}
\DoxyCodeLine{4616 \textcolor{comment}{}}
\DoxyCodeLine{4617 \textcolor{comment}{The default option is to use 50\% of the dataset for training, 50\% for  the}}
\DoxyCodeLine{4618 \textcolor{comment}{OOB estimates. You can decrease fraction F down to 10\%, 1\% or  even  below}}
\DoxyCodeLine{4619 \textcolor{comment}{in order to reduce overfitting.}}
\DoxyCodeLine{4620 \textcolor{comment}{}}
\DoxyCodeLine{4621 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4622 \textcolor{comment}{    S           -\/   decision forest builder object}}
\DoxyCodeLine{4623 \textcolor{comment}{    F           -\/   fraction of the dataset to use, in (0,1] range. Values}}
\DoxyCodeLine{4624 \textcolor{comment}{                    outside of this range will  be  silently  clipped.  At}}
\DoxyCodeLine{4625 \textcolor{comment}{                    least one element is always selected for the  training}}
\DoxyCodeLine{4626 \textcolor{comment}{                    set.}}
\DoxyCodeLine{4627 \textcolor{comment}{}}
\DoxyCodeLine{4628 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4629 \textcolor{comment}{    S           -\/   decision forest builder}}
\DoxyCodeLine{4630 \textcolor{comment}{}}
\DoxyCodeLine{4631 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4632 \textcolor{comment}{     Copyright 21.05.2018 by Bochkanov Sergey}}
\DoxyCodeLine{4633 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4634 \textcolor{keywordtype}{void} dfbuildersetsubsampleratio(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&s, \textcolor{keyword}{const} \textcolor{keywordtype}{double} f, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4635 }
\DoxyCodeLine{4636 }
\DoxyCodeLine{4637 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4638 \textcolor{comment}{This function sets seed used by internal RNG for  random  subsampling  and}}
\DoxyCodeLine{4639 \textcolor{comment}{random selection of variable subsets.}}
\DoxyCodeLine{4640 \textcolor{comment}{}}
\DoxyCodeLine{4641 \textcolor{comment}{By default random seed is used, i.e. every time you build decision forest,}}
\DoxyCodeLine{4642 \textcolor{comment}{we seed generator with new value  obtained  from  system-\/wide  RNG.  Thus,}}
\DoxyCodeLine{4643 \textcolor{comment}{decision forest builder returns non-\/deterministic results. You can  change}}
\DoxyCodeLine{4644 \textcolor{comment}{such behavior by specyfing fixed positive seed value.}}
\DoxyCodeLine{4645 \textcolor{comment}{}}
\DoxyCodeLine{4646 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4647 \textcolor{comment}{    S           -\/   decision forest builder object}}
\DoxyCodeLine{4648 \textcolor{comment}{    SeedVal     -\/   seed value:}}
\DoxyCodeLine{4649 \textcolor{comment}{                    * positive values are used for seeding RNG with fixed}}
\DoxyCodeLine{4650 \textcolor{comment}{                      seed, i.e. subsequent runs on same data will return}}
\DoxyCodeLine{4651 \textcolor{comment}{                      same decision forests}}
\DoxyCodeLine{4652 \textcolor{comment}{                    * non-\/positive seed means that random seed is used}}
\DoxyCodeLine{4653 \textcolor{comment}{                      for every run of builder, i.e. subsequent  runs  on}}
\DoxyCodeLine{4654 \textcolor{comment}{                      same  datasets  will  return   slightly   different}}
\DoxyCodeLine{4655 \textcolor{comment}{                      decision forests}}
\DoxyCodeLine{4656 \textcolor{comment}{}}
\DoxyCodeLine{4657 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4658 \textcolor{comment}{    S           -\/   decision forest builder, see}}
\DoxyCodeLine{4659 \textcolor{comment}{}}
\DoxyCodeLine{4660 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4661 \textcolor{comment}{     Copyright 21.05.2018 by Bochkanov Sergey}}
\DoxyCodeLine{4662 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4663 \textcolor{keywordtype}{void} dfbuildersetseed(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&s, \textcolor{keyword}{const} ae\_int\_t seedval, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4664 }
\DoxyCodeLine{4665 }
\DoxyCodeLine{4666 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4667 \textcolor{comment}{This function sets random decision forest construction algorithm.}}
\DoxyCodeLine{4668 \textcolor{comment}{}}
\DoxyCodeLine{4669 \textcolor{comment}{As for now, only one decision forest construction algorithm is supported -\/}}
\DoxyCodeLine{4670 \textcolor{comment}{a dense "{}baseline"{} RDF algorithm.}}
\DoxyCodeLine{4671 \textcolor{comment}{}}
\DoxyCodeLine{4672 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4673 \textcolor{comment}{    S           -\/   decision forest builder object}}
\DoxyCodeLine{4674 \textcolor{comment}{    AlgoType    -\/   algorithm type:}}
\DoxyCodeLine{4675 \textcolor{comment}{                    * 0 = baseline dense RDF}}
\DoxyCodeLine{4676 \textcolor{comment}{}}
\DoxyCodeLine{4677 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4678 \textcolor{comment}{    S           -\/   decision forest builder, see}}
\DoxyCodeLine{4679 \textcolor{comment}{}}
\DoxyCodeLine{4680 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4681 \textcolor{comment}{     Copyright 21.05.2018 by Bochkanov Sergey}}
\DoxyCodeLine{4682 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4683 \textcolor{keywordtype}{void} dfbuildersetrdfalgo(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&s, \textcolor{keyword}{const} ae\_int\_t algotype, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4684 }
\DoxyCodeLine{4685 }
\DoxyCodeLine{4686 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4687 \textcolor{comment}{This  function  sets  split  selection  algorithm used by decision  forest}}
\DoxyCodeLine{4688 \textcolor{comment}{classifier. You may choose several algorithms, with  different  speed  and}}
\DoxyCodeLine{4689 \textcolor{comment}{quality of the results.}}
\DoxyCodeLine{4690 \textcolor{comment}{}}
\DoxyCodeLine{4691 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4692 \textcolor{comment}{    S           -\/   decision forest builder object}}
\DoxyCodeLine{4693 \textcolor{comment}{    SplitStrength-\/  split type:}}
\DoxyCodeLine{4694 \textcolor{comment}{                    * 0 = split at the random position, fastest one}}
\DoxyCodeLine{4695 \textcolor{comment}{                    * 1 = split at the middle of the range}}
\DoxyCodeLine{4696 \textcolor{comment}{                    * 2 = strong split at the best point of the range (default)}}
\DoxyCodeLine{4697 \textcolor{comment}{}}
\DoxyCodeLine{4698 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4699 \textcolor{comment}{    S           -\/   decision forest builder, see}}
\DoxyCodeLine{4700 \textcolor{comment}{}}
\DoxyCodeLine{4701 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4702 \textcolor{comment}{     Copyright 21.05.2018 by Bochkanov Sergey}}
\DoxyCodeLine{4703 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4704 \textcolor{keywordtype}{void} dfbuildersetrdfsplitstrength(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&s, \textcolor{keyword}{const} ae\_int\_t splitstrength, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4705 }
\DoxyCodeLine{4706 }
\DoxyCodeLine{4707 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4708 \textcolor{comment}{This  function  tells  decision  forest  construction  algorithm  to   use}}
\DoxyCodeLine{4709 \textcolor{comment}{Gini impurity based variable importance estimation (also known as MDI).}}
\DoxyCodeLine{4710 \textcolor{comment}{}}
\DoxyCodeLine{4711 \textcolor{comment}{This version of importance estimation algorithm analyzes mean decrease  in}}
\DoxyCodeLine{4712 \textcolor{comment}{impurity (MDI) on training sample during  splits.  The result  is  divided}}
\DoxyCodeLine{4713 \textcolor{comment}{by impurity at the root node in order to produce estimate in [0,1] range.}}
\DoxyCodeLine{4714 \textcolor{comment}{}}
\DoxyCodeLine{4715 \textcolor{comment}{Such estimates are fast to calculate and beautifully  normalized  (sum  to}}
\DoxyCodeLine{4716 \textcolor{comment}{one) but have following downsides:}}
\DoxyCodeLine{4717 \textcolor{comment}{* They ALWAYS sum to 1.0, even if output is completely unpredictable. I.e.}}
\DoxyCodeLine{4718 \textcolor{comment}{  MDI allows to order variables by importance, but does not  tell us about}}
\DoxyCodeLine{4719 \textcolor{comment}{  "{}absolute"{} importances of variables}}
\DoxyCodeLine{4720 \textcolor{comment}{* there exist some bias towards continuous and high-\/cardinality categorical}}
\DoxyCodeLine{4721 \textcolor{comment}{  variables}}
\DoxyCodeLine{4722 \textcolor{comment}{}}
\DoxyCodeLine{4723 \textcolor{comment}{NOTE: informally speaking, MDA (permutation importance) rating answers the}}
\DoxyCodeLine{4724 \textcolor{comment}{      question  "{}what  part  of  the  model  predictive power is ruined by}}
\DoxyCodeLine{4725 \textcolor{comment}{      permuting k-\/th variable?"{} while MDI tells us "{}what part of the model}}
\DoxyCodeLine{4726 \textcolor{comment}{      predictive power was achieved due to usage of k-\/th variable"{}.}}
\DoxyCodeLine{4727 \textcolor{comment}{}}
\DoxyCodeLine{4728 \textcolor{comment}{      Thus, MDA rates each variable independently at "{}0 to 1"{}  scale while}}
\DoxyCodeLine{4729 \textcolor{comment}{      MDI (and OOB-\/MDI too) tends to divide "{}unit  amount  of  importance"{}}}
\DoxyCodeLine{4730 \textcolor{comment}{      between several important variables.}}
\DoxyCodeLine{4731 \textcolor{comment}{}}
\DoxyCodeLine{4732 \textcolor{comment}{      If  all  variables  are  equally  important,  they  will  have  same}}
\DoxyCodeLine{4733 \textcolor{comment}{      MDI/OOB-\/MDI rating, equal (for OOB-\/MDI: roughly equal)  to  1/NVars.}}
\DoxyCodeLine{4734 \textcolor{comment}{      However, roughly  same  picture  will  be  produced   for  the  "{}all}}
\DoxyCodeLine{4735 \textcolor{comment}{      variables provide information no one is critical"{} situation  and for}}
\DoxyCodeLine{4736 \textcolor{comment}{      the "{}all variables are critical, drop any one, everything is ruined"{}}}
\DoxyCodeLine{4737 \textcolor{comment}{      situation.}}
\DoxyCodeLine{4738 \textcolor{comment}{}}
\DoxyCodeLine{4739 \textcolor{comment}{      Contrary to that, MDA will rate critical variable as \string~1.0 important,}}
\DoxyCodeLine{4740 \textcolor{comment}{      and important but non-\/critical variable will  have  less  than  unit}}
\DoxyCodeLine{4741 \textcolor{comment}{      rating.}}
\DoxyCodeLine{4742 \textcolor{comment}{}}
\DoxyCodeLine{4743 \textcolor{comment}{NOTE: quite an often MDA and MDI return same results. It generally happens}}
\DoxyCodeLine{4744 \textcolor{comment}{      on problems with low test set error (a few  percents  at  most)  and}}
\DoxyCodeLine{4745 \textcolor{comment}{      large enough training set to avoid overfitting.}}
\DoxyCodeLine{4746 \textcolor{comment}{}}
\DoxyCodeLine{4747 \textcolor{comment}{      The difference between MDA, MDI and OOB-\/MDI becomes  important  only}}
\DoxyCodeLine{4748 \textcolor{comment}{      on "{}hard"{} tasks with high test set error and/or small training set.}}
\DoxyCodeLine{4749 \textcolor{comment}{}}
\DoxyCodeLine{4750 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4751 \textcolor{comment}{    S           -\/   decision forest builder object}}
\DoxyCodeLine{4752 \textcolor{comment}{}}
\DoxyCodeLine{4753 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4754 \textcolor{comment}{    S           -\/   decision forest builder object. Next call to the forest}}
\DoxyCodeLine{4755 \textcolor{comment}{                    construction function will produce:}}
\DoxyCodeLine{4756 \textcolor{comment}{                    * importance estimates in rep.varimportances field}}
\DoxyCodeLine{4757 \textcolor{comment}{                    * variable ranks in rep.topvars field}}
\DoxyCodeLine{4758 \textcolor{comment}{}}
\DoxyCodeLine{4759 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4760 \textcolor{comment}{     Copyright 29.07.2019 by Bochkanov Sergey}}
\DoxyCodeLine{4761 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4762 \textcolor{keywordtype}{void} dfbuildersetimportancetrngini(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4763 }
\DoxyCodeLine{4764 }
\DoxyCodeLine{4765 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4766 \textcolor{comment}{This  function  tells  decision  forest  construction  algorithm  to   use}}
\DoxyCodeLine{4767 \textcolor{comment}{out-\/of-\/bag version of Gini variable importance estimation (also  known  as}}
\DoxyCodeLine{4768 \textcolor{comment}{OOB-\/MDI).}}
\DoxyCodeLine{4769 \textcolor{comment}{}}
\DoxyCodeLine{4770 \textcolor{comment}{This version of importance estimation algorithm analyzes mean decrease  in}}
\DoxyCodeLine{4771 \textcolor{comment}{impurity (MDI) on out-\/of-\/bag sample during splits. The result  is  divided}}
\DoxyCodeLine{4772 \textcolor{comment}{by impurity at the root node in order to produce estimate in [0,1] range.}}
\DoxyCodeLine{4773 \textcolor{comment}{}}
\DoxyCodeLine{4774 \textcolor{comment}{Such estimates are fast to calculate and resistant to  overfitting  issues}}
\DoxyCodeLine{4775 \textcolor{comment}{(thanks to the  out-\/of-\/bag  estimates  used). However, OOB Gini rating has}}
\DoxyCodeLine{4776 \textcolor{comment}{following downsides:}}
\DoxyCodeLine{4777 \textcolor{comment}{* there exist some bias towards continuous and high-\/cardinality categorical}}
\DoxyCodeLine{4778 \textcolor{comment}{  variables}}
\DoxyCodeLine{4779 \textcolor{comment}{* Gini rating allows us to order variables by importance, but it  is  hard}}
\DoxyCodeLine{4780 \textcolor{comment}{  to define importance of the variable by itself.}}
\DoxyCodeLine{4781 \textcolor{comment}{}}
\DoxyCodeLine{4782 \textcolor{comment}{NOTE: informally speaking, MDA (permutation importance) rating answers the}}
\DoxyCodeLine{4783 \textcolor{comment}{      question  "{}what  part  of  the  model  predictive power is ruined by}}
\DoxyCodeLine{4784 \textcolor{comment}{      permuting k-\/th variable?"{} while MDI tells us "{}what part of the model}}
\DoxyCodeLine{4785 \textcolor{comment}{      predictive power was achieved due to usage of k-\/th variable"{}.}}
\DoxyCodeLine{4786 \textcolor{comment}{}}
\DoxyCodeLine{4787 \textcolor{comment}{      Thus, MDA rates each variable independently at "{}0 to 1"{}  scale while}}
\DoxyCodeLine{4788 \textcolor{comment}{      MDI (and OOB-\/MDI too) tends to divide "{}unit  amount  of  importance"{}}}
\DoxyCodeLine{4789 \textcolor{comment}{      between several important variables.}}
\DoxyCodeLine{4790 \textcolor{comment}{}}
\DoxyCodeLine{4791 \textcolor{comment}{      If  all  variables  are  equally  important,  they  will  have  same}}
\DoxyCodeLine{4792 \textcolor{comment}{      MDI/OOB-\/MDI rating, equal (for OOB-\/MDI: roughly equal)  to  1/NVars.}}
\DoxyCodeLine{4793 \textcolor{comment}{      However, roughly  same  picture  will  be  produced   for  the  "{}all}}
\DoxyCodeLine{4794 \textcolor{comment}{      variables provide information no one is critical"{} situation  and for}}
\DoxyCodeLine{4795 \textcolor{comment}{      the "{}all variables are critical, drop any one, everything is ruined"{}}}
\DoxyCodeLine{4796 \textcolor{comment}{      situation.}}
\DoxyCodeLine{4797 \textcolor{comment}{}}
\DoxyCodeLine{4798 \textcolor{comment}{      Contrary to that, MDA will rate critical variable as \string~1.0 important,}}
\DoxyCodeLine{4799 \textcolor{comment}{      and important but non-\/critical variable will  have  less  than  unit}}
\DoxyCodeLine{4800 \textcolor{comment}{      rating.}}
\DoxyCodeLine{4801 \textcolor{comment}{}}
\DoxyCodeLine{4802 \textcolor{comment}{NOTE: quite an often MDA and MDI return same results. It generally happens}}
\DoxyCodeLine{4803 \textcolor{comment}{      on problems with low test set error (a few  percents  at  most)  and}}
\DoxyCodeLine{4804 \textcolor{comment}{      large enough training set to avoid overfitting.}}
\DoxyCodeLine{4805 \textcolor{comment}{}}
\DoxyCodeLine{4806 \textcolor{comment}{      The difference between MDA, MDI and OOB-\/MDI becomes  important  only}}
\DoxyCodeLine{4807 \textcolor{comment}{      on "{}hard"{} tasks with high test set error and/or small training set.}}
\DoxyCodeLine{4808 \textcolor{comment}{}}
\DoxyCodeLine{4809 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4810 \textcolor{comment}{    S           -\/   decision forest builder object}}
\DoxyCodeLine{4811 \textcolor{comment}{}}
\DoxyCodeLine{4812 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4813 \textcolor{comment}{    S           -\/   decision forest builder object. Next call to the forest}}
\DoxyCodeLine{4814 \textcolor{comment}{                    construction function will produce:}}
\DoxyCodeLine{4815 \textcolor{comment}{                    * importance estimates in rep.varimportances field}}
\DoxyCodeLine{4816 \textcolor{comment}{                    * variable ranks in rep.topvars field}}
\DoxyCodeLine{4817 \textcolor{comment}{}}
\DoxyCodeLine{4818 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4819 \textcolor{comment}{     Copyright 29.07.2019 by Bochkanov Sergey}}
\DoxyCodeLine{4820 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4821 \textcolor{keywordtype}{void} dfbuildersetimportanceoobgini(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4822 }
\DoxyCodeLine{4823 }
\DoxyCodeLine{4824 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4825 \textcolor{comment}{This  function  tells  decision  forest  construction  algorithm  to   use}}
\DoxyCodeLine{4826 \textcolor{comment}{permutation variable importance estimator (also known as MDA).}}
\DoxyCodeLine{4827 \textcolor{comment}{}}
\DoxyCodeLine{4828 \textcolor{comment}{This version of importance estimation algorithm analyzes mean increase  in}}
\DoxyCodeLine{4829 \textcolor{comment}{out-\/of-\/bag sum of squared  residuals  after  random  permutation  of  J-\/th}}
\DoxyCodeLine{4830 \textcolor{comment}{variable. The result is divided by error computed with all variables being}}
\DoxyCodeLine{4831 \textcolor{comment}{perturbed in order to produce R-\/squared-\/like estimate in [0,1] range.}}
\DoxyCodeLine{4832 \textcolor{comment}{}}
\DoxyCodeLine{4833 \textcolor{comment}{Such estimate  is  slower to calculate than Gini-\/based rating  because  it}}
\DoxyCodeLine{4834 \textcolor{comment}{needs multiple inference runs for each of variables being studied.}}
\DoxyCodeLine{4835 \textcolor{comment}{}}
\DoxyCodeLine{4836 \textcolor{comment}{ALGLIB uses parallelized and highly  optimized  algorithm  which  analyzes}}
\DoxyCodeLine{4837 \textcolor{comment}{path through the decision tree and allows  to  handle  most  perturbations}}
\DoxyCodeLine{4838 \textcolor{comment}{in O(1) time; nevertheless, requesting MDA importances may increase forest}}
\DoxyCodeLine{4839 \textcolor{comment}{construction time from 10\% to 200\% (or more,  if  you  have  thousands  of}}
\DoxyCodeLine{4840 \textcolor{comment}{variables).}}
\DoxyCodeLine{4841 \textcolor{comment}{}}
\DoxyCodeLine{4842 \textcolor{comment}{However, MDA rating has following benefits over Gini-\/based ones:}}
\DoxyCodeLine{4843 \textcolor{comment}{* no bias towards specific variable types}}
\DoxyCodeLine{4844 \textcolor{comment}{* ability to directly evaluate "{}absolute"{} importance of some  variable  at}}
\DoxyCodeLine{4845 \textcolor{comment}{  "{}0 to 1"{} scale (contrary to Gini-\/based rating, which returns comparative}}
\DoxyCodeLine{4846 \textcolor{comment}{  importances).}}
\DoxyCodeLine{4847 \textcolor{comment}{}}
\DoxyCodeLine{4848 \textcolor{comment}{NOTE: informally speaking, MDA (permutation importance) rating answers the}}
\DoxyCodeLine{4849 \textcolor{comment}{      question  "{}what  part  of  the  model  predictive power is ruined by}}
\DoxyCodeLine{4850 \textcolor{comment}{      permuting k-\/th variable?"{} while MDI tells us "{}what part of the model}}
\DoxyCodeLine{4851 \textcolor{comment}{      predictive power was achieved due to usage of k-\/th variable"{}.}}
\DoxyCodeLine{4852 \textcolor{comment}{}}
\DoxyCodeLine{4853 \textcolor{comment}{      Thus, MDA rates each variable independently at "{}0 to 1"{}  scale while}}
\DoxyCodeLine{4854 \textcolor{comment}{      MDI (and OOB-\/MDI too) tends to divide "{}unit  amount  of  importance"{}}}
\DoxyCodeLine{4855 \textcolor{comment}{      between several important variables.}}
\DoxyCodeLine{4856 \textcolor{comment}{}}
\DoxyCodeLine{4857 \textcolor{comment}{      If  all  variables  are  equally  important,  they  will  have  same}}
\DoxyCodeLine{4858 \textcolor{comment}{      MDI/OOB-\/MDI rating, equal (for OOB-\/MDI: roughly equal)  to  1/NVars.}}
\DoxyCodeLine{4859 \textcolor{comment}{      However, roughly  same  picture  will  be  produced   for  the  "{}all}}
\DoxyCodeLine{4860 \textcolor{comment}{      variables provide information no one is critical"{} situation  and for}}
\DoxyCodeLine{4861 \textcolor{comment}{      the "{}all variables are critical, drop any one, everything is ruined"{}}}
\DoxyCodeLine{4862 \textcolor{comment}{      situation.}}
\DoxyCodeLine{4863 \textcolor{comment}{}}
\DoxyCodeLine{4864 \textcolor{comment}{      Contrary to that, MDA will rate critical variable as \string~1.0 important,}}
\DoxyCodeLine{4865 \textcolor{comment}{      and important but non-\/critical variable will  have  less  than  unit}}
\DoxyCodeLine{4866 \textcolor{comment}{      rating.}}
\DoxyCodeLine{4867 \textcolor{comment}{}}
\DoxyCodeLine{4868 \textcolor{comment}{NOTE: quite an often MDA and MDI return same results. It generally happens}}
\DoxyCodeLine{4869 \textcolor{comment}{      on problems with low test set error (a few  percents  at  most)  and}}
\DoxyCodeLine{4870 \textcolor{comment}{      large enough training set to avoid overfitting.}}
\DoxyCodeLine{4871 \textcolor{comment}{}}
\DoxyCodeLine{4872 \textcolor{comment}{      The difference between MDA, MDI and OOB-\/MDI becomes  important  only}}
\DoxyCodeLine{4873 \textcolor{comment}{      on "{}hard"{} tasks with high test set error and/or small training set.}}
\DoxyCodeLine{4874 \textcolor{comment}{}}
\DoxyCodeLine{4875 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4876 \textcolor{comment}{    S           -\/   decision forest builder object}}
\DoxyCodeLine{4877 \textcolor{comment}{}}
\DoxyCodeLine{4878 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4879 \textcolor{comment}{    S           -\/   decision forest builder object. Next call to the forest}}
\DoxyCodeLine{4880 \textcolor{comment}{                    construction function will produce:}}
\DoxyCodeLine{4881 \textcolor{comment}{                    * importance estimates in rep.varimportances field}}
\DoxyCodeLine{4882 \textcolor{comment}{                    * variable ranks in rep.topvars field}}
\DoxyCodeLine{4883 \textcolor{comment}{}}
\DoxyCodeLine{4884 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4885 \textcolor{comment}{     Copyright 29.07.2019 by Bochkanov Sergey}}
\DoxyCodeLine{4886 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4887 \textcolor{keywordtype}{void} dfbuildersetimportancepermutation(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4888 }
\DoxyCodeLine{4889 }
\DoxyCodeLine{4890 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4891 \textcolor{comment}{This  function  tells  decision  forest  construction  algorithm  to  skip}}
\DoxyCodeLine{4892 \textcolor{comment}{variable importance estimation.}}
\DoxyCodeLine{4893 \textcolor{comment}{}}
\DoxyCodeLine{4894 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4895 \textcolor{comment}{    S           -\/   decision forest builder object}}
\DoxyCodeLine{4896 \textcolor{comment}{}}
\DoxyCodeLine{4897 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4898 \textcolor{comment}{    S           -\/   decision forest builder object. Next call to the forest}}
\DoxyCodeLine{4899 \textcolor{comment}{                    construction function will result in forest being built}}
\DoxyCodeLine{4900 \textcolor{comment}{                    without variable importance estimation.}}
\DoxyCodeLine{4901 \textcolor{comment}{}}
\DoxyCodeLine{4902 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4903 \textcolor{comment}{     Copyright 29.07.2019 by Bochkanov Sergey}}
\DoxyCodeLine{4904 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4905 \textcolor{keywordtype}{void} dfbuildersetimportancenone(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4906 }
\DoxyCodeLine{4907 }
\DoxyCodeLine{4908 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4909 \textcolor{comment}{This function is an alias for dfbuilderpeekprogress(), left in ALGLIB  for}}
\DoxyCodeLine{4910 \textcolor{comment}{backward compatibility reasons.}}
\DoxyCodeLine{4911 \textcolor{comment}{}}
\DoxyCodeLine{4912 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4913 \textcolor{comment}{     Copyright 21.05.2018 by Bochkanov Sergey}}
\DoxyCodeLine{4914 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4915 \textcolor{keywordtype}{double} dfbuildergetprogress(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4916 }
\DoxyCodeLine{4917 }
\DoxyCodeLine{4918 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4919 \textcolor{comment}{This function is used to peek into  decision  forest  construction process}}
\DoxyCodeLine{4920 \textcolor{comment}{from some other thread and get current progress indicator.}}
\DoxyCodeLine{4921 \textcolor{comment}{}}
\DoxyCodeLine{4922 \textcolor{comment}{It returns value in [0,1].}}
\DoxyCodeLine{4923 \textcolor{comment}{}}
\DoxyCodeLine{4924 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4925 \textcolor{comment}{    S           -\/   decision forest builder object used  to  build  forest}}
\DoxyCodeLine{4926 \textcolor{comment}{                    in some other thread}}
\DoxyCodeLine{4927 \textcolor{comment}{}}
\DoxyCodeLine{4928 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{4929 \textcolor{comment}{    progress value, in [0,1]}}
\DoxyCodeLine{4930 \textcolor{comment}{}}
\DoxyCodeLine{4931 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{4932 \textcolor{comment}{     Copyright 21.05.2018 by Bochkanov Sergey}}
\DoxyCodeLine{4933 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{4934 \textcolor{keywordtype}{double} dfbuilderpeekprogress(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{4935 }
\DoxyCodeLine{4936 }
\DoxyCodeLine{4937 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{4938 \textcolor{comment}{This subroutine builds decision forest according to current settings using}}
\DoxyCodeLine{4939 \textcolor{comment}{dataset internally stored in the builder object. Dense algorithm is used.}}
\DoxyCodeLine{4940 \textcolor{comment}{}}
\DoxyCodeLine{4941 \textcolor{comment}{NOTE: this   function   uses   dense  algorithm  for  forest  construction}}
\DoxyCodeLine{4942 \textcolor{comment}{      independently from the dataset format (dense or sparse).}}
\DoxyCodeLine{4943 \textcolor{comment}{}}
\DoxyCodeLine{4944 \textcolor{comment}{NOTE: forest built with this function is  stored  in-\/memory  using  64-\/bit}}
\DoxyCodeLine{4945 \textcolor{comment}{      data structures for offsets/indexes/split values. It is possible  to}}
\DoxyCodeLine{4946 \textcolor{comment}{      convert  forest  into  more  memory-\/efficient   compressed    binary}}
\DoxyCodeLine{4947 \textcolor{comment}{      representation.  Depending  on  the  problem  properties,  3.7x-\/5.7x}}
\DoxyCodeLine{4948 \textcolor{comment}{      compression factors are possible.}}
\DoxyCodeLine{4949 \textcolor{comment}{}}
\DoxyCodeLine{4950 \textcolor{comment}{      The downsides of compression are (a) slight reduction in  the  model}}
\DoxyCodeLine{4951 \textcolor{comment}{      accuracy and (b) \string~1.5x reduction in  the  inference  speed  (due  to}}
\DoxyCodeLine{4952 \textcolor{comment}{      increased complexity of the storage format).}}
\DoxyCodeLine{4953 \textcolor{comment}{}}
\DoxyCodeLine{4954 \textcolor{comment}{      See comments on dfbinarycompression() for more info.}}
\DoxyCodeLine{4955 \textcolor{comment}{}}
\DoxyCodeLine{4956 \textcolor{comment}{Default settings are used by the algorithm; you can tweak  them  with  the}}
\DoxyCodeLine{4957 \textcolor{comment}{help of the following functions:}}
\DoxyCodeLine{4958 \textcolor{comment}{* dfbuildersetrfactor() -\/ to control a fraction of the  dataset  used  for}}
\DoxyCodeLine{4959 \textcolor{comment}{  subsampling}}
\DoxyCodeLine{4960 \textcolor{comment}{* dfbuildersetrandomvars() -\/ to control number of variables randomly chosen}}
\DoxyCodeLine{4961 \textcolor{comment}{  for decision rule creation}}
\DoxyCodeLine{4962 \textcolor{comment}{}}
\DoxyCodeLine{4963 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{4964 \textcolor{comment}{  !}}
\DoxyCodeLine{4965 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{4966 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{4967 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{4968 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{4969 \textcolor{comment}{  !}}
\DoxyCodeLine{4970 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{4971 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{4972 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{4973 \textcolor{comment}{}}
\DoxyCodeLine{4974 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{4975 \textcolor{comment}{    S           -\/   decision forest builder object}}
\DoxyCodeLine{4976 \textcolor{comment}{    NTrees      -\/   NTrees>=1, number of trees to train}}
\DoxyCodeLine{4977 \textcolor{comment}{}}
\DoxyCodeLine{4978 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{4979 \textcolor{comment}{    DF          -\/   decision forest. You can compress this forest to  more}}
\DoxyCodeLine{4980 \textcolor{comment}{                    compact 16-\/bit representation with dfbinarycompression()}}
\DoxyCodeLine{4981 \textcolor{comment}{    Rep         -\/   report, see below for information on its fields.}}
\DoxyCodeLine{4982 \textcolor{comment}{}}
\DoxyCodeLine{4983 \textcolor{comment}{=== report information produced by forest construction function ==========}}
\DoxyCodeLine{4984 \textcolor{comment}{}}
\DoxyCodeLine{4985 \textcolor{comment}{Decision forest training report includes following information:}}
\DoxyCodeLine{4986 \textcolor{comment}{* training set errors}}
\DoxyCodeLine{4987 \textcolor{comment}{* out-\/of-\/bag estimates of errors}}
\DoxyCodeLine{4988 \textcolor{comment}{* variable importance ratings}}
\DoxyCodeLine{4989 \textcolor{comment}{}}
\DoxyCodeLine{4990 \textcolor{comment}{Following fields are used to store information:}}
\DoxyCodeLine{4991 \textcolor{comment}{* training set errors are stored in rep.relclserror, rep.avgce, rep.rmserror,}}
\DoxyCodeLine{4992 \textcolor{comment}{  rep.avgerror and rep.avgrelerror}}
\DoxyCodeLine{4993 \textcolor{comment}{* out-\/of-\/bag estimates of errors are stored in rep.oobrelclserror, rep.oobavgce,}}
\DoxyCodeLine{4994 \textcolor{comment}{  rep.oobrmserror, rep.oobavgerror and rep.oobavgrelerror}}
\DoxyCodeLine{4995 \textcolor{comment}{}}
\DoxyCodeLine{4996 \textcolor{comment}{Variable importance reports, if requested by dfbuildersetimportancegini(),}}
\DoxyCodeLine{4997 \textcolor{comment}{dfbuildersetimportancetrngini() or dfbuildersetimportancepermutation()}}
\DoxyCodeLine{4998 \textcolor{comment}{call, are stored in:}}
\DoxyCodeLine{4999 \textcolor{comment}{* rep.varimportances field stores importance ratings}}
\DoxyCodeLine{5000 \textcolor{comment}{* rep.topvars stores variable indexes ordered from the most important to}}
\DoxyCodeLine{5001 \textcolor{comment}{  less important ones}}
\DoxyCodeLine{5002 \textcolor{comment}{}}
\DoxyCodeLine{5003 \textcolor{comment}{You can find more information about report fields in:}}
\DoxyCodeLine{5004 \textcolor{comment}{* comments on dfreport structure}}
\DoxyCodeLine{5005 \textcolor{comment}{* comments on dfbuildersetimportancegini function}}
\DoxyCodeLine{5006 \textcolor{comment}{* comments on dfbuildersetimportancetrngini function}}
\DoxyCodeLine{5007 \textcolor{comment}{* comments on dfbuildersetimportancepermutation function}}
\DoxyCodeLine{5008 \textcolor{comment}{}}
\DoxyCodeLine{5009 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5010 \textcolor{comment}{     Copyright 21.05.2018 by Bochkanov Sergey}}
\DoxyCodeLine{5011 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5012 \textcolor{keywordtype}{void} dfbuilderbuildrandomforest(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuilder}{decisionforestbuilder}} \&s, \textcolor{keyword}{const} ae\_int\_t ntrees, \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&df, \mbox{\hyperlink{classalglib_1_1dfreport}{dfreport}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5013 }
\DoxyCodeLine{5014 }
\DoxyCodeLine{5015 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5016 \textcolor{comment}{This function performs binary compression of the decision forest.}}
\DoxyCodeLine{5017 \textcolor{comment}{}}
\DoxyCodeLine{5018 \textcolor{comment}{Original decision forest produced by the  forest  builder  is stored using}}
\DoxyCodeLine{5019 \textcolor{comment}{64-\/bit representation for all numbers -\/ offsets, variable  indexes,  split}}
\DoxyCodeLine{5020 \textcolor{comment}{points.}}
\DoxyCodeLine{5021 \textcolor{comment}{}}
\DoxyCodeLine{5022 \textcolor{comment}{It is possible to significantly reduce model size by means of:}}
\DoxyCodeLine{5023 \textcolor{comment}{* using compressed  dynamic encoding for integers  (offsets  and  variable}}
\DoxyCodeLine{5024 \textcolor{comment}{  indexes), which uses just 1 byte to store small ints  (less  than  128),}}
\DoxyCodeLine{5025 \textcolor{comment}{  just 2 bytes for larger values (less than 128\string^2) and so on}}
\DoxyCodeLine{5026 \textcolor{comment}{* storing floating point numbers using 8-\/bit exponent and 16-\/bit mantissa}}
\DoxyCodeLine{5027 \textcolor{comment}{}}
\DoxyCodeLine{5028 \textcolor{comment}{As  result,  model  needs  significantly  less  memory (compression factor}}
\DoxyCodeLine{5029 \textcolor{comment}{depends on  variable and class counts). In particular:}}
\DoxyCodeLine{5030 \textcolor{comment}{* NVars<128   and NClasses<128 result in 4.4x-\/5.7x model size reduction}}
\DoxyCodeLine{5031 \textcolor{comment}{* NVars<16384 and NClasses<128 result in 3.7x-\/4.5x model size reduction}}
\DoxyCodeLine{5032 \textcolor{comment}{}}
\DoxyCodeLine{5033 \textcolor{comment}{Such storage format performs lossless compression  of  all  integers,  but}}
\DoxyCodeLine{5034 \textcolor{comment}{compression of floating point values (split values) is lossy, with roughly}}
\DoxyCodeLine{5035 \textcolor{comment}{0.01\% relative error introduced during rounding. Thus, we recommend you to}}
\DoxyCodeLine{5036 \textcolor{comment}{re-\/evaluate model accuracy after compression.}}
\DoxyCodeLine{5037 \textcolor{comment}{}}
\DoxyCodeLine{5038 \textcolor{comment}{Another downside  of  compression  is  \string~1.5x reduction  in  the  inference}}
\DoxyCodeLine{5039 \textcolor{comment}{speed due to necessity of dynamic decompression of the compressed model.}}
\DoxyCodeLine{5040 \textcolor{comment}{}}
\DoxyCodeLine{5041 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5042 \textcolor{comment}{    DF      -\/   decision forest built by forest builder}}
\DoxyCodeLine{5043 \textcolor{comment}{}}
\DoxyCodeLine{5044 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{5045 \textcolor{comment}{    DF      -\/   replaced by compressed forest}}
\DoxyCodeLine{5046 \textcolor{comment}{}}
\DoxyCodeLine{5047 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{5048 \textcolor{comment}{    compression factor (in-\/RAM size of the compressed model vs than of the}}
\DoxyCodeLine{5049 \textcolor{comment}{    uncompressed one), positive number larger than 1.0}}
\DoxyCodeLine{5050 \textcolor{comment}{}}
\DoxyCodeLine{5051 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5052 \textcolor{comment}{     Copyright 22.07.2019 by Bochkanov Sergey}}
\DoxyCodeLine{5053 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5054 \textcolor{keywordtype}{double} dfbinarycompression(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&df, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5055 }
\DoxyCodeLine{5056 }
\DoxyCodeLine{5057 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5058 \textcolor{comment}{Inference using decision forest}}
\DoxyCodeLine{5059 \textcolor{comment}{}}
\DoxyCodeLine{5060 \textcolor{comment}{IMPORTANT: this  function  is  thread-\/unsafe  and  may   modify   internal}}
\DoxyCodeLine{5061 \textcolor{comment}{           structures of the model! You can not use same model  object for}}
\DoxyCodeLine{5062 \textcolor{comment}{           parallel evaluation from several threads.}}
\DoxyCodeLine{5063 \textcolor{comment}{}}
\DoxyCodeLine{5064 \textcolor{comment}{           Use dftsprocess()  with  independent  thread-\/local  buffers  if}}
\DoxyCodeLine{5065 \textcolor{comment}{           you need thread-\/safe evaluation.}}
\DoxyCodeLine{5066 \textcolor{comment}{}}
\DoxyCodeLine{5067 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5068 \textcolor{comment}{    DF      -\/   decision forest model}}
\DoxyCodeLine{5069 \textcolor{comment}{    X       -\/   input vector,  array[NVars]}}
\DoxyCodeLine{5070 \textcolor{comment}{    Y       -\/   possibly preallocated buffer, reallocated if too small}}
\DoxyCodeLine{5071 \textcolor{comment}{}}
\DoxyCodeLine{5072 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{5073 \textcolor{comment}{    Y       -\/   result. Regression estimate when solving regression  task,}}
\DoxyCodeLine{5074 \textcolor{comment}{                vector of posterior probabilities for classification task.}}
\DoxyCodeLine{5075 \textcolor{comment}{}}
\DoxyCodeLine{5076 \textcolor{comment}{See also DFProcessI.}}
\DoxyCodeLine{5077 \textcolor{comment}{}}
\DoxyCodeLine{5078 \textcolor{comment}{}}
\DoxyCodeLine{5079 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5080 \textcolor{comment}{     Copyright 16.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{5081 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5082 \textcolor{keywordtype}{void} dfprocess(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&df, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&y, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5083 }
\DoxyCodeLine{5084 }
\DoxyCodeLine{5085 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5086 \textcolor{comment}{'interactive' variant of DFProcess for languages like Python which support}}
\DoxyCodeLine{5087 \textcolor{comment}{constructs like "{}Y = DFProcessI(DF,X)"{} and interactive mode of interpreter}}
\DoxyCodeLine{5088 \textcolor{comment}{}}
\DoxyCodeLine{5089 \textcolor{comment}{This function allocates new array on each call,  so  it  is  significantly}}
\DoxyCodeLine{5090 \textcolor{comment}{slower than its 'non-\/interactive' counterpart, but it is  more  convenient}}
\DoxyCodeLine{5091 \textcolor{comment}{when you call it from command line.}}
\DoxyCodeLine{5092 \textcolor{comment}{}}
\DoxyCodeLine{5093 \textcolor{comment}{IMPORTANT: this  function  is  thread-\/unsafe  and  may   modify   internal}}
\DoxyCodeLine{5094 \textcolor{comment}{           structures of the model! You can not use same model  object for}}
\DoxyCodeLine{5095 \textcolor{comment}{           parallel evaluation from several threads.}}
\DoxyCodeLine{5096 \textcolor{comment}{}}
\DoxyCodeLine{5097 \textcolor{comment}{           Use dftsprocess()  with  independent  thread-\/local  buffers  if}}
\DoxyCodeLine{5098 \textcolor{comment}{           you need thread-\/safe evaluation.}}
\DoxyCodeLine{5099 \textcolor{comment}{}}
\DoxyCodeLine{5100 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5101 \textcolor{comment}{     Copyright 28.02.2010 by Bochkanov Sergey}}
\DoxyCodeLine{5102 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5103 \textcolor{keywordtype}{void} dfprocessi(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&df, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&y, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5104 }
\DoxyCodeLine{5105 }
\DoxyCodeLine{5106 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5107 \textcolor{comment}{This function returns first component of the  inferred  vector  (i.e.  one}}
\DoxyCodeLine{5108 \textcolor{comment}{with index \#0).}}
\DoxyCodeLine{5109 \textcolor{comment}{}}
\DoxyCodeLine{5110 \textcolor{comment}{It is a convenience wrapper for dfprocess() intended for either:}}
\DoxyCodeLine{5111 \textcolor{comment}{* 1-\/dimensional regression problems}}
\DoxyCodeLine{5112 \textcolor{comment}{* 2-\/class classification problems}}
\DoxyCodeLine{5113 \textcolor{comment}{}}
\DoxyCodeLine{5114 \textcolor{comment}{In the former case this function returns inference result as scalar, which}}
\DoxyCodeLine{5115 \textcolor{comment}{is definitely more convenient that wrapping it as vector.  In  the  latter}}
\DoxyCodeLine{5116 \textcolor{comment}{case it returns probability of object belonging to class \#0.}}
\DoxyCodeLine{5117 \textcolor{comment}{}}
\DoxyCodeLine{5118 \textcolor{comment}{If you call it for anything different from two cases above, it  will  work}}
\DoxyCodeLine{5119 \textcolor{comment}{as defined, i.e. return y[0], although it is of less use in such cases.}}
\DoxyCodeLine{5120 \textcolor{comment}{}}
\DoxyCodeLine{5121 \textcolor{comment}{IMPORTANT: this function is thread-\/unsafe and modifies internal structures}}
\DoxyCodeLine{5122 \textcolor{comment}{           of the model! You can not use same model  object  for  parallel}}
\DoxyCodeLine{5123 \textcolor{comment}{           evaluation from several threads.}}
\DoxyCodeLine{5124 \textcolor{comment}{}}
\DoxyCodeLine{5125 \textcolor{comment}{           Use dftsprocess() with  independent  thread-\/local  buffers,  if}}
\DoxyCodeLine{5126 \textcolor{comment}{           you need thread-\/safe evaluation.}}
\DoxyCodeLine{5127 \textcolor{comment}{}}
\DoxyCodeLine{5128 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5129 \textcolor{comment}{    Model   -\/   DF model}}
\DoxyCodeLine{5130 \textcolor{comment}{    X       -\/   input vector,  array[0..NVars-\/1].}}
\DoxyCodeLine{5131 \textcolor{comment}{}}
\DoxyCodeLine{5132 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{5133 \textcolor{comment}{    Y[0]}}
\DoxyCodeLine{5134 \textcolor{comment}{}}
\DoxyCodeLine{5135 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5136 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{5137 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5138 \textcolor{keywordtype}{double} dfprocess0(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&model, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5139 }
\DoxyCodeLine{5140 }
\DoxyCodeLine{5141 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5142 \textcolor{comment}{This function returns most probable class number for an  input  X.  It  is}}
\DoxyCodeLine{5143 \textcolor{comment}{same as calling  dfprocess(model,x,y), then determining i=argmax(y[i]) and}}
\DoxyCodeLine{5144 \textcolor{comment}{returning i.}}
\DoxyCodeLine{5145 \textcolor{comment}{}}
\DoxyCodeLine{5146 \textcolor{comment}{A class number in [0,NOut) range in returned for classification  problems,}}
\DoxyCodeLine{5147 \textcolor{comment}{-\/1 is returned when this function is called for regression problems.}}
\DoxyCodeLine{5148 \textcolor{comment}{}}
\DoxyCodeLine{5149 \textcolor{comment}{IMPORTANT: this function is thread-\/unsafe and modifies internal structures}}
\DoxyCodeLine{5150 \textcolor{comment}{           of the model! You can not use same model  object  for  parallel}}
\DoxyCodeLine{5151 \textcolor{comment}{           evaluation from several threads.}}
\DoxyCodeLine{5152 \textcolor{comment}{}}
\DoxyCodeLine{5153 \textcolor{comment}{           Use dftsprocess()  with independent  thread-\/local  buffers,  if}}
\DoxyCodeLine{5154 \textcolor{comment}{           you need thread-\/safe evaluation.}}
\DoxyCodeLine{5155 \textcolor{comment}{}}
\DoxyCodeLine{5156 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5157 \textcolor{comment}{    Model   -\/   decision forest model}}
\DoxyCodeLine{5158 \textcolor{comment}{    X       -\/   input vector,  array[0..NVars-\/1].}}
\DoxyCodeLine{5159 \textcolor{comment}{}}
\DoxyCodeLine{5160 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{5161 \textcolor{comment}{    class number, -\/1 for regression tasks}}
\DoxyCodeLine{5162 \textcolor{comment}{}}
\DoxyCodeLine{5163 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5164 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{5165 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5166 ae\_int\_t dfclassify(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&model, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5167 }
\DoxyCodeLine{5168 }
\DoxyCodeLine{5169 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5170 \textcolor{comment}{Inference using decision forest}}
\DoxyCodeLine{5171 \textcolor{comment}{}}
\DoxyCodeLine{5172 \textcolor{comment}{Thread-\/safe procesing using external buffer for temporaries.}}
\DoxyCodeLine{5173 \textcolor{comment}{}}
\DoxyCodeLine{5174 \textcolor{comment}{This function is thread-\/safe (i.e .  you  can  use  same  DF   model  from}}
\DoxyCodeLine{5175 \textcolor{comment}{multiple threads) as long as you use different buffer objects for different}}
\DoxyCodeLine{5176 \textcolor{comment}{threads.}}
\DoxyCodeLine{5177 \textcolor{comment}{}}
\DoxyCodeLine{5178 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5179 \textcolor{comment}{    DF      -\/   decision forest model}}
\DoxyCodeLine{5180 \textcolor{comment}{    Buf     -\/   buffer object, must be  allocated  specifically  for  this}}
\DoxyCodeLine{5181 \textcolor{comment}{                model with dfcreatebuffer().}}
\DoxyCodeLine{5182 \textcolor{comment}{    X       -\/   input vector,  array[NVars]}}
\DoxyCodeLine{5183 \textcolor{comment}{    Y       -\/   possibly preallocated buffer, reallocated if too small}}
\DoxyCodeLine{5184 \textcolor{comment}{}}
\DoxyCodeLine{5185 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{5186 \textcolor{comment}{    Y       -\/   result. Regression estimate when solving regression  task,}}
\DoxyCodeLine{5187 \textcolor{comment}{                vector of posterior probabilities for classification task.}}
\DoxyCodeLine{5188 \textcolor{comment}{}}
\DoxyCodeLine{5189 \textcolor{comment}{See also DFProcessI.}}
\DoxyCodeLine{5190 \textcolor{comment}{}}
\DoxyCodeLine{5191 \textcolor{comment}{}}
\DoxyCodeLine{5192 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5193 \textcolor{comment}{     Copyright 16.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{5194 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5195 \textcolor{keywordtype}{void} dftsprocess(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&df, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforestbuffer}{decisionforestbuffer}} \&buf, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&y, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5196 }
\DoxyCodeLine{5197 }
\DoxyCodeLine{5198 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5199 \textcolor{comment}{Relative classification error on the test set}}
\DoxyCodeLine{5200 \textcolor{comment}{}}
\DoxyCodeLine{5201 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5202 \textcolor{comment}{    DF      -\/   decision forest model}}
\DoxyCodeLine{5203 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{5204 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{5205 \textcolor{comment}{}}
\DoxyCodeLine{5206 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{5207 \textcolor{comment}{    percent of incorrectly classified cases.}}
\DoxyCodeLine{5208 \textcolor{comment}{    Zero if model solves regression task.}}
\DoxyCodeLine{5209 \textcolor{comment}{}}
\DoxyCodeLine{5210 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5211 \textcolor{comment}{     Copyright 16.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{5212 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5213 \textcolor{keywordtype}{double} dfrelclserror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&df, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5214 }
\DoxyCodeLine{5215 }
\DoxyCodeLine{5216 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5217 \textcolor{comment}{Average cross-\/entropy (in bits per element) on the test set}}
\DoxyCodeLine{5218 \textcolor{comment}{}}
\DoxyCodeLine{5219 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5220 \textcolor{comment}{    DF      -\/   decision forest model}}
\DoxyCodeLine{5221 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{5222 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{5223 \textcolor{comment}{}}
\DoxyCodeLine{5224 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{5225 \textcolor{comment}{    CrossEntropy/(NPoints*LN(2)).}}
\DoxyCodeLine{5226 \textcolor{comment}{    Zero if model solves regression task.}}
\DoxyCodeLine{5227 \textcolor{comment}{}}
\DoxyCodeLine{5228 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5229 \textcolor{comment}{     Copyright 16.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{5230 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5231 \textcolor{keywordtype}{double} dfavgce(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&df, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5232 }
\DoxyCodeLine{5233 }
\DoxyCodeLine{5234 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5235 \textcolor{comment}{RMS error on the test set}}
\DoxyCodeLine{5236 \textcolor{comment}{}}
\DoxyCodeLine{5237 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5238 \textcolor{comment}{    DF      -\/   decision forest model}}
\DoxyCodeLine{5239 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{5240 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{5241 \textcolor{comment}{}}
\DoxyCodeLine{5242 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{5243 \textcolor{comment}{    root mean square error.}}
\DoxyCodeLine{5244 \textcolor{comment}{    Its meaning for regression task is obvious. As for}}
\DoxyCodeLine{5245 \textcolor{comment}{    classification task, RMS error means error when estimating posterior}}
\DoxyCodeLine{5246 \textcolor{comment}{    probabilities.}}
\DoxyCodeLine{5247 \textcolor{comment}{}}
\DoxyCodeLine{5248 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5249 \textcolor{comment}{     Copyright 16.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{5250 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5251 \textcolor{keywordtype}{double} dfrmserror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&df, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5252 }
\DoxyCodeLine{5253 }
\DoxyCodeLine{5254 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5255 \textcolor{comment}{Average error on the test set}}
\DoxyCodeLine{5256 \textcolor{comment}{}}
\DoxyCodeLine{5257 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5258 \textcolor{comment}{    DF      -\/   decision forest model}}
\DoxyCodeLine{5259 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{5260 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{5261 \textcolor{comment}{}}
\DoxyCodeLine{5262 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{5263 \textcolor{comment}{    Its meaning for regression task is obvious. As for}}
\DoxyCodeLine{5264 \textcolor{comment}{    classification task, it means average error when estimating posterior}}
\DoxyCodeLine{5265 \textcolor{comment}{    probabilities.}}
\DoxyCodeLine{5266 \textcolor{comment}{}}
\DoxyCodeLine{5267 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5268 \textcolor{comment}{     Copyright 16.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{5269 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5270 \textcolor{keywordtype}{double} dfavgerror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&df, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5271 }
\DoxyCodeLine{5272 }
\DoxyCodeLine{5273 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5274 \textcolor{comment}{Average relative error on the test set}}
\DoxyCodeLine{5275 \textcolor{comment}{}}
\DoxyCodeLine{5276 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5277 \textcolor{comment}{    DF      -\/   decision forest model}}
\DoxyCodeLine{5278 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{5279 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{5280 \textcolor{comment}{}}
\DoxyCodeLine{5281 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{5282 \textcolor{comment}{    Its meaning for regression task is obvious. As for}}
\DoxyCodeLine{5283 \textcolor{comment}{    classification task, it means average relative error when estimating}}
\DoxyCodeLine{5284 \textcolor{comment}{    posterior probability of belonging to the correct class.}}
\DoxyCodeLine{5285 \textcolor{comment}{}}
\DoxyCodeLine{5286 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5287 \textcolor{comment}{     Copyright 16.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{5288 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5289 \textcolor{keywordtype}{double} dfavgrelerror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&df, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5290 }
\DoxyCodeLine{5291 }
\DoxyCodeLine{5292 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5293 \textcolor{comment}{This subroutine builds random decision forest.}}
\DoxyCodeLine{5294 \textcolor{comment}{}}
\DoxyCodeLine{5295 \textcolor{comment}{-\/-\/-\/-\/-\/-\/-\/-\/-\/ DEPRECATED VERSION! USE DECISION FOREST BUILDER OBJECT -\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{5296 \textcolor{comment}{}}
\DoxyCodeLine{5297 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5298 \textcolor{comment}{     Copyright 19.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{5299 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5300 \textcolor{keywordtype}{void} dfbuildrandomdecisionforest(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nvars, \textcolor{keyword}{const} ae\_int\_t nclasses, \textcolor{keyword}{const} ae\_int\_t ntrees, \textcolor{keyword}{const} \textcolor{keywordtype}{double} r, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&df, \mbox{\hyperlink{classalglib_1_1dfreport}{dfreport}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5301 }
\DoxyCodeLine{5302 }
\DoxyCodeLine{5303 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5304 \textcolor{comment}{This subroutine builds random decision forest.}}
\DoxyCodeLine{5305 \textcolor{comment}{}}
\DoxyCodeLine{5306 \textcolor{comment}{-\/-\/-\/-\/-\/-\/-\/-\/-\/ DEPRECATED VERSION! USE DECISION FOREST BUILDER OBJECT -\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{5307 \textcolor{comment}{}}
\DoxyCodeLine{5308 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5309 \textcolor{comment}{     Copyright 19.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{5310 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5311 \textcolor{keywordtype}{void} dfbuildrandomdecisionforestx1(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nvars, \textcolor{keyword}{const} ae\_int\_t nclasses, \textcolor{keyword}{const} ae\_int\_t ntrees, \textcolor{keyword}{const} ae\_int\_t nrndvars, \textcolor{keyword}{const} \textcolor{keywordtype}{double} r, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1decisionforest}{decisionforest}} \&df, \mbox{\hyperlink{classalglib_1_1dfreport}{dfreport}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5312 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{5313 }
\DoxyCodeLine{5314 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_LINREG) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{5315 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5316 \textcolor{comment}{Linear regression}}
\DoxyCodeLine{5317 \textcolor{comment}{}}
\DoxyCodeLine{5318 \textcolor{comment}{Subroutine builds model:}}
\DoxyCodeLine{5319 \textcolor{comment}{}}
\DoxyCodeLine{5320 \textcolor{comment}{    Y = A(0)*X[0] + ... + A(N-\/1)*X[N-\/1] + A(N)}}
\DoxyCodeLine{5321 \textcolor{comment}{}}
\DoxyCodeLine{5322 \textcolor{comment}{and model found in ALGLIB format, covariation matrix, training set  errors}}
\DoxyCodeLine{5323 \textcolor{comment}{(rms,  average,  average  relative)   and  leave-\/one-\/out  cross-\/validation}}
\DoxyCodeLine{5324 \textcolor{comment}{estimate of the generalization error. CV  estimate calculated  using  fast}}
\DoxyCodeLine{5325 \textcolor{comment}{algorithm with O(NPoints*NVars) complexity.}}
\DoxyCodeLine{5326 \textcolor{comment}{}}
\DoxyCodeLine{5327 \textcolor{comment}{When  covariation  matrix  is  calculated  standard deviations of function}}
\DoxyCodeLine{5328 \textcolor{comment}{values are assumed to be equal to RMS error on the training set.}}
\DoxyCodeLine{5329 \textcolor{comment}{}}
\DoxyCodeLine{5330 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5331 \textcolor{comment}{    XY          -\/   training set, array [0..NPoints-\/1,0..NVars]:}}
\DoxyCodeLine{5332 \textcolor{comment}{                    * NVars columns -\/ independent variables}}
\DoxyCodeLine{5333 \textcolor{comment}{                    * last column -\/ dependent variable}}
\DoxyCodeLine{5334 \textcolor{comment}{    NPoints     -\/   training set size, NPoints>NVars+1}}
\DoxyCodeLine{5335 \textcolor{comment}{    NVars       -\/   number of independent variables}}
\DoxyCodeLine{5336 \textcolor{comment}{}}
\DoxyCodeLine{5337 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{5338 \textcolor{comment}{    Info        -\/   return code:}}
\DoxyCodeLine{5339 \textcolor{comment}{                    * -\/255, in case of unknown internal error}}
\DoxyCodeLine{5340 \textcolor{comment}{                    * -\/4, if internal SVD subroutine haven't converged}}
\DoxyCodeLine{5341 \textcolor{comment}{                    * -\/1, if incorrect parameters was passed (NPoints<NVars+2, NVars<1).}}
\DoxyCodeLine{5342 \textcolor{comment}{                    *  1, if subroutine successfully finished}}
\DoxyCodeLine{5343 \textcolor{comment}{    LM          -\/   linear model in the ALGLIB format. Use subroutines of}}
\DoxyCodeLine{5344 \textcolor{comment}{                    this unit to work with the model.}}
\DoxyCodeLine{5345 \textcolor{comment}{    AR          -\/   additional results}}
\DoxyCodeLine{5346 \textcolor{comment}{}}
\DoxyCodeLine{5347 \textcolor{comment}{}}
\DoxyCodeLine{5348 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5349 \textcolor{comment}{     Copyright 02.08.2008 by Bochkanov Sergey}}
\DoxyCodeLine{5350 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5351 \textcolor{keywordtype}{void} lrbuild(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nvars, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1linearmodel}{linearmodel}} \&lm, \mbox{\hyperlink{classalglib_1_1lrreport}{lrreport}} \&ar, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5352 }
\DoxyCodeLine{5353 }
\DoxyCodeLine{5354 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5355 \textcolor{comment}{Linear regression}}
\DoxyCodeLine{5356 \textcolor{comment}{}}
\DoxyCodeLine{5357 \textcolor{comment}{Variant of LRBuild which uses vector of standatd deviations (errors in}}
\DoxyCodeLine{5358 \textcolor{comment}{function values).}}
\DoxyCodeLine{5359 \textcolor{comment}{}}
\DoxyCodeLine{5360 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5361 \textcolor{comment}{    XY          -\/   training set, array [0..NPoints-\/1,0..NVars]:}}
\DoxyCodeLine{5362 \textcolor{comment}{                    * NVars columns -\/ independent variables}}
\DoxyCodeLine{5363 \textcolor{comment}{                    * last column -\/ dependent variable}}
\DoxyCodeLine{5364 \textcolor{comment}{    S           -\/   standard deviations (errors in function values)}}
\DoxyCodeLine{5365 \textcolor{comment}{                    array[0..NPoints-\/1], S[i]>0.}}
\DoxyCodeLine{5366 \textcolor{comment}{    NPoints     -\/   training set size, NPoints>NVars+1}}
\DoxyCodeLine{5367 \textcolor{comment}{    NVars       -\/   number of independent variables}}
\DoxyCodeLine{5368 \textcolor{comment}{}}
\DoxyCodeLine{5369 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{5370 \textcolor{comment}{    Info        -\/   return code:}}
\DoxyCodeLine{5371 \textcolor{comment}{                    * -\/255, in case of unknown internal error}}
\DoxyCodeLine{5372 \textcolor{comment}{                    * -\/4, if internal SVD subroutine haven't converged}}
\DoxyCodeLine{5373 \textcolor{comment}{                    * -\/1, if incorrect parameters was passed (NPoints<NVars+2, NVars<1).}}
\DoxyCodeLine{5374 \textcolor{comment}{                    * -\/2, if S[I]<=0}}
\DoxyCodeLine{5375 \textcolor{comment}{                    *  1, if subroutine successfully finished}}
\DoxyCodeLine{5376 \textcolor{comment}{    LM          -\/   linear model in the ALGLIB format. Use subroutines of}}
\DoxyCodeLine{5377 \textcolor{comment}{                    this unit to work with the model.}}
\DoxyCodeLine{5378 \textcolor{comment}{    AR          -\/   additional results}}
\DoxyCodeLine{5379 \textcolor{comment}{}}
\DoxyCodeLine{5380 \textcolor{comment}{}}
\DoxyCodeLine{5381 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5382 \textcolor{comment}{     Copyright 02.08.2008 by Bochkanov Sergey}}
\DoxyCodeLine{5383 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5384 \textcolor{keywordtype}{void} lrbuilds(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&s, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nvars, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1linearmodel}{linearmodel}} \&lm, \mbox{\hyperlink{classalglib_1_1lrreport}{lrreport}} \&ar, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5385 }
\DoxyCodeLine{5386 }
\DoxyCodeLine{5387 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5388 \textcolor{comment}{Like LRBuildS, but builds model}}
\DoxyCodeLine{5389 \textcolor{comment}{}}
\DoxyCodeLine{5390 \textcolor{comment}{    Y = A(0)*X[0] + ... + A(N-\/1)*X[N-\/1]}}
\DoxyCodeLine{5391 \textcolor{comment}{}}
\DoxyCodeLine{5392 \textcolor{comment}{i.e. with zero constant term.}}
\DoxyCodeLine{5393 \textcolor{comment}{}}
\DoxyCodeLine{5394 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5395 \textcolor{comment}{     Copyright 30.10.2008 by Bochkanov Sergey}}
\DoxyCodeLine{5396 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5397 \textcolor{keywordtype}{void} lrbuildzs(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&s, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nvars, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1linearmodel}{linearmodel}} \&lm, \mbox{\hyperlink{classalglib_1_1lrreport}{lrreport}} \&ar, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5398 }
\DoxyCodeLine{5399 }
\DoxyCodeLine{5400 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5401 \textcolor{comment}{Like LRBuild but builds model}}
\DoxyCodeLine{5402 \textcolor{comment}{}}
\DoxyCodeLine{5403 \textcolor{comment}{    Y = A(0)*X[0] + ... + A(N-\/1)*X[N-\/1]}}
\DoxyCodeLine{5404 \textcolor{comment}{}}
\DoxyCodeLine{5405 \textcolor{comment}{i.e. with zero constant term.}}
\DoxyCodeLine{5406 \textcolor{comment}{}}
\DoxyCodeLine{5407 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5408 \textcolor{comment}{     Copyright 30.10.2008 by Bochkanov Sergey}}
\DoxyCodeLine{5409 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5410 \textcolor{keywordtype}{void} lrbuildz(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nvars, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1linearmodel}{linearmodel}} \&lm, \mbox{\hyperlink{classalglib_1_1lrreport}{lrreport}} \&ar, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5411 }
\DoxyCodeLine{5412 }
\DoxyCodeLine{5413 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5414 \textcolor{comment}{Unpacks coefficients of linear model.}}
\DoxyCodeLine{5415 \textcolor{comment}{}}
\DoxyCodeLine{5416 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5417 \textcolor{comment}{    LM          -\/   linear model in ALGLIB format}}
\DoxyCodeLine{5418 \textcolor{comment}{}}
\DoxyCodeLine{5419 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{5420 \textcolor{comment}{    V           -\/   coefficients, array[0..NVars]}}
\DoxyCodeLine{5421 \textcolor{comment}{                    constant term (intercept) is stored in the V[NVars].}}
\DoxyCodeLine{5422 \textcolor{comment}{    NVars       -\/   number of independent variables (one less than number}}
\DoxyCodeLine{5423 \textcolor{comment}{                    of coefficients)}}
\DoxyCodeLine{5424 \textcolor{comment}{}}
\DoxyCodeLine{5425 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5426 \textcolor{comment}{     Copyright 30.08.2008 by Bochkanov Sergey}}
\DoxyCodeLine{5427 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5428 \textcolor{keywordtype}{void} lrunpack(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1linearmodel}{linearmodel}} \&lm, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&v, ae\_int\_t \&nvars, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5429 }
\DoxyCodeLine{5430 }
\DoxyCodeLine{5431 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5432 \textcolor{comment}{"{}Packs"{} coefficients and creates linear model in ALGLIB format (LRUnpack}}
\DoxyCodeLine{5433 \textcolor{comment}{reversed).}}
\DoxyCodeLine{5434 \textcolor{comment}{}}
\DoxyCodeLine{5435 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5436 \textcolor{comment}{    V           -\/   coefficients, array[0..NVars]}}
\DoxyCodeLine{5437 \textcolor{comment}{    NVars       -\/   number of independent variables}}
\DoxyCodeLine{5438 \textcolor{comment}{}}
\DoxyCodeLine{5439 \textcolor{comment}{OUTPUT PAREMETERS:}}
\DoxyCodeLine{5440 \textcolor{comment}{    LM          -\/   linear model.}}
\DoxyCodeLine{5441 \textcolor{comment}{}}
\DoxyCodeLine{5442 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5443 \textcolor{comment}{     Copyright 30.08.2008 by Bochkanov Sergey}}
\DoxyCodeLine{5444 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5445 \textcolor{keywordtype}{void} lrpack(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&v, \textcolor{keyword}{const} ae\_int\_t nvars, \mbox{\hyperlink{classalglib_1_1linearmodel}{linearmodel}} \&lm, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5446 }
\DoxyCodeLine{5447 }
\DoxyCodeLine{5448 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5449 \textcolor{comment}{Procesing}}
\DoxyCodeLine{5450 \textcolor{comment}{}}
\DoxyCodeLine{5451 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5452 \textcolor{comment}{    LM      -\/   linear model}}
\DoxyCodeLine{5453 \textcolor{comment}{    X       -\/   input vector,  array[0..NVars-\/1].}}
\DoxyCodeLine{5454 \textcolor{comment}{}}
\DoxyCodeLine{5455 \textcolor{comment}{Result:}}
\DoxyCodeLine{5456 \textcolor{comment}{    value of linear model regression estimate}}
\DoxyCodeLine{5457 \textcolor{comment}{}}
\DoxyCodeLine{5458 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5459 \textcolor{comment}{     Copyright 03.09.2008 by Bochkanov Sergey}}
\DoxyCodeLine{5460 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5461 \textcolor{keywordtype}{double} lrprocess(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1linearmodel}{linearmodel}} \&lm, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5462 }
\DoxyCodeLine{5463 }
\DoxyCodeLine{5464 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5465 \textcolor{comment}{RMS error on the test set}}
\DoxyCodeLine{5466 \textcolor{comment}{}}
\DoxyCodeLine{5467 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5468 \textcolor{comment}{    LM      -\/   linear model}}
\DoxyCodeLine{5469 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{5470 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{5471 \textcolor{comment}{}}
\DoxyCodeLine{5472 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{5473 \textcolor{comment}{    root mean square error.}}
\DoxyCodeLine{5474 \textcolor{comment}{}}
\DoxyCodeLine{5475 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5476 \textcolor{comment}{     Copyright 30.08.2008 by Bochkanov Sergey}}
\DoxyCodeLine{5477 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5478 \textcolor{keywordtype}{double} lrrmserror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1linearmodel}{linearmodel}} \&lm, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5479 }
\DoxyCodeLine{5480 }
\DoxyCodeLine{5481 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5482 \textcolor{comment}{Average error on the test set}}
\DoxyCodeLine{5483 \textcolor{comment}{}}
\DoxyCodeLine{5484 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5485 \textcolor{comment}{    LM      -\/   linear model}}
\DoxyCodeLine{5486 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{5487 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{5488 \textcolor{comment}{}}
\DoxyCodeLine{5489 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{5490 \textcolor{comment}{    average error.}}
\DoxyCodeLine{5491 \textcolor{comment}{}}
\DoxyCodeLine{5492 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5493 \textcolor{comment}{     Copyright 30.08.2008 by Bochkanov Sergey}}
\DoxyCodeLine{5494 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5495 \textcolor{keywordtype}{double} lravgerror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1linearmodel}{linearmodel}} \&lm, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5496 }
\DoxyCodeLine{5497 }
\DoxyCodeLine{5498 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5499 \textcolor{comment}{RMS error on the test set}}
\DoxyCodeLine{5500 \textcolor{comment}{}}
\DoxyCodeLine{5501 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5502 \textcolor{comment}{    LM      -\/   linear model}}
\DoxyCodeLine{5503 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{5504 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{5505 \textcolor{comment}{}}
\DoxyCodeLine{5506 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{5507 \textcolor{comment}{    average relative error.}}
\DoxyCodeLine{5508 \textcolor{comment}{}}
\DoxyCodeLine{5509 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5510 \textcolor{comment}{     Copyright 30.08.2008 by Bochkanov Sergey}}
\DoxyCodeLine{5511 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5512 \textcolor{keywordtype}{double} lravgrelerror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1linearmodel}{linearmodel}} \&lm, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5513 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{5514 }
\DoxyCodeLine{5515 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_FILTERS) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{5516 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5517 \textcolor{comment}{Filters: simple moving averages (unsymmetric).}}
\DoxyCodeLine{5518 \textcolor{comment}{}}
\DoxyCodeLine{5519 \textcolor{comment}{This filter replaces array by results of SMA(K) filter. SMA(K) is defined}}
\DoxyCodeLine{5520 \textcolor{comment}{as filter which averages at most K previous points (previous -\/ not points}}
\DoxyCodeLine{5521 \textcolor{comment}{AROUND central point) -\/ or less, in case of the first K-\/1 points.}}
\DoxyCodeLine{5522 \textcolor{comment}{}}
\DoxyCodeLine{5523 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5524 \textcolor{comment}{    X           -\/   array[N], array to process. It can be larger than N,}}
\DoxyCodeLine{5525 \textcolor{comment}{                    in this case only first N points are processed.}}
\DoxyCodeLine{5526 \textcolor{comment}{    N           -\/   points count, N>=0}}
\DoxyCodeLine{5527 \textcolor{comment}{    K           -\/   K>=1 (K can be larger than N ,  such  cases  will  be}}
\DoxyCodeLine{5528 \textcolor{comment}{                    correctly handled). Window width. K=1 corresponds  to}}
\DoxyCodeLine{5529 \textcolor{comment}{                    identity transformation (nothing changes).}}
\DoxyCodeLine{5530 \textcolor{comment}{}}
\DoxyCodeLine{5531 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{5532 \textcolor{comment}{    X           -\/   array, whose first N elements were processed with SMA(K)}}
\DoxyCodeLine{5533 \textcolor{comment}{}}
\DoxyCodeLine{5534 \textcolor{comment}{NOTE 1: this function uses efficient in-\/place  algorithm  which  does not}}
\DoxyCodeLine{5535 \textcolor{comment}{        allocate temporary arrays.}}
\DoxyCodeLine{5536 \textcolor{comment}{}}
\DoxyCodeLine{5537 \textcolor{comment}{NOTE 2: this algorithm makes only one pass through array and uses running}}
\DoxyCodeLine{5538 \textcolor{comment}{        sum  to speed-\/up calculation of the averages. Additional measures}}
\DoxyCodeLine{5539 \textcolor{comment}{        are taken to ensure that running sum on a long sequence  of  zero}}
\DoxyCodeLine{5540 \textcolor{comment}{        elements will be correctly reset to zero even in the presence  of}}
\DoxyCodeLine{5541 \textcolor{comment}{        round-\/off error.}}
\DoxyCodeLine{5542 \textcolor{comment}{}}
\DoxyCodeLine{5543 \textcolor{comment}{NOTE 3: this  is  unsymmetric version of the algorithm,  which  does  NOT}}
\DoxyCodeLine{5544 \textcolor{comment}{        averages points after the current one. Only X[i], X[i-\/1], ... are}}
\DoxyCodeLine{5545 \textcolor{comment}{        used when calculating new value of X[i]. We should also note that}}
\DoxyCodeLine{5546 \textcolor{comment}{        this algorithm uses BOTH previous points and  current  one,  i.e.}}
\DoxyCodeLine{5547 \textcolor{comment}{        new value of X[i] depends on BOTH previous point and X[i] itself.}}
\DoxyCodeLine{5548 \textcolor{comment}{}}
\DoxyCodeLine{5549 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5550 \textcolor{comment}{     Copyright 25.10.2011 by Bochkanov Sergey}}
\DoxyCodeLine{5551 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5552 \textcolor{keywordtype}{void} filtersma(\mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} ae\_int\_t n, \textcolor{keyword}{const} ae\_int\_t k, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5553 \textcolor{keywordtype}{void} filtersma(\mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} ae\_int\_t k, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5554 }
\DoxyCodeLine{5555 }
\DoxyCodeLine{5556 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5557 \textcolor{comment}{Filters: exponential moving averages.}}
\DoxyCodeLine{5558 \textcolor{comment}{}}
\DoxyCodeLine{5559 \textcolor{comment}{This filter replaces array by results of EMA(alpha) filter. EMA(alpha) is}}
\DoxyCodeLine{5560 \textcolor{comment}{defined as filter which replaces X[] by S[]:}}
\DoxyCodeLine{5561 \textcolor{comment}{    S[0] = X[0]}}
\DoxyCodeLine{5562 \textcolor{comment}{    S[t] = alpha*X[t] + (1-\/alpha)*S[t-\/1]}}
\DoxyCodeLine{5563 \textcolor{comment}{}}
\DoxyCodeLine{5564 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5565 \textcolor{comment}{    X           -\/   array[N], array to process. It can be larger than N,}}
\DoxyCodeLine{5566 \textcolor{comment}{                    in this case only first N points are processed.}}
\DoxyCodeLine{5567 \textcolor{comment}{    N           -\/   points count, N>=0}}
\DoxyCodeLine{5568 \textcolor{comment}{    alpha       -\/   0<alpha<=1, smoothing parameter.}}
\DoxyCodeLine{5569 \textcolor{comment}{}}
\DoxyCodeLine{5570 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{5571 \textcolor{comment}{    X           -\/   array, whose first N elements were processed}}
\DoxyCodeLine{5572 \textcolor{comment}{                    with EMA(alpha)}}
\DoxyCodeLine{5573 \textcolor{comment}{}}
\DoxyCodeLine{5574 \textcolor{comment}{NOTE 1: this function uses efficient in-\/place  algorithm  which  does not}}
\DoxyCodeLine{5575 \textcolor{comment}{        allocate temporary arrays.}}
\DoxyCodeLine{5576 \textcolor{comment}{}}
\DoxyCodeLine{5577 \textcolor{comment}{NOTE 2: this algorithm uses BOTH previous points and  current  one,  i.e.}}
\DoxyCodeLine{5578 \textcolor{comment}{        new value of X[i] depends on BOTH previous point and X[i] itself.}}
\DoxyCodeLine{5579 \textcolor{comment}{}}
\DoxyCodeLine{5580 \textcolor{comment}{NOTE 3: technical analytis users quite often work  with  EMA  coefficient}}
\DoxyCodeLine{5581 \textcolor{comment}{        expressed in DAYS instead of fractions. If you want to  calculate}}
\DoxyCodeLine{5582 \textcolor{comment}{        EMA(N), where N is a number of days, you can use alpha=2/(N+1).}}
\DoxyCodeLine{5583 \textcolor{comment}{}}
\DoxyCodeLine{5584 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5585 \textcolor{comment}{     Copyright 25.10.2011 by Bochkanov Sergey}}
\DoxyCodeLine{5586 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5587 \textcolor{keywordtype}{void} filterema(\mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} ae\_int\_t n, \textcolor{keyword}{const} \textcolor{keywordtype}{double} alpha, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5588 \textcolor{keywordtype}{void} filterema(\mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} \textcolor{keywordtype}{double} alpha, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5589 }
\DoxyCodeLine{5590 }
\DoxyCodeLine{5591 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5592 \textcolor{comment}{Filters: linear regression moving averages.}}
\DoxyCodeLine{5593 \textcolor{comment}{}}
\DoxyCodeLine{5594 \textcolor{comment}{This filter replaces array by results of LRMA(K) filter.}}
\DoxyCodeLine{5595 \textcolor{comment}{}}
\DoxyCodeLine{5596 \textcolor{comment}{LRMA(K) is defined as filter which, for each data  point,  builds  linear}}
\DoxyCodeLine{5597 \textcolor{comment}{regression  model  using  K  prevous  points (point itself is included in}}
\DoxyCodeLine{5598 \textcolor{comment}{these K points) and calculates value of this linear model at the point in}}
\DoxyCodeLine{5599 \textcolor{comment}{question.}}
\DoxyCodeLine{5600 \textcolor{comment}{}}
\DoxyCodeLine{5601 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5602 \textcolor{comment}{    X           -\/   array[N], array to process. It can be larger than N,}}
\DoxyCodeLine{5603 \textcolor{comment}{                    in this case only first N points are processed.}}
\DoxyCodeLine{5604 \textcolor{comment}{    N           -\/   points count, N>=0}}
\DoxyCodeLine{5605 \textcolor{comment}{    K           -\/   K>=1 (K can be larger than N ,  such  cases  will  be}}
\DoxyCodeLine{5606 \textcolor{comment}{                    correctly handled). Window width. K=1 corresponds  to}}
\DoxyCodeLine{5607 \textcolor{comment}{                    identity transformation (nothing changes).}}
\DoxyCodeLine{5608 \textcolor{comment}{}}
\DoxyCodeLine{5609 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{5610 \textcolor{comment}{    X           -\/   array, whose first N elements were processed with SMA(K)}}
\DoxyCodeLine{5611 \textcolor{comment}{}}
\DoxyCodeLine{5612 \textcolor{comment}{NOTE 1: this function uses efficient in-\/place  algorithm  which  does not}}
\DoxyCodeLine{5613 \textcolor{comment}{        allocate temporary arrays.}}
\DoxyCodeLine{5614 \textcolor{comment}{}}
\DoxyCodeLine{5615 \textcolor{comment}{NOTE 2: this algorithm makes only one pass through array and uses running}}
\DoxyCodeLine{5616 \textcolor{comment}{        sum  to speed-\/up calculation of the averages. Additional measures}}
\DoxyCodeLine{5617 \textcolor{comment}{        are taken to ensure that running sum on a long sequence  of  zero}}
\DoxyCodeLine{5618 \textcolor{comment}{        elements will be correctly reset to zero even in the presence  of}}
\DoxyCodeLine{5619 \textcolor{comment}{        round-\/off error.}}
\DoxyCodeLine{5620 \textcolor{comment}{}}
\DoxyCodeLine{5621 \textcolor{comment}{NOTE 3: this  is  unsymmetric version of the algorithm,  which  does  NOT}}
\DoxyCodeLine{5622 \textcolor{comment}{        averages points after the current one. Only X[i], X[i-\/1], ... are}}
\DoxyCodeLine{5623 \textcolor{comment}{        used when calculating new value of X[i]. We should also note that}}
\DoxyCodeLine{5624 \textcolor{comment}{        this algorithm uses BOTH previous points and  current  one,  i.e.}}
\DoxyCodeLine{5625 \textcolor{comment}{        new value of X[i] depends on BOTH previous point and X[i] itself.}}
\DoxyCodeLine{5626 \textcolor{comment}{}}
\DoxyCodeLine{5627 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5628 \textcolor{comment}{     Copyright 25.10.2011 by Bochkanov Sergey}}
\DoxyCodeLine{5629 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5630 \textcolor{keywordtype}{void} filterlrma(\mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} ae\_int\_t n, \textcolor{keyword}{const} ae\_int\_t k, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5631 \textcolor{keywordtype}{void} filterlrma(\mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} ae\_int\_t k, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5632 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{5633 }
\DoxyCodeLine{5634 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_SSA) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{5635 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5636 \textcolor{comment}{This function creates SSA model object.  Right after creation model is  in}}
\DoxyCodeLine{5637 \textcolor{comment}{"{}dummy"{} mode -\/ you can add data,  but   analyzing/prediction  will  return}}
\DoxyCodeLine{5638 \textcolor{comment}{just zeros (it assumes that basis is empty).}}
\DoxyCodeLine{5639 \textcolor{comment}{}}
\DoxyCodeLine{5640 \textcolor{comment}{HOW TO USE SSA MODEL:}}
\DoxyCodeLine{5641 \textcolor{comment}{}}
\DoxyCodeLine{5642 \textcolor{comment}{1. create model with ssacreate()}}
\DoxyCodeLine{5643 \textcolor{comment}{2. add data with one/many ssaaddsequence() calls}}
\DoxyCodeLine{5644 \textcolor{comment}{3. choose SSA algorithm with one of ssasetalgo...() functions:}}
\DoxyCodeLine{5645 \textcolor{comment}{   * ssasetalgotopkdirect() for direct one-\/run analysis}}
\DoxyCodeLine{5646 \textcolor{comment}{   * ssasetalgotopkrealtime() for algorithm optimized for many  subsequent}}
\DoxyCodeLine{5647 \textcolor{comment}{     runs with warm-\/start capabilities}}
\DoxyCodeLine{5648 \textcolor{comment}{   * ssasetalgoprecomputed() for user-\/supplied basis}}
\DoxyCodeLine{5649 \textcolor{comment}{4. set window width with ssasetwindow()}}
\DoxyCodeLine{5650 \textcolor{comment}{5. perform one of the analysis-\/related activities:}}
\DoxyCodeLine{5651 \textcolor{comment}{   a) call ssagetbasis() to get basis}}
\DoxyCodeLine{5652 \textcolor{comment}{   b) call ssaanalyzelast() ssaanalyzesequence() or ssaanalyzelastwindow()}}
\DoxyCodeLine{5653 \textcolor{comment}{      to perform analysis (trend/noise separation)}}
\DoxyCodeLine{5654 \textcolor{comment}{   c) call  one  of   the   forecasting   functions  (ssaforecastlast() or}}
\DoxyCodeLine{5655 \textcolor{comment}{      ssaforecastsequence()) to perform prediction; alternatively, you can}}
\DoxyCodeLine{5656 \textcolor{comment}{      extract linear recurrence coefficients with ssagetlrr().}}
\DoxyCodeLine{5657 \textcolor{comment}{   SSA analysis will be performed during first  call  to  analysis-\/related}}
\DoxyCodeLine{5658 \textcolor{comment}{   function. SSA model is smart enough to track all changes in the dataset}}
\DoxyCodeLine{5659 \textcolor{comment}{   and  model  settings,  to  cache  previously  computed  basis  and   to}}
\DoxyCodeLine{5660 \textcolor{comment}{   re-\/evaluate basis only when necessary.}}
\DoxyCodeLine{5661 \textcolor{comment}{}}
\DoxyCodeLine{5662 \textcolor{comment}{Additionally, if your setting involves constant stream  of  incoming data,}}
\DoxyCodeLine{5663 \textcolor{comment}{you can perform quick update already calculated  model  with  one  of  the}}
\DoxyCodeLine{5664 \textcolor{comment}{incremental   append-\/and-\/update   functions:  ssaappendpointandupdate() or}}
\DoxyCodeLine{5665 \textcolor{comment}{ssaappendsequenceandupdate().}}
\DoxyCodeLine{5666 \textcolor{comment}{}}
\DoxyCodeLine{5667 \textcolor{comment}{NOTE: steps (2), (3), (4) can be performed in arbitrary order.}}
\DoxyCodeLine{5668 \textcolor{comment}{}}
\DoxyCodeLine{5669 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5670 \textcolor{comment}{    none}}
\DoxyCodeLine{5671 \textcolor{comment}{}}
\DoxyCodeLine{5672 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{5673 \textcolor{comment}{    S               -\/   structure which stores model state}}
\DoxyCodeLine{5674 \textcolor{comment}{}}
\DoxyCodeLine{5675 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5676 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{5677 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5678 \textcolor{keywordtype}{void} ssacreate(\mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5679 }
\DoxyCodeLine{5680 }
\DoxyCodeLine{5681 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5682 \textcolor{comment}{This function sets window width for SSA model. You should call  it  before}}
\DoxyCodeLine{5683 \textcolor{comment}{analysis phase. Default window width is 1 (not for real use).}}
\DoxyCodeLine{5684 \textcolor{comment}{}}
\DoxyCodeLine{5685 \textcolor{comment}{Special notes:}}
\DoxyCodeLine{5686 \textcolor{comment}{* this function call can be performed at any moment before  first call  to}}
\DoxyCodeLine{5687 \textcolor{comment}{  analysis-\/related functions}}
\DoxyCodeLine{5688 \textcolor{comment}{* changing window width invalidates internally stored basis; if you change}}
\DoxyCodeLine{5689 \textcolor{comment}{  window width AFTER you call analysis-\/related  function,  next  analysis}}
\DoxyCodeLine{5690 \textcolor{comment}{  phase will require re-\/calculation of  the  basis  according  to  current}}
\DoxyCodeLine{5691 \textcolor{comment}{  algorithm.}}
\DoxyCodeLine{5692 \textcolor{comment}{* calling this function with exactly  same window width as current one has}}
\DoxyCodeLine{5693 \textcolor{comment}{  no effect}}
\DoxyCodeLine{5694 \textcolor{comment}{* if you specify window width larger  than any data sequence stored in the}}
\DoxyCodeLine{5695 \textcolor{comment}{  model, analysis will return zero basis.}}
\DoxyCodeLine{5696 \textcolor{comment}{}}
\DoxyCodeLine{5697 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5698 \textcolor{comment}{    S               -\/   SSA model created with ssacreate()}}
\DoxyCodeLine{5699 \textcolor{comment}{    WindowWidth     -\/   >=1, new window width}}
\DoxyCodeLine{5700 \textcolor{comment}{}}
\DoxyCodeLine{5701 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{5702 \textcolor{comment}{    S               -\/   SSA model, updated}}
\DoxyCodeLine{5703 \textcolor{comment}{}}
\DoxyCodeLine{5704 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5705 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{5706 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5707 \textcolor{keywordtype}{void} ssasetwindow(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} ae\_int\_t windowwidth, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5708 }
\DoxyCodeLine{5709 }
\DoxyCodeLine{5710 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5711 \textcolor{comment}{This  function  sets  seed  which  is used to initialize internal RNG when}}
\DoxyCodeLine{5712 \textcolor{comment}{we make pseudorandom decisions on model updates.}}
\DoxyCodeLine{5713 \textcolor{comment}{}}
\DoxyCodeLine{5714 \textcolor{comment}{By default, deterministic seed is used -\/ which results in same sequence of}}
\DoxyCodeLine{5715 \textcolor{comment}{pseudorandom decisions every time you run SSA model. If you  specify  non-\/}}
\DoxyCodeLine{5716 \textcolor{comment}{deterministic seed value, then SSA  model  may  return  slightly different}}
\DoxyCodeLine{5717 \textcolor{comment}{results after each run.}}
\DoxyCodeLine{5718 \textcolor{comment}{}}
\DoxyCodeLine{5719 \textcolor{comment}{This function can be useful when you have several SSA models updated  with}}
\DoxyCodeLine{5720 \textcolor{comment}{sseappendpointandupdate() called with 0<UpdateIts<1 (fractional value) and}}
\DoxyCodeLine{5721 \textcolor{comment}{due to performance limitations want them to perform updates  at  different}}
\DoxyCodeLine{5722 \textcolor{comment}{moments.}}
\DoxyCodeLine{5723 \textcolor{comment}{}}
\DoxyCodeLine{5724 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5725 \textcolor{comment}{    S       -\/   SSA model}}
\DoxyCodeLine{5726 \textcolor{comment}{    Seed    -\/   seed:}}
\DoxyCodeLine{5727 \textcolor{comment}{                * positive values = use deterministic seed for each run of}}
\DoxyCodeLine{5728 \textcolor{comment}{                  algorithms which depend on random initialization}}
\DoxyCodeLine{5729 \textcolor{comment}{                * zero or negative values = use non-\/deterministic seed}}
\DoxyCodeLine{5730 \textcolor{comment}{}}
\DoxyCodeLine{5731 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5732 \textcolor{comment}{     Copyright 03.11.2017 by Bochkanov Sergey}}
\DoxyCodeLine{5733 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5734 \textcolor{keywordtype}{void} ssasetseed(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} ae\_int\_t seed, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5735 }
\DoxyCodeLine{5736 }
\DoxyCodeLine{5737 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5738 \textcolor{comment}{This function sets length of power-\/up cycle for real-\/time algorithm.}}
\DoxyCodeLine{5739 \textcolor{comment}{}}
\DoxyCodeLine{5740 \textcolor{comment}{By default, this algorithm performs costly O(N*WindowWidth\string^2)  init  phase}}
\DoxyCodeLine{5741 \textcolor{comment}{followed by full run of truncated  EVD.  However,  if  you  are  ready  to}}
\DoxyCodeLine{5742 \textcolor{comment}{live with a bit lower-\/quality basis during first few iterations,  you  can}}
\DoxyCodeLine{5743 \textcolor{comment}{split this O(N*WindowWidth\string^2) initialization  between  several  subsequent}}
\DoxyCodeLine{5744 \textcolor{comment}{append-\/and-\/update rounds. It results in better latency of the algorithm.}}
\DoxyCodeLine{5745 \textcolor{comment}{}}
\DoxyCodeLine{5746 \textcolor{comment}{This function invalidates basis/solver, next analysis call will result  in}}
\DoxyCodeLine{5747 \textcolor{comment}{full recalculation of everything.}}
\DoxyCodeLine{5748 \textcolor{comment}{}}
\DoxyCodeLine{5749 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5750 \textcolor{comment}{    S       -\/   SSA model}}
\DoxyCodeLine{5751 \textcolor{comment}{    PWLen   -\/   length of the power-\/up stage:}}
\DoxyCodeLine{5752 \textcolor{comment}{                * 0 means that no power-\/up is requested}}
\DoxyCodeLine{5753 \textcolor{comment}{                * 1 is the same as 0}}
\DoxyCodeLine{5754 \textcolor{comment}{                * >1 means that delayed power-\/up is performed}}
\DoxyCodeLine{5755 \textcolor{comment}{}}
\DoxyCodeLine{5756 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5757 \textcolor{comment}{     Copyright 03.11.2017 by Bochkanov Sergey}}
\DoxyCodeLine{5758 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5759 \textcolor{keywordtype}{void} ssasetpoweruplength(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} ae\_int\_t pwlen, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5760 }
\DoxyCodeLine{5761 }
\DoxyCodeLine{5762 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5763 \textcolor{comment}{This function sets memory limit of SSA analysis.}}
\DoxyCodeLine{5764 \textcolor{comment}{}}
\DoxyCodeLine{5765 \textcolor{comment}{Straightforward SSA with sequence length T and window width W needs O(T*W)}}
\DoxyCodeLine{5766 \textcolor{comment}{memory. It is possible to reduce memory consumption by splitting task into}}
\DoxyCodeLine{5767 \textcolor{comment}{smaller chunks.}}
\DoxyCodeLine{5768 \textcolor{comment}{}}
\DoxyCodeLine{5769 \textcolor{comment}{Thus function allows you to specify approximate memory limit (measured  in}}
\DoxyCodeLine{5770 \textcolor{comment}{double precision numbers used for buffers). Actual memory consumption will}}
\DoxyCodeLine{5771 \textcolor{comment}{be comparable to the number specified by you.}}
\DoxyCodeLine{5772 \textcolor{comment}{}}
\DoxyCodeLine{5773 \textcolor{comment}{Default memory limit is 50.000.000 (400Mbytes) in current version.}}
\DoxyCodeLine{5774 \textcolor{comment}{}}
\DoxyCodeLine{5775 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5776 \textcolor{comment}{    S       -\/   SSA model}}
\DoxyCodeLine{5777 \textcolor{comment}{    MemLimit-\/   memory limit, >=0. Zero value means no limit.}}
\DoxyCodeLine{5778 \textcolor{comment}{}}
\DoxyCodeLine{5779 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5780 \textcolor{comment}{     Copyright 20.12.2017 by Bochkanov Sergey}}
\DoxyCodeLine{5781 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5782 \textcolor{keywordtype}{void} ssasetmemorylimit(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} ae\_int\_t memlimit, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5783 }
\DoxyCodeLine{5784 }
\DoxyCodeLine{5785 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5786 \textcolor{comment}{This function adds data sequence to SSA  model.  Only   single-\/dimensional}}
\DoxyCodeLine{5787 \textcolor{comment}{sequences are supported.}}
\DoxyCodeLine{5788 \textcolor{comment}{}}
\DoxyCodeLine{5789 \textcolor{comment}{What is a sequences? Following definitions/requirements apply:}}
\DoxyCodeLine{5790 \textcolor{comment}{* a sequence  is  an  array of  values  measured  in  subsequent,  equally}}
\DoxyCodeLine{5791 \textcolor{comment}{  separated time moments (ticks).}}
\DoxyCodeLine{5792 \textcolor{comment}{* you may have many sequences  in your  dataset;  say,  one  sequence  may}}
\DoxyCodeLine{5793 \textcolor{comment}{  correspond to one trading session.}}
\DoxyCodeLine{5794 \textcolor{comment}{* sequence length should be larger  than current  window  length  (shorter}}
\DoxyCodeLine{5795 \textcolor{comment}{  sequences will be ignored during analysis).}}
\DoxyCodeLine{5796 \textcolor{comment}{* analysis is performed within a  sequence; different  sequences  are  NOT}}
\DoxyCodeLine{5797 \textcolor{comment}{  stacked together to produce one large contiguous stream of data.}}
\DoxyCodeLine{5798 \textcolor{comment}{* analysis is performed for all  sequences at once, i.e. same set of basis}}
\DoxyCodeLine{5799 \textcolor{comment}{  vectors is computed for all sequences}}
\DoxyCodeLine{5800 \textcolor{comment}{}}
\DoxyCodeLine{5801 \textcolor{comment}{INCREMENTAL ANALYSIS}}
\DoxyCodeLine{5802 \textcolor{comment}{}}
\DoxyCodeLine{5803 \textcolor{comment}{This function is non intended for  incremental updates of previously found}}
\DoxyCodeLine{5804 \textcolor{comment}{SSA basis. Calling it invalidates  all previous analysis results (basis is}}
\DoxyCodeLine{5805 \textcolor{comment}{reset and will be recalculated from zero during next analysis).}}
\DoxyCodeLine{5806 \textcolor{comment}{}}
\DoxyCodeLine{5807 \textcolor{comment}{If  you  want  to  perform   incremental/real-\/time  SSA,  consider   using}}
\DoxyCodeLine{5808 \textcolor{comment}{following functions:}}
\DoxyCodeLine{5809 \textcolor{comment}{* ssaappendpointandupdate() for appending one point}}
\DoxyCodeLine{5810 \textcolor{comment}{* ssaappendsequenceandupdate() for appending new sequence}}
\DoxyCodeLine{5811 \textcolor{comment}{}}
\DoxyCodeLine{5812 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5813 \textcolor{comment}{    S               -\/   SSA model created with ssacreate()}}
\DoxyCodeLine{5814 \textcolor{comment}{    X               -\/   array[N], data, can be larger (additional values}}
\DoxyCodeLine{5815 \textcolor{comment}{                        are ignored)}}
\DoxyCodeLine{5816 \textcolor{comment}{    N               -\/   data length, can be automatically determined from}}
\DoxyCodeLine{5817 \textcolor{comment}{                        the array length. N>=0.}}
\DoxyCodeLine{5818 \textcolor{comment}{}}
\DoxyCodeLine{5819 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{5820 \textcolor{comment}{    S               -\/   SSA model, updated}}
\DoxyCodeLine{5821 \textcolor{comment}{}}
\DoxyCodeLine{5822 \textcolor{comment}{NOTE: you can clear dataset with ssacleardata()}}
\DoxyCodeLine{5823 \textcolor{comment}{}}
\DoxyCodeLine{5824 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5825 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{5826 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5827 \textcolor{keywordtype}{void} ssaaddsequence(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} ae\_int\_t n, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5828 \textcolor{keywordtype}{void} ssaaddsequence(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5829 }
\DoxyCodeLine{5830 }
\DoxyCodeLine{5831 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5832 \textcolor{comment}{This function appends single point to last data sequence stored in the SSA}}
\DoxyCodeLine{5833 \textcolor{comment}{model and tries to update model in the  incremental  manner  (if  possible}}
\DoxyCodeLine{5834 \textcolor{comment}{with current algorithm).}}
\DoxyCodeLine{5835 \textcolor{comment}{}}
\DoxyCodeLine{5836 \textcolor{comment}{If you want to add more than one point at once:}}
\DoxyCodeLine{5837 \textcolor{comment}{* if you want to add M points to the same sequence, perform M-\/1 calls with}}
\DoxyCodeLine{5838 \textcolor{comment}{  UpdateIts parameter set to 0.0, and last call with non-\/zero UpdateIts.}}
\DoxyCodeLine{5839 \textcolor{comment}{* if you want to add new sequence, use ssaappendsequenceandupdate()}}
\DoxyCodeLine{5840 \textcolor{comment}{}}
\DoxyCodeLine{5841 \textcolor{comment}{Running time of this function does NOT depend on  dataset  size,  only  on}}
\DoxyCodeLine{5842 \textcolor{comment}{window width and number of singular vectors. Depending on algorithm  being}}
\DoxyCodeLine{5843 \textcolor{comment}{used, incremental update has complexity:}}
\DoxyCodeLine{5844 \textcolor{comment}{* for top-\/K real time   -\/ O(UpdateIts*K*Width\string^2), with fractional UpdateIts}}
\DoxyCodeLine{5845 \textcolor{comment}{* for top-\/K direct      -\/ O(Width\string^3) for any non-\/zero UpdateIts}}
\DoxyCodeLine{5846 \textcolor{comment}{* for precomputed basis -\/ O(1), no update is performed}}
\DoxyCodeLine{5847 \textcolor{comment}{}}
\DoxyCodeLine{5848 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5849 \textcolor{comment}{    S               -\/   SSA model created with ssacreate()}}
\DoxyCodeLine{5850 \textcolor{comment}{    X               -\/   new point}}
\DoxyCodeLine{5851 \textcolor{comment}{    UpdateIts       -\/   >=0,  floating  point (!)  value,  desired  update}}
\DoxyCodeLine{5852 \textcolor{comment}{                        frequency:}}
\DoxyCodeLine{5853 \textcolor{comment}{                        * zero value means that point is  stored,  but  no}}
\DoxyCodeLine{5854 \textcolor{comment}{                          update is performed}}
\DoxyCodeLine{5855 \textcolor{comment}{                        * integer part of the value means  that  specified}}
\DoxyCodeLine{5856 \textcolor{comment}{                          number of iterations is always performed}}
\DoxyCodeLine{5857 \textcolor{comment}{                        * fractional part of  the  value  means  that  one}}
\DoxyCodeLine{5858 \textcolor{comment}{                          iteration is performed with this probability.}}
\DoxyCodeLine{5859 \textcolor{comment}{}}
\DoxyCodeLine{5860 \textcolor{comment}{                        Recommended value: 0<UpdateIts<=1.  Values  larger}}
\DoxyCodeLine{5861 \textcolor{comment}{                        than 1 are VERY seldom  needed.  If  your  dataset}}
\DoxyCodeLine{5862 \textcolor{comment}{                        changes slowly, you can set it  to  0.1  and  skip}}
\DoxyCodeLine{5863 \textcolor{comment}{                        90\% of updates.}}
\DoxyCodeLine{5864 \textcolor{comment}{}}
\DoxyCodeLine{5865 \textcolor{comment}{                        In any case, no information is lost even with zero}}
\DoxyCodeLine{5866 \textcolor{comment}{                        value of UpdateIts! It will be  incorporated  into}}
\DoxyCodeLine{5867 \textcolor{comment}{                        model, sooner or later.}}
\DoxyCodeLine{5868 \textcolor{comment}{}}
\DoxyCodeLine{5869 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{5870 \textcolor{comment}{    S               -\/   SSA model, updated}}
\DoxyCodeLine{5871 \textcolor{comment}{}}
\DoxyCodeLine{5872 \textcolor{comment}{NOTE: this function uses internal  RNG  to  handle  fractional  values  of}}
\DoxyCodeLine{5873 \textcolor{comment}{      UpdateIts. By default it  is  initialized  with  fixed  seed  during}}
\DoxyCodeLine{5874 \textcolor{comment}{      initial calculation of basis. Thus subsequent calls to this function}}
\DoxyCodeLine{5875 \textcolor{comment}{      will result in the same sequence of pseudorandom decisions.}}
\DoxyCodeLine{5876 \textcolor{comment}{}}
\DoxyCodeLine{5877 \textcolor{comment}{      However, if  you  have  several  SSA  models  which  are  calculated}}
\DoxyCodeLine{5878 \textcolor{comment}{      simultaneously, and if you want to reduce computational  bottlenecks}}
\DoxyCodeLine{5879 \textcolor{comment}{      by performing random updates at random moments, then fixed  seed  is}}
\DoxyCodeLine{5880 \textcolor{comment}{      not an option -\/ all updates will fire at same moments.}}
\DoxyCodeLine{5881 \textcolor{comment}{}}
\DoxyCodeLine{5882 \textcolor{comment}{      You may change it with ssasetseed() function.}}
\DoxyCodeLine{5883 \textcolor{comment}{}}
\DoxyCodeLine{5884 \textcolor{comment}{NOTE: this function throws an exception if called for empty dataset (there}}
\DoxyCodeLine{5885 \textcolor{comment}{      is no "{}last"{} sequence to modify).}}
\DoxyCodeLine{5886 \textcolor{comment}{}}
\DoxyCodeLine{5887 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5888 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{5889 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5890 \textcolor{keywordtype}{void} ssaappendpointandupdate(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} \textcolor{keywordtype}{double} x, \textcolor{keyword}{const} \textcolor{keywordtype}{double} updateits, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5891 }
\DoxyCodeLine{5892 }
\DoxyCodeLine{5893 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5894 \textcolor{comment}{This function appends new sequence to dataset stored in the SSA  model and}}
\DoxyCodeLine{5895 \textcolor{comment}{tries to update model in the incremental manner (if possible  with current}}
\DoxyCodeLine{5896 \textcolor{comment}{algorithm).}}
\DoxyCodeLine{5897 \textcolor{comment}{}}
\DoxyCodeLine{5898 \textcolor{comment}{Notes:}}
\DoxyCodeLine{5899 \textcolor{comment}{* if you want to add M sequences at once, perform M-\/1 calls with UpdateIts}}
\DoxyCodeLine{5900 \textcolor{comment}{  parameter set to 0.0, and last call with non-\/zero UpdateIts.}}
\DoxyCodeLine{5901 \textcolor{comment}{* if you want to add just one point, use ssaappendpointandupdate()}}
\DoxyCodeLine{5902 \textcolor{comment}{}}
\DoxyCodeLine{5903 \textcolor{comment}{Running time of this function does NOT depend on  dataset  size,  only  on}}
\DoxyCodeLine{5904 \textcolor{comment}{sequence length, window width and number of singular vectors. Depending on}}
\DoxyCodeLine{5905 \textcolor{comment}{algorithm being used, incremental update has complexity:}}
\DoxyCodeLine{5906 \textcolor{comment}{* for top-\/K real time   -\/ O(UpdateIts*K*Width\string^2+(NTicks-\/Width)*Width\string^2)}}
\DoxyCodeLine{5907 \textcolor{comment}{* for top-\/K direct      -\/ O(Width\string^3+(NTicks-\/Width)*Width\string^2)}}
\DoxyCodeLine{5908 \textcolor{comment}{* for precomputed basis -\/ O(1), no update is performed}}
\DoxyCodeLine{5909 \textcolor{comment}{}}
\DoxyCodeLine{5910 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5911 \textcolor{comment}{    S               -\/   SSA model created with ssacreate()}}
\DoxyCodeLine{5912 \textcolor{comment}{    X               -\/   new sequence, array[NTicks] or larget}}
\DoxyCodeLine{5913 \textcolor{comment}{    NTicks          -\/   >=1, number of ticks in the sequence}}
\DoxyCodeLine{5914 \textcolor{comment}{    UpdateIts       -\/   >=0,  floating  point (!)  value,  desired  update}}
\DoxyCodeLine{5915 \textcolor{comment}{                        frequency:}}
\DoxyCodeLine{5916 \textcolor{comment}{                        * zero value means that point is  stored,  but  no}}
\DoxyCodeLine{5917 \textcolor{comment}{                          update is performed}}
\DoxyCodeLine{5918 \textcolor{comment}{                        * integer part of the value means  that  specified}}
\DoxyCodeLine{5919 \textcolor{comment}{                          number of iterations is always performed}}
\DoxyCodeLine{5920 \textcolor{comment}{                        * fractional part of  the  value  means  that  one}}
\DoxyCodeLine{5921 \textcolor{comment}{                          iteration is performed with this probability.}}
\DoxyCodeLine{5922 \textcolor{comment}{}}
\DoxyCodeLine{5923 \textcolor{comment}{                        Recommended value: 0<UpdateIts<=1.  Values  larger}}
\DoxyCodeLine{5924 \textcolor{comment}{                        than 1 are VERY seldom  needed.  If  your  dataset}}
\DoxyCodeLine{5925 \textcolor{comment}{                        changes slowly, you can set it  to  0.1  and  skip}}
\DoxyCodeLine{5926 \textcolor{comment}{                        90\% of updates.}}
\DoxyCodeLine{5927 \textcolor{comment}{}}
\DoxyCodeLine{5928 \textcolor{comment}{                        In any case, no information is lost even with zero}}
\DoxyCodeLine{5929 \textcolor{comment}{                        value of UpdateIts! It will be  incorporated  into}}
\DoxyCodeLine{5930 \textcolor{comment}{                        model, sooner or later.}}
\DoxyCodeLine{5931 \textcolor{comment}{}}
\DoxyCodeLine{5932 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{5933 \textcolor{comment}{    S               -\/   SSA model, updated}}
\DoxyCodeLine{5934 \textcolor{comment}{}}
\DoxyCodeLine{5935 \textcolor{comment}{NOTE: this function uses internal  RNG  to  handle  fractional  values  of}}
\DoxyCodeLine{5936 \textcolor{comment}{      UpdateIts. By default it  is  initialized  with  fixed  seed  during}}
\DoxyCodeLine{5937 \textcolor{comment}{      initial calculation of basis. Thus subsequent calls to this function}}
\DoxyCodeLine{5938 \textcolor{comment}{      will result in the same sequence of pseudorandom decisions.}}
\DoxyCodeLine{5939 \textcolor{comment}{}}
\DoxyCodeLine{5940 \textcolor{comment}{      However, if  you  have  several  SSA  models  which  are  calculated}}
\DoxyCodeLine{5941 \textcolor{comment}{      simultaneously, and if you want to reduce computational  bottlenecks}}
\DoxyCodeLine{5942 \textcolor{comment}{      by performing random updates at random moments, then fixed  seed  is}}
\DoxyCodeLine{5943 \textcolor{comment}{      not an option -\/ all updates will fire at same moments.}}
\DoxyCodeLine{5944 \textcolor{comment}{}}
\DoxyCodeLine{5945 \textcolor{comment}{      You may change it with ssasetseed() function.}}
\DoxyCodeLine{5946 \textcolor{comment}{}}
\DoxyCodeLine{5947 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5948 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{5949 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5950 \textcolor{keywordtype}{void} ssaappendsequenceandupdate(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} ae\_int\_t nticks, \textcolor{keyword}{const} \textcolor{keywordtype}{double} updateits, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5951 \textcolor{keywordtype}{void} ssaappendsequenceandupdate(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} \textcolor{keywordtype}{double} updateits, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5952 }
\DoxyCodeLine{5953 }
\DoxyCodeLine{5954 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5955 \textcolor{comment}{This  function sets SSA algorithm to "{}precomputed vectors"{} algorithm.}}
\DoxyCodeLine{5956 \textcolor{comment}{}}
\DoxyCodeLine{5957 \textcolor{comment}{This  algorithm  uses  precomputed  set  of  orthonormal  (orthogonal  AND}}
\DoxyCodeLine{5958 \textcolor{comment}{normalized) basis vectors supplied by user. Thus, basis calculation  phase}}
\DoxyCodeLine{5959 \textcolor{comment}{is not performed -\/  we  already  have  our  basis  -\/  and  only  analysis/}}
\DoxyCodeLine{5960 \textcolor{comment}{forecasting phase requires actual calculations.}}
\DoxyCodeLine{5961 \textcolor{comment}{}}
\DoxyCodeLine{5962 \textcolor{comment}{This algorithm may handle "{}append"{} requests which add just  one/few  ticks}}
\DoxyCodeLine{5963 \textcolor{comment}{to the end of the last sequence in O(1) time.}}
\DoxyCodeLine{5964 \textcolor{comment}{}}
\DoxyCodeLine{5965 \textcolor{comment}{NOTE: this algorithm accepts both basis and window  width,  because  these}}
\DoxyCodeLine{5966 \textcolor{comment}{      two parameters are naturally aligned.  Calling  this  function  sets}}
\DoxyCodeLine{5967 \textcolor{comment}{      window width; if you call ssasetwindow() with  other  window  width,}}
\DoxyCodeLine{5968 \textcolor{comment}{      then during analysis stage algorithm will detect conflict and  reset}}
\DoxyCodeLine{5969 \textcolor{comment}{      to zero basis.}}
\DoxyCodeLine{5970 \textcolor{comment}{}}
\DoxyCodeLine{5971 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{5972 \textcolor{comment}{    S               -\/   SSA model}}
\DoxyCodeLine{5973 \textcolor{comment}{    A               -\/   array[WindowWidth,NBasis], orthonormalized  basis;}}
\DoxyCodeLine{5974 \textcolor{comment}{                        this function does NOT control  orthogonality  and}}
\DoxyCodeLine{5975 \textcolor{comment}{                        does NOT perform any kind of  renormalization.  It}}
\DoxyCodeLine{5976 \textcolor{comment}{                        is your responsibility to provide it with  correct}}
\DoxyCodeLine{5977 \textcolor{comment}{                        basis.}}
\DoxyCodeLine{5978 \textcolor{comment}{    WindowWidth     -\/   window width, >=1}}
\DoxyCodeLine{5979 \textcolor{comment}{    NBasis          -\/   number of basis vectors, 1<=NBasis<=WindowWidth}}
\DoxyCodeLine{5980 \textcolor{comment}{}}
\DoxyCodeLine{5981 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{5982 \textcolor{comment}{    S               -\/   updated model}}
\DoxyCodeLine{5983 \textcolor{comment}{}}
\DoxyCodeLine{5984 \textcolor{comment}{NOTE: calling this function invalidates basis in all cases.}}
\DoxyCodeLine{5985 \textcolor{comment}{}}
\DoxyCodeLine{5986 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{5987 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{5988 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{5989 \textcolor{keywordtype}{void} ssasetalgoprecomputed(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&a, \textcolor{keyword}{const} ae\_int\_t windowwidth, \textcolor{keyword}{const} ae\_int\_t nbasis, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5990 \textcolor{keywordtype}{void} ssasetalgoprecomputed(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&a, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{5991 }
\DoxyCodeLine{5992 }
\DoxyCodeLine{5993 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{5994 \textcolor{comment}{This  function sets SSA algorithm to "{}direct top-\/K"{} algorithm.}}
\DoxyCodeLine{5995 \textcolor{comment}{}}
\DoxyCodeLine{5996 \textcolor{comment}{"{}Direct top-\/K"{} algorithm performs full  SVD  of  the  N*WINDOW  trajectory}}
\DoxyCodeLine{5997 \textcolor{comment}{matrix (hence its name -\/ direct solver  is  used),  then  extracts  top  K}}
\DoxyCodeLine{5998 \textcolor{comment}{components. Overall running time is O(N*WINDOW\string^2), where N is a number  of}}
\DoxyCodeLine{5999 \textcolor{comment}{ticks in the dataset, WINDOW is window width.}}
\DoxyCodeLine{6000 \textcolor{comment}{}}
\DoxyCodeLine{6001 \textcolor{comment}{This algorithm may handle "{}append"{} requests which add just  one/few  ticks}}
\DoxyCodeLine{6002 \textcolor{comment}{to the end of the last sequence in O(WINDOW\string^3) time,  which  is  \string~N/WINDOW}}
\DoxyCodeLine{6003 \textcolor{comment}{times faster than re-\/computing everything from scratch.}}
\DoxyCodeLine{6004 \textcolor{comment}{}}
\DoxyCodeLine{6005 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{6006 \textcolor{comment}{    S               -\/   SSA model}}
\DoxyCodeLine{6007 \textcolor{comment}{    TopK            -\/   number of components to analyze; TopK>=1.}}
\DoxyCodeLine{6008 \textcolor{comment}{}}
\DoxyCodeLine{6009 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{6010 \textcolor{comment}{    S               -\/   updated model}}
\DoxyCodeLine{6011 \textcolor{comment}{}}
\DoxyCodeLine{6012 \textcolor{comment}{}}
\DoxyCodeLine{6013 \textcolor{comment}{NOTE: TopK>WindowWidth is silently decreased to WindowWidth during analysis}}
\DoxyCodeLine{6014 \textcolor{comment}{      phase}}
\DoxyCodeLine{6015 \textcolor{comment}{}}
\DoxyCodeLine{6016 \textcolor{comment}{NOTE: calling this function invalidates basis, except  for  the  situation}}
\DoxyCodeLine{6017 \textcolor{comment}{      when this algorithm was already set with same parameters.}}
\DoxyCodeLine{6018 \textcolor{comment}{}}
\DoxyCodeLine{6019 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{6020 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{6021 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{6022 \textcolor{keywordtype}{void} ssasetalgotopkdirect(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} ae\_int\_t topk, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6023 }
\DoxyCodeLine{6024 }
\DoxyCodeLine{6025 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{6026 \textcolor{comment}{This function sets SSA algorithm to "{}top-\/K real time algorithm"{}. This algo}}
\DoxyCodeLine{6027 \textcolor{comment}{extracts K components with largest singular values.}}
\DoxyCodeLine{6028 \textcolor{comment}{}}
\DoxyCodeLine{6029 \textcolor{comment}{It  is  real-\/time  version  of  top-\/K  algorithm  which  is  optimized for}}
\DoxyCodeLine{6030 \textcolor{comment}{incremental processing and  fast  start-\/up. Internally  it  uses  subspace}}
\DoxyCodeLine{6031 \textcolor{comment}{eigensolver for truncated SVD. It results  in  ability  to  perform  quick}}
\DoxyCodeLine{6032 \textcolor{comment}{updates of the basis when only a few points/sequences is added to dataset.}}
\DoxyCodeLine{6033 \textcolor{comment}{}}
\DoxyCodeLine{6034 \textcolor{comment}{Performance profile of the algorithm is given below:}}
\DoxyCodeLine{6035 \textcolor{comment}{* O(K*WindowWidth\string^2) running time for incremental update  of  the  dataset}}
\DoxyCodeLine{6036 \textcolor{comment}{  with one of the "{}append-\/and-\/update"{} functions (ssaappendpointandupdate()}}
\DoxyCodeLine{6037 \textcolor{comment}{  or ssaappendsequenceandupdate()).}}
\DoxyCodeLine{6038 \textcolor{comment}{* O(N*WindowWidth\string^2) running time for initial basis evaluation (N=size  of}}
\DoxyCodeLine{6039 \textcolor{comment}{  dataset)}}
\DoxyCodeLine{6040 \textcolor{comment}{* ability  to  split  costly  initialization  across  several  incremental}}
\DoxyCodeLine{6041 \textcolor{comment}{  updates of the basis (so called "{}Power-\/Up"{} functionality,  activated  by}}
\DoxyCodeLine{6042 \textcolor{comment}{  ssasetpoweruplength() function)}}
\DoxyCodeLine{6043 \textcolor{comment}{}}
\DoxyCodeLine{6044 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{6045 \textcolor{comment}{    S               -\/   SSA model}}
\DoxyCodeLine{6046 \textcolor{comment}{    TopK            -\/   number of components to analyze; TopK>=1.}}
\DoxyCodeLine{6047 \textcolor{comment}{}}
\DoxyCodeLine{6048 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{6049 \textcolor{comment}{    S               -\/   updated model}}
\DoxyCodeLine{6050 \textcolor{comment}{}}
\DoxyCodeLine{6051 \textcolor{comment}{NOTE: this  algorithm  is  optimized  for  large-\/scale  tasks  with  large}}
\DoxyCodeLine{6052 \textcolor{comment}{      datasets. On toy problems with just  5-\/10 points it can return basis}}
\DoxyCodeLine{6053 \textcolor{comment}{      which is slightly different from that returned by  direct  algorithm}}
\DoxyCodeLine{6054 \textcolor{comment}{      (ssasetalgotopkdirect() function). However, the  difference  becomes}}
\DoxyCodeLine{6055 \textcolor{comment}{      negligible as dataset grows.}}
\DoxyCodeLine{6056 \textcolor{comment}{}}
\DoxyCodeLine{6057 \textcolor{comment}{NOTE: TopK>WindowWidth is silently decreased to WindowWidth during analysis}}
\DoxyCodeLine{6058 \textcolor{comment}{      phase}}
\DoxyCodeLine{6059 \textcolor{comment}{}}
\DoxyCodeLine{6060 \textcolor{comment}{NOTE: calling this function invalidates basis, except  for  the  situation}}
\DoxyCodeLine{6061 \textcolor{comment}{      when this algorithm was already set with same parameters.}}
\DoxyCodeLine{6062 \textcolor{comment}{}}
\DoxyCodeLine{6063 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{6064 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{6065 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{6066 \textcolor{keywordtype}{void} ssasetalgotopkrealtime(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} ae\_int\_t topk, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6067 }
\DoxyCodeLine{6068 }
\DoxyCodeLine{6069 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{6070 \textcolor{comment}{This function clears all data stored in the  model  and  invalidates  all}}
\DoxyCodeLine{6071 \textcolor{comment}{basis components found so far.}}
\DoxyCodeLine{6072 \textcolor{comment}{}}
\DoxyCodeLine{6073 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{6074 \textcolor{comment}{    S               -\/   SSA model created with ssacreate()}}
\DoxyCodeLine{6075 \textcolor{comment}{}}
\DoxyCodeLine{6076 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{6077 \textcolor{comment}{    S               -\/   SSA model, updated}}
\DoxyCodeLine{6078 \textcolor{comment}{}}
\DoxyCodeLine{6079 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{6080 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{6081 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{6082 \textcolor{keywordtype}{void} ssacleardata(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6083 }
\DoxyCodeLine{6084 }
\DoxyCodeLine{6085 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{6086 \textcolor{comment}{This function executes SSA on internally stored dataset and returns  basis}}
\DoxyCodeLine{6087 \textcolor{comment}{found by current method.}}
\DoxyCodeLine{6088 \textcolor{comment}{}}
\DoxyCodeLine{6089 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{6090 \textcolor{comment}{    S               -\/   SSA model}}
\DoxyCodeLine{6091 \textcolor{comment}{}}
\DoxyCodeLine{6092 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{6093 \textcolor{comment}{    A               -\/   array[WindowWidth,NBasis],   basis;  vectors  are}}
\DoxyCodeLine{6094 \textcolor{comment}{                        stored in matrix columns, by descreasing variance}}
\DoxyCodeLine{6095 \textcolor{comment}{    SV              -\/   array[NBasis]:}}
\DoxyCodeLine{6096 \textcolor{comment}{                        * zeros -\/ for model initialized with SSASetAlgoPrecomputed()}}
\DoxyCodeLine{6097 \textcolor{comment}{                        * singular values -\/ for other algorithms}}
\DoxyCodeLine{6098 \textcolor{comment}{    WindowWidth     -\/   current window}}
\DoxyCodeLine{6099 \textcolor{comment}{    NBasis          -\/   basis size}}
\DoxyCodeLine{6100 \textcolor{comment}{}}
\DoxyCodeLine{6101 \textcolor{comment}{}}
\DoxyCodeLine{6102 \textcolor{comment}{CACHING/REUSE OF THE BASIS}}
\DoxyCodeLine{6103 \textcolor{comment}{}}
\DoxyCodeLine{6104 \textcolor{comment}{Caching/reuse of previous results is performed:}}
\DoxyCodeLine{6105 \textcolor{comment}{* first call performs full run of SSA; basis is stored in the cache}}
\DoxyCodeLine{6106 \textcolor{comment}{* subsequent calls reuse previously cached basis}}
\DoxyCodeLine{6107 \textcolor{comment}{* if you call any function which changes model properties (window  length,}}
\DoxyCodeLine{6108 \textcolor{comment}{  algorithm, dataset), internal basis will be invalidated.}}
\DoxyCodeLine{6109 \textcolor{comment}{* the only calls which do NOT invalidate basis are listed below:}}
\DoxyCodeLine{6110 \textcolor{comment}{  a) ssasetwindow() with same window length}}
\DoxyCodeLine{6111 \textcolor{comment}{  b) ssaappendpointandupdate()}}
\DoxyCodeLine{6112 \textcolor{comment}{  c) ssaappendsequenceandupdate()}}
\DoxyCodeLine{6113 \textcolor{comment}{  d) ssasetalgotopk...() with exactly same K}}
\DoxyCodeLine{6114 \textcolor{comment}{  Calling these functions will result in reuse of previously found basis.}}
\DoxyCodeLine{6115 \textcolor{comment}{}}
\DoxyCodeLine{6116 \textcolor{comment}{}}
\DoxyCodeLine{6117 \textcolor{comment}{HANDLING OF DEGENERATE CASES}}
\DoxyCodeLine{6118 \textcolor{comment}{}}
\DoxyCodeLine{6119 \textcolor{comment}{Calling  this  function  in  degenerate  cases  (no  data  or all data are}}
\DoxyCodeLine{6120 \textcolor{comment}{shorter than window size; no algorithm is specified)  returns  basis  with}}
\DoxyCodeLine{6121 \textcolor{comment}{just one zero vector.}}
\DoxyCodeLine{6122 \textcolor{comment}{}}
\DoxyCodeLine{6123 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{6124 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{6125 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{6126 \textcolor{keywordtype}{void} ssagetbasis(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&a, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&sv, ae\_int\_t \&windowwidth, ae\_int\_t \&nbasis, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6127 }
\DoxyCodeLine{6128 }
\DoxyCodeLine{6129 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{6130 \textcolor{comment}{This function returns linear recurrence relation (LRR) coefficients  found}}
\DoxyCodeLine{6131 \textcolor{comment}{by current SSA algorithm.}}
\DoxyCodeLine{6132 \textcolor{comment}{}}
\DoxyCodeLine{6133 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{6134 \textcolor{comment}{    S               -\/   SSA model}}
\DoxyCodeLine{6135 \textcolor{comment}{}}
\DoxyCodeLine{6136 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{6137 \textcolor{comment}{    A               -\/   array[WindowWidth-\/1]. Coefficients  of  the}}
\DoxyCodeLine{6138 \textcolor{comment}{                        linear recurrence of the form:}}
\DoxyCodeLine{6139 \textcolor{comment}{                        X[W-\/1] = X[W-\/2]*A[W-\/2] + X[W-\/3]*A[W-\/3] + ... + X[0]*A[0].}}
\DoxyCodeLine{6140 \textcolor{comment}{                        Empty array for WindowWidth=1.}}
\DoxyCodeLine{6141 \textcolor{comment}{    WindowWidth     -\/   current window width}}
\DoxyCodeLine{6142 \textcolor{comment}{}}
\DoxyCodeLine{6143 \textcolor{comment}{}}
\DoxyCodeLine{6144 \textcolor{comment}{CACHING/REUSE OF THE BASIS}}
\DoxyCodeLine{6145 \textcolor{comment}{}}
\DoxyCodeLine{6146 \textcolor{comment}{Caching/reuse of previous results is performed:}}
\DoxyCodeLine{6147 \textcolor{comment}{* first call performs full run of SSA; basis is stored in the cache}}
\DoxyCodeLine{6148 \textcolor{comment}{* subsequent calls reuse previously cached basis}}
\DoxyCodeLine{6149 \textcolor{comment}{* if you call any function which changes model properties (window  length,}}
\DoxyCodeLine{6150 \textcolor{comment}{  algorithm, dataset), internal basis will be invalidated.}}
\DoxyCodeLine{6151 \textcolor{comment}{* the only calls which do NOT invalidate basis are listed below:}}
\DoxyCodeLine{6152 \textcolor{comment}{  a) ssasetwindow() with same window length}}
\DoxyCodeLine{6153 \textcolor{comment}{  b) ssaappendpointandupdate()}}
\DoxyCodeLine{6154 \textcolor{comment}{  c) ssaappendsequenceandupdate()}}
\DoxyCodeLine{6155 \textcolor{comment}{  d) ssasetalgotopk...() with exactly same K}}
\DoxyCodeLine{6156 \textcolor{comment}{  Calling these functions will result in reuse of previously found basis.}}
\DoxyCodeLine{6157 \textcolor{comment}{}}
\DoxyCodeLine{6158 \textcolor{comment}{}}
\DoxyCodeLine{6159 \textcolor{comment}{HANDLING OF DEGENERATE CASES}}
\DoxyCodeLine{6160 \textcolor{comment}{}}
\DoxyCodeLine{6161 \textcolor{comment}{Calling  this  function  in  degenerate  cases  (no  data  or all data are}}
\DoxyCodeLine{6162 \textcolor{comment}{shorter than window size; no algorithm is specified) returns zeros.}}
\DoxyCodeLine{6163 \textcolor{comment}{}}
\DoxyCodeLine{6164 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{6165 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{6166 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{6167 \textcolor{keywordtype}{void} ssagetlrr(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&a, ae\_int\_t \&windowwidth, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6168 }
\DoxyCodeLine{6169 }
\DoxyCodeLine{6170 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{6171 \textcolor{comment}{This  function  executes  SSA  on  internally  stored  dataset and returns}}
\DoxyCodeLine{6172 \textcolor{comment}{analysis  for  the  last  window  of  the  last sequence. Such analysis is}}
\DoxyCodeLine{6173 \textcolor{comment}{an lightweight alternative for full scale reconstruction (see below).}}
\DoxyCodeLine{6174 \textcolor{comment}{}}
\DoxyCodeLine{6175 \textcolor{comment}{Typical use case for this function is  real-\/time  setting,  when  you  are}}
\DoxyCodeLine{6176 \textcolor{comment}{interested in quick-\/and-\/dirty (very quick and very  dirty)  processing  of}}
\DoxyCodeLine{6177 \textcolor{comment}{just a few last ticks of the trend.}}
\DoxyCodeLine{6178 \textcolor{comment}{}}
\DoxyCodeLine{6179 \textcolor{comment}{IMPORTANT: full  scale  SSA  involves  analysis  of  the  ENTIRE  dataset,}}
\DoxyCodeLine{6180 \textcolor{comment}{           with reconstruction being done for  all  positions  of  sliding}}
\DoxyCodeLine{6181 \textcolor{comment}{           window with subsequent hankelization  (diagonal  averaging)  of}}
\DoxyCodeLine{6182 \textcolor{comment}{           the resulting matrix.}}
\DoxyCodeLine{6183 \textcolor{comment}{}}
\DoxyCodeLine{6184 \textcolor{comment}{           Such analysis requires O((DataLen-\/Window)*Window*NBasis)  FLOPs}}
\DoxyCodeLine{6185 \textcolor{comment}{           and can be quite costly. However, it has  nice  noise-\/canceling}}
\DoxyCodeLine{6186 \textcolor{comment}{           effects due to averaging.}}
\DoxyCodeLine{6187 \textcolor{comment}{}}
\DoxyCodeLine{6188 \textcolor{comment}{           This function performs REDUCED analysis of the last window.  It}}
\DoxyCodeLine{6189 \textcolor{comment}{           is much faster -\/ just O(Window*NBasis),  but  its  results  are}}
\DoxyCodeLine{6190 \textcolor{comment}{           DIFFERENT from that of ssaanalyzelast(). In  particular,  first}}
\DoxyCodeLine{6191 \textcolor{comment}{           few points of the trend are much more prone to noise.}}
\DoxyCodeLine{6192 \textcolor{comment}{}}
\DoxyCodeLine{6193 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{6194 \textcolor{comment}{    S               -\/   SSA model}}
\DoxyCodeLine{6195 \textcolor{comment}{}}
\DoxyCodeLine{6196 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{6197 \textcolor{comment}{    Trend           -\/   array[WindowSize], reconstructed trend line}}
\DoxyCodeLine{6198 \textcolor{comment}{    Noise           -\/   array[WindowSize], the rest of the signal;}}
\DoxyCodeLine{6199 \textcolor{comment}{                        it holds that ActualData = Trend+Noise.}}
\DoxyCodeLine{6200 \textcolor{comment}{    NTicks          -\/   current WindowSize}}
\DoxyCodeLine{6201 \textcolor{comment}{}}
\DoxyCodeLine{6202 \textcolor{comment}{}}
\DoxyCodeLine{6203 \textcolor{comment}{CACHING/REUSE OF THE BASIS}}
\DoxyCodeLine{6204 \textcolor{comment}{}}
\DoxyCodeLine{6205 \textcolor{comment}{Caching/reuse of previous results is performed:}}
\DoxyCodeLine{6206 \textcolor{comment}{* first call performs full run of SSA; basis is stored in the cache}}
\DoxyCodeLine{6207 \textcolor{comment}{* subsequent calls reuse previously cached basis}}
\DoxyCodeLine{6208 \textcolor{comment}{* if you call any function which changes model properties (window  length,}}
\DoxyCodeLine{6209 \textcolor{comment}{  algorithm, dataset), internal basis will be invalidated.}}
\DoxyCodeLine{6210 \textcolor{comment}{* the only calls which do NOT invalidate basis are listed below:}}
\DoxyCodeLine{6211 \textcolor{comment}{  a) ssasetwindow() with same window length}}
\DoxyCodeLine{6212 \textcolor{comment}{  b) ssaappendpointandupdate()}}
\DoxyCodeLine{6213 \textcolor{comment}{  c) ssaappendsequenceandupdate()}}
\DoxyCodeLine{6214 \textcolor{comment}{  d) ssasetalgotopk...() with exactly same K}}
\DoxyCodeLine{6215 \textcolor{comment}{  Calling these functions will result in reuse of previously found basis.}}
\DoxyCodeLine{6216 \textcolor{comment}{}}
\DoxyCodeLine{6217 \textcolor{comment}{In  any  case,  only  basis  is  reused. Reconstruction is performed  from}}
\DoxyCodeLine{6218 \textcolor{comment}{scratch every time you call this function.}}
\DoxyCodeLine{6219 \textcolor{comment}{}}
\DoxyCodeLine{6220 \textcolor{comment}{}}
\DoxyCodeLine{6221 \textcolor{comment}{HANDLING OF DEGENERATE CASES}}
\DoxyCodeLine{6222 \textcolor{comment}{}}
\DoxyCodeLine{6223 \textcolor{comment}{Following degenerate cases may happen:}}
\DoxyCodeLine{6224 \textcolor{comment}{* dataset is empty (no analysis can be done)}}
\DoxyCodeLine{6225 \textcolor{comment}{* all sequences are shorter than the window length,no analysis can be done}}
\DoxyCodeLine{6226 \textcolor{comment}{* no algorithm is specified (no analysis can be done)}}
\DoxyCodeLine{6227 \textcolor{comment}{* last sequence is shorter than the window length (analysis can  be  done,}}
\DoxyCodeLine{6228 \textcolor{comment}{  but we can not perform reconstruction on the last sequence)}}
\DoxyCodeLine{6229 \textcolor{comment}{}}
\DoxyCodeLine{6230 \textcolor{comment}{Calling this function in degenerate cases returns following result:}}
\DoxyCodeLine{6231 \textcolor{comment}{* in any case, WindowWidth ticks is returned}}
\DoxyCodeLine{6232 \textcolor{comment}{* trend is assumed to be zero}}
\DoxyCodeLine{6233 \textcolor{comment}{* noise is initialized by the last sequence; if last sequence  is  shorter}}
\DoxyCodeLine{6234 \textcolor{comment}{  than the window size, it is moved to  the  end  of  the  array, and  the}}
\DoxyCodeLine{6235 \textcolor{comment}{  beginning of the noise array is filled by zeros}}
\DoxyCodeLine{6236 \textcolor{comment}{}}
\DoxyCodeLine{6237 \textcolor{comment}{No analysis is performed in degenerate cases (we immediately return  dummy}}
\DoxyCodeLine{6238 \textcolor{comment}{values, no basis is constructed).}}
\DoxyCodeLine{6239 \textcolor{comment}{}}
\DoxyCodeLine{6240 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{6241 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{6242 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{6243 \textcolor{keywordtype}{void} ssaanalyzelastwindow(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&trend, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&noise, ae\_int\_t \&nticks, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6244 }
\DoxyCodeLine{6245 }
\DoxyCodeLine{6246 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{6247 \textcolor{comment}{This function:}}
\DoxyCodeLine{6248 \textcolor{comment}{* builds SSA basis using internally stored (entire) dataset}}
\DoxyCodeLine{6249 \textcolor{comment}{* returns reconstruction for the last NTicks of the last sequence}}
\DoxyCodeLine{6250 \textcolor{comment}{}}
\DoxyCodeLine{6251 \textcolor{comment}{If you want to analyze some other sequence, use ssaanalyzesequence().}}
\DoxyCodeLine{6252 \textcolor{comment}{}}
\DoxyCodeLine{6253 \textcolor{comment}{Reconstruction phase involves  generation  of  NTicks-\/WindowWidth  sliding}}
\DoxyCodeLine{6254 \textcolor{comment}{windows, their decomposition using empirical orthogonal functions found by}}
\DoxyCodeLine{6255 \textcolor{comment}{SSA, followed by averaging of each data point across  several  overlapping}}
\DoxyCodeLine{6256 \textcolor{comment}{windows. Thus, every point in the output trend is reconstructed  using  up}}
\DoxyCodeLine{6257 \textcolor{comment}{to WindowWidth overlapping  windows  (WindowWidth windows exactly  in  the}}
\DoxyCodeLine{6258 \textcolor{comment}{inner points, just one window at the extremal points).}}
\DoxyCodeLine{6259 \textcolor{comment}{}}
\DoxyCodeLine{6260 \textcolor{comment}{IMPORTANT: due to averaging this function returns  different  results  for}}
\DoxyCodeLine{6261 \textcolor{comment}{           different values of NTicks. It is expected and not a bug.}}
\DoxyCodeLine{6262 \textcolor{comment}{}}
\DoxyCodeLine{6263 \textcolor{comment}{           For example:}}
\DoxyCodeLine{6264 \textcolor{comment}{           * Trend[NTicks-\/1] is always same because it is not averaged  in}}
\DoxyCodeLine{6265 \textcolor{comment}{             any case (same applies to Trend[0]).}}
\DoxyCodeLine{6266 \textcolor{comment}{           * Trend[NTicks-\/2] has different values  for  NTicks=WindowWidth}}
\DoxyCodeLine{6267 \textcolor{comment}{             and NTicks=WindowWidth+1 because former  case  means that  no}}
\DoxyCodeLine{6268 \textcolor{comment}{             averaging is performed, and latter  case means that averaging}}
\DoxyCodeLine{6269 \textcolor{comment}{             using two sliding windows  is  performed.  Larger  values  of}}
\DoxyCodeLine{6270 \textcolor{comment}{             NTicks produce same results as NTicks=WindowWidth+1.}}
\DoxyCodeLine{6271 \textcolor{comment}{           * ...and so on...}}
\DoxyCodeLine{6272 \textcolor{comment}{}}
\DoxyCodeLine{6273 \textcolor{comment}{PERFORMANCE: this  function has O((NTicks-\/WindowWidth)*WindowWidth*NBasis)}}
\DoxyCodeLine{6274 \textcolor{comment}{             running time. If you work  in  time-\/constrained  setting  and}}
\DoxyCodeLine{6275 \textcolor{comment}{             have to analyze just a few last ticks, choosing NTicks  equal}}
\DoxyCodeLine{6276 \textcolor{comment}{             to WindowWidth+SmoothingLen, with SmoothingLen=1...WindowWidth}}
\DoxyCodeLine{6277 \textcolor{comment}{             will result in good compromise between noise cancellation and}}
\DoxyCodeLine{6278 \textcolor{comment}{             analysis speed.}}
\DoxyCodeLine{6279 \textcolor{comment}{}}
\DoxyCodeLine{6280 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{6281 \textcolor{comment}{    S               -\/   SSA model}}
\DoxyCodeLine{6282 \textcolor{comment}{    NTicks          -\/   number of ticks to analyze, Nticks>=1.}}
\DoxyCodeLine{6283 \textcolor{comment}{                        * special case of NTicks<=WindowWidth  is  handled}}
\DoxyCodeLine{6284 \textcolor{comment}{                          by analyzing last window and  returning   NTicks}}
\DoxyCodeLine{6285 \textcolor{comment}{                          last ticks.}}
\DoxyCodeLine{6286 \textcolor{comment}{                        * special case NTicks>LastSequenceLen  is  handled}}
\DoxyCodeLine{6287 \textcolor{comment}{                          by prepending result with NTicks-\/LastSequenceLen}}
\DoxyCodeLine{6288 \textcolor{comment}{                          zeros.}}
\DoxyCodeLine{6289 \textcolor{comment}{}}
\DoxyCodeLine{6290 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{6291 \textcolor{comment}{    Trend           -\/   array[NTicks], reconstructed trend line}}
\DoxyCodeLine{6292 \textcolor{comment}{    Noise           -\/   array[NTicks], the rest of the signal;}}
\DoxyCodeLine{6293 \textcolor{comment}{                        it holds that ActualData = Trend+Noise.}}
\DoxyCodeLine{6294 \textcolor{comment}{}}
\DoxyCodeLine{6295 \textcolor{comment}{}}
\DoxyCodeLine{6296 \textcolor{comment}{CACHING/REUSE OF THE BASIS}}
\DoxyCodeLine{6297 \textcolor{comment}{}}
\DoxyCodeLine{6298 \textcolor{comment}{Caching/reuse of previous results is performed:}}
\DoxyCodeLine{6299 \textcolor{comment}{* first call performs full run of SSA; basis is stored in the cache}}
\DoxyCodeLine{6300 \textcolor{comment}{* subsequent calls reuse previously cached basis}}
\DoxyCodeLine{6301 \textcolor{comment}{* if you call any function which changes model properties (window  length,}}
\DoxyCodeLine{6302 \textcolor{comment}{  algorithm, dataset), internal basis will be invalidated.}}
\DoxyCodeLine{6303 \textcolor{comment}{* the only calls which do NOT invalidate basis are listed below:}}
\DoxyCodeLine{6304 \textcolor{comment}{  a) ssasetwindow() with same window length}}
\DoxyCodeLine{6305 \textcolor{comment}{  b) ssaappendpointandupdate()}}
\DoxyCodeLine{6306 \textcolor{comment}{  c) ssaappendsequenceandupdate()}}
\DoxyCodeLine{6307 \textcolor{comment}{  d) ssasetalgotopk...() with exactly same K}}
\DoxyCodeLine{6308 \textcolor{comment}{  Calling these functions will result in reuse of previously found basis.}}
\DoxyCodeLine{6309 \textcolor{comment}{}}
\DoxyCodeLine{6310 \textcolor{comment}{In  any  case,  only  basis  is  reused. Reconstruction is performed  from}}
\DoxyCodeLine{6311 \textcolor{comment}{scratch every time you call this function.}}
\DoxyCodeLine{6312 \textcolor{comment}{}}
\DoxyCodeLine{6313 \textcolor{comment}{}}
\DoxyCodeLine{6314 \textcolor{comment}{HANDLING OF DEGENERATE CASES}}
\DoxyCodeLine{6315 \textcolor{comment}{}}
\DoxyCodeLine{6316 \textcolor{comment}{Following degenerate cases may happen:}}
\DoxyCodeLine{6317 \textcolor{comment}{* dataset is empty (no analysis can be done)}}
\DoxyCodeLine{6318 \textcolor{comment}{* all sequences are shorter than the window length,no analysis can be done}}
\DoxyCodeLine{6319 \textcolor{comment}{* no algorithm is specified (no analysis can be done)}}
\DoxyCodeLine{6320 \textcolor{comment}{* last sequence is shorter than the window length (analysis  can  be done,}}
\DoxyCodeLine{6321 \textcolor{comment}{  but we can not perform reconstruction on the last sequence)}}
\DoxyCodeLine{6322 \textcolor{comment}{}}
\DoxyCodeLine{6323 \textcolor{comment}{Calling this function in degenerate cases returns following result:}}
\DoxyCodeLine{6324 \textcolor{comment}{* in any case, NTicks ticks is returned}}
\DoxyCodeLine{6325 \textcolor{comment}{* trend is assumed to be zero}}
\DoxyCodeLine{6326 \textcolor{comment}{* noise is initialized by the last sequence; if last sequence  is  shorter}}
\DoxyCodeLine{6327 \textcolor{comment}{  than the window size, it is moved to  the  end  of  the  array, and  the}}
\DoxyCodeLine{6328 \textcolor{comment}{  beginning of the noise array is filled by zeros}}
\DoxyCodeLine{6329 \textcolor{comment}{}}
\DoxyCodeLine{6330 \textcolor{comment}{No analysis is performed in degenerate cases (we immediately return  dummy}}
\DoxyCodeLine{6331 \textcolor{comment}{values, no basis is constructed).}}
\DoxyCodeLine{6332 \textcolor{comment}{}}
\DoxyCodeLine{6333 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{6334 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{6335 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{6336 \textcolor{keywordtype}{void} ssaanalyzelast(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} ae\_int\_t nticks, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&trend, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&noise, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6337 }
\DoxyCodeLine{6338 }
\DoxyCodeLine{6339 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{6340 \textcolor{comment}{This function:}}
\DoxyCodeLine{6341 \textcolor{comment}{* builds SSA basis using internally stored (entire) dataset}}
\DoxyCodeLine{6342 \textcolor{comment}{* returns reconstruction for the sequence being passed to this function}}
\DoxyCodeLine{6343 \textcolor{comment}{}}
\DoxyCodeLine{6344 \textcolor{comment}{If  you  want  to  analyze  last  sequence  stored  in   the   model,  use}}
\DoxyCodeLine{6345 \textcolor{comment}{ssaanalyzelast().}}
\DoxyCodeLine{6346 \textcolor{comment}{}}
\DoxyCodeLine{6347 \textcolor{comment}{Reconstruction phase involves  generation  of  NTicks-\/WindowWidth  sliding}}
\DoxyCodeLine{6348 \textcolor{comment}{windows, their decomposition using empirical orthogonal functions found by}}
\DoxyCodeLine{6349 \textcolor{comment}{SSA, followed by averaging of each data point across  several  overlapping}}
\DoxyCodeLine{6350 \textcolor{comment}{windows. Thus, every point in the output trend is reconstructed  using  up}}
\DoxyCodeLine{6351 \textcolor{comment}{to WindowWidth overlapping  windows  (WindowWidth windows exactly  in  the}}
\DoxyCodeLine{6352 \textcolor{comment}{inner points, just one window at the extremal points).}}
\DoxyCodeLine{6353 \textcolor{comment}{}}
\DoxyCodeLine{6354 \textcolor{comment}{PERFORMANCE: this  function has O((NTicks-\/WindowWidth)*WindowWidth*NBasis)}}
\DoxyCodeLine{6355 \textcolor{comment}{             running time. If you work  in  time-\/constrained  setting  and}}
\DoxyCodeLine{6356 \textcolor{comment}{             have to analyze just a few last ticks, choosing NTicks  equal}}
\DoxyCodeLine{6357 \textcolor{comment}{             to WindowWidth+SmoothingLen, with SmoothingLen=1...WindowWidth}}
\DoxyCodeLine{6358 \textcolor{comment}{             will result in good compromise between noise cancellation and}}
\DoxyCodeLine{6359 \textcolor{comment}{             analysis speed.}}
\DoxyCodeLine{6360 \textcolor{comment}{}}
\DoxyCodeLine{6361 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{6362 \textcolor{comment}{    S               -\/   SSA model}}
\DoxyCodeLine{6363 \textcolor{comment}{    Data            -\/   array[NTicks], can be larger (only NTicks  leading}}
\DoxyCodeLine{6364 \textcolor{comment}{                        elements will be used)}}
\DoxyCodeLine{6365 \textcolor{comment}{    NTicks          -\/   number of ticks to analyze, Nticks>=1.}}
\DoxyCodeLine{6366 \textcolor{comment}{                        * special case of NTicks<WindowWidth  is   handled}}
\DoxyCodeLine{6367 \textcolor{comment}{                          by returning zeros as trend, and signal as noise}}
\DoxyCodeLine{6368 \textcolor{comment}{}}
\DoxyCodeLine{6369 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{6370 \textcolor{comment}{    Trend           -\/   array[NTicks], reconstructed trend line}}
\DoxyCodeLine{6371 \textcolor{comment}{    Noise           -\/   array[NTicks], the rest of the signal;}}
\DoxyCodeLine{6372 \textcolor{comment}{                        it holds that ActualData = Trend+Noise.}}
\DoxyCodeLine{6373 \textcolor{comment}{}}
\DoxyCodeLine{6374 \textcolor{comment}{}}
\DoxyCodeLine{6375 \textcolor{comment}{CACHING/REUSE OF THE BASIS}}
\DoxyCodeLine{6376 \textcolor{comment}{}}
\DoxyCodeLine{6377 \textcolor{comment}{Caching/reuse of previous results is performed:}}
\DoxyCodeLine{6378 \textcolor{comment}{* first call performs full run of SSA; basis is stored in the cache}}
\DoxyCodeLine{6379 \textcolor{comment}{* subsequent calls reuse previously cached basis}}
\DoxyCodeLine{6380 \textcolor{comment}{* if you call any function which changes model properties (window  length,}}
\DoxyCodeLine{6381 \textcolor{comment}{  algorithm, dataset), internal basis will be invalidated.}}
\DoxyCodeLine{6382 \textcolor{comment}{* the only calls which do NOT invalidate basis are listed below:}}
\DoxyCodeLine{6383 \textcolor{comment}{  a) ssasetwindow() with same window length}}
\DoxyCodeLine{6384 \textcolor{comment}{  b) ssaappendpointandupdate()}}
\DoxyCodeLine{6385 \textcolor{comment}{  c) ssaappendsequenceandupdate()}}
\DoxyCodeLine{6386 \textcolor{comment}{  d) ssasetalgotopk...() with exactly same K}}
\DoxyCodeLine{6387 \textcolor{comment}{  Calling these functions will result in reuse of previously found basis.}}
\DoxyCodeLine{6388 \textcolor{comment}{}}
\DoxyCodeLine{6389 \textcolor{comment}{In  any  case,  only  basis  is  reused. Reconstruction is performed  from}}
\DoxyCodeLine{6390 \textcolor{comment}{scratch every time you call this function.}}
\DoxyCodeLine{6391 \textcolor{comment}{}}
\DoxyCodeLine{6392 \textcolor{comment}{}}
\DoxyCodeLine{6393 \textcolor{comment}{HANDLING OF DEGENERATE CASES}}
\DoxyCodeLine{6394 \textcolor{comment}{}}
\DoxyCodeLine{6395 \textcolor{comment}{Following degenerate cases may happen:}}
\DoxyCodeLine{6396 \textcolor{comment}{* dataset is empty (no analysis can be done)}}
\DoxyCodeLine{6397 \textcolor{comment}{* all sequences are shorter than the window length,no analysis can be done}}
\DoxyCodeLine{6398 \textcolor{comment}{* no algorithm is specified (no analysis can be done)}}
\DoxyCodeLine{6399 \textcolor{comment}{* sequence being passed is shorter than the window length}}
\DoxyCodeLine{6400 \textcolor{comment}{}}
\DoxyCodeLine{6401 \textcolor{comment}{Calling this function in degenerate cases returns following result:}}
\DoxyCodeLine{6402 \textcolor{comment}{* in any case, NTicks ticks is returned}}
\DoxyCodeLine{6403 \textcolor{comment}{* trend is assumed to be zero}}
\DoxyCodeLine{6404 \textcolor{comment}{* noise is initialized by the sequence.}}
\DoxyCodeLine{6405 \textcolor{comment}{}}
\DoxyCodeLine{6406 \textcolor{comment}{No analysis is performed in degenerate cases (we immediately return  dummy}}
\DoxyCodeLine{6407 \textcolor{comment}{values, no basis is constructed).}}
\DoxyCodeLine{6408 \textcolor{comment}{}}
\DoxyCodeLine{6409 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{6410 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{6411 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{6412 \textcolor{keywordtype}{void} ssaanalyzesequence(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&data, \textcolor{keyword}{const} ae\_int\_t nticks, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&trend, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&noise, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6413 \textcolor{keywordtype}{void} ssaanalyzesequence(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&data, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&trend, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&noise, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6414 }
\DoxyCodeLine{6415 }
\DoxyCodeLine{6416 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{6417 \textcolor{comment}{This function builds SSA basis and performs forecasting  for  a  specified}}
\DoxyCodeLine{6418 \textcolor{comment}{number of ticks, returning value of trend.}}
\DoxyCodeLine{6419 \textcolor{comment}{}}
\DoxyCodeLine{6420 \textcolor{comment}{Forecast is performed as follows:}}
\DoxyCodeLine{6421 \textcolor{comment}{* SSA  trend  extraction  is  applied  to last WindowWidth elements of the}}
\DoxyCodeLine{6422 \textcolor{comment}{  internally stored dataset; this step is basically a noise reduction.}}
\DoxyCodeLine{6423 \textcolor{comment}{* linear recurrence relation is applied to extracted trend}}
\DoxyCodeLine{6424 \textcolor{comment}{}}
\DoxyCodeLine{6425 \textcolor{comment}{This function has following running time:}}
\DoxyCodeLine{6426 \textcolor{comment}{* O(NBasis*WindowWidth) for trend extraction phase (always performed)}}
\DoxyCodeLine{6427 \textcolor{comment}{* O(WindowWidth*NTicks) for forecast phase}}
\DoxyCodeLine{6428 \textcolor{comment}{}}
\DoxyCodeLine{6429 \textcolor{comment}{NOTE: noise reduction is ALWAYS applied by this algorithm; if you want  to}}
\DoxyCodeLine{6430 \textcolor{comment}{      apply recurrence relation  to  raw  unprocessed  data,  use  another}}
\DoxyCodeLine{6431 \textcolor{comment}{      function -\/ ssaforecastsequence() which allows to  turn  on  and  off}}
\DoxyCodeLine{6432 \textcolor{comment}{      noise reduction phase.}}
\DoxyCodeLine{6433 \textcolor{comment}{}}
\DoxyCodeLine{6434 \textcolor{comment}{NOTE: this algorithm performs prediction using only one -\/ last  -\/  sliding}}
\DoxyCodeLine{6435 \textcolor{comment}{      window.  Predictions  produced   by   such   approach   are   smooth}}
\DoxyCodeLine{6436 \textcolor{comment}{      continuations of the reconstructed  trend  line,  but  they  can  be}}
\DoxyCodeLine{6437 \textcolor{comment}{      easily corrupted by noise. If you need  noise-\/resistant  prediction,}}
\DoxyCodeLine{6438 \textcolor{comment}{      use ssaforecastavglast() function, which averages predictions  built}}
\DoxyCodeLine{6439 \textcolor{comment}{      using several sliding windows.}}
\DoxyCodeLine{6440 \textcolor{comment}{}}
\DoxyCodeLine{6441 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{6442 \textcolor{comment}{    S               -\/   SSA model}}
\DoxyCodeLine{6443 \textcolor{comment}{    NTicks          -\/   number of ticks to forecast, NTicks>=1}}
\DoxyCodeLine{6444 \textcolor{comment}{}}
\DoxyCodeLine{6445 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{6446 \textcolor{comment}{    Trend           -\/   array[NTicks], predicted trend line}}
\DoxyCodeLine{6447 \textcolor{comment}{}}
\DoxyCodeLine{6448 \textcolor{comment}{}}
\DoxyCodeLine{6449 \textcolor{comment}{CACHING/REUSE OF THE BASIS}}
\DoxyCodeLine{6450 \textcolor{comment}{}}
\DoxyCodeLine{6451 \textcolor{comment}{Caching/reuse of previous results is performed:}}
\DoxyCodeLine{6452 \textcolor{comment}{* first call performs full run of SSA; basis is stored in the cache}}
\DoxyCodeLine{6453 \textcolor{comment}{* subsequent calls reuse previously cached basis}}
\DoxyCodeLine{6454 \textcolor{comment}{* if you call any function which changes model properties (window  length,}}
\DoxyCodeLine{6455 \textcolor{comment}{  algorithm, dataset), internal basis will be invalidated.}}
\DoxyCodeLine{6456 \textcolor{comment}{* the only calls which do NOT invalidate basis are listed below:}}
\DoxyCodeLine{6457 \textcolor{comment}{  a) ssasetwindow() with same window length}}
\DoxyCodeLine{6458 \textcolor{comment}{  b) ssaappendpointandupdate()}}
\DoxyCodeLine{6459 \textcolor{comment}{  c) ssaappendsequenceandupdate()}}
\DoxyCodeLine{6460 \textcolor{comment}{  d) ssasetalgotopk...() with exactly same K}}
\DoxyCodeLine{6461 \textcolor{comment}{  Calling these functions will result in reuse of previously found basis.}}
\DoxyCodeLine{6462 \textcolor{comment}{}}
\DoxyCodeLine{6463 \textcolor{comment}{}}
\DoxyCodeLine{6464 \textcolor{comment}{HANDLING OF DEGENERATE CASES}}
\DoxyCodeLine{6465 \textcolor{comment}{}}
\DoxyCodeLine{6466 \textcolor{comment}{Following degenerate cases may happen:}}
\DoxyCodeLine{6467 \textcolor{comment}{* dataset is empty (no analysis can be done)}}
\DoxyCodeLine{6468 \textcolor{comment}{* all sequences are shorter than the window length,no analysis can be done}}
\DoxyCodeLine{6469 \textcolor{comment}{* no algorithm is specified (no analysis can be done)}}
\DoxyCodeLine{6470 \textcolor{comment}{* last sequence is shorter than the WindowWidth   (analysis  can  be done,}}
\DoxyCodeLine{6471 \textcolor{comment}{  but we can not perform forecasting on the last sequence)}}
\DoxyCodeLine{6472 \textcolor{comment}{* window lentgh is 1 (impossible to use for forecasting)}}
\DoxyCodeLine{6473 \textcolor{comment}{* SSA analysis algorithm is  configured  to  extract  basis  whose size is}}
\DoxyCodeLine{6474 \textcolor{comment}{  equal to window length (impossible to use for  forecasting;  only  basis}}
\DoxyCodeLine{6475 \textcolor{comment}{  whose size is less than window length can be used).}}
\DoxyCodeLine{6476 \textcolor{comment}{}}
\DoxyCodeLine{6477 \textcolor{comment}{Calling this function in degenerate cases returns following result:}}
\DoxyCodeLine{6478 \textcolor{comment}{* NTicks  copies  of  the  last  value is returned for non-\/empty task with}}
\DoxyCodeLine{6479 \textcolor{comment}{  large enough dataset, but with overcomplete  basis  (window  width=1  or}}
\DoxyCodeLine{6480 \textcolor{comment}{  basis size is equal to window width)}}
\DoxyCodeLine{6481 \textcolor{comment}{* zero trend with length=NTicks is returned for empty task}}
\DoxyCodeLine{6482 \textcolor{comment}{}}
\DoxyCodeLine{6483 \textcolor{comment}{No analysis is performed in degenerate cases (we immediately return  dummy}}
\DoxyCodeLine{6484 \textcolor{comment}{values, no basis is ever constructed).}}
\DoxyCodeLine{6485 \textcolor{comment}{}}
\DoxyCodeLine{6486 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{6487 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{6488 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{6489 \textcolor{keywordtype}{void} ssaforecastlast(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} ae\_int\_t nticks, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&trend, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6490 }
\DoxyCodeLine{6491 }
\DoxyCodeLine{6492 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{6493 \textcolor{comment}{This function builds SSA  basis  and  performs  forecasting  for  a  user-\/}}
\DoxyCodeLine{6494 \textcolor{comment}{specified sequence, returning value of trend.}}
\DoxyCodeLine{6495 \textcolor{comment}{}}
\DoxyCodeLine{6496 \textcolor{comment}{Forecasting is done in two stages:}}
\DoxyCodeLine{6497 \textcolor{comment}{* first,  we  extract  trend  from the WindowWidth  last  elements of  the}}
\DoxyCodeLine{6498 \textcolor{comment}{  sequence. This stage is optional, you  can  turn  it  off  if  you  pass}}
\DoxyCodeLine{6499 \textcolor{comment}{  data which are already processed with SSA. Of course, you  can  turn  it}}
\DoxyCodeLine{6500 \textcolor{comment}{  off even for raw data, but it is not recommended -\/ noise suppression  is}}
\DoxyCodeLine{6501 \textcolor{comment}{  very important for correct prediction.}}
\DoxyCodeLine{6502 \textcolor{comment}{* then, we apply LRR for last  WindowWidth-\/1  elements  of  the  extracted}}
\DoxyCodeLine{6503 \textcolor{comment}{  trend.}}
\DoxyCodeLine{6504 \textcolor{comment}{}}
\DoxyCodeLine{6505 \textcolor{comment}{This function has following running time:}}
\DoxyCodeLine{6506 \textcolor{comment}{* O(NBasis*WindowWidth) for trend extraction phase}}
\DoxyCodeLine{6507 \textcolor{comment}{* O(WindowWidth*NTicks) for forecast phase}}
\DoxyCodeLine{6508 \textcolor{comment}{}}
\DoxyCodeLine{6509 \textcolor{comment}{NOTE: this algorithm performs prediction using only one -\/ last  -\/  sliding}}
\DoxyCodeLine{6510 \textcolor{comment}{      window.  Predictions  produced   by   such   approach   are   smooth}}
\DoxyCodeLine{6511 \textcolor{comment}{      continuations of the reconstructed  trend  line,  but  they  can  be}}
\DoxyCodeLine{6512 \textcolor{comment}{      easily corrupted by noise. If you need  noise-\/resistant  prediction,}}
\DoxyCodeLine{6513 \textcolor{comment}{      use ssaforecastavgsequence() function,  which  averages  predictions}}
\DoxyCodeLine{6514 \textcolor{comment}{      built using several sliding windows.}}
\DoxyCodeLine{6515 \textcolor{comment}{}}
\DoxyCodeLine{6516 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{6517 \textcolor{comment}{    S               -\/   SSA model}}
\DoxyCodeLine{6518 \textcolor{comment}{    Data            -\/   array[NTicks], data to forecast}}
\DoxyCodeLine{6519 \textcolor{comment}{    DataLen         -\/   number of ticks in the data, DataLen>=1}}
\DoxyCodeLine{6520 \textcolor{comment}{    ForecastLen     -\/   number of ticks to predict, ForecastLen>=1}}
\DoxyCodeLine{6521 \textcolor{comment}{    ApplySmoothing  -\/   whether to apply smoothing trend extraction or not;}}
\DoxyCodeLine{6522 \textcolor{comment}{                        if you do not know what to specify, pass True.}}
\DoxyCodeLine{6523 \textcolor{comment}{}}
\DoxyCodeLine{6524 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{6525 \textcolor{comment}{    Trend           -\/   array[ForecastLen], forecasted trend}}
\DoxyCodeLine{6526 \textcolor{comment}{}}
\DoxyCodeLine{6527 \textcolor{comment}{}}
\DoxyCodeLine{6528 \textcolor{comment}{CACHING/REUSE OF THE BASIS}}
\DoxyCodeLine{6529 \textcolor{comment}{}}
\DoxyCodeLine{6530 \textcolor{comment}{Caching/reuse of previous results is performed:}}
\DoxyCodeLine{6531 \textcolor{comment}{* first call performs full run of SSA; basis is stored in the cache}}
\DoxyCodeLine{6532 \textcolor{comment}{* subsequent calls reuse previously cached basis}}
\DoxyCodeLine{6533 \textcolor{comment}{* if you call any function which changes model properties (window  length,}}
\DoxyCodeLine{6534 \textcolor{comment}{  algorithm, dataset), internal basis will be invalidated.}}
\DoxyCodeLine{6535 \textcolor{comment}{* the only calls which do NOT invalidate basis are listed below:}}
\DoxyCodeLine{6536 \textcolor{comment}{  a) ssasetwindow() with same window length}}
\DoxyCodeLine{6537 \textcolor{comment}{  b) ssaappendpointandupdate()}}
\DoxyCodeLine{6538 \textcolor{comment}{  c) ssaappendsequenceandupdate()}}
\DoxyCodeLine{6539 \textcolor{comment}{  d) ssasetalgotopk...() with exactly same K}}
\DoxyCodeLine{6540 \textcolor{comment}{  Calling these functions will result in reuse of previously found basis.}}
\DoxyCodeLine{6541 \textcolor{comment}{}}
\DoxyCodeLine{6542 \textcolor{comment}{}}
\DoxyCodeLine{6543 \textcolor{comment}{HANDLING OF DEGENERATE CASES}}
\DoxyCodeLine{6544 \textcolor{comment}{}}
\DoxyCodeLine{6545 \textcolor{comment}{Following degenerate cases may happen:}}
\DoxyCodeLine{6546 \textcolor{comment}{* dataset is empty (no analysis can be done)}}
\DoxyCodeLine{6547 \textcolor{comment}{* all sequences are shorter than the window length,no analysis can be done}}
\DoxyCodeLine{6548 \textcolor{comment}{* no algorithm is specified (no analysis can be done)}}
\DoxyCodeLine{6549 \textcolor{comment}{* data sequence is shorter than the WindowWidth   (analysis  can  be done,}}
\DoxyCodeLine{6550 \textcolor{comment}{  but we can not perform forecasting on the last sequence)}}
\DoxyCodeLine{6551 \textcolor{comment}{* window lentgh is 1 (impossible to use for forecasting)}}
\DoxyCodeLine{6552 \textcolor{comment}{* SSA analysis algorithm is  configured  to  extract  basis  whose size is}}
\DoxyCodeLine{6553 \textcolor{comment}{  equal to window length (impossible to use for  forecasting;  only  basis}}
\DoxyCodeLine{6554 \textcolor{comment}{  whose size is less than window length can be used).}}
\DoxyCodeLine{6555 \textcolor{comment}{}}
\DoxyCodeLine{6556 \textcolor{comment}{Calling this function in degenerate cases returns following result:}}
\DoxyCodeLine{6557 \textcolor{comment}{* ForecastLen copies of the last value is returned for non-\/empty task with}}
\DoxyCodeLine{6558 \textcolor{comment}{  large enough dataset, but with overcomplete  basis  (window  width=1  or}}
\DoxyCodeLine{6559 \textcolor{comment}{  basis size is equal to window width)}}
\DoxyCodeLine{6560 \textcolor{comment}{* zero trend with length=ForecastLen is returned for empty task}}
\DoxyCodeLine{6561 \textcolor{comment}{}}
\DoxyCodeLine{6562 \textcolor{comment}{No analysis is performed in degenerate cases (we immediately return  dummy}}
\DoxyCodeLine{6563 \textcolor{comment}{values, no basis is ever constructed).}}
\DoxyCodeLine{6564 \textcolor{comment}{}}
\DoxyCodeLine{6565 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{6566 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{6567 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{6568 \textcolor{keywordtype}{void} ssaforecastsequence(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&data, \textcolor{keyword}{const} ae\_int\_t datalen, \textcolor{keyword}{const} ae\_int\_t forecastlen, \textcolor{keyword}{const} \textcolor{keywordtype}{bool} applysmoothing, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&trend, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6569 \textcolor{keywordtype}{void} ssaforecastsequence(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&data, \textcolor{keyword}{const} ae\_int\_t forecastlen, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&trend, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6570 }
\DoxyCodeLine{6571 }
\DoxyCodeLine{6572 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{6573 \textcolor{comment}{This function builds SSA basis and performs forecasting  for  a  specified}}
\DoxyCodeLine{6574 \textcolor{comment}{number of ticks, returning value of trend.}}
\DoxyCodeLine{6575 \textcolor{comment}{}}
\DoxyCodeLine{6576 \textcolor{comment}{Forecast is performed as follows:}}
\DoxyCodeLine{6577 \textcolor{comment}{* SSA  trend  extraction  is  applied to last  M  sliding windows  of  the}}
\DoxyCodeLine{6578 \textcolor{comment}{  internally stored dataset}}
\DoxyCodeLine{6579 \textcolor{comment}{* for each of M sliding windows, M predictions are built}}
\DoxyCodeLine{6580 \textcolor{comment}{* average value of M predictions is returned}}
\DoxyCodeLine{6581 \textcolor{comment}{}}
\DoxyCodeLine{6582 \textcolor{comment}{This function has following running time:}}
\DoxyCodeLine{6583 \textcolor{comment}{* O(NBasis*WindowWidth*M) for trend extraction phase (always performed)}}
\DoxyCodeLine{6584 \textcolor{comment}{* O(WindowWidth*NTicks*M) for forecast phase}}
\DoxyCodeLine{6585 \textcolor{comment}{}}
\DoxyCodeLine{6586 \textcolor{comment}{NOTE: noise reduction is ALWAYS applied by this algorithm; if you want  to}}
\DoxyCodeLine{6587 \textcolor{comment}{      apply recurrence relation  to  raw  unprocessed  data,  use  another}}
\DoxyCodeLine{6588 \textcolor{comment}{      function -\/ ssaforecastsequence() which allows to  turn  on  and  off}}
\DoxyCodeLine{6589 \textcolor{comment}{      noise reduction phase.}}
\DoxyCodeLine{6590 \textcolor{comment}{}}
\DoxyCodeLine{6591 \textcolor{comment}{NOTE: combination of several predictions results in lesser sensitivity  to}}
\DoxyCodeLine{6592 \textcolor{comment}{      noise, but it may produce undesirable discontinuities  between  last}}
\DoxyCodeLine{6593 \textcolor{comment}{      point of the trend and first point of the prediction. The reason  is}}
\DoxyCodeLine{6594 \textcolor{comment}{      that  last  point  of  the  trend is usually corrupted by noise, but}}
\DoxyCodeLine{6595 \textcolor{comment}{      average  value of  several  predictions  is less sensitive to noise,}}
\DoxyCodeLine{6596 \textcolor{comment}{      thus discontinuity appears. It is not a bug.}}
\DoxyCodeLine{6597 \textcolor{comment}{}}
\DoxyCodeLine{6598 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{6599 \textcolor{comment}{    S               -\/   SSA model}}
\DoxyCodeLine{6600 \textcolor{comment}{    M               -\/   number  of  sliding  windows  to combine, M>=1. If}}
\DoxyCodeLine{6601 \textcolor{comment}{                        your dataset has less than M sliding windows, this}}
\DoxyCodeLine{6602 \textcolor{comment}{                        parameter will be silently reduced.}}
\DoxyCodeLine{6603 \textcolor{comment}{    NTicks          -\/   number of ticks to forecast, NTicks>=1}}
\DoxyCodeLine{6604 \textcolor{comment}{}}
\DoxyCodeLine{6605 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{6606 \textcolor{comment}{    Trend           -\/   array[NTicks], predicted trend line}}
\DoxyCodeLine{6607 \textcolor{comment}{}}
\DoxyCodeLine{6608 \textcolor{comment}{}}
\DoxyCodeLine{6609 \textcolor{comment}{CACHING/REUSE OF THE BASIS}}
\DoxyCodeLine{6610 \textcolor{comment}{}}
\DoxyCodeLine{6611 \textcolor{comment}{Caching/reuse of previous results is performed:}}
\DoxyCodeLine{6612 \textcolor{comment}{* first call performs full run of SSA; basis is stored in the cache}}
\DoxyCodeLine{6613 \textcolor{comment}{* subsequent calls reuse previously cached basis}}
\DoxyCodeLine{6614 \textcolor{comment}{* if you call any function which changes model properties (window  length,}}
\DoxyCodeLine{6615 \textcolor{comment}{  algorithm, dataset), internal basis will be invalidated.}}
\DoxyCodeLine{6616 \textcolor{comment}{* the only calls which do NOT invalidate basis are listed below:}}
\DoxyCodeLine{6617 \textcolor{comment}{  a) ssasetwindow() with same window length}}
\DoxyCodeLine{6618 \textcolor{comment}{  b) ssaappendpointandupdate()}}
\DoxyCodeLine{6619 \textcolor{comment}{  c) ssaappendsequenceandupdate()}}
\DoxyCodeLine{6620 \textcolor{comment}{  d) ssasetalgotopk...() with exactly same K}}
\DoxyCodeLine{6621 \textcolor{comment}{  Calling these functions will result in reuse of previously found basis.}}
\DoxyCodeLine{6622 \textcolor{comment}{}}
\DoxyCodeLine{6623 \textcolor{comment}{}}
\DoxyCodeLine{6624 \textcolor{comment}{HANDLING OF DEGENERATE CASES}}
\DoxyCodeLine{6625 \textcolor{comment}{}}
\DoxyCodeLine{6626 \textcolor{comment}{Following degenerate cases may happen:}}
\DoxyCodeLine{6627 \textcolor{comment}{* dataset is empty (no analysis can be done)}}
\DoxyCodeLine{6628 \textcolor{comment}{* all sequences are shorter than the window length,no analysis can be done}}
\DoxyCodeLine{6629 \textcolor{comment}{* no algorithm is specified (no analysis can be done)}}
\DoxyCodeLine{6630 \textcolor{comment}{* last sequence is shorter than the WindowWidth   (analysis  can  be done,}}
\DoxyCodeLine{6631 \textcolor{comment}{  but we can not perform forecasting on the last sequence)}}
\DoxyCodeLine{6632 \textcolor{comment}{* window lentgh is 1 (impossible to use for forecasting)}}
\DoxyCodeLine{6633 \textcolor{comment}{* SSA analysis algorithm is  configured  to  extract  basis  whose size is}}
\DoxyCodeLine{6634 \textcolor{comment}{  equal to window length (impossible to use for  forecasting;  only  basis}}
\DoxyCodeLine{6635 \textcolor{comment}{  whose size is less than window length can be used).}}
\DoxyCodeLine{6636 \textcolor{comment}{}}
\DoxyCodeLine{6637 \textcolor{comment}{Calling this function in degenerate cases returns following result:}}
\DoxyCodeLine{6638 \textcolor{comment}{* NTicks  copies  of  the  last  value is returned for non-\/empty task with}}
\DoxyCodeLine{6639 \textcolor{comment}{  large enough dataset, but with overcomplete  basis  (window  width=1  or}}
\DoxyCodeLine{6640 \textcolor{comment}{  basis size is equal to window width)}}
\DoxyCodeLine{6641 \textcolor{comment}{* zero trend with length=NTicks is returned for empty task}}
\DoxyCodeLine{6642 \textcolor{comment}{}}
\DoxyCodeLine{6643 \textcolor{comment}{No analysis is performed in degenerate cases (we immediately return  dummy}}
\DoxyCodeLine{6644 \textcolor{comment}{values, no basis is ever constructed).}}
\DoxyCodeLine{6645 \textcolor{comment}{}}
\DoxyCodeLine{6646 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{6647 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{6648 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{6649 \textcolor{keywordtype}{void} ssaforecastavglast(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} ae\_int\_t m, \textcolor{keyword}{const} ae\_int\_t nticks, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&trend, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6650 }
\DoxyCodeLine{6651 }
\DoxyCodeLine{6652 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{6653 \textcolor{comment}{This function builds SSA  basis  and  performs  forecasting  for  a  user-\/}}
\DoxyCodeLine{6654 \textcolor{comment}{specified sequence, returning value of trend.}}
\DoxyCodeLine{6655 \textcolor{comment}{}}
\DoxyCodeLine{6656 \textcolor{comment}{Forecasting is done in two stages:}}
\DoxyCodeLine{6657 \textcolor{comment}{* first,  we  extract  trend  from M last sliding windows of the sequence.}}
\DoxyCodeLine{6658 \textcolor{comment}{  This stage is optional, you can  turn  it  off  if  you  pass data which}}
\DoxyCodeLine{6659 \textcolor{comment}{  are already processed with SSA. Of course, you  can  turn  it  off  even}}
\DoxyCodeLine{6660 \textcolor{comment}{  for raw data, but it is not recommended  -\/  noise  suppression  is  very}}
\DoxyCodeLine{6661 \textcolor{comment}{  important for correct prediction.}}
\DoxyCodeLine{6662 \textcolor{comment}{* then, we apply LRR independently for M sliding windows}}
\DoxyCodeLine{6663 \textcolor{comment}{* average of M predictions is returned}}
\DoxyCodeLine{6664 \textcolor{comment}{}}
\DoxyCodeLine{6665 \textcolor{comment}{This function has following running time:}}
\DoxyCodeLine{6666 \textcolor{comment}{* O(NBasis*WindowWidth*M) for trend extraction phase}}
\DoxyCodeLine{6667 \textcolor{comment}{* O(WindowWidth*NTicks*M) for forecast phase}}
\DoxyCodeLine{6668 \textcolor{comment}{}}
\DoxyCodeLine{6669 \textcolor{comment}{NOTE: combination of several predictions results in lesser sensitivity  to}}
\DoxyCodeLine{6670 \textcolor{comment}{      noise, but it may produce undesirable discontinuities  between  last}}
\DoxyCodeLine{6671 \textcolor{comment}{      point of the trend and first point of the prediction. The reason  is}}
\DoxyCodeLine{6672 \textcolor{comment}{      that  last  point  of  the  trend is usually corrupted by noise, but}}
\DoxyCodeLine{6673 \textcolor{comment}{      average  value of  several  predictions  is less sensitive to noise,}}
\DoxyCodeLine{6674 \textcolor{comment}{      thus discontinuity appears. It is not a bug.}}
\DoxyCodeLine{6675 \textcolor{comment}{}}
\DoxyCodeLine{6676 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{6677 \textcolor{comment}{    S               -\/   SSA model}}
\DoxyCodeLine{6678 \textcolor{comment}{    Data            -\/   array[NTicks], data to forecast}}
\DoxyCodeLine{6679 \textcolor{comment}{    DataLen         -\/   number of ticks in the data, DataLen>=1}}
\DoxyCodeLine{6680 \textcolor{comment}{    M               -\/   number  of  sliding  windows  to combine, M>=1. If}}
\DoxyCodeLine{6681 \textcolor{comment}{                        your dataset has less than M sliding windows, this}}
\DoxyCodeLine{6682 \textcolor{comment}{                        parameter will be silently reduced.}}
\DoxyCodeLine{6683 \textcolor{comment}{    ForecastLen     -\/   number of ticks to predict, ForecastLen>=1}}
\DoxyCodeLine{6684 \textcolor{comment}{    ApplySmoothing  -\/   whether to apply smoothing trend extraction or not.}}
\DoxyCodeLine{6685 \textcolor{comment}{                        if you do not know what to specify, pass true.}}
\DoxyCodeLine{6686 \textcolor{comment}{}}
\DoxyCodeLine{6687 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{6688 \textcolor{comment}{    Trend           -\/   array[ForecastLen], forecasted trend}}
\DoxyCodeLine{6689 \textcolor{comment}{}}
\DoxyCodeLine{6690 \textcolor{comment}{}}
\DoxyCodeLine{6691 \textcolor{comment}{CACHING/REUSE OF THE BASIS}}
\DoxyCodeLine{6692 \textcolor{comment}{}}
\DoxyCodeLine{6693 \textcolor{comment}{Caching/reuse of previous results is performed:}}
\DoxyCodeLine{6694 \textcolor{comment}{* first call performs full run of SSA; basis is stored in the cache}}
\DoxyCodeLine{6695 \textcolor{comment}{* subsequent calls reuse previously cached basis}}
\DoxyCodeLine{6696 \textcolor{comment}{* if you call any function which changes model properties (window  length,}}
\DoxyCodeLine{6697 \textcolor{comment}{  algorithm, dataset), internal basis will be invalidated.}}
\DoxyCodeLine{6698 \textcolor{comment}{* the only calls which do NOT invalidate basis are listed below:}}
\DoxyCodeLine{6699 \textcolor{comment}{  a) ssasetwindow() with same window length}}
\DoxyCodeLine{6700 \textcolor{comment}{  b) ssaappendpointandupdate()}}
\DoxyCodeLine{6701 \textcolor{comment}{  c) ssaappendsequenceandupdate()}}
\DoxyCodeLine{6702 \textcolor{comment}{  d) ssasetalgotopk...() with exactly same K}}
\DoxyCodeLine{6703 \textcolor{comment}{  Calling these functions will result in reuse of previously found basis.}}
\DoxyCodeLine{6704 \textcolor{comment}{}}
\DoxyCodeLine{6705 \textcolor{comment}{}}
\DoxyCodeLine{6706 \textcolor{comment}{HANDLING OF DEGENERATE CASES}}
\DoxyCodeLine{6707 \textcolor{comment}{}}
\DoxyCodeLine{6708 \textcolor{comment}{Following degenerate cases may happen:}}
\DoxyCodeLine{6709 \textcolor{comment}{* dataset is empty (no analysis can be done)}}
\DoxyCodeLine{6710 \textcolor{comment}{* all sequences are shorter than the window length,no analysis can be done}}
\DoxyCodeLine{6711 \textcolor{comment}{* no algorithm is specified (no analysis can be done)}}
\DoxyCodeLine{6712 \textcolor{comment}{* data sequence is shorter than the WindowWidth   (analysis  can  be done,}}
\DoxyCodeLine{6713 \textcolor{comment}{  but we can not perform forecasting on the last sequence)}}
\DoxyCodeLine{6714 \textcolor{comment}{* window lentgh is 1 (impossible to use for forecasting)}}
\DoxyCodeLine{6715 \textcolor{comment}{* SSA analysis algorithm is  configured  to  extract  basis  whose size is}}
\DoxyCodeLine{6716 \textcolor{comment}{  equal to window length (impossible to use for  forecasting;  only  basis}}
\DoxyCodeLine{6717 \textcolor{comment}{  whose size is less than window length can be used).}}
\DoxyCodeLine{6718 \textcolor{comment}{}}
\DoxyCodeLine{6719 \textcolor{comment}{Calling this function in degenerate cases returns following result:}}
\DoxyCodeLine{6720 \textcolor{comment}{* ForecastLen copies of the last value is returned for non-\/empty task with}}
\DoxyCodeLine{6721 \textcolor{comment}{  large enough dataset, but with overcomplete  basis  (window  width=1  or}}
\DoxyCodeLine{6722 \textcolor{comment}{  basis size is equal to window width)}}
\DoxyCodeLine{6723 \textcolor{comment}{* zero trend with length=ForecastLen is returned for empty task}}
\DoxyCodeLine{6724 \textcolor{comment}{}}
\DoxyCodeLine{6725 \textcolor{comment}{No analysis is performed in degenerate cases (we immediately return  dummy}}
\DoxyCodeLine{6726 \textcolor{comment}{values, no basis is ever constructed).}}
\DoxyCodeLine{6727 \textcolor{comment}{}}
\DoxyCodeLine{6728 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{6729 \textcolor{comment}{     Copyright 30.10.2017 by Bochkanov Sergey}}
\DoxyCodeLine{6730 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{6731 \textcolor{keywordtype}{void} ssaforecastavgsequence(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&data, \textcolor{keyword}{const} ae\_int\_t datalen, \textcolor{keyword}{const} ae\_int\_t m, \textcolor{keyword}{const} ae\_int\_t forecastlen, \textcolor{keyword}{const} \textcolor{keywordtype}{bool} applysmoothing, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&trend, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6732 \textcolor{keywordtype}{void} ssaforecastavgsequence(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1ssamodel}{ssamodel}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&data, \textcolor{keyword}{const} ae\_int\_t m, \textcolor{keyword}{const} ae\_int\_t forecastlen, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&trend, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6733 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{6734 }
\DoxyCodeLine{6735 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_LDA) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{6736 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{6737 \textcolor{comment}{Multiclass Fisher LDA}}
\DoxyCodeLine{6738 \textcolor{comment}{}}
\DoxyCodeLine{6739 \textcolor{comment}{Subroutine finds coefficients of linear combination which optimally separates}}
\DoxyCodeLine{6740 \textcolor{comment}{training set on classes.}}
\DoxyCodeLine{6741 \textcolor{comment}{}}
\DoxyCodeLine{6742 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{6743 \textcolor{comment}{    XY          -\/   training set, array[0..NPoints-\/1,0..NVars].}}
\DoxyCodeLine{6744 \textcolor{comment}{                    First NVars columns store values of independent}}
\DoxyCodeLine{6745 \textcolor{comment}{                    variables, next column stores number of class (from 0}}
\DoxyCodeLine{6746 \textcolor{comment}{                    to NClasses-\/1) which dataset element belongs to. Fractional}}
\DoxyCodeLine{6747 \textcolor{comment}{                    values are rounded to nearest integer.}}
\DoxyCodeLine{6748 \textcolor{comment}{    NPoints     -\/   training set size, NPoints>=0}}
\DoxyCodeLine{6749 \textcolor{comment}{    NVars       -\/   number of independent variables, NVars>=1}}
\DoxyCodeLine{6750 \textcolor{comment}{    NClasses    -\/   number of classes, NClasses>=2}}
\DoxyCodeLine{6751 \textcolor{comment}{}}
\DoxyCodeLine{6752 \textcolor{comment}{}}
\DoxyCodeLine{6753 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{6754 \textcolor{comment}{    Info        -\/   return code:}}
\DoxyCodeLine{6755 \textcolor{comment}{                    * -\/4, if internal EVD subroutine hasn't converged}}
\DoxyCodeLine{6756 \textcolor{comment}{                    * -\/2, if there is a point with class number}}
\DoxyCodeLine{6757 \textcolor{comment}{                          outside of [0..NClasses-\/1].}}
\DoxyCodeLine{6758 \textcolor{comment}{                    * -\/1, if incorrect parameters was passed (NPoints<0,}}
\DoxyCodeLine{6759 \textcolor{comment}{                          NVars<1, NClasses<2)}}
\DoxyCodeLine{6760 \textcolor{comment}{                    *  1, if task has been solved}}
\DoxyCodeLine{6761 \textcolor{comment}{                    *  2, if there was a multicollinearity in training set,}}
\DoxyCodeLine{6762 \textcolor{comment}{                          but task has been solved.}}
\DoxyCodeLine{6763 \textcolor{comment}{    W           -\/   linear combination coefficients, array[0..NVars-\/1]}}
\DoxyCodeLine{6764 \textcolor{comment}{}}
\DoxyCodeLine{6765 \textcolor{comment}{  ! FREE EDITION OF ALGLIB:}}
\DoxyCodeLine{6766 \textcolor{comment}{  !}}
\DoxyCodeLine{6767 \textcolor{comment}{  ! Free Edition of ALGLIB supports following important features for  this}}
\DoxyCodeLine{6768 \textcolor{comment}{  ! function:}}
\DoxyCodeLine{6769 \textcolor{comment}{  ! * C++ version: x64 SIMD support using C++ intrinsics}}
\DoxyCodeLine{6770 \textcolor{comment}{  ! * C\#  version: x64 SIMD support using NET5/NetCore hardware intrinsics}}
\DoxyCodeLine{6771 \textcolor{comment}{  !}}
\DoxyCodeLine{6772 \textcolor{comment}{  ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB}}
\DoxyCodeLine{6773 \textcolor{comment}{  ! Reference Manual in order  to  find  out  how to activate SIMD support}}
\DoxyCodeLine{6774 \textcolor{comment}{  ! in ALGLIB.}}
\DoxyCodeLine{6775 \textcolor{comment}{}}
\DoxyCodeLine{6776 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{6777 \textcolor{comment}{  !}}
\DoxyCodeLine{6778 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{6779 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{6780 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{6781 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{6782 \textcolor{comment}{  ! * hardware vendor (Intel) implementations of linear algebra primitives}}
\DoxyCodeLine{6783 \textcolor{comment}{  !   (C++ and C\# versions, x86/x64 platform)}}
\DoxyCodeLine{6784 \textcolor{comment}{  !}}
\DoxyCodeLine{6785 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{6786 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{6787 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{6788 \textcolor{comment}{}}
\DoxyCodeLine{6789 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{6790 \textcolor{comment}{     Copyright 31.05.2008 by Bochkanov Sergey}}
\DoxyCodeLine{6791 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{6792 \textcolor{keywordtype}{void} fisherlda(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nvars, \textcolor{keyword}{const} ae\_int\_t nclasses, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&w, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6793 }
\DoxyCodeLine{6794 }
\DoxyCodeLine{6795 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{6796 \textcolor{comment}{N-\/dimensional multiclass Fisher LDA}}
\DoxyCodeLine{6797 \textcolor{comment}{}}
\DoxyCodeLine{6798 \textcolor{comment}{Subroutine finds coefficients of linear combinations which optimally separates}}
\DoxyCodeLine{6799 \textcolor{comment}{training set on classes. It returns N-\/dimensional basis whose vector are sorted}}
\DoxyCodeLine{6800 \textcolor{comment}{by quality of training set separation (in descending order).}}
\DoxyCodeLine{6801 \textcolor{comment}{}}
\DoxyCodeLine{6802 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{6803 \textcolor{comment}{    XY          -\/   training set, array[0..NPoints-\/1,0..NVars].}}
\DoxyCodeLine{6804 \textcolor{comment}{                    First NVars columns store values of independent}}
\DoxyCodeLine{6805 \textcolor{comment}{                    variables, next column stores number of class (from 0}}
\DoxyCodeLine{6806 \textcolor{comment}{                    to NClasses-\/1) which dataset element belongs to. Fractional}}
\DoxyCodeLine{6807 \textcolor{comment}{                    values are rounded to nearest integer.}}
\DoxyCodeLine{6808 \textcolor{comment}{    NPoints     -\/   training set size, NPoints>=0}}
\DoxyCodeLine{6809 \textcolor{comment}{    NVars       -\/   number of independent variables, NVars>=1}}
\DoxyCodeLine{6810 \textcolor{comment}{    NClasses    -\/   number of classes, NClasses>=2}}
\DoxyCodeLine{6811 \textcolor{comment}{}}
\DoxyCodeLine{6812 \textcolor{comment}{}}
\DoxyCodeLine{6813 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{6814 \textcolor{comment}{    Info        -\/   return code:}}
\DoxyCodeLine{6815 \textcolor{comment}{                    * -\/4, if internal EVD subroutine hasn't converged}}
\DoxyCodeLine{6816 \textcolor{comment}{                    * -\/2, if there is a point with class number}}
\DoxyCodeLine{6817 \textcolor{comment}{                          outside of [0..NClasses-\/1].}}
\DoxyCodeLine{6818 \textcolor{comment}{                    * -\/1, if incorrect parameters was passed (NPoints<0,}}
\DoxyCodeLine{6819 \textcolor{comment}{                          NVars<1, NClasses<2)}}
\DoxyCodeLine{6820 \textcolor{comment}{                    *  1, if task has been solved}}
\DoxyCodeLine{6821 \textcolor{comment}{                    *  2, if there was a multicollinearity in training set,}}
\DoxyCodeLine{6822 \textcolor{comment}{                          but task has been solved.}}
\DoxyCodeLine{6823 \textcolor{comment}{    W           -\/   basis, array[0..NVars-\/1,0..NVars-\/1]}}
\DoxyCodeLine{6824 \textcolor{comment}{                    columns of matrix stores basis vectors, sorted by}}
\DoxyCodeLine{6825 \textcolor{comment}{                    quality of training set separation (in descending order)}}
\DoxyCodeLine{6826 \textcolor{comment}{}}
\DoxyCodeLine{6827 \textcolor{comment}{  ! FREE EDITION OF ALGLIB:}}
\DoxyCodeLine{6828 \textcolor{comment}{  !}}
\DoxyCodeLine{6829 \textcolor{comment}{  ! Free Edition of ALGLIB supports following important features for  this}}
\DoxyCodeLine{6830 \textcolor{comment}{  ! function:}}
\DoxyCodeLine{6831 \textcolor{comment}{  ! * C++ version: x64 SIMD support using C++ intrinsics}}
\DoxyCodeLine{6832 \textcolor{comment}{  ! * C\#  version: x64 SIMD support using NET5/NetCore hardware intrinsics}}
\DoxyCodeLine{6833 \textcolor{comment}{  !}}
\DoxyCodeLine{6834 \textcolor{comment}{  ! We  recommend  you  to  read  'Compiling ALGLIB' section of the ALGLIB}}
\DoxyCodeLine{6835 \textcolor{comment}{  ! Reference Manual in order  to  find  out  how to activate SIMD support}}
\DoxyCodeLine{6836 \textcolor{comment}{  ! in ALGLIB.}}
\DoxyCodeLine{6837 \textcolor{comment}{}}
\DoxyCodeLine{6838 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{6839 \textcolor{comment}{  !}}
\DoxyCodeLine{6840 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{6841 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{6842 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{6843 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{6844 \textcolor{comment}{  ! * hardware vendor (Intel) implementations of linear algebra primitives}}
\DoxyCodeLine{6845 \textcolor{comment}{  !   (C++ and C\# versions, x86/x64 platform)}}
\DoxyCodeLine{6846 \textcolor{comment}{  !}}
\DoxyCodeLine{6847 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{6848 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{6849 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{6850 \textcolor{comment}{}}
\DoxyCodeLine{6851 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{6852 \textcolor{comment}{     Copyright 31.05.2008 by Bochkanov Sergey}}
\DoxyCodeLine{6853 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{6854 \textcolor{keywordtype}{void} fisherldan(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nvars, \textcolor{keyword}{const} ae\_int\_t nclasses, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&w, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6855 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{6856 }
\DoxyCodeLine{6857 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_MCPD) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{6858 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{6859 \textcolor{comment}{DESCRIPTION:}}
\DoxyCodeLine{6860 \textcolor{comment}{}}
\DoxyCodeLine{6861 \textcolor{comment}{This function creates MCPD (Markov Chains for Population Data) solver.}}
\DoxyCodeLine{6862 \textcolor{comment}{}}
\DoxyCodeLine{6863 \textcolor{comment}{This  solver  can  be  used  to find transition matrix P for N-\/dimensional}}
\DoxyCodeLine{6864 \textcolor{comment}{prediction  problem  where transition from X[i] to X[i+1] is  modelled  as}}
\DoxyCodeLine{6865 \textcolor{comment}{    X[i+1] = P*X[i]}}
\DoxyCodeLine{6866 \textcolor{comment}{where X[i] and X[i+1] are N-\/dimensional population vectors (components  of}}
\DoxyCodeLine{6867 \textcolor{comment}{each X are non-\/negative), and P is a N*N transition matrix (elements of  P}}
\DoxyCodeLine{6868 \textcolor{comment}{are non-\/negative, each column sums to 1.0).}}
\DoxyCodeLine{6869 \textcolor{comment}{}}
\DoxyCodeLine{6870 \textcolor{comment}{Such models arise when when:}}
\DoxyCodeLine{6871 \textcolor{comment}{* there is some population of individuals}}
\DoxyCodeLine{6872 \textcolor{comment}{* individuals can have different states}}
\DoxyCodeLine{6873 \textcolor{comment}{* individuals can transit from one state to another}}
\DoxyCodeLine{6874 \textcolor{comment}{* population size is constant, i.e. there is no new individuals and no one}}
\DoxyCodeLine{6875 \textcolor{comment}{  leaves population}}
\DoxyCodeLine{6876 \textcolor{comment}{* you want to model transitions of individuals from one state into another}}
\DoxyCodeLine{6877 \textcolor{comment}{}}
\DoxyCodeLine{6878 \textcolor{comment}{USAGE:}}
\DoxyCodeLine{6879 \textcolor{comment}{}}
\DoxyCodeLine{6880 \textcolor{comment}{Here we give very brief outline of the MCPD. We strongly recommend you  to}}
\DoxyCodeLine{6881 \textcolor{comment}{read examples in the ALGLIB Reference Manual and to read ALGLIB User Guide}}
\DoxyCodeLine{6882 \textcolor{comment}{on data analysis which is available at http://www.alglib.net/dataanalysis/}}
\DoxyCodeLine{6883 \textcolor{comment}{}}
\DoxyCodeLine{6884 \textcolor{comment}{1. User initializes algorithm state with MCPDCreate() call}}
\DoxyCodeLine{6885 \textcolor{comment}{}}
\DoxyCodeLine{6886 \textcolor{comment}{2. User  adds  one  or  more  tracks -\/  sequences of states which describe}}
\DoxyCodeLine{6887 \textcolor{comment}{   evolution of a system being modelled from different starting conditions}}
\DoxyCodeLine{6888 \textcolor{comment}{}}
\DoxyCodeLine{6889 \textcolor{comment}{3. User may add optional boundary, equality  and/or  linear constraints on}}
\DoxyCodeLine{6890 \textcolor{comment}{   the coefficients of P by calling one of the following functions:}}
\DoxyCodeLine{6891 \textcolor{comment}{   * MCPDSetEC() to set equality constraints}}
\DoxyCodeLine{6892 \textcolor{comment}{   * MCPDSetBC() to set bound constraints}}
\DoxyCodeLine{6893 \textcolor{comment}{   * MCPDSetLC() to set linear constraints}}
\DoxyCodeLine{6894 \textcolor{comment}{}}
\DoxyCodeLine{6895 \textcolor{comment}{4. Optionally,  user  may  set  custom  weights  for prediction errors (by}}
\DoxyCodeLine{6896 \textcolor{comment}{   default, algorithm assigns non-\/equal, automatically chosen weights  for}}
\DoxyCodeLine{6897 \textcolor{comment}{   errors in the prediction of different components of X). It can be  done}}
\DoxyCodeLine{6898 \textcolor{comment}{   with a call of MCPDSetPredictionWeights() function.}}
\DoxyCodeLine{6899 \textcolor{comment}{}}
\DoxyCodeLine{6900 \textcolor{comment}{5. User calls MCPDSolve() function which takes algorithm  state and}}
\DoxyCodeLine{6901 \textcolor{comment}{   pointer (delegate, etc.) to callback function which calculates F/G.}}
\DoxyCodeLine{6902 \textcolor{comment}{}}
\DoxyCodeLine{6903 \textcolor{comment}{6. User calls MCPDResults() to get solution}}
\DoxyCodeLine{6904 \textcolor{comment}{}}
\DoxyCodeLine{6905 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{6906 \textcolor{comment}{    N       -\/   problem dimension, N>=1}}
\DoxyCodeLine{6907 \textcolor{comment}{}}
\DoxyCodeLine{6908 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{6909 \textcolor{comment}{    State   -\/   structure stores algorithm state}}
\DoxyCodeLine{6910 \textcolor{comment}{}}
\DoxyCodeLine{6911 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{6912 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{6913 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{6914 \textcolor{keywordtype}{void} mcpdcreate(\textcolor{keyword}{const} ae\_int\_t n, \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6915 }
\DoxyCodeLine{6916 }
\DoxyCodeLine{6917 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{6918 \textcolor{comment}{DESCRIPTION:}}
\DoxyCodeLine{6919 \textcolor{comment}{}}
\DoxyCodeLine{6920 \textcolor{comment}{This function is a specialized version of MCPDCreate()  function,  and  we}}
\DoxyCodeLine{6921 \textcolor{comment}{recommend  you  to read comments for this function for general information}}
\DoxyCodeLine{6922 \textcolor{comment}{about MCPD solver.}}
\DoxyCodeLine{6923 \textcolor{comment}{}}
\DoxyCodeLine{6924 \textcolor{comment}{This  function  creates  MCPD (Markov Chains for Population  Data)  solver}}
\DoxyCodeLine{6925 \textcolor{comment}{for "{}Entry-\/state"{} model,  i.e. model  where transition from X[i] to X[i+1]}}
\DoxyCodeLine{6926 \textcolor{comment}{is modelled as}}
\DoxyCodeLine{6927 \textcolor{comment}{    X[i+1] = P*X[i]}}
\DoxyCodeLine{6928 \textcolor{comment}{where}}
\DoxyCodeLine{6929 \textcolor{comment}{    X[i] and X[i+1] are N-\/dimensional state vectors}}
\DoxyCodeLine{6930 \textcolor{comment}{    P is a N*N transition matrix}}
\DoxyCodeLine{6931 \textcolor{comment}{and  one  selected component of X[] is called "{}entry"{} state and is treated}}
\DoxyCodeLine{6932 \textcolor{comment}{in a special way:}}
\DoxyCodeLine{6933 \textcolor{comment}{    system state always transits from "{}entry"{} state to some another state}}
\DoxyCodeLine{6934 \textcolor{comment}{    system state can not transit from any state into "{}entry"{} state}}
\DoxyCodeLine{6935 \textcolor{comment}{Such conditions basically mean that row of P which corresponds to  "{}entry"{}}}
\DoxyCodeLine{6936 \textcolor{comment}{state is zero.}}
\DoxyCodeLine{6937 \textcolor{comment}{}}
\DoxyCodeLine{6938 \textcolor{comment}{Such models arise when:}}
\DoxyCodeLine{6939 \textcolor{comment}{* there is some population of individuals}}
\DoxyCodeLine{6940 \textcolor{comment}{* individuals can have different states}}
\DoxyCodeLine{6941 \textcolor{comment}{* individuals can transit from one state to another}}
\DoxyCodeLine{6942 \textcolor{comment}{* population size is NOT constant -\/  at every moment of time there is some}}
\DoxyCodeLine{6943 \textcolor{comment}{  (unpredictable) amount of "{}new"{} individuals, which can transit into  one}}
\DoxyCodeLine{6944 \textcolor{comment}{  of the states at the next turn, but still no one leaves population}}
\DoxyCodeLine{6945 \textcolor{comment}{* you want to model transitions of individuals from one state into another}}
\DoxyCodeLine{6946 \textcolor{comment}{* but you do NOT want to predict amount of "{}new"{}  individuals  because  it}}
\DoxyCodeLine{6947 \textcolor{comment}{  does not depends on individuals already present (hence  system  can  not}}
\DoxyCodeLine{6948 \textcolor{comment}{  transit INTO entry state -\/ it can only transit FROM it).}}
\DoxyCodeLine{6949 \textcolor{comment}{}}
\DoxyCodeLine{6950 \textcolor{comment}{This model is discussed  in  more  details  in  the ALGLIB User Guide (see}}
\DoxyCodeLine{6951 \textcolor{comment}{http://www.alglib.net/dataanalysis/ for more data).}}
\DoxyCodeLine{6952 \textcolor{comment}{}}
\DoxyCodeLine{6953 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{6954 \textcolor{comment}{    N       -\/   problem dimension, N>=2}}
\DoxyCodeLine{6955 \textcolor{comment}{    EntryState-\/ index of entry state, in 0..N-\/1}}
\DoxyCodeLine{6956 \textcolor{comment}{}}
\DoxyCodeLine{6957 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{6958 \textcolor{comment}{    State   -\/   structure stores algorithm state}}
\DoxyCodeLine{6959 \textcolor{comment}{}}
\DoxyCodeLine{6960 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{6961 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{6962 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{6963 \textcolor{keywordtype}{void} mcpdcreateentry(\textcolor{keyword}{const} ae\_int\_t n, \textcolor{keyword}{const} ae\_int\_t entrystate, \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{6964 }
\DoxyCodeLine{6965 }
\DoxyCodeLine{6966 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{6967 \textcolor{comment}{DESCRIPTION:}}
\DoxyCodeLine{6968 \textcolor{comment}{}}
\DoxyCodeLine{6969 \textcolor{comment}{This function is a specialized version of MCPDCreate()  function,  and  we}}
\DoxyCodeLine{6970 \textcolor{comment}{recommend  you  to read comments for this function for general information}}
\DoxyCodeLine{6971 \textcolor{comment}{about MCPD solver.}}
\DoxyCodeLine{6972 \textcolor{comment}{}}
\DoxyCodeLine{6973 \textcolor{comment}{This  function  creates  MCPD (Markov Chains for Population  Data)  solver}}
\DoxyCodeLine{6974 \textcolor{comment}{for "{}Exit-\/state"{} model,  i.e. model  where  transition from X[i] to X[i+1]}}
\DoxyCodeLine{6975 \textcolor{comment}{is modelled as}}
\DoxyCodeLine{6976 \textcolor{comment}{    X[i+1] = P*X[i]}}
\DoxyCodeLine{6977 \textcolor{comment}{where}}
\DoxyCodeLine{6978 \textcolor{comment}{    X[i] and X[i+1] are N-\/dimensional state vectors}}
\DoxyCodeLine{6979 \textcolor{comment}{    P is a N*N transition matrix}}
\DoxyCodeLine{6980 \textcolor{comment}{and  one  selected component of X[] is called "{}exit"{}  state and is treated}}
\DoxyCodeLine{6981 \textcolor{comment}{in a special way:}}
\DoxyCodeLine{6982 \textcolor{comment}{    system state can transit from any state into "{}exit"{} state}}
\DoxyCodeLine{6983 \textcolor{comment}{    system state can not transit from "{}exit"{} state into any other state}}
\DoxyCodeLine{6984 \textcolor{comment}{    transition operator discards "{}exit"{} state (makes it zero at each turn)}}
\DoxyCodeLine{6985 \textcolor{comment}{Such  conditions  basically  mean  that  column  of P which corresponds to}}
\DoxyCodeLine{6986 \textcolor{comment}{"{}exit"{} state is zero. Multiplication by such P may decrease sum of  vector}}
\DoxyCodeLine{6987 \textcolor{comment}{components.}}
\DoxyCodeLine{6988 \textcolor{comment}{}}
\DoxyCodeLine{6989 \textcolor{comment}{Such models arise when:}}
\DoxyCodeLine{6990 \textcolor{comment}{* there is some population of individuals}}
\DoxyCodeLine{6991 \textcolor{comment}{* individuals can have different states}}
\DoxyCodeLine{6992 \textcolor{comment}{* individuals can transit from one state to another}}
\DoxyCodeLine{6993 \textcolor{comment}{* population size is NOT constant -\/ individuals can move into "{}exit"{} state}}
\DoxyCodeLine{6994 \textcolor{comment}{  and leave population at the next turn, but there are no new individuals}}
\DoxyCodeLine{6995 \textcolor{comment}{* amount of individuals which leave population can be predicted}}
\DoxyCodeLine{6996 \textcolor{comment}{* you want to model transitions of individuals from one state into another}}
\DoxyCodeLine{6997 \textcolor{comment}{  (including transitions into the "{}exit"{} state)}}
\DoxyCodeLine{6998 \textcolor{comment}{}}
\DoxyCodeLine{6999 \textcolor{comment}{This model is discussed  in  more  details  in  the ALGLIB User Guide (see}}
\DoxyCodeLine{7000 \textcolor{comment}{http://www.alglib.net/dataanalysis/ for more data).}}
\DoxyCodeLine{7001 \textcolor{comment}{}}
\DoxyCodeLine{7002 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7003 \textcolor{comment}{    N       -\/   problem dimension, N>=2}}
\DoxyCodeLine{7004 \textcolor{comment}{    ExitState-\/  index of exit state, in 0..N-\/1}}
\DoxyCodeLine{7005 \textcolor{comment}{}}
\DoxyCodeLine{7006 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{7007 \textcolor{comment}{    State   -\/   structure stores algorithm state}}
\DoxyCodeLine{7008 \textcolor{comment}{}}
\DoxyCodeLine{7009 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7010 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{7011 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7012 \textcolor{keywordtype}{void} mcpdcreateexit(\textcolor{keyword}{const} ae\_int\_t n, \textcolor{keyword}{const} ae\_int\_t exitstate, \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7013 }
\DoxyCodeLine{7014 }
\DoxyCodeLine{7015 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7016 \textcolor{comment}{DESCRIPTION:}}
\DoxyCodeLine{7017 \textcolor{comment}{}}
\DoxyCodeLine{7018 \textcolor{comment}{This function is a specialized version of MCPDCreate()  function,  and  we}}
\DoxyCodeLine{7019 \textcolor{comment}{recommend  you  to read comments for this function for general information}}
\DoxyCodeLine{7020 \textcolor{comment}{about MCPD solver.}}
\DoxyCodeLine{7021 \textcolor{comment}{}}
\DoxyCodeLine{7022 \textcolor{comment}{This  function  creates  MCPD (Markov Chains for Population  Data)  solver}}
\DoxyCodeLine{7023 \textcolor{comment}{for "{}Entry-\/Exit-\/states"{} model, i.e. model where  transition  from  X[i] to}}
\DoxyCodeLine{7024 \textcolor{comment}{X[i+1] is modelled as}}
\DoxyCodeLine{7025 \textcolor{comment}{    X[i+1] = P*X[i]}}
\DoxyCodeLine{7026 \textcolor{comment}{where}}
\DoxyCodeLine{7027 \textcolor{comment}{    X[i] and X[i+1] are N-\/dimensional state vectors}}
\DoxyCodeLine{7028 \textcolor{comment}{    P is a N*N transition matrix}}
\DoxyCodeLine{7029 \textcolor{comment}{one selected component of X[] is called "{}entry"{} state and is treated in  a}}
\DoxyCodeLine{7030 \textcolor{comment}{special way:}}
\DoxyCodeLine{7031 \textcolor{comment}{    system state always transits from "{}entry"{} state to some another state}}
\DoxyCodeLine{7032 \textcolor{comment}{    system state can not transit from any state into "{}entry"{} state}}
\DoxyCodeLine{7033 \textcolor{comment}{and another one component of X[] is called "{}exit"{} state and is treated  in}}
\DoxyCodeLine{7034 \textcolor{comment}{a special way too:}}
\DoxyCodeLine{7035 \textcolor{comment}{    system state can transit from any state into "{}exit"{} state}}
\DoxyCodeLine{7036 \textcolor{comment}{    system state can not transit from "{}exit"{} state into any other state}}
\DoxyCodeLine{7037 \textcolor{comment}{    transition operator discards "{}exit"{} state (makes it zero at each turn)}}
\DoxyCodeLine{7038 \textcolor{comment}{Such conditions basically mean that:}}
\DoxyCodeLine{7039 \textcolor{comment}{    row of P which corresponds to "{}entry"{} state is zero}}
\DoxyCodeLine{7040 \textcolor{comment}{    column of P which corresponds to "{}exit"{} state is zero}}
\DoxyCodeLine{7041 \textcolor{comment}{Multiplication by such P may decrease sum of vector components.}}
\DoxyCodeLine{7042 \textcolor{comment}{}}
\DoxyCodeLine{7043 \textcolor{comment}{Such models arise when:}}
\DoxyCodeLine{7044 \textcolor{comment}{* there is some population of individuals}}
\DoxyCodeLine{7045 \textcolor{comment}{* individuals can have different states}}
\DoxyCodeLine{7046 \textcolor{comment}{* individuals can transit from one state to another}}
\DoxyCodeLine{7047 \textcolor{comment}{* population size is NOT constant}}
\DoxyCodeLine{7048 \textcolor{comment}{* at every moment of time there is some (unpredictable)  amount  of  "{}new"{}}}
\DoxyCodeLine{7049 \textcolor{comment}{  individuals, which can transit into one of the states at the next turn}}
\DoxyCodeLine{7050 \textcolor{comment}{* some  individuals  can  move  (predictably)  into "{}exit"{} state and leave}}
\DoxyCodeLine{7051 \textcolor{comment}{  population at the next turn}}
\DoxyCodeLine{7052 \textcolor{comment}{* you want to model transitions of individuals from one state into another,}}
\DoxyCodeLine{7053 \textcolor{comment}{  including transitions from the "{}entry"{} state and into the "{}exit"{} state.}}
\DoxyCodeLine{7054 \textcolor{comment}{* but you do NOT want to predict amount of "{}new"{}  individuals  because  it}}
\DoxyCodeLine{7055 \textcolor{comment}{  does not depends on individuals already present (hence  system  can  not}}
\DoxyCodeLine{7056 \textcolor{comment}{  transit INTO entry state -\/ it can only transit FROM it).}}
\DoxyCodeLine{7057 \textcolor{comment}{}}
\DoxyCodeLine{7058 \textcolor{comment}{This model is discussed  in  more  details  in  the ALGLIB User Guide (see}}
\DoxyCodeLine{7059 \textcolor{comment}{http://www.alglib.net/dataanalysis/ for more data).}}
\DoxyCodeLine{7060 \textcolor{comment}{}}
\DoxyCodeLine{7061 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7062 \textcolor{comment}{    N       -\/   problem dimension, N>=2}}
\DoxyCodeLine{7063 \textcolor{comment}{    EntryState-\/ index of entry state, in 0..N-\/1}}
\DoxyCodeLine{7064 \textcolor{comment}{    ExitState-\/  index of exit state, in 0..N-\/1}}
\DoxyCodeLine{7065 \textcolor{comment}{}}
\DoxyCodeLine{7066 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{7067 \textcolor{comment}{    State   -\/   structure stores algorithm state}}
\DoxyCodeLine{7068 \textcolor{comment}{}}
\DoxyCodeLine{7069 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7070 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{7071 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7072 \textcolor{keywordtype}{void} mcpdcreateentryexit(\textcolor{keyword}{const} ae\_int\_t n, \textcolor{keyword}{const} ae\_int\_t entrystate, \textcolor{keyword}{const} ae\_int\_t exitstate, \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7073 }
\DoxyCodeLine{7074 }
\DoxyCodeLine{7075 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7076 \textcolor{comment}{This  function  is  used to add a track -\/ sequence of system states at the}}
\DoxyCodeLine{7077 \textcolor{comment}{different moments of its evolution.}}
\DoxyCodeLine{7078 \textcolor{comment}{}}
\DoxyCodeLine{7079 \textcolor{comment}{You  may  add  one  or several tracks to the MCPD solver. In case you have}}
\DoxyCodeLine{7080 \textcolor{comment}{several tracks, they won't overwrite each other. For example,  if you pass}}
\DoxyCodeLine{7081 \textcolor{comment}{two tracks, A1-\/A2-\/A3 (system at t=A+1, t=A+2 and t=A+3) and B1-\/B2-\/B3, then}}
\DoxyCodeLine{7082 \textcolor{comment}{solver will try to model transitions from t=A+1 to t=A+2, t=A+2 to  t=A+3,}}
\DoxyCodeLine{7083 \textcolor{comment}{t=B+1 to t=B+2, t=B+2 to t=B+3. But it WONT mix these two tracks -\/ i.e. it}}
\DoxyCodeLine{7084 \textcolor{comment}{wont try to model transition from t=A+3 to t=B+1.}}
\DoxyCodeLine{7085 \textcolor{comment}{}}
\DoxyCodeLine{7086 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7087 \textcolor{comment}{    S       -\/   solver}}
\DoxyCodeLine{7088 \textcolor{comment}{    XY      -\/   track, array[K,N]:}}
\DoxyCodeLine{7089 \textcolor{comment}{                * I-\/th row is a state at t=I}}
\DoxyCodeLine{7090 \textcolor{comment}{                * elements of XY must be non-\/negative (exception will be}}
\DoxyCodeLine{7091 \textcolor{comment}{                  thrown on negative elements)}}
\DoxyCodeLine{7092 \textcolor{comment}{    K       -\/   number of points in a track}}
\DoxyCodeLine{7093 \textcolor{comment}{                * if given, only leading K rows of XY are used}}
\DoxyCodeLine{7094 \textcolor{comment}{                * if not given, automatically determined from size of XY}}
\DoxyCodeLine{7095 \textcolor{comment}{}}
\DoxyCodeLine{7096 \textcolor{comment}{NOTES:}}
\DoxyCodeLine{7097 \textcolor{comment}{}}
\DoxyCodeLine{7098 \textcolor{comment}{1. Track may contain either proportional or population data:}}
\DoxyCodeLine{7099 \textcolor{comment}{   * with proportional data all rows of XY must sum to 1.0, i.e. we have}}
\DoxyCodeLine{7100 \textcolor{comment}{     proportions instead of absolute population values}}
\DoxyCodeLine{7101 \textcolor{comment}{   * with population data rows of XY contain population counts and generally}}
\DoxyCodeLine{7102 \textcolor{comment}{     do not sum to 1.0 (although they still must be non-\/negative)}}
\DoxyCodeLine{7103 \textcolor{comment}{}}
\DoxyCodeLine{7104 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7105 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{7106 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7107 \textcolor{keywordtype}{void} mcpdaddtrack(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t k, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7108 \textcolor{keywordtype}{void} mcpdaddtrack(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7109 }
\DoxyCodeLine{7110 }
\DoxyCodeLine{7111 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7112 \textcolor{comment}{This function is used to add equality constraints on the elements  of  the}}
\DoxyCodeLine{7113 \textcolor{comment}{transition matrix P.}}
\DoxyCodeLine{7114 \textcolor{comment}{}}
\DoxyCodeLine{7115 \textcolor{comment}{MCPD solver has four types of constraints which can be placed on P:}}
\DoxyCodeLine{7116 \textcolor{comment}{* user-\/specified equality constraints (optional)}}
\DoxyCodeLine{7117 \textcolor{comment}{* user-\/specified bound constraints (optional)}}
\DoxyCodeLine{7118 \textcolor{comment}{* user-\/specified general linear constraints (optional)}}
\DoxyCodeLine{7119 \textcolor{comment}{* basic constraints (always present):}}
\DoxyCodeLine{7120 \textcolor{comment}{  * non-\/negativity: P[i,j]>=0}}
\DoxyCodeLine{7121 \textcolor{comment}{  * consistency: every column of P sums to 1.0}}
\DoxyCodeLine{7122 \textcolor{comment}{}}
\DoxyCodeLine{7123 \textcolor{comment}{Final  constraints  which  are  passed  to  the  underlying  optimizer are}}
\DoxyCodeLine{7124 \textcolor{comment}{calculated  as  intersection  of all present constraints. For example, you}}
\DoxyCodeLine{7125 \textcolor{comment}{may specify boundary constraint on P[0,0] and equality one:}}
\DoxyCodeLine{7126 \textcolor{comment}{    0.1<=P[0,0]<=0.9}}
\DoxyCodeLine{7127 \textcolor{comment}{    P[0,0]=0.5}}
\DoxyCodeLine{7128 \textcolor{comment}{Such  combination  of  constraints  will  be  silently  reduced  to  their}}
\DoxyCodeLine{7129 \textcolor{comment}{intersection, which is P[0,0]=0.5.}}
\DoxyCodeLine{7130 \textcolor{comment}{}}
\DoxyCodeLine{7131 \textcolor{comment}{This  function  can  be  used  to  place equality constraints on arbitrary}}
\DoxyCodeLine{7132 \textcolor{comment}{subset of elements of P. Set of constraints is specified by EC, which  may}}
\DoxyCodeLine{7133 \textcolor{comment}{contain either NAN's or finite numbers from [0,1]. NAN denotes absence  of}}
\DoxyCodeLine{7134 \textcolor{comment}{constraint, finite number denotes equality constraint on specific  element}}
\DoxyCodeLine{7135 \textcolor{comment}{of P.}}
\DoxyCodeLine{7136 \textcolor{comment}{}}
\DoxyCodeLine{7137 \textcolor{comment}{You can also  use  MCPDAddEC()  function  which  allows  to  ADD  equality}}
\DoxyCodeLine{7138 \textcolor{comment}{constraint  for  one  element  of P without changing constraints for other}}
\DoxyCodeLine{7139 \textcolor{comment}{elements.}}
\DoxyCodeLine{7140 \textcolor{comment}{}}
\DoxyCodeLine{7141 \textcolor{comment}{These functions (MCPDSetEC and MCPDAddEC) interact as follows:}}
\DoxyCodeLine{7142 \textcolor{comment}{* there is internal matrix of equality constraints which is stored in  the}}
\DoxyCodeLine{7143 \textcolor{comment}{  MCPD solver}}
\DoxyCodeLine{7144 \textcolor{comment}{* MCPDSetEC() replaces this matrix by another one (SET)}}
\DoxyCodeLine{7145 \textcolor{comment}{* MCPDAddEC() modifies one element of this matrix and  leaves  other  ones}}
\DoxyCodeLine{7146 \textcolor{comment}{  unchanged (ADD)}}
\DoxyCodeLine{7147 \textcolor{comment}{* thus  MCPDAddEC()  call  preserves  all  modifications  done by previous}}
\DoxyCodeLine{7148 \textcolor{comment}{  calls,  while  MCPDSetEC()  completely discards all changes  done to the}}
\DoxyCodeLine{7149 \textcolor{comment}{  equality constraints.}}
\DoxyCodeLine{7150 \textcolor{comment}{}}
\DoxyCodeLine{7151 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7152 \textcolor{comment}{    S       -\/   solver}}
\DoxyCodeLine{7153 \textcolor{comment}{    EC      -\/   equality constraints, array[N,N]. Elements of  EC  can  be}}
\DoxyCodeLine{7154 \textcolor{comment}{                either NAN's or finite  numbers from  [0,1].  NAN  denotes}}
\DoxyCodeLine{7155 \textcolor{comment}{                absence  of  constraints,  while  finite  value    denotes}}
\DoxyCodeLine{7156 \textcolor{comment}{                equality constraint on the corresponding element of P.}}
\DoxyCodeLine{7157 \textcolor{comment}{}}
\DoxyCodeLine{7158 \textcolor{comment}{NOTES:}}
\DoxyCodeLine{7159 \textcolor{comment}{}}
\DoxyCodeLine{7160 \textcolor{comment}{1. infinite values of EC will lead to exception being thrown. Values  less}}
\DoxyCodeLine{7161 \textcolor{comment}{than 0.0 or greater than 1.0 will lead to error code being returned  after}}
\DoxyCodeLine{7162 \textcolor{comment}{call to MCPDSolve().}}
\DoxyCodeLine{7163 \textcolor{comment}{}}
\DoxyCodeLine{7164 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7165 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{7166 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7167 \textcolor{keywordtype}{void} mcpdsetec(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&ec, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7168 }
\DoxyCodeLine{7169 }
\DoxyCodeLine{7170 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7171 \textcolor{comment}{This function is used to add equality constraints on the elements  of  the}}
\DoxyCodeLine{7172 \textcolor{comment}{transition matrix P.}}
\DoxyCodeLine{7173 \textcolor{comment}{}}
\DoxyCodeLine{7174 \textcolor{comment}{MCPD solver has four types of constraints which can be placed on P:}}
\DoxyCodeLine{7175 \textcolor{comment}{* user-\/specified equality constraints (optional)}}
\DoxyCodeLine{7176 \textcolor{comment}{* user-\/specified bound constraints (optional)}}
\DoxyCodeLine{7177 \textcolor{comment}{* user-\/specified general linear constraints (optional)}}
\DoxyCodeLine{7178 \textcolor{comment}{* basic constraints (always present):}}
\DoxyCodeLine{7179 \textcolor{comment}{  * non-\/negativity: P[i,j]>=0}}
\DoxyCodeLine{7180 \textcolor{comment}{  * consistency: every column of P sums to 1.0}}
\DoxyCodeLine{7181 \textcolor{comment}{}}
\DoxyCodeLine{7182 \textcolor{comment}{Final  constraints  which  are  passed  to  the  underlying  optimizer are}}
\DoxyCodeLine{7183 \textcolor{comment}{calculated  as  intersection  of all present constraints. For example, you}}
\DoxyCodeLine{7184 \textcolor{comment}{may specify boundary constraint on P[0,0] and equality one:}}
\DoxyCodeLine{7185 \textcolor{comment}{    0.1<=P[0,0]<=0.9}}
\DoxyCodeLine{7186 \textcolor{comment}{    P[0,0]=0.5}}
\DoxyCodeLine{7187 \textcolor{comment}{Such  combination  of  constraints  will  be  silently  reduced  to  their}}
\DoxyCodeLine{7188 \textcolor{comment}{intersection, which is P[0,0]=0.5.}}
\DoxyCodeLine{7189 \textcolor{comment}{}}
\DoxyCodeLine{7190 \textcolor{comment}{This function can be used to ADD equality constraint for one element of  P}}
\DoxyCodeLine{7191 \textcolor{comment}{without changing constraints for other elements.}}
\DoxyCodeLine{7192 \textcolor{comment}{}}
\DoxyCodeLine{7193 \textcolor{comment}{You  can  also  use  MCPDSetEC()  function  which  allows  you  to specify}}
\DoxyCodeLine{7194 \textcolor{comment}{arbitrary set of equality constraints in one call.}}
\DoxyCodeLine{7195 \textcolor{comment}{}}
\DoxyCodeLine{7196 \textcolor{comment}{These functions (MCPDSetEC and MCPDAddEC) interact as follows:}}
\DoxyCodeLine{7197 \textcolor{comment}{* there is internal matrix of equality constraints which is stored in the}}
\DoxyCodeLine{7198 \textcolor{comment}{  MCPD solver}}
\DoxyCodeLine{7199 \textcolor{comment}{* MCPDSetEC() replaces this matrix by another one (SET)}}
\DoxyCodeLine{7200 \textcolor{comment}{* MCPDAddEC() modifies one element of this matrix and leaves  other  ones}}
\DoxyCodeLine{7201 \textcolor{comment}{  unchanged (ADD)}}
\DoxyCodeLine{7202 \textcolor{comment}{* thus  MCPDAddEC()  call  preserves  all  modifications done by previous}}
\DoxyCodeLine{7203 \textcolor{comment}{  calls,  while  MCPDSetEC()  completely discards all changes done to the}}
\DoxyCodeLine{7204 \textcolor{comment}{  equality constraints.}}
\DoxyCodeLine{7205 \textcolor{comment}{}}
\DoxyCodeLine{7206 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7207 \textcolor{comment}{    S       -\/   solver}}
\DoxyCodeLine{7208 \textcolor{comment}{    I       -\/   row index of element being constrained}}
\DoxyCodeLine{7209 \textcolor{comment}{    J       -\/   column index of element being constrained}}
\DoxyCodeLine{7210 \textcolor{comment}{    C       -\/   value (constraint for P[I,J]).  Can  be  either  NAN  (no}}
\DoxyCodeLine{7211 \textcolor{comment}{                constraint) or finite value from [0,1].}}
\DoxyCodeLine{7212 \textcolor{comment}{}}
\DoxyCodeLine{7213 \textcolor{comment}{NOTES:}}
\DoxyCodeLine{7214 \textcolor{comment}{}}
\DoxyCodeLine{7215 \textcolor{comment}{1. infinite values of C  will lead to exception being thrown. Values  less}}
\DoxyCodeLine{7216 \textcolor{comment}{than 0.0 or greater than 1.0 will lead to error code being returned  after}}
\DoxyCodeLine{7217 \textcolor{comment}{call to MCPDSolve().}}
\DoxyCodeLine{7218 \textcolor{comment}{}}
\DoxyCodeLine{7219 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7220 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{7221 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7222 \textcolor{keywordtype}{void} mcpdaddec(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \textcolor{keyword}{const} ae\_int\_t i, \textcolor{keyword}{const} ae\_int\_t j, \textcolor{keyword}{const} \textcolor{keywordtype}{double} c, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7223 }
\DoxyCodeLine{7224 }
\DoxyCodeLine{7225 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7226 \textcolor{comment}{This function is used to add bound constraints  on  the  elements  of  the}}
\DoxyCodeLine{7227 \textcolor{comment}{transition matrix P.}}
\DoxyCodeLine{7228 \textcolor{comment}{}}
\DoxyCodeLine{7229 \textcolor{comment}{MCPD solver has four types of constraints which can be placed on P:}}
\DoxyCodeLine{7230 \textcolor{comment}{* user-\/specified equality constraints (optional)}}
\DoxyCodeLine{7231 \textcolor{comment}{* user-\/specified bound constraints (optional)}}
\DoxyCodeLine{7232 \textcolor{comment}{* user-\/specified general linear constraints (optional)}}
\DoxyCodeLine{7233 \textcolor{comment}{* basic constraints (always present):}}
\DoxyCodeLine{7234 \textcolor{comment}{  * non-\/negativity: P[i,j]>=0}}
\DoxyCodeLine{7235 \textcolor{comment}{  * consistency: every column of P sums to 1.0}}
\DoxyCodeLine{7236 \textcolor{comment}{}}
\DoxyCodeLine{7237 \textcolor{comment}{Final  constraints  which  are  passed  to  the  underlying  optimizer are}}
\DoxyCodeLine{7238 \textcolor{comment}{calculated  as  intersection  of all present constraints. For example, you}}
\DoxyCodeLine{7239 \textcolor{comment}{may specify boundary constraint on P[0,0] and equality one:}}
\DoxyCodeLine{7240 \textcolor{comment}{    0.1<=P[0,0]<=0.9}}
\DoxyCodeLine{7241 \textcolor{comment}{    P[0,0]=0.5}}
\DoxyCodeLine{7242 \textcolor{comment}{Such  combination  of  constraints  will  be  silently  reduced  to  their}}
\DoxyCodeLine{7243 \textcolor{comment}{intersection, which is P[0,0]=0.5.}}
\DoxyCodeLine{7244 \textcolor{comment}{}}
\DoxyCodeLine{7245 \textcolor{comment}{This  function  can  be  used  to  place bound   constraints  on arbitrary}}
\DoxyCodeLine{7246 \textcolor{comment}{subset  of  elements  of  P.  Set of constraints is specified by BndL/BndU}}
\DoxyCodeLine{7247 \textcolor{comment}{matrices, which may contain arbitrary combination  of  finite  numbers  or}}
\DoxyCodeLine{7248 \textcolor{comment}{infinities (like -\/INF<x<=0.5 or 0.1<=x<+INF).}}
\DoxyCodeLine{7249 \textcolor{comment}{}}
\DoxyCodeLine{7250 \textcolor{comment}{You can also use MCPDAddBC() function which allows to ADD bound constraint}}
\DoxyCodeLine{7251 \textcolor{comment}{for one element of P without changing constraints for other elements.}}
\DoxyCodeLine{7252 \textcolor{comment}{}}
\DoxyCodeLine{7253 \textcolor{comment}{These functions (MCPDSetBC and MCPDAddBC) interact as follows:}}
\DoxyCodeLine{7254 \textcolor{comment}{* there is internal matrix of bound constraints which is stored in the}}
\DoxyCodeLine{7255 \textcolor{comment}{  MCPD solver}}
\DoxyCodeLine{7256 \textcolor{comment}{* MCPDSetBC() replaces this matrix by another one (SET)}}
\DoxyCodeLine{7257 \textcolor{comment}{* MCPDAddBC() modifies one element of this matrix and  leaves  other  ones}}
\DoxyCodeLine{7258 \textcolor{comment}{  unchanged (ADD)}}
\DoxyCodeLine{7259 \textcolor{comment}{* thus  MCPDAddBC()  call  preserves  all  modifications  done by previous}}
\DoxyCodeLine{7260 \textcolor{comment}{  calls,  while  MCPDSetBC()  completely discards all changes  done to the}}
\DoxyCodeLine{7261 \textcolor{comment}{  equality constraints.}}
\DoxyCodeLine{7262 \textcolor{comment}{}}
\DoxyCodeLine{7263 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7264 \textcolor{comment}{    S       -\/   solver}}
\DoxyCodeLine{7265 \textcolor{comment}{    BndL    -\/   lower bounds constraints, array[N,N]. Elements of BndL can}}
\DoxyCodeLine{7266 \textcolor{comment}{                be finite numbers or -\/INF.}}
\DoxyCodeLine{7267 \textcolor{comment}{    BndU    -\/   upper bounds constraints, array[N,N]. Elements of BndU can}}
\DoxyCodeLine{7268 \textcolor{comment}{                be finite numbers or +INF.}}
\DoxyCodeLine{7269 \textcolor{comment}{}}
\DoxyCodeLine{7270 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7271 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{7272 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7273 \textcolor{keywordtype}{void} mcpdsetbc(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&bndl, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&bndu, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7274 }
\DoxyCodeLine{7275 }
\DoxyCodeLine{7276 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7277 \textcolor{comment}{This function is used to add bound constraints  on  the  elements  of  the}}
\DoxyCodeLine{7278 \textcolor{comment}{transition matrix P.}}
\DoxyCodeLine{7279 \textcolor{comment}{}}
\DoxyCodeLine{7280 \textcolor{comment}{MCPD solver has four types of constraints which can be placed on P:}}
\DoxyCodeLine{7281 \textcolor{comment}{* user-\/specified equality constraints (optional)}}
\DoxyCodeLine{7282 \textcolor{comment}{* user-\/specified bound constraints (optional)}}
\DoxyCodeLine{7283 \textcolor{comment}{* user-\/specified general linear constraints (optional)}}
\DoxyCodeLine{7284 \textcolor{comment}{* basic constraints (always present):}}
\DoxyCodeLine{7285 \textcolor{comment}{  * non-\/negativity: P[i,j]>=0}}
\DoxyCodeLine{7286 \textcolor{comment}{  * consistency: every column of P sums to 1.0}}
\DoxyCodeLine{7287 \textcolor{comment}{}}
\DoxyCodeLine{7288 \textcolor{comment}{Final  constraints  which  are  passed  to  the  underlying  optimizer are}}
\DoxyCodeLine{7289 \textcolor{comment}{calculated  as  intersection  of all present constraints. For example, you}}
\DoxyCodeLine{7290 \textcolor{comment}{may specify boundary constraint on P[0,0] and equality one:}}
\DoxyCodeLine{7291 \textcolor{comment}{    0.1<=P[0,0]<=0.9}}
\DoxyCodeLine{7292 \textcolor{comment}{    P[0,0]=0.5}}
\DoxyCodeLine{7293 \textcolor{comment}{Such  combination  of  constraints  will  be  silently  reduced  to  their}}
\DoxyCodeLine{7294 \textcolor{comment}{intersection, which is P[0,0]=0.5.}}
\DoxyCodeLine{7295 \textcolor{comment}{}}
\DoxyCodeLine{7296 \textcolor{comment}{This  function  can  be  used to ADD bound constraint for one element of P}}
\DoxyCodeLine{7297 \textcolor{comment}{without changing constraints for other elements.}}
\DoxyCodeLine{7298 \textcolor{comment}{}}
\DoxyCodeLine{7299 \textcolor{comment}{You  can  also  use  MCPDSetBC()  function  which  allows to  place  bound}}
\DoxyCodeLine{7300 \textcolor{comment}{constraints  on arbitrary subset of elements of P.   Set of constraints is}}
\DoxyCodeLine{7301 \textcolor{comment}{specified  by  BndL/BndU matrices, which may contain arbitrary combination}}
\DoxyCodeLine{7302 \textcolor{comment}{of finite numbers or infinities (like -\/INF<x<=0.5 or 0.1<=x<+INF).}}
\DoxyCodeLine{7303 \textcolor{comment}{}}
\DoxyCodeLine{7304 \textcolor{comment}{These functions (MCPDSetBC and MCPDAddBC) interact as follows:}}
\DoxyCodeLine{7305 \textcolor{comment}{* there is internal matrix of bound constraints which is stored in the}}
\DoxyCodeLine{7306 \textcolor{comment}{  MCPD solver}}
\DoxyCodeLine{7307 \textcolor{comment}{* MCPDSetBC() replaces this matrix by another one (SET)}}
\DoxyCodeLine{7308 \textcolor{comment}{* MCPDAddBC() modifies one element of this matrix and  leaves  other  ones}}
\DoxyCodeLine{7309 \textcolor{comment}{  unchanged (ADD)}}
\DoxyCodeLine{7310 \textcolor{comment}{* thus  MCPDAddBC()  call  preserves  all  modifications  done by previous}}
\DoxyCodeLine{7311 \textcolor{comment}{  calls,  while  MCPDSetBC()  completely discards all changes  done to the}}
\DoxyCodeLine{7312 \textcolor{comment}{  equality constraints.}}
\DoxyCodeLine{7313 \textcolor{comment}{}}
\DoxyCodeLine{7314 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7315 \textcolor{comment}{    S       -\/   solver}}
\DoxyCodeLine{7316 \textcolor{comment}{    I       -\/   row index of element being constrained}}
\DoxyCodeLine{7317 \textcolor{comment}{    J       -\/   column index of element being constrained}}
\DoxyCodeLine{7318 \textcolor{comment}{    BndL    -\/   lower bound}}
\DoxyCodeLine{7319 \textcolor{comment}{    BndU    -\/   upper bound}}
\DoxyCodeLine{7320 \textcolor{comment}{}}
\DoxyCodeLine{7321 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7322 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{7323 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7324 \textcolor{keywordtype}{void} mcpdaddbc(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \textcolor{keyword}{const} ae\_int\_t i, \textcolor{keyword}{const} ae\_int\_t j, \textcolor{keyword}{const} \textcolor{keywordtype}{double} bndl, \textcolor{keyword}{const} \textcolor{keywordtype}{double} bndu, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7325 }
\DoxyCodeLine{7326 }
\DoxyCodeLine{7327 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7328 \textcolor{comment}{This function is used to set linear equality/inequality constraints on the}}
\DoxyCodeLine{7329 \textcolor{comment}{elements of the transition matrix P.}}
\DoxyCodeLine{7330 \textcolor{comment}{}}
\DoxyCodeLine{7331 \textcolor{comment}{This function can be used to set one or several general linear constraints}}
\DoxyCodeLine{7332 \textcolor{comment}{on the elements of P. Two types of constraints are supported:}}
\DoxyCodeLine{7333 \textcolor{comment}{* equality constraints}}
\DoxyCodeLine{7334 \textcolor{comment}{* inequality constraints (both less-\/or-\/equal and greater-\/or-\/equal)}}
\DoxyCodeLine{7335 \textcolor{comment}{}}
\DoxyCodeLine{7336 \textcolor{comment}{Coefficients  of  constraints  are  specified  by  matrix  C (one  of  the}}
\DoxyCodeLine{7337 \textcolor{comment}{parameters).  One  row  of  C  corresponds  to  one  constraint.   Because}}
\DoxyCodeLine{7338 \textcolor{comment}{transition  matrix P has N*N elements,  we  need  N*N columns to store all}}
\DoxyCodeLine{7339 \textcolor{comment}{coefficients  (they  are  stored row by row), and one more column to store}}
\DoxyCodeLine{7340 \textcolor{comment}{right part -\/ hence C has N*N+1 columns.  Constraint  kind is stored in the}}
\DoxyCodeLine{7341 \textcolor{comment}{CT array.}}
\DoxyCodeLine{7342 \textcolor{comment}{}}
\DoxyCodeLine{7343 \textcolor{comment}{Thus, I-\/th linear constraint is}}
\DoxyCodeLine{7344 \textcolor{comment}{    P[0,0]*C[I,0] + P[0,1]*C[I,1] + .. + P[0,N-\/1]*C[I,N-\/1] +}}
\DoxyCodeLine{7345 \textcolor{comment}{        + P[1,0]*C[I,N] + P[1,1]*C[I,N+1] + ... +}}
\DoxyCodeLine{7346 \textcolor{comment}{        + P[N-\/1,N-\/1]*C[I,N*N-\/1]  ?=?  C[I,N*N]}}
\DoxyCodeLine{7347 \textcolor{comment}{where ?=? can be either "{}="{} (CT[i]=0), "{}<="{} (CT[i]<0) or "{}>="{} (CT[i]>0).}}
\DoxyCodeLine{7348 \textcolor{comment}{}}
\DoxyCodeLine{7349 \textcolor{comment}{Your constraint may involve only some subset of P (less than N*N elements).}}
\DoxyCodeLine{7350 \textcolor{comment}{For example it can be something like}}
\DoxyCodeLine{7351 \textcolor{comment}{    P[0,0] + P[0,1] = 0.5}}
\DoxyCodeLine{7352 \textcolor{comment}{In this case you still should pass matrix  with N*N+1 columns, but all its}}
\DoxyCodeLine{7353 \textcolor{comment}{elements (except for C[0,0], C[0,1] and C[0,N*N-\/1]) will be zero.}}
\DoxyCodeLine{7354 \textcolor{comment}{}}
\DoxyCodeLine{7355 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7356 \textcolor{comment}{    S       -\/   solver}}
\DoxyCodeLine{7357 \textcolor{comment}{    C       -\/   array[K,N*N+1] -\/ coefficients of constraints}}
\DoxyCodeLine{7358 \textcolor{comment}{                (see above for complete description)}}
\DoxyCodeLine{7359 \textcolor{comment}{    CT      -\/   array[K] -\/ constraint types}}
\DoxyCodeLine{7360 \textcolor{comment}{                (see above for complete description)}}
\DoxyCodeLine{7361 \textcolor{comment}{    K       -\/   number of equality/inequality constraints, K>=0:}}
\DoxyCodeLine{7362 \textcolor{comment}{                * if given, only leading K elements of C/CT are used}}
\DoxyCodeLine{7363 \textcolor{comment}{                * if not given, automatically determined from sizes of C/CT}}
\DoxyCodeLine{7364 \textcolor{comment}{}}
\DoxyCodeLine{7365 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7366 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{7367 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7368 \textcolor{keywordtype}{void} mcpdsetlc(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&c, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&ct, \textcolor{keyword}{const} ae\_int\_t k, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7369 \textcolor{keywordtype}{void} mcpdsetlc(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&c, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&ct, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7370 }
\DoxyCodeLine{7371 }
\DoxyCodeLine{7372 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7373 \textcolor{comment}{This function allows to  tune  amount  of  Tikhonov  regularization  being}}
\DoxyCodeLine{7374 \textcolor{comment}{applied to your problem.}}
\DoxyCodeLine{7375 \textcolor{comment}{}}
\DoxyCodeLine{7376 \textcolor{comment}{By default, regularizing term is equal to r*||P-\/prior\_P||\string^2, where r is  a}}
\DoxyCodeLine{7377 \textcolor{comment}{small non-\/zero value,  P is transition matrix, prior\_P is identity matrix,}}
\DoxyCodeLine{7378 \textcolor{comment}{||X||\string^2 is a sum of squared elements of X.}}
\DoxyCodeLine{7379 \textcolor{comment}{}}
\DoxyCodeLine{7380 \textcolor{comment}{This  function  allows  you to change coefficient r. You can  also  change}}
\DoxyCodeLine{7381 \textcolor{comment}{prior values with MCPDSetPrior() function.}}
\DoxyCodeLine{7382 \textcolor{comment}{}}
\DoxyCodeLine{7383 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7384 \textcolor{comment}{    S       -\/   solver}}
\DoxyCodeLine{7385 \textcolor{comment}{    V       -\/   regularization  coefficient, finite non-\/negative value. It}}
\DoxyCodeLine{7386 \textcolor{comment}{                is  not  recommended  to specify zero value unless you are}}
\DoxyCodeLine{7387 \textcolor{comment}{                pretty sure that you want it.}}
\DoxyCodeLine{7388 \textcolor{comment}{}}
\DoxyCodeLine{7389 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7390 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{7391 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7392 \textcolor{keywordtype}{void} mcpdsettikhonovregularizer(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \textcolor{keyword}{const} \textcolor{keywordtype}{double} v, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7393 }
\DoxyCodeLine{7394 }
\DoxyCodeLine{7395 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7396 \textcolor{comment}{This  function  allows to set prior values used for regularization of your}}
\DoxyCodeLine{7397 \textcolor{comment}{problem.}}
\DoxyCodeLine{7398 \textcolor{comment}{}}
\DoxyCodeLine{7399 \textcolor{comment}{By default, regularizing term is equal to r*||P-\/prior\_P||\string^2, where r is  a}}
\DoxyCodeLine{7400 \textcolor{comment}{small non-\/zero value,  P is transition matrix, prior\_P is identity matrix,}}
\DoxyCodeLine{7401 \textcolor{comment}{||X||\string^2 is a sum of squared elements of X.}}
\DoxyCodeLine{7402 \textcolor{comment}{}}
\DoxyCodeLine{7403 \textcolor{comment}{This  function  allows  you to change prior values prior\_P. You  can  also}}
\DoxyCodeLine{7404 \textcolor{comment}{change r with MCPDSetTikhonovRegularizer() function.}}
\DoxyCodeLine{7405 \textcolor{comment}{}}
\DoxyCodeLine{7406 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7407 \textcolor{comment}{    S       -\/   solver}}
\DoxyCodeLine{7408 \textcolor{comment}{    PP      -\/   array[N,N], matrix of prior values:}}
\DoxyCodeLine{7409 \textcolor{comment}{                1. elements must be real numbers from [0,1]}}
\DoxyCodeLine{7410 \textcolor{comment}{                2. columns must sum to 1.0.}}
\DoxyCodeLine{7411 \textcolor{comment}{                First property is checked (exception is thrown otherwise),}}
\DoxyCodeLine{7412 \textcolor{comment}{                while second one is not checked/enforced.}}
\DoxyCodeLine{7413 \textcolor{comment}{}}
\DoxyCodeLine{7414 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7415 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{7416 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7417 \textcolor{keywordtype}{void} mcpdsetprior(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&pp, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7418 }
\DoxyCodeLine{7419 }
\DoxyCodeLine{7420 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7421 \textcolor{comment}{This function is used to change prediction weights}}
\DoxyCodeLine{7422 \textcolor{comment}{}}
\DoxyCodeLine{7423 \textcolor{comment}{MCPD solver scales prediction errors as follows}}
\DoxyCodeLine{7424 \textcolor{comment}{    Error(P) = ||W*(y-\/P*x)||\string^2}}
\DoxyCodeLine{7425 \textcolor{comment}{where}}
\DoxyCodeLine{7426 \textcolor{comment}{    x is a system state at time t}}
\DoxyCodeLine{7427 \textcolor{comment}{    y is a system state at time t+1}}
\DoxyCodeLine{7428 \textcolor{comment}{    P is a transition matrix}}
\DoxyCodeLine{7429 \textcolor{comment}{    W is a diagonal scaling matrix}}
\DoxyCodeLine{7430 \textcolor{comment}{}}
\DoxyCodeLine{7431 \textcolor{comment}{By default, weights are chosen in order  to  minimize  relative prediction}}
\DoxyCodeLine{7432 \textcolor{comment}{error instead of absolute one. For example, if one component of  state  is}}
\DoxyCodeLine{7433 \textcolor{comment}{about 0.5 in magnitude and another one is about 0.05, then algorithm  will}}
\DoxyCodeLine{7434 \textcolor{comment}{make corresponding weights equal to 2.0 and 20.0.}}
\DoxyCodeLine{7435 \textcolor{comment}{}}
\DoxyCodeLine{7436 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7437 \textcolor{comment}{    S       -\/   solver}}
\DoxyCodeLine{7438 \textcolor{comment}{    PW      -\/   array[N], weights:}}
\DoxyCodeLine{7439 \textcolor{comment}{                * must be non-\/negative values (exception will be thrown otherwise)}}
\DoxyCodeLine{7440 \textcolor{comment}{                * zero values will be replaced by automatically chosen values}}
\DoxyCodeLine{7441 \textcolor{comment}{}}
\DoxyCodeLine{7442 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7443 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{7444 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7445 \textcolor{keywordtype}{void} mcpdsetpredictionweights(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&pw, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7446 }
\DoxyCodeLine{7447 }
\DoxyCodeLine{7448 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7449 \textcolor{comment}{This function is used to start solution of the MCPD problem.}}
\DoxyCodeLine{7450 \textcolor{comment}{}}
\DoxyCodeLine{7451 \textcolor{comment}{After return from this function, you can use MCPDResults() to get solution}}
\DoxyCodeLine{7452 \textcolor{comment}{and completion code.}}
\DoxyCodeLine{7453 \textcolor{comment}{}}
\DoxyCodeLine{7454 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7455 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{7456 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7457 \textcolor{keywordtype}{void} mcpdsolve(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7458 }
\DoxyCodeLine{7459 }
\DoxyCodeLine{7460 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7461 \textcolor{comment}{MCPD results}}
\DoxyCodeLine{7462 \textcolor{comment}{}}
\DoxyCodeLine{7463 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7464 \textcolor{comment}{    State   -\/   algorithm state}}
\DoxyCodeLine{7465 \textcolor{comment}{}}
\DoxyCodeLine{7466 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{7467 \textcolor{comment}{    P       -\/   array[N,N], transition matrix}}
\DoxyCodeLine{7468 \textcolor{comment}{    Rep     -\/   optimization report. You should check Rep.TerminationType}}
\DoxyCodeLine{7469 \textcolor{comment}{                in  order  to  distinguish  successful  termination  from}}
\DoxyCodeLine{7470 \textcolor{comment}{                unsuccessful one. Speaking short, positive values  denote}}
\DoxyCodeLine{7471 \textcolor{comment}{                success, negative ones are failures.}}
\DoxyCodeLine{7472 \textcolor{comment}{                More information about fields of this  structure  can  be}}
\DoxyCodeLine{7473 \textcolor{comment}{                found in the comments on MCPDReport datatype.}}
\DoxyCodeLine{7474 \textcolor{comment}{}}
\DoxyCodeLine{7475 \textcolor{comment}{}}
\DoxyCodeLine{7476 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7477 \textcolor{comment}{     Copyright 23.05.2010 by Bochkanov Sergey}}
\DoxyCodeLine{7478 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7479 \textcolor{keywordtype}{void} mcpdresults(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mcpdstate}{mcpdstate}} \&s, \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&p, \mbox{\hyperlink{classalglib_1_1mcpdreport}{mcpdreport}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7480 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{7481 }
\DoxyCodeLine{7482 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_LOGIT) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{7483 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7484 \textcolor{comment}{This subroutine trains logit model.}}
\DoxyCodeLine{7485 \textcolor{comment}{}}
\DoxyCodeLine{7486 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7487 \textcolor{comment}{    XY          -\/   training set, array[0..NPoints-\/1,0..NVars]}}
\DoxyCodeLine{7488 \textcolor{comment}{                    First NVars columns store values of independent}}
\DoxyCodeLine{7489 \textcolor{comment}{                    variables, next column stores number of class (from 0}}
\DoxyCodeLine{7490 \textcolor{comment}{                    to NClasses-\/1) which dataset element belongs to. Fractional}}
\DoxyCodeLine{7491 \textcolor{comment}{                    values are rounded to nearest integer.}}
\DoxyCodeLine{7492 \textcolor{comment}{    NPoints     -\/   training set size, NPoints>=1}}
\DoxyCodeLine{7493 \textcolor{comment}{    NVars       -\/   number of independent variables, NVars>=1}}
\DoxyCodeLine{7494 \textcolor{comment}{    NClasses    -\/   number of classes, NClasses>=2}}
\DoxyCodeLine{7495 \textcolor{comment}{}}
\DoxyCodeLine{7496 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{7497 \textcolor{comment}{    Info        -\/   return code:}}
\DoxyCodeLine{7498 \textcolor{comment}{                    * -\/2, if there is a point with class number}}
\DoxyCodeLine{7499 \textcolor{comment}{                          outside of [0..NClasses-\/1].}}
\DoxyCodeLine{7500 \textcolor{comment}{                    * -\/1, if incorrect parameters was passed}}
\DoxyCodeLine{7501 \textcolor{comment}{                          (NPoints<NVars+2, NVars<1, NClasses<2).}}
\DoxyCodeLine{7502 \textcolor{comment}{                    *  1, if task has been solved}}
\DoxyCodeLine{7503 \textcolor{comment}{    LM          -\/   model built}}
\DoxyCodeLine{7504 \textcolor{comment}{    Rep         -\/   training report}}
\DoxyCodeLine{7505 \textcolor{comment}{}}
\DoxyCodeLine{7506 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7507 \textcolor{comment}{     Copyright 10.09.2008 by Bochkanov Sergey}}
\DoxyCodeLine{7508 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7509 \textcolor{keywordtype}{void} mnltrainh(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nvars, \textcolor{keyword}{const} ae\_int\_t nclasses, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}} \&lm, \mbox{\hyperlink{classalglib_1_1mnlreport}{mnlreport}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7510 }
\DoxyCodeLine{7511 }
\DoxyCodeLine{7512 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7513 \textcolor{comment}{Procesing}}
\DoxyCodeLine{7514 \textcolor{comment}{}}
\DoxyCodeLine{7515 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7516 \textcolor{comment}{    LM      -\/   logit model, passed by non-\/constant reference}}
\DoxyCodeLine{7517 \textcolor{comment}{                (some fields of structure are used as temporaries}}
\DoxyCodeLine{7518 \textcolor{comment}{                when calculating model output).}}
\DoxyCodeLine{7519 \textcolor{comment}{    X       -\/   input vector,  array[0..NVars-\/1].}}
\DoxyCodeLine{7520 \textcolor{comment}{    Y       -\/   (possibly) preallocated buffer; if size of Y is less than}}
\DoxyCodeLine{7521 \textcolor{comment}{                NClasses, it will be reallocated.If it is large enough, it}}
\DoxyCodeLine{7522 \textcolor{comment}{                is NOT reallocated, so we can save some time on reallocation.}}
\DoxyCodeLine{7523 \textcolor{comment}{}}
\DoxyCodeLine{7524 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{7525 \textcolor{comment}{    Y       -\/   result, array[0..NClasses-\/1]}}
\DoxyCodeLine{7526 \textcolor{comment}{                Vector of posterior probabilities for classification task.}}
\DoxyCodeLine{7527 \textcolor{comment}{}}
\DoxyCodeLine{7528 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7529 \textcolor{comment}{     Copyright 10.09.2008 by Bochkanov Sergey}}
\DoxyCodeLine{7530 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7531 \textcolor{keywordtype}{void} mnlprocess(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}} \&lm, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&y, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7532 }
\DoxyCodeLine{7533 }
\DoxyCodeLine{7534 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7535 \textcolor{comment}{'interactive'  variant  of  MNLProcess  for  languages  like  Python which}}
\DoxyCodeLine{7536 \textcolor{comment}{support constructs like "{}Y = MNLProcess(LM,X)"{} and interactive mode of the}}
\DoxyCodeLine{7537 \textcolor{comment}{interpreter}}
\DoxyCodeLine{7538 \textcolor{comment}{}}
\DoxyCodeLine{7539 \textcolor{comment}{This function allocates new array on each call,  so  it  is  significantly}}
\DoxyCodeLine{7540 \textcolor{comment}{slower than its 'non-\/interactive' counterpart, but it is  more  convenient}}
\DoxyCodeLine{7541 \textcolor{comment}{when you call it from command line.}}
\DoxyCodeLine{7542 \textcolor{comment}{}}
\DoxyCodeLine{7543 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7544 \textcolor{comment}{     Copyright 10.09.2008 by Bochkanov Sergey}}
\DoxyCodeLine{7545 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7546 \textcolor{keywordtype}{void} mnlprocessi(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}} \&lm, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&y, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7547 }
\DoxyCodeLine{7548 }
\DoxyCodeLine{7549 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7550 \textcolor{comment}{Unpacks coefficients of logit model. Logit model have form:}}
\DoxyCodeLine{7551 \textcolor{comment}{}}
\DoxyCodeLine{7552 \textcolor{comment}{    P(class=i) = S(i) / (S(0) + S(1) + ... +S(M-\/1))}}
\DoxyCodeLine{7553 \textcolor{comment}{          S(i) = Exp(A[i,0]*X[0] + ... + A[i,N-\/1]*X[N-\/1] + A[i,N]), when i<M-\/1}}
\DoxyCodeLine{7554 \textcolor{comment}{        S(M-\/1) = 1}}
\DoxyCodeLine{7555 \textcolor{comment}{}}
\DoxyCodeLine{7556 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7557 \textcolor{comment}{    LM          -\/   logit model in ALGLIB format}}
\DoxyCodeLine{7558 \textcolor{comment}{}}
\DoxyCodeLine{7559 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{7560 \textcolor{comment}{    V           -\/   coefficients, array[0..NClasses-\/2,0..NVars]}}
\DoxyCodeLine{7561 \textcolor{comment}{    NVars       -\/   number of independent variables}}
\DoxyCodeLine{7562 \textcolor{comment}{    NClasses    -\/   number of classes}}
\DoxyCodeLine{7563 \textcolor{comment}{}}
\DoxyCodeLine{7564 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7565 \textcolor{comment}{     Copyright 10.09.2008 by Bochkanov Sergey}}
\DoxyCodeLine{7566 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7567 \textcolor{keywordtype}{void} mnlunpack(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}} \&lm, \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&a, ae\_int\_t \&nvars, ae\_int\_t \&nclasses, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7568 }
\DoxyCodeLine{7569 }
\DoxyCodeLine{7570 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7571 \textcolor{comment}{"{}Packs"{} coefficients and creates logit model in ALGLIB format (MNLUnpack}}
\DoxyCodeLine{7572 \textcolor{comment}{reversed).}}
\DoxyCodeLine{7573 \textcolor{comment}{}}
\DoxyCodeLine{7574 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7575 \textcolor{comment}{    A           -\/   model (see MNLUnpack)}}
\DoxyCodeLine{7576 \textcolor{comment}{    NVars       -\/   number of independent variables}}
\DoxyCodeLine{7577 \textcolor{comment}{    NClasses    -\/   number of classes}}
\DoxyCodeLine{7578 \textcolor{comment}{}}
\DoxyCodeLine{7579 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{7580 \textcolor{comment}{    LM          -\/   logit model.}}
\DoxyCodeLine{7581 \textcolor{comment}{}}
\DoxyCodeLine{7582 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7583 \textcolor{comment}{     Copyright 10.09.2008 by Bochkanov Sergey}}
\DoxyCodeLine{7584 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7585 \textcolor{keywordtype}{void} mnlpack(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&a, \textcolor{keyword}{const} ae\_int\_t nvars, \textcolor{keyword}{const} ae\_int\_t nclasses, \mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}} \&lm, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7586 }
\DoxyCodeLine{7587 }
\DoxyCodeLine{7588 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7589 \textcolor{comment}{Average cross-\/entropy (in bits per element) on the test set}}
\DoxyCodeLine{7590 \textcolor{comment}{}}
\DoxyCodeLine{7591 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7592 \textcolor{comment}{    LM      -\/   logit model}}
\DoxyCodeLine{7593 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{7594 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{7595 \textcolor{comment}{}}
\DoxyCodeLine{7596 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{7597 \textcolor{comment}{    CrossEntropy/(NPoints*ln(2)).}}
\DoxyCodeLine{7598 \textcolor{comment}{}}
\DoxyCodeLine{7599 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7600 \textcolor{comment}{     Copyright 10.09.2008 by Bochkanov Sergey}}
\DoxyCodeLine{7601 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7602 \textcolor{keywordtype}{double} mnlavgce(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}} \&lm, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7603 }
\DoxyCodeLine{7604 }
\DoxyCodeLine{7605 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7606 \textcolor{comment}{Relative classification error on the test set}}
\DoxyCodeLine{7607 \textcolor{comment}{}}
\DoxyCodeLine{7608 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7609 \textcolor{comment}{    LM      -\/   logit model}}
\DoxyCodeLine{7610 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{7611 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{7612 \textcolor{comment}{}}
\DoxyCodeLine{7613 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{7614 \textcolor{comment}{    percent of incorrectly classified cases.}}
\DoxyCodeLine{7615 \textcolor{comment}{}}
\DoxyCodeLine{7616 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7617 \textcolor{comment}{     Copyright 10.09.2008 by Bochkanov Sergey}}
\DoxyCodeLine{7618 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7619 \textcolor{keywordtype}{double} mnlrelclserror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}} \&lm, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7620 }
\DoxyCodeLine{7621 }
\DoxyCodeLine{7622 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7623 \textcolor{comment}{RMS error on the test set}}
\DoxyCodeLine{7624 \textcolor{comment}{}}
\DoxyCodeLine{7625 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7626 \textcolor{comment}{    LM      -\/   logit model}}
\DoxyCodeLine{7627 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{7628 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{7629 \textcolor{comment}{}}
\DoxyCodeLine{7630 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{7631 \textcolor{comment}{    root mean square error (error when estimating posterior probabilities).}}
\DoxyCodeLine{7632 \textcolor{comment}{}}
\DoxyCodeLine{7633 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7634 \textcolor{comment}{     Copyright 30.08.2008 by Bochkanov Sergey}}
\DoxyCodeLine{7635 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7636 \textcolor{keywordtype}{double} mnlrmserror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}} \&lm, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7637 }
\DoxyCodeLine{7638 }
\DoxyCodeLine{7639 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7640 \textcolor{comment}{Average error on the test set}}
\DoxyCodeLine{7641 \textcolor{comment}{}}
\DoxyCodeLine{7642 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7643 \textcolor{comment}{    LM      -\/   logit model}}
\DoxyCodeLine{7644 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{7645 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{7646 \textcolor{comment}{}}
\DoxyCodeLine{7647 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{7648 \textcolor{comment}{    average error (error when estimating posterior probabilities).}}
\DoxyCodeLine{7649 \textcolor{comment}{}}
\DoxyCodeLine{7650 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7651 \textcolor{comment}{     Copyright 30.08.2008 by Bochkanov Sergey}}
\DoxyCodeLine{7652 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7653 \textcolor{keywordtype}{double} mnlavgerror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}} \&lm, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7654 }
\DoxyCodeLine{7655 }
\DoxyCodeLine{7656 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7657 \textcolor{comment}{Average relative error on the test set}}
\DoxyCodeLine{7658 \textcolor{comment}{}}
\DoxyCodeLine{7659 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7660 \textcolor{comment}{    LM      -\/   logit model}}
\DoxyCodeLine{7661 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{7662 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{7663 \textcolor{comment}{}}
\DoxyCodeLine{7664 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{7665 \textcolor{comment}{    average relative error (error when estimating posterior probabilities).}}
\DoxyCodeLine{7666 \textcolor{comment}{}}
\DoxyCodeLine{7667 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7668 \textcolor{comment}{     Copyright 30.08.2008 by Bochkanov Sergey}}
\DoxyCodeLine{7669 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7670 \textcolor{keywordtype}{double} mnlavgrelerror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}} \&lm, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t ssize, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7671 }
\DoxyCodeLine{7672 }
\DoxyCodeLine{7673 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7674 \textcolor{comment}{Classification error on test set = MNLRelClsError*NPoints}}
\DoxyCodeLine{7675 \textcolor{comment}{}}
\DoxyCodeLine{7676 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7677 \textcolor{comment}{     Copyright 10.09.2008 by Bochkanov Sergey}}
\DoxyCodeLine{7678 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7679 ae\_int\_t mnlclserror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1logitmodel}{logitmodel}} \&lm, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7680 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{7681 }
\DoxyCodeLine{7682 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_KNN) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{7683 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7684 \textcolor{comment}{This function serializes data structure to string.}}
\DoxyCodeLine{7685 \textcolor{comment}{}}
\DoxyCodeLine{7686 \textcolor{comment}{Important properties of s\_out:}}
\DoxyCodeLine{7687 \textcolor{comment}{* it contains alphanumeric characters, dots, underscores, minus signs}}
\DoxyCodeLine{7688 \textcolor{comment}{* these symbols are grouped into words, which are separated by spaces}}
\DoxyCodeLine{7689 \textcolor{comment}{  and Windows-\/style (CR+LF) newlines}}
\DoxyCodeLine{7690 \textcolor{comment}{* although  serializer  uses  spaces and CR+LF as separators, you can }}
\DoxyCodeLine{7691 \textcolor{comment}{  replace any separator character by arbitrary combination of spaces,}}
\DoxyCodeLine{7692 \textcolor{comment}{  tabs, Windows or Unix newlines. It allows flexible reformatting  of}}
\DoxyCodeLine{7693 \textcolor{comment}{  the  string  in  case you want to include it into text or XML file. }}
\DoxyCodeLine{7694 \textcolor{comment}{  But you should not insert separators into the middle of the "{}words"{}}}
\DoxyCodeLine{7695 \textcolor{comment}{  nor you should change case of letters.}}
\DoxyCodeLine{7696 \textcolor{comment}{* s\_out can be freely moved between 32-\/bit and 64-\/bit systems, little}}
\DoxyCodeLine{7697 \textcolor{comment}{  and big endian machines, and so on. You can serialize structure  on}}
\DoxyCodeLine{7698 \textcolor{comment}{  32-\/bit machine and unserialize it on 64-\/bit one (or vice versa), or}}
\DoxyCodeLine{7699 \textcolor{comment}{  serialize  it  on  SPARC  and  unserialize  on  x86.  You  can also }}
\DoxyCodeLine{7700 \textcolor{comment}{  serialize  it  in  C++ version of ALGLIB and unserialize in C\# one, }}
\DoxyCodeLine{7701 \textcolor{comment}{  and vice versa.}}
\DoxyCodeLine{7702 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7703 \textcolor{keywordtype}{void} knnserialize(\mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&obj, std::string \&s\_out);}
\DoxyCodeLine{7704 }
\DoxyCodeLine{7705 }
\DoxyCodeLine{7706 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7707 \textcolor{comment}{This function unserializes data structure from string.}}
\DoxyCodeLine{7708 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7709 \textcolor{keywordtype}{void} knnunserialize(\textcolor{keyword}{const} std::string \&s\_in, \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&obj);}
\DoxyCodeLine{7710 }
\DoxyCodeLine{7711 }
\DoxyCodeLine{7712 }
\DoxyCodeLine{7713 }
\DoxyCodeLine{7714 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7715 \textcolor{comment}{This function serializes data structure to C++ stream.}}
\DoxyCodeLine{7716 \textcolor{comment}{}}
\DoxyCodeLine{7717 \textcolor{comment}{Data stream generated by this function is same as  string  representation}}
\DoxyCodeLine{7718 \textcolor{comment}{generated  by  string  version  of  serializer -\/ alphanumeric characters,}}
\DoxyCodeLine{7719 \textcolor{comment}{dots, underscores, minus signs, which are grouped into words separated by}}
\DoxyCodeLine{7720 \textcolor{comment}{spaces and CR+LF.}}
\DoxyCodeLine{7721 \textcolor{comment}{}}
\DoxyCodeLine{7722 \textcolor{comment}{We recommend you to read comments on string version of serializer to find}}
\DoxyCodeLine{7723 \textcolor{comment}{out more about serialization of AlGLIB objects.}}
\DoxyCodeLine{7724 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7725 \textcolor{keywordtype}{void} knnserialize(\mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&obj, std::ostream \&s\_out);}
\DoxyCodeLine{7726 }
\DoxyCodeLine{7727 }
\DoxyCodeLine{7728 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7729 \textcolor{comment}{This function unserializes data structure from stream.}}
\DoxyCodeLine{7730 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7731 \textcolor{keywordtype}{void} knnunserialize(\textcolor{keyword}{const} std::istream \&s\_in, \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&obj);}
\DoxyCodeLine{7732 }
\DoxyCodeLine{7733 }
\DoxyCodeLine{7734 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7735 \textcolor{comment}{This function creates buffer  structure  which  can  be  used  to  perform}}
\DoxyCodeLine{7736 \textcolor{comment}{parallel KNN requests.}}
\DoxyCodeLine{7737 \textcolor{comment}{}}
\DoxyCodeLine{7738 \textcolor{comment}{KNN subpackage provides two sets of computing functions -\/ ones  which  use}}
\DoxyCodeLine{7739 \textcolor{comment}{internal buffer of KNN model (these  functions are single-\/threaded because}}
\DoxyCodeLine{7740 \textcolor{comment}{they use same buffer, which can not  shared  between  threads),  and  ones}}
\DoxyCodeLine{7741 \textcolor{comment}{which use external buffer.}}
\DoxyCodeLine{7742 \textcolor{comment}{}}
\DoxyCodeLine{7743 \textcolor{comment}{This function is used to initialize external buffer.}}
\DoxyCodeLine{7744 \textcolor{comment}{}}
\DoxyCodeLine{7745 \textcolor{comment}{INPUT PARAMETERS}}
\DoxyCodeLine{7746 \textcolor{comment}{    Model       -\/   KNN model which is associated with newly created buffer}}
\DoxyCodeLine{7747 \textcolor{comment}{}}
\DoxyCodeLine{7748 \textcolor{comment}{OUTPUT PARAMETERS}}
\DoxyCodeLine{7749 \textcolor{comment}{    Buf         -\/   external buffer.}}
\DoxyCodeLine{7750 \textcolor{comment}{}}
\DoxyCodeLine{7751 \textcolor{comment}{}}
\DoxyCodeLine{7752 \textcolor{comment}{IMPORTANT: buffer object should be used only with model which was used  to}}
\DoxyCodeLine{7753 \textcolor{comment}{           initialize buffer. Any attempt to  use  buffer  with  different}}
\DoxyCodeLine{7754 \textcolor{comment}{           object is dangerous -\/ you  may   get  integrity  check  failure}}
\DoxyCodeLine{7755 \textcolor{comment}{           (exception) because sizes of internal  arrays  do  not  fit  to}}
\DoxyCodeLine{7756 \textcolor{comment}{           dimensions of the model structure.}}
\DoxyCodeLine{7757 \textcolor{comment}{}}
\DoxyCodeLine{7758 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7759 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{7760 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7761 \textcolor{keywordtype}{void} knncreatebuffer(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&model, \mbox{\hyperlink{classalglib_1_1knnbuffer}{knnbuffer}} \&buf, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7762 }
\DoxyCodeLine{7763 }
\DoxyCodeLine{7764 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7765 \textcolor{comment}{This subroutine creates KNNBuilder object which is used to train KNN models.}}
\DoxyCodeLine{7766 \textcolor{comment}{}}
\DoxyCodeLine{7767 \textcolor{comment}{By default, new builder stores empty dataset and some  reasonable  default}}
\DoxyCodeLine{7768 \textcolor{comment}{settings. At the very least, you should specify dataset prior to  building}}
\DoxyCodeLine{7769 \textcolor{comment}{KNN model. You can also tweak settings of the model construction algorithm}}
\DoxyCodeLine{7770 \textcolor{comment}{(recommended, although default settings should work well).}}
\DoxyCodeLine{7771 \textcolor{comment}{}}
\DoxyCodeLine{7772 \textcolor{comment}{Following actions are mandatory:}}
\DoxyCodeLine{7773 \textcolor{comment}{* calling knnbuildersetdataset() to specify dataset}}
\DoxyCodeLine{7774 \textcolor{comment}{* calling knnbuilderbuildknnmodel() to build KNN model using current}}
\DoxyCodeLine{7775 \textcolor{comment}{  dataset and default settings}}
\DoxyCodeLine{7776 \textcolor{comment}{}}
\DoxyCodeLine{7777 \textcolor{comment}{Additionally, you may call:}}
\DoxyCodeLine{7778 \textcolor{comment}{* knnbuildersetnorm() to change norm being used}}
\DoxyCodeLine{7779 \textcolor{comment}{}}
\DoxyCodeLine{7780 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7781 \textcolor{comment}{    none}}
\DoxyCodeLine{7782 \textcolor{comment}{}}
\DoxyCodeLine{7783 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{7784 \textcolor{comment}{    S           -\/   KNN builder}}
\DoxyCodeLine{7785 \textcolor{comment}{}}
\DoxyCodeLine{7786 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7787 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{7788 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7789 \textcolor{keywordtype}{void} knnbuildercreate(\mbox{\hyperlink{classalglib_1_1knnbuilder}{knnbuilder}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7790 }
\DoxyCodeLine{7791 }
\DoxyCodeLine{7792 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7793 \textcolor{comment}{Specifies regression problem (one or more continuous  output variables are}}
\DoxyCodeLine{7794 \textcolor{comment}{predicted). There also exists "{}classification"{} version of this function.}}
\DoxyCodeLine{7795 \textcolor{comment}{}}
\DoxyCodeLine{7796 \textcolor{comment}{This subroutine adds dense dataset to the internal storage of the  builder}}
\DoxyCodeLine{7797 \textcolor{comment}{object. Specifying your dataset in the dense format means that  the  dense}}
\DoxyCodeLine{7798 \textcolor{comment}{version of the KNN construction algorithm will be invoked.}}
\DoxyCodeLine{7799 \textcolor{comment}{}}
\DoxyCodeLine{7800 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7801 \textcolor{comment}{    S           -\/   KNN builder object}}
\DoxyCodeLine{7802 \textcolor{comment}{    XY          -\/   array[NPoints,NVars+NOut] (note: actual  size  can  be}}
\DoxyCodeLine{7803 \textcolor{comment}{                    larger, only leading part is used anyway), dataset:}}
\DoxyCodeLine{7804 \textcolor{comment}{                    * first NVars elements of each row store values of the}}
\DoxyCodeLine{7805 \textcolor{comment}{                      independent variables}}
\DoxyCodeLine{7806 \textcolor{comment}{                    * next NOut elements store  values  of  the  dependent}}
\DoxyCodeLine{7807 \textcolor{comment}{                      variables}}
\DoxyCodeLine{7808 \textcolor{comment}{    NPoints     -\/   number of rows in the dataset, NPoints>=1}}
\DoxyCodeLine{7809 \textcolor{comment}{    NVars       -\/   number of independent variables, NVars>=1}}
\DoxyCodeLine{7810 \textcolor{comment}{    NOut        -\/   number of dependent variables, NOut>=1}}
\DoxyCodeLine{7811 \textcolor{comment}{}}
\DoxyCodeLine{7812 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{7813 \textcolor{comment}{    S           -\/   KNN builder}}
\DoxyCodeLine{7814 \textcolor{comment}{}}
\DoxyCodeLine{7815 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7816 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{7817 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7818 \textcolor{keywordtype}{void} knnbuildersetdatasetreg(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnbuilder}{knnbuilder}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nvars, \textcolor{keyword}{const} ae\_int\_t nout, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7819 }
\DoxyCodeLine{7820 }
\DoxyCodeLine{7821 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7822 \textcolor{comment}{Specifies classification problem (two  or  more  classes  are  predicted).}}
\DoxyCodeLine{7823 \textcolor{comment}{There also exists "{}regression"{} version of this function.}}
\DoxyCodeLine{7824 \textcolor{comment}{}}
\DoxyCodeLine{7825 \textcolor{comment}{This subroutine adds dense dataset to the internal storage of the  builder}}
\DoxyCodeLine{7826 \textcolor{comment}{object. Specifying your dataset in the dense format means that  the  dense}}
\DoxyCodeLine{7827 \textcolor{comment}{version of the KNN construction algorithm will be invoked.}}
\DoxyCodeLine{7828 \textcolor{comment}{}}
\DoxyCodeLine{7829 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7830 \textcolor{comment}{    S           -\/   KNN builder object}}
\DoxyCodeLine{7831 \textcolor{comment}{    XY          -\/   array[NPoints,NVars+1] (note:   actual   size  can  be}}
\DoxyCodeLine{7832 \textcolor{comment}{                    larger, only leading part is used anyway), dataset:}}
\DoxyCodeLine{7833 \textcolor{comment}{                    * first NVars elements of each row store values of the}}
\DoxyCodeLine{7834 \textcolor{comment}{                      independent variables}}
\DoxyCodeLine{7835 \textcolor{comment}{                    * next element stores class index, in [0,NClasses)}}
\DoxyCodeLine{7836 \textcolor{comment}{    NPoints     -\/   number of rows in the dataset, NPoints>=1}}
\DoxyCodeLine{7837 \textcolor{comment}{    NVars       -\/   number of independent variables, NVars>=1}}
\DoxyCodeLine{7838 \textcolor{comment}{    NClasses    -\/   number of classes, NClasses>=2}}
\DoxyCodeLine{7839 \textcolor{comment}{}}
\DoxyCodeLine{7840 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{7841 \textcolor{comment}{    S           -\/   KNN builder}}
\DoxyCodeLine{7842 \textcolor{comment}{}}
\DoxyCodeLine{7843 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7844 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{7845 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7846 \textcolor{keywordtype}{void} knnbuildersetdatasetcls(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnbuilder}{knnbuilder}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nvars, \textcolor{keyword}{const} ae\_int\_t nclasses, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7847 }
\DoxyCodeLine{7848 }
\DoxyCodeLine{7849 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7850 \textcolor{comment}{This function sets norm type used for neighbor search.}}
\DoxyCodeLine{7851 \textcolor{comment}{}}
\DoxyCodeLine{7852 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7853 \textcolor{comment}{    S           -\/   decision forest builder object}}
\DoxyCodeLine{7854 \textcolor{comment}{    NormType    -\/   norm type:}}
\DoxyCodeLine{7855 \textcolor{comment}{                    * 0      inf-\/norm}}
\DoxyCodeLine{7856 \textcolor{comment}{                    * 1      1-\/norm}}
\DoxyCodeLine{7857 \textcolor{comment}{                    * 2      Euclidean norm (default)}}
\DoxyCodeLine{7858 \textcolor{comment}{}}
\DoxyCodeLine{7859 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{7860 \textcolor{comment}{    S           -\/   decision forest builder}}
\DoxyCodeLine{7861 \textcolor{comment}{}}
\DoxyCodeLine{7862 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7863 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{7864 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7865 \textcolor{keywordtype}{void} knnbuildersetnorm(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnbuilder}{knnbuilder}} \&s, \textcolor{keyword}{const} ae\_int\_t nrmtype, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7866 }
\DoxyCodeLine{7867 }
\DoxyCodeLine{7868 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7869 \textcolor{comment}{This subroutine builds KNN model  according  to  current  settings,  using}}
\DoxyCodeLine{7870 \textcolor{comment}{dataset internally stored in the builder object.}}
\DoxyCodeLine{7871 \textcolor{comment}{}}
\DoxyCodeLine{7872 \textcolor{comment}{The model being built performs inference using Eps-\/approximate  K  nearest}}
\DoxyCodeLine{7873 \textcolor{comment}{neighbors search algorithm, with:}}
\DoxyCodeLine{7874 \textcolor{comment}{* K=1,  Eps=0 corresponding to the "{}nearest neighbor algorithm"{}}}
\DoxyCodeLine{7875 \textcolor{comment}{* K>1,  Eps=0 corresponding to the "{}K nearest neighbors algorithm"{}}}
\DoxyCodeLine{7876 \textcolor{comment}{* K>=1, Eps>0 corresponding to "{}approximate nearest neighbors algorithm"{}}}
\DoxyCodeLine{7877 \textcolor{comment}{}}
\DoxyCodeLine{7878 \textcolor{comment}{An approximate KNN is a good option for high-\/dimensional  datasets  (exact}}
\DoxyCodeLine{7879 \textcolor{comment}{KNN works slowly when dimensions count grows).}}
\DoxyCodeLine{7880 \textcolor{comment}{}}
\DoxyCodeLine{7881 \textcolor{comment}{An ALGLIB implementation of kd-\/trees is used to perform k-\/nn searches.}}
\DoxyCodeLine{7882 \textcolor{comment}{}}
\DoxyCodeLine{7883 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{7884 \textcolor{comment}{  !}}
\DoxyCodeLine{7885 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{7886 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{7887 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{7888 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{7889 \textcolor{comment}{  !}}
\DoxyCodeLine{7890 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{7891 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{7892 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{7893 \textcolor{comment}{}}
\DoxyCodeLine{7894 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7895 \textcolor{comment}{    S       -\/   KNN builder object}}
\DoxyCodeLine{7896 \textcolor{comment}{    K       -\/   number of neighbors to search for, K>=1}}
\DoxyCodeLine{7897 \textcolor{comment}{    Eps     -\/   approximation factor:}}
\DoxyCodeLine{7898 \textcolor{comment}{                * Eps=0 means that exact kNN search is performed}}
\DoxyCodeLine{7899 \textcolor{comment}{                * Eps>0 means that (1+Eps)-\/approximate search is performed}}
\DoxyCodeLine{7900 \textcolor{comment}{}}
\DoxyCodeLine{7901 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{7902 \textcolor{comment}{    Model       -\/   KNN model}}
\DoxyCodeLine{7903 \textcolor{comment}{    Rep         -\/   report}}
\DoxyCodeLine{7904 \textcolor{comment}{}}
\DoxyCodeLine{7905 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7906 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{7907 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7908 \textcolor{keywordtype}{void} knnbuilderbuildknnmodel(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnbuilder}{knnbuilder}} \&s, \textcolor{keyword}{const} ae\_int\_t k, \textcolor{keyword}{const} \textcolor{keywordtype}{double} eps, \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&model, \mbox{\hyperlink{classalglib_1_1knnreport}{knnreport}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7909 }
\DoxyCodeLine{7910 }
\DoxyCodeLine{7911 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7912 \textcolor{comment}{Changing search settings of KNN model.}}
\DoxyCodeLine{7913 \textcolor{comment}{}}
\DoxyCodeLine{7914 \textcolor{comment}{K and EPS parameters of KNN  (AKNN)  search  are  specified  during  model}}
\DoxyCodeLine{7915 \textcolor{comment}{construction. However, plain KNN algorithm with Euclidean distance  allows}}
\DoxyCodeLine{7916 \textcolor{comment}{you to change them at any moment.}}
\DoxyCodeLine{7917 \textcolor{comment}{}}
\DoxyCodeLine{7918 \textcolor{comment}{NOTE: future versions of KNN model may support advanced versions  of  KNN,}}
\DoxyCodeLine{7919 \textcolor{comment}{      such as NCA or LMNN. It is possible that such algorithms won't allow}}
\DoxyCodeLine{7920 \textcolor{comment}{      you to change search settings on the fly. If you call this  function}}
\DoxyCodeLine{7921 \textcolor{comment}{      for an algorithm which does not support on-\/the-\/fly changes, it  will}}
\DoxyCodeLine{7922 \textcolor{comment}{      throw an exception.}}
\DoxyCodeLine{7923 \textcolor{comment}{}}
\DoxyCodeLine{7924 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7925 \textcolor{comment}{    Model   -\/   KNN model}}
\DoxyCodeLine{7926 \textcolor{comment}{    K       -\/   K>=1, neighbors count}}
\DoxyCodeLine{7927 \textcolor{comment}{    EPS     -\/   accuracy of the EPS-\/approximate NN search. Set to 0.0,  if}}
\DoxyCodeLine{7928 \textcolor{comment}{                you want to perform "{}classic"{} KNN search.  Specify  larger}}
\DoxyCodeLine{7929 \textcolor{comment}{                values  if  you  need  to  speed-\/up  high-\/dimensional  KNN}}
\DoxyCodeLine{7930 \textcolor{comment}{                queries.}}
\DoxyCodeLine{7931 \textcolor{comment}{}}
\DoxyCodeLine{7932 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{7933 \textcolor{comment}{    nothing on success, exception on failure}}
\DoxyCodeLine{7934 \textcolor{comment}{}}
\DoxyCodeLine{7935 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7936 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{7937 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7938 \textcolor{keywordtype}{void} knnrewritekeps(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&model, \textcolor{keyword}{const} ae\_int\_t k, \textcolor{keyword}{const} \textcolor{keywordtype}{double} eps, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7939 }
\DoxyCodeLine{7940 }
\DoxyCodeLine{7941 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7942 \textcolor{comment}{Inference using KNN model.}}
\DoxyCodeLine{7943 \textcolor{comment}{}}
\DoxyCodeLine{7944 \textcolor{comment}{See also knnprocess0(), knnprocessi() and knnclassify() for options with a}}
\DoxyCodeLine{7945 \textcolor{comment}{bit more convenient interface.}}
\DoxyCodeLine{7946 \textcolor{comment}{}}
\DoxyCodeLine{7947 \textcolor{comment}{IMPORTANT: this function is thread-\/unsafe and modifies internal structures}}
\DoxyCodeLine{7948 \textcolor{comment}{           of the model! You can not use same model  object  for  parallel}}
\DoxyCodeLine{7949 \textcolor{comment}{           evaluation from several threads.}}
\DoxyCodeLine{7950 \textcolor{comment}{}}
\DoxyCodeLine{7951 \textcolor{comment}{           Use knntsprocess() with independent  thread-\/local  buffers,  if}}
\DoxyCodeLine{7952 \textcolor{comment}{           you need thread-\/safe evaluation.}}
\DoxyCodeLine{7953 \textcolor{comment}{}}
\DoxyCodeLine{7954 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7955 \textcolor{comment}{    Model   -\/   KNN model}}
\DoxyCodeLine{7956 \textcolor{comment}{    X       -\/   input vector,  array[0..NVars-\/1].}}
\DoxyCodeLine{7957 \textcolor{comment}{    Y       -\/   possible preallocated buffer. Reused if long enough.}}
\DoxyCodeLine{7958 \textcolor{comment}{}}
\DoxyCodeLine{7959 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{7960 \textcolor{comment}{    Y       -\/   result. Regression estimate when solving regression  task,}}
\DoxyCodeLine{7961 \textcolor{comment}{                vector of posterior probabilities for classification task.}}
\DoxyCodeLine{7962 \textcolor{comment}{}}
\DoxyCodeLine{7963 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7964 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{7965 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{7966 \textcolor{keywordtype}{void} knnprocess(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&model, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&y, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{7967 }
\DoxyCodeLine{7968 }
\DoxyCodeLine{7969 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{7970 \textcolor{comment}{This function returns first component of the  inferred  vector  (i.e.  one}}
\DoxyCodeLine{7971 \textcolor{comment}{with index \#0).}}
\DoxyCodeLine{7972 \textcolor{comment}{}}
\DoxyCodeLine{7973 \textcolor{comment}{It is a convenience wrapper for knnprocess() intended for either:}}
\DoxyCodeLine{7974 \textcolor{comment}{* 1-\/dimensional regression problems}}
\DoxyCodeLine{7975 \textcolor{comment}{* 2-\/class classification problems}}
\DoxyCodeLine{7976 \textcolor{comment}{}}
\DoxyCodeLine{7977 \textcolor{comment}{In the former case this function returns inference result as scalar, which}}
\DoxyCodeLine{7978 \textcolor{comment}{is definitely more convenient that wrapping it as vector.  In  the  latter}}
\DoxyCodeLine{7979 \textcolor{comment}{case it returns probability of object belonging to class \#0.}}
\DoxyCodeLine{7980 \textcolor{comment}{}}
\DoxyCodeLine{7981 \textcolor{comment}{If you call it for anything different from two cases above, it  will  work}}
\DoxyCodeLine{7982 \textcolor{comment}{as defined, i.e. return y[0], although it is of less use in such cases.}}
\DoxyCodeLine{7983 \textcolor{comment}{}}
\DoxyCodeLine{7984 \textcolor{comment}{IMPORTANT: this function is thread-\/unsafe and modifies internal structures}}
\DoxyCodeLine{7985 \textcolor{comment}{           of the model! You can not use same model  object  for  parallel}}
\DoxyCodeLine{7986 \textcolor{comment}{           evaluation from several threads.}}
\DoxyCodeLine{7987 \textcolor{comment}{}}
\DoxyCodeLine{7988 \textcolor{comment}{           Use knntsprocess() with independent  thread-\/local  buffers,  if}}
\DoxyCodeLine{7989 \textcolor{comment}{           you need thread-\/safe evaluation.}}
\DoxyCodeLine{7990 \textcolor{comment}{}}
\DoxyCodeLine{7991 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{7992 \textcolor{comment}{    Model   -\/   KNN model}}
\DoxyCodeLine{7993 \textcolor{comment}{    X       -\/   input vector,  array[0..NVars-\/1].}}
\DoxyCodeLine{7994 \textcolor{comment}{}}
\DoxyCodeLine{7995 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{7996 \textcolor{comment}{    Y[0]}}
\DoxyCodeLine{7997 \textcolor{comment}{}}
\DoxyCodeLine{7998 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{7999 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{8000 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8001 \textcolor{keywordtype}{double} knnprocess0(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&model, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8002 }
\DoxyCodeLine{8003 }
\DoxyCodeLine{8004 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8005 \textcolor{comment}{This function returns most probable class number for an  input  X.  It  is}}
\DoxyCodeLine{8006 \textcolor{comment}{same as calling knnprocess(model,x,y), then determining i=argmax(y[i]) and}}
\DoxyCodeLine{8007 \textcolor{comment}{returning i.}}
\DoxyCodeLine{8008 \textcolor{comment}{}}
\DoxyCodeLine{8009 \textcolor{comment}{A class number in [0,NOut) range in returned for classification  problems,}}
\DoxyCodeLine{8010 \textcolor{comment}{-\/1 is returned when this function is called for regression problems.}}
\DoxyCodeLine{8011 \textcolor{comment}{}}
\DoxyCodeLine{8012 \textcolor{comment}{IMPORTANT: this function is thread-\/unsafe and modifies internal structures}}
\DoxyCodeLine{8013 \textcolor{comment}{           of the model! You can not use same model  object  for  parallel}}
\DoxyCodeLine{8014 \textcolor{comment}{           evaluation from several threads.}}
\DoxyCodeLine{8015 \textcolor{comment}{}}
\DoxyCodeLine{8016 \textcolor{comment}{           Use knntsprocess() with independent  thread-\/local  buffers,  if}}
\DoxyCodeLine{8017 \textcolor{comment}{           you need thread-\/safe evaluation.}}
\DoxyCodeLine{8018 \textcolor{comment}{}}
\DoxyCodeLine{8019 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8020 \textcolor{comment}{    Model   -\/   KNN model}}
\DoxyCodeLine{8021 \textcolor{comment}{    X       -\/   input vector,  array[0..NVars-\/1].}}
\DoxyCodeLine{8022 \textcolor{comment}{}}
\DoxyCodeLine{8023 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{8024 \textcolor{comment}{    class number, -\/1 for regression tasks}}
\DoxyCodeLine{8025 \textcolor{comment}{}}
\DoxyCodeLine{8026 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8027 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{8028 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8029 ae\_int\_t knnclassify(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&model, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8030 }
\DoxyCodeLine{8031 }
\DoxyCodeLine{8032 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8033 \textcolor{comment}{'interactive' variant of knnprocess()  for  languages  like  Python  which}}
\DoxyCodeLine{8034 \textcolor{comment}{support constructs like "{}y = knnprocessi(model,x)"{} and interactive mode of}}
\DoxyCodeLine{8035 \textcolor{comment}{the interpreter.}}
\DoxyCodeLine{8036 \textcolor{comment}{}}
\DoxyCodeLine{8037 \textcolor{comment}{This function allocates new array on each call,  so  it  is  significantly}}
\DoxyCodeLine{8038 \textcolor{comment}{slower than its 'non-\/interactive' counterpart, but it is  more  convenient}}
\DoxyCodeLine{8039 \textcolor{comment}{when you call it from command line.}}
\DoxyCodeLine{8040 \textcolor{comment}{}}
\DoxyCodeLine{8041 \textcolor{comment}{IMPORTANT: this  function  is  thread-\/unsafe  and  may   modify   internal}}
\DoxyCodeLine{8042 \textcolor{comment}{           structures of the model! You can not use same model  object for}}
\DoxyCodeLine{8043 \textcolor{comment}{           parallel evaluation from several threads.}}
\DoxyCodeLine{8044 \textcolor{comment}{}}
\DoxyCodeLine{8045 \textcolor{comment}{           Use knntsprocess()  with  independent  thread-\/local  buffers if}}
\DoxyCodeLine{8046 \textcolor{comment}{           you need thread-\/safe evaluation.}}
\DoxyCodeLine{8047 \textcolor{comment}{}}
\DoxyCodeLine{8048 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8049 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{8050 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8051 \textcolor{keywordtype}{void} knnprocessi(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&model, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&y, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8052 }
\DoxyCodeLine{8053 }
\DoxyCodeLine{8054 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8055 \textcolor{comment}{Thread-\/safe procesing using external buffer for temporaries.}}
\DoxyCodeLine{8056 \textcolor{comment}{}}
\DoxyCodeLine{8057 \textcolor{comment}{This function is thread-\/safe (i.e .  you  can  use  same  KNN  model  from}}
\DoxyCodeLine{8058 \textcolor{comment}{multiple threads) as long as you use different buffer objects for different}}
\DoxyCodeLine{8059 \textcolor{comment}{threads.}}
\DoxyCodeLine{8060 \textcolor{comment}{}}
\DoxyCodeLine{8061 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8062 \textcolor{comment}{    Model   -\/   KNN model}}
\DoxyCodeLine{8063 \textcolor{comment}{    Buf     -\/   buffer object, must be  allocated  specifically  for  this}}
\DoxyCodeLine{8064 \textcolor{comment}{                model with knncreatebuffer().}}
\DoxyCodeLine{8065 \textcolor{comment}{    X       -\/   input vector,  array[NVars]}}
\DoxyCodeLine{8066 \textcolor{comment}{}}
\DoxyCodeLine{8067 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8068 \textcolor{comment}{    Y       -\/   result, array[NOut].   Regression  estimate  when  solving}}
\DoxyCodeLine{8069 \textcolor{comment}{                regression task,  vector  of  posterior  probabilities for}}
\DoxyCodeLine{8070 \textcolor{comment}{                a classification task.}}
\DoxyCodeLine{8071 \textcolor{comment}{}}
\DoxyCodeLine{8072 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8073 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{8074 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8075 \textcolor{keywordtype}{void} knntsprocess(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&model, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnbuffer}{knnbuffer}} \&buf, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&x, \mbox{\hyperlink{classalglib_1_1real__1d__array}{real\_1d\_array}} \&y, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8076 }
\DoxyCodeLine{8077 }
\DoxyCodeLine{8078 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8079 \textcolor{comment}{Relative classification error on the test set}}
\DoxyCodeLine{8080 \textcolor{comment}{}}
\DoxyCodeLine{8081 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8082 \textcolor{comment}{    Model   -\/   KNN model}}
\DoxyCodeLine{8083 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{8084 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{8085 \textcolor{comment}{}}
\DoxyCodeLine{8086 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{8087 \textcolor{comment}{    percent of incorrectly classified cases.}}
\DoxyCodeLine{8088 \textcolor{comment}{    Zero if model solves regression task.}}
\DoxyCodeLine{8089 \textcolor{comment}{}}
\DoxyCodeLine{8090 \textcolor{comment}{NOTE: if  you  need several different kinds of error metrics, it is better}}
\DoxyCodeLine{8091 \textcolor{comment}{      to use knnallerrors() which computes all error metric  with just one}}
\DoxyCodeLine{8092 \textcolor{comment}{      pass over dataset.}}
\DoxyCodeLine{8093 \textcolor{comment}{}}
\DoxyCodeLine{8094 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8095 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{8096 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8097 \textcolor{keywordtype}{double} knnrelclserror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&model, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8098 }
\DoxyCodeLine{8099 }
\DoxyCodeLine{8100 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8101 \textcolor{comment}{Average cross-\/entropy (in bits per element) on the test set}}
\DoxyCodeLine{8102 \textcolor{comment}{}}
\DoxyCodeLine{8103 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8104 \textcolor{comment}{    Model   -\/   KNN model}}
\DoxyCodeLine{8105 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{8106 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{8107 \textcolor{comment}{}}
\DoxyCodeLine{8108 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{8109 \textcolor{comment}{    CrossEntropy/NPoints.}}
\DoxyCodeLine{8110 \textcolor{comment}{    Zero if model solves regression task.}}
\DoxyCodeLine{8111 \textcolor{comment}{}}
\DoxyCodeLine{8112 \textcolor{comment}{NOTE: the cross-\/entropy metric is too unstable when used to  evaluate  KNN}}
\DoxyCodeLine{8113 \textcolor{comment}{      models (such models can report exactly  zero probabilities),  so  we}}
\DoxyCodeLine{8114 \textcolor{comment}{      do not recommend using it.}}
\DoxyCodeLine{8115 \textcolor{comment}{}}
\DoxyCodeLine{8116 \textcolor{comment}{NOTE: if  you  need several different kinds of error metrics, it is better}}
\DoxyCodeLine{8117 \textcolor{comment}{      to use knnallerrors() which computes all error metric  with just one}}
\DoxyCodeLine{8118 \textcolor{comment}{      pass over dataset.}}
\DoxyCodeLine{8119 \textcolor{comment}{}}
\DoxyCodeLine{8120 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8121 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{8122 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8123 \textcolor{keywordtype}{double} knnavgce(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&model, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8124 }
\DoxyCodeLine{8125 }
\DoxyCodeLine{8126 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8127 \textcolor{comment}{RMS error on the test set.}}
\DoxyCodeLine{8128 \textcolor{comment}{}}
\DoxyCodeLine{8129 \textcolor{comment}{Its meaning for regression task is obvious. As for classification problems,}}
\DoxyCodeLine{8130 \textcolor{comment}{RMS error means error when estimating posterior probabilities.}}
\DoxyCodeLine{8131 \textcolor{comment}{}}
\DoxyCodeLine{8132 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8133 \textcolor{comment}{    Model   -\/   KNN model}}
\DoxyCodeLine{8134 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{8135 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{8136 \textcolor{comment}{}}
\DoxyCodeLine{8137 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{8138 \textcolor{comment}{    root mean square error.}}
\DoxyCodeLine{8139 \textcolor{comment}{}}
\DoxyCodeLine{8140 \textcolor{comment}{NOTE: if  you  need several different kinds of error metrics, it is better}}
\DoxyCodeLine{8141 \textcolor{comment}{      to use knnallerrors() which computes all error metric  with just one}}
\DoxyCodeLine{8142 \textcolor{comment}{      pass over dataset.}}
\DoxyCodeLine{8143 \textcolor{comment}{}}
\DoxyCodeLine{8144 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8145 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{8146 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8147 \textcolor{keywordtype}{double} knnrmserror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&model, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8148 }
\DoxyCodeLine{8149 }
\DoxyCodeLine{8150 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8151 \textcolor{comment}{Average error on the test set}}
\DoxyCodeLine{8152 \textcolor{comment}{}}
\DoxyCodeLine{8153 \textcolor{comment}{Its meaning for regression task is obvious. As for classification problems,}}
\DoxyCodeLine{8154 \textcolor{comment}{average error means error when estimating posterior probabilities.}}
\DoxyCodeLine{8155 \textcolor{comment}{}}
\DoxyCodeLine{8156 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8157 \textcolor{comment}{    Model   -\/   KNN model}}
\DoxyCodeLine{8158 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{8159 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{8160 \textcolor{comment}{}}
\DoxyCodeLine{8161 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{8162 \textcolor{comment}{    average error}}
\DoxyCodeLine{8163 \textcolor{comment}{}}
\DoxyCodeLine{8164 \textcolor{comment}{NOTE: if  you  need several different kinds of error metrics, it is better}}
\DoxyCodeLine{8165 \textcolor{comment}{      to use knnallerrors() which computes all error metric  with just one}}
\DoxyCodeLine{8166 \textcolor{comment}{      pass over dataset.}}
\DoxyCodeLine{8167 \textcolor{comment}{}}
\DoxyCodeLine{8168 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8169 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{8170 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8171 \textcolor{keywordtype}{double} knnavgerror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&model, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8172 }
\DoxyCodeLine{8173 }
\DoxyCodeLine{8174 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8175 \textcolor{comment}{Average relative error on the test set}}
\DoxyCodeLine{8176 \textcolor{comment}{}}
\DoxyCodeLine{8177 \textcolor{comment}{Its meaning for regression task is obvious. As for classification problems,}}
\DoxyCodeLine{8178 \textcolor{comment}{average relative error means error when estimating posterior probabilities.}}
\DoxyCodeLine{8179 \textcolor{comment}{}}
\DoxyCodeLine{8180 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8181 \textcolor{comment}{    Model   -\/   KNN model}}
\DoxyCodeLine{8182 \textcolor{comment}{    XY      -\/   test set}}
\DoxyCodeLine{8183 \textcolor{comment}{    NPoints -\/   test set size}}
\DoxyCodeLine{8184 \textcolor{comment}{}}
\DoxyCodeLine{8185 \textcolor{comment}{RESULT:}}
\DoxyCodeLine{8186 \textcolor{comment}{    average relative error}}
\DoxyCodeLine{8187 \textcolor{comment}{}}
\DoxyCodeLine{8188 \textcolor{comment}{NOTE: if  you  need several different kinds of error metrics, it is better}}
\DoxyCodeLine{8189 \textcolor{comment}{      to use knnallerrors() which computes all error metric  with just one}}
\DoxyCodeLine{8190 \textcolor{comment}{      pass over dataset.}}
\DoxyCodeLine{8191 \textcolor{comment}{}}
\DoxyCodeLine{8192 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8193 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{8194 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8195 \textcolor{keywordtype}{double} knnavgrelerror(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&model, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8196 }
\DoxyCodeLine{8197 }
\DoxyCodeLine{8198 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8199 \textcolor{comment}{Calculates all kinds of errors for the model in one call.}}
\DoxyCodeLine{8200 \textcolor{comment}{}}
\DoxyCodeLine{8201 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8202 \textcolor{comment}{    Model   -\/   KNN model}}
\DoxyCodeLine{8203 \textcolor{comment}{    XY      -\/   test set:}}
\DoxyCodeLine{8204 \textcolor{comment}{                * one row per point}}
\DoxyCodeLine{8205 \textcolor{comment}{                * first NVars columns store independent variables}}
\DoxyCodeLine{8206 \textcolor{comment}{                * depending on problem type:}}
\DoxyCodeLine{8207 \textcolor{comment}{                  * next column stores class number in [0,NClasses) -\/  for}}
\DoxyCodeLine{8208 \textcolor{comment}{                    classification problems}}
\DoxyCodeLine{8209 \textcolor{comment}{                  * next NOut columns  store  dependent  variables  -\/  for}}
\DoxyCodeLine{8210 \textcolor{comment}{                    regression problems}}
\DoxyCodeLine{8211 \textcolor{comment}{    NPoints -\/   test set size, NPoints>=0}}
\DoxyCodeLine{8212 \textcolor{comment}{}}
\DoxyCodeLine{8213 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8214 \textcolor{comment}{    Rep     -\/   following fields are loaded with errors for both regression}}
\DoxyCodeLine{8215 \textcolor{comment}{                and classification models:}}
\DoxyCodeLine{8216 \textcolor{comment}{                * rep.rmserror -\/ RMS error for the output}}
\DoxyCodeLine{8217 \textcolor{comment}{                * rep.avgerror -\/ average error}}
\DoxyCodeLine{8218 \textcolor{comment}{                * rep.avgrelerror -\/ average relative error}}
\DoxyCodeLine{8219 \textcolor{comment}{                following fields are set only  for classification  models,}}
\DoxyCodeLine{8220 \textcolor{comment}{                zero for regression ones:}}
\DoxyCodeLine{8221 \textcolor{comment}{                * relclserror   -\/ relative classification error, in [0,1]}}
\DoxyCodeLine{8222 \textcolor{comment}{                * avgce -\/ average cross-\/entropy in bits per dataset entry}}
\DoxyCodeLine{8223 \textcolor{comment}{}}
\DoxyCodeLine{8224 \textcolor{comment}{NOTE: the cross-\/entropy metric is too unstable when used to  evaluate  KNN}}
\DoxyCodeLine{8225 \textcolor{comment}{      models (such models can report exactly  zero probabilities),  so  we}}
\DoxyCodeLine{8226 \textcolor{comment}{      do not recommend using it.}}
\DoxyCodeLine{8227 \textcolor{comment}{}}
\DoxyCodeLine{8228 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8229 \textcolor{comment}{     Copyright 15.02.2019 by Bochkanov Sergey}}
\DoxyCodeLine{8230 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8231 \textcolor{keywordtype}{void} knnallerrors(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1knnmodel}{knnmodel}} \&model, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \mbox{\hyperlink{classalglib_1_1knnreport}{knnreport}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8232 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{8233 }
\DoxyCodeLine{8234 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_MLPTRAIN) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{8235 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8236 \textcolor{comment}{Neural network training  using  modified  Levenberg-\/Marquardt  with  exact}}
\DoxyCodeLine{8237 \textcolor{comment}{Hessian calculation and regularization. Subroutine trains  neural  network}}
\DoxyCodeLine{8238 \textcolor{comment}{with restarts from random positions. Algorithm is well  suited  for  small}}
\DoxyCodeLine{8239 \textcolor{comment}{and medium scale problems (hundreds of weights).}}
\DoxyCodeLine{8240 \textcolor{comment}{}}
\DoxyCodeLine{8241 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8242 \textcolor{comment}{    Network     -\/   neural network with initialized geometry}}
\DoxyCodeLine{8243 \textcolor{comment}{    XY          -\/   training set}}
\DoxyCodeLine{8244 \textcolor{comment}{    NPoints     -\/   training set size}}
\DoxyCodeLine{8245 \textcolor{comment}{    Decay       -\/   weight decay constant, >=0.001}}
\DoxyCodeLine{8246 \textcolor{comment}{                    Decay term 'Decay*||Weights||\string^2' is added to error}}
\DoxyCodeLine{8247 \textcolor{comment}{                    function.}}
\DoxyCodeLine{8248 \textcolor{comment}{                    If you don't know what Decay to choose, use 0.001.}}
\DoxyCodeLine{8249 \textcolor{comment}{    Restarts    -\/   number of restarts from random position, >0.}}
\DoxyCodeLine{8250 \textcolor{comment}{                    If you don't know what Restarts to choose, use 2.}}
\DoxyCodeLine{8251 \textcolor{comment}{}}
\DoxyCodeLine{8252 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8253 \textcolor{comment}{    Network     -\/   trained neural network.}}
\DoxyCodeLine{8254 \textcolor{comment}{    Info        -\/   return code:}}
\DoxyCodeLine{8255 \textcolor{comment}{                    * -\/9, if internal matrix inverse subroutine failed}}
\DoxyCodeLine{8256 \textcolor{comment}{                    * -\/2, if there is a point with class number}}
\DoxyCodeLine{8257 \textcolor{comment}{                          outside of [0..NOut-\/1].}}
\DoxyCodeLine{8258 \textcolor{comment}{                    * -\/1, if wrong parameters specified}}
\DoxyCodeLine{8259 \textcolor{comment}{                          (NPoints<0, Restarts<1).}}
\DoxyCodeLine{8260 \textcolor{comment}{                    *  2, if task has been solved.}}
\DoxyCodeLine{8261 \textcolor{comment}{    Rep         -\/   training report}}
\DoxyCodeLine{8262 \textcolor{comment}{}}
\DoxyCodeLine{8263 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8264 \textcolor{comment}{     Copyright 10.03.2009 by Bochkanov Sergey}}
\DoxyCodeLine{8265 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8266 \textcolor{keywordtype}{void} mlptrainlm(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \textcolor{keywordtype}{double} decay, \textcolor{keyword}{const} ae\_int\_t restarts, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8267 }
\DoxyCodeLine{8268 }
\DoxyCodeLine{8269 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8270 \textcolor{comment}{Neural  network  training  using  L-\/BFGS  algorithm  with  regularization.}}
\DoxyCodeLine{8271 \textcolor{comment}{Subroutine  trains  neural  network  with  restarts from random positions.}}
\DoxyCodeLine{8272 \textcolor{comment}{Algorithm  is  well  suited  for  problems  of  any dimensionality (memory}}
\DoxyCodeLine{8273 \textcolor{comment}{requirements and step complexity are linear by weights number).}}
\DoxyCodeLine{8274 \textcolor{comment}{}}
\DoxyCodeLine{8275 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8276 \textcolor{comment}{    Network     -\/   neural network with initialized geometry}}
\DoxyCodeLine{8277 \textcolor{comment}{    XY          -\/   training set}}
\DoxyCodeLine{8278 \textcolor{comment}{    NPoints     -\/   training set size}}
\DoxyCodeLine{8279 \textcolor{comment}{    Decay       -\/   weight decay constant, >=0.001}}
\DoxyCodeLine{8280 \textcolor{comment}{                    Decay term 'Decay*||Weights||\string^2' is added to error}}
\DoxyCodeLine{8281 \textcolor{comment}{                    function.}}
\DoxyCodeLine{8282 \textcolor{comment}{                    If you don't know what Decay to choose, use 0.001.}}
\DoxyCodeLine{8283 \textcolor{comment}{    Restarts    -\/   number of restarts from random position, >0.}}
\DoxyCodeLine{8284 \textcolor{comment}{                    If you don't know what Restarts to choose, use 2.}}
\DoxyCodeLine{8285 \textcolor{comment}{    WStep       -\/   stopping criterion. Algorithm stops if  step  size  is}}
\DoxyCodeLine{8286 \textcolor{comment}{                    less than WStep. Recommended value -\/ 0.01.  Zero  step}}
\DoxyCodeLine{8287 \textcolor{comment}{                    size means stopping after MaxIts iterations.}}
\DoxyCodeLine{8288 \textcolor{comment}{    MaxIts      -\/   stopping   criterion.  Algorithm  stops  after  MaxIts}}
\DoxyCodeLine{8289 \textcolor{comment}{                    iterations (NOT gradient  calculations).  Zero  MaxIts}}
\DoxyCodeLine{8290 \textcolor{comment}{                    means stopping when step is sufficiently small.}}
\DoxyCodeLine{8291 \textcolor{comment}{}}
\DoxyCodeLine{8292 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8293 \textcolor{comment}{    Network     -\/   trained neural network.}}
\DoxyCodeLine{8294 \textcolor{comment}{    Info        -\/   return code:}}
\DoxyCodeLine{8295 \textcolor{comment}{                    * -\/8, if both WStep=0 and MaxIts=0}}
\DoxyCodeLine{8296 \textcolor{comment}{                    * -\/2, if there is a point with class number}}
\DoxyCodeLine{8297 \textcolor{comment}{                          outside of [0..NOut-\/1].}}
\DoxyCodeLine{8298 \textcolor{comment}{                    * -\/1, if wrong parameters specified}}
\DoxyCodeLine{8299 \textcolor{comment}{                          (NPoints<0, Restarts<1).}}
\DoxyCodeLine{8300 \textcolor{comment}{                    *  2, if task has been solved.}}
\DoxyCodeLine{8301 \textcolor{comment}{    Rep         -\/   training report}}
\DoxyCodeLine{8302 \textcolor{comment}{}}
\DoxyCodeLine{8303 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8304 \textcolor{comment}{     Copyright 09.12.2007 by Bochkanov Sergey}}
\DoxyCodeLine{8305 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8306 \textcolor{keywordtype}{void} mlptrainlbfgs(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \textcolor{keywordtype}{double} decay, \textcolor{keyword}{const} ae\_int\_t restarts, \textcolor{keyword}{const} \textcolor{keywordtype}{double} wstep, \textcolor{keyword}{const} ae\_int\_t maxits, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8307 }
\DoxyCodeLine{8308 }
\DoxyCodeLine{8309 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8310 \textcolor{comment}{Neural network training using early stopping (base algorithm -\/ L-\/BFGS with}}
\DoxyCodeLine{8311 \textcolor{comment}{regularization).}}
\DoxyCodeLine{8312 \textcolor{comment}{}}
\DoxyCodeLine{8313 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8314 \textcolor{comment}{    Network     -\/   neural network with initialized geometry}}
\DoxyCodeLine{8315 \textcolor{comment}{    TrnXY       -\/   training set}}
\DoxyCodeLine{8316 \textcolor{comment}{    TrnSize     -\/   training set size, TrnSize>0}}
\DoxyCodeLine{8317 \textcolor{comment}{    ValXY       -\/   validation set}}
\DoxyCodeLine{8318 \textcolor{comment}{    ValSize     -\/   validation set size, ValSize>0}}
\DoxyCodeLine{8319 \textcolor{comment}{    Decay       -\/   weight decay constant, >=0.001}}
\DoxyCodeLine{8320 \textcolor{comment}{                    Decay term 'Decay*||Weights||\string^2' is added to error}}
\DoxyCodeLine{8321 \textcolor{comment}{                    function.}}
\DoxyCodeLine{8322 \textcolor{comment}{                    If you don't know what Decay to choose, use 0.001.}}
\DoxyCodeLine{8323 \textcolor{comment}{    Restarts    -\/   number of restarts, either:}}
\DoxyCodeLine{8324 \textcolor{comment}{                    * strictly positive number -\/ algorithm make specified}}
\DoxyCodeLine{8325 \textcolor{comment}{                      number of restarts from random position.}}
\DoxyCodeLine{8326 \textcolor{comment}{                    * -\/1, in which case algorithm makes exactly one run}}
\DoxyCodeLine{8327 \textcolor{comment}{                      from the initial state of the network (no randomization).}}
\DoxyCodeLine{8328 \textcolor{comment}{                    If you don't know what Restarts to choose, choose one}}
\DoxyCodeLine{8329 \textcolor{comment}{                    one the following:}}
\DoxyCodeLine{8330 \textcolor{comment}{                    * -\/1 (deterministic start)}}
\DoxyCodeLine{8331 \textcolor{comment}{                    * +1 (one random restart)}}
\DoxyCodeLine{8332 \textcolor{comment}{                    * +5 (moderate amount of random restarts)}}
\DoxyCodeLine{8333 \textcolor{comment}{}}
\DoxyCodeLine{8334 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8335 \textcolor{comment}{    Network     -\/   trained neural network.}}
\DoxyCodeLine{8336 \textcolor{comment}{    Info        -\/   return code:}}
\DoxyCodeLine{8337 \textcolor{comment}{                    * -\/2, if there is a point with class number}}
\DoxyCodeLine{8338 \textcolor{comment}{                          outside of [0..NOut-\/1].}}
\DoxyCodeLine{8339 \textcolor{comment}{                    * -\/1, if wrong parameters specified}}
\DoxyCodeLine{8340 \textcolor{comment}{                          (NPoints<0, Restarts<1, ...).}}
\DoxyCodeLine{8341 \textcolor{comment}{                    *  2, task has been solved, stopping  criterion  met -\/}}
\DoxyCodeLine{8342 \textcolor{comment}{                          sufficiently small step size.  Not expected  (we}}
\DoxyCodeLine{8343 \textcolor{comment}{                          use  EARLY  stopping)  but  possible  and not an}}
\DoxyCodeLine{8344 \textcolor{comment}{                          error.}}
\DoxyCodeLine{8345 \textcolor{comment}{                    *  6, task has been solved, stopping  criterion  met -\/}}
\DoxyCodeLine{8346 \textcolor{comment}{                          increasing of validation set error.}}
\DoxyCodeLine{8347 \textcolor{comment}{    Rep         -\/   training report}}
\DoxyCodeLine{8348 \textcolor{comment}{}}
\DoxyCodeLine{8349 \textcolor{comment}{NOTE:}}
\DoxyCodeLine{8350 \textcolor{comment}{}}
\DoxyCodeLine{8351 \textcolor{comment}{Algorithm stops if validation set error increases for  a  long  enough  or}}
\DoxyCodeLine{8352 \textcolor{comment}{step size is small enought  (there  are  task  where  validation  set  may}}
\DoxyCodeLine{8353 \textcolor{comment}{decrease for eternity). In any case solution returned corresponds  to  the}}
\DoxyCodeLine{8354 \textcolor{comment}{minimum of validation set error.}}
\DoxyCodeLine{8355 \textcolor{comment}{}}
\DoxyCodeLine{8356 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8357 \textcolor{comment}{     Copyright 10.03.2009 by Bochkanov Sergey}}
\DoxyCodeLine{8358 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8359 \textcolor{keywordtype}{void} mlptraines(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&trnxy, \textcolor{keyword}{const} ae\_int\_t trnsize, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&valxy, \textcolor{keyword}{const} ae\_int\_t valsize, \textcolor{keyword}{const} \textcolor{keywordtype}{double} decay, \textcolor{keyword}{const} ae\_int\_t restarts, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8360 }
\DoxyCodeLine{8361 }
\DoxyCodeLine{8362 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8363 \textcolor{comment}{Cross-\/validation estimate of generalization error.}}
\DoxyCodeLine{8364 \textcolor{comment}{}}
\DoxyCodeLine{8365 \textcolor{comment}{Base algorithm -\/ L-\/BFGS.}}
\DoxyCodeLine{8366 \textcolor{comment}{}}
\DoxyCodeLine{8367 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8368 \textcolor{comment}{    Network     -\/   neural network with initialized geometry.   Network is}}
\DoxyCodeLine{8369 \textcolor{comment}{                    not changed during cross-\/validation -\/  it is used only}}
\DoxyCodeLine{8370 \textcolor{comment}{                    as a representative of its architecture.}}
\DoxyCodeLine{8371 \textcolor{comment}{    XY          -\/   training set.}}
\DoxyCodeLine{8372 \textcolor{comment}{    SSize       -\/   training set size}}
\DoxyCodeLine{8373 \textcolor{comment}{    Decay       -\/   weight  decay, same as in MLPTrainLBFGS}}
\DoxyCodeLine{8374 \textcolor{comment}{    Restarts    -\/   number of restarts, >0.}}
\DoxyCodeLine{8375 \textcolor{comment}{                    restarts are counted for each partition separately, so}}
\DoxyCodeLine{8376 \textcolor{comment}{                    total number of restarts will be Restarts*FoldsCount.}}
\DoxyCodeLine{8377 \textcolor{comment}{    WStep       -\/   stopping criterion, same as in MLPTrainLBFGS}}
\DoxyCodeLine{8378 \textcolor{comment}{    MaxIts      -\/   stopping criterion, same as in MLPTrainLBFGS}}
\DoxyCodeLine{8379 \textcolor{comment}{    FoldsCount  -\/   number of folds in k-\/fold cross-\/validation,}}
\DoxyCodeLine{8380 \textcolor{comment}{                    2<=FoldsCount<=SSize.}}
\DoxyCodeLine{8381 \textcolor{comment}{                    recommended value: 10.}}
\DoxyCodeLine{8382 \textcolor{comment}{}}
\DoxyCodeLine{8383 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8384 \textcolor{comment}{    Info        -\/   return code, same as in MLPTrainLBFGS}}
\DoxyCodeLine{8385 \textcolor{comment}{    Rep         -\/   report, same as in MLPTrainLM/MLPTrainLBFGS}}
\DoxyCodeLine{8386 \textcolor{comment}{    CVRep       -\/   generalization error estimates}}
\DoxyCodeLine{8387 \textcolor{comment}{}}
\DoxyCodeLine{8388 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8389 \textcolor{comment}{     Copyright 09.12.2007 by Bochkanov Sergey}}
\DoxyCodeLine{8390 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8391 \textcolor{keywordtype}{void} mlpkfoldcvlbfgs(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \textcolor{keywordtype}{double} decay, \textcolor{keyword}{const} ae\_int\_t restarts, \textcolor{keyword}{const} \textcolor{keywordtype}{double} wstep, \textcolor{keyword}{const} ae\_int\_t maxits, \textcolor{keyword}{const} ae\_int\_t foldscount, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}} \&rep, \mbox{\hyperlink{classalglib_1_1mlpcvreport}{mlpcvreport}} \&cvrep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8392 }
\DoxyCodeLine{8393 }
\DoxyCodeLine{8394 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8395 \textcolor{comment}{Cross-\/validation estimate of generalization error.}}
\DoxyCodeLine{8396 \textcolor{comment}{}}
\DoxyCodeLine{8397 \textcolor{comment}{Base algorithm -\/ Levenberg-\/Marquardt.}}
\DoxyCodeLine{8398 \textcolor{comment}{}}
\DoxyCodeLine{8399 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8400 \textcolor{comment}{    Network     -\/   neural network with initialized geometry.   Network is}}
\DoxyCodeLine{8401 \textcolor{comment}{                    not changed during cross-\/validation -\/  it is used only}}
\DoxyCodeLine{8402 \textcolor{comment}{                    as a representative of its architecture.}}
\DoxyCodeLine{8403 \textcolor{comment}{    XY          -\/   training set.}}
\DoxyCodeLine{8404 \textcolor{comment}{    SSize       -\/   training set size}}
\DoxyCodeLine{8405 \textcolor{comment}{    Decay       -\/   weight  decay, same as in MLPTrainLBFGS}}
\DoxyCodeLine{8406 \textcolor{comment}{    Restarts    -\/   number of restarts, >0.}}
\DoxyCodeLine{8407 \textcolor{comment}{                    restarts are counted for each partition separately, so}}
\DoxyCodeLine{8408 \textcolor{comment}{                    total number of restarts will be Restarts*FoldsCount.}}
\DoxyCodeLine{8409 \textcolor{comment}{    FoldsCount  -\/   number of folds in k-\/fold cross-\/validation,}}
\DoxyCodeLine{8410 \textcolor{comment}{                    2<=FoldsCount<=SSize.}}
\DoxyCodeLine{8411 \textcolor{comment}{                    recommended value: 10.}}
\DoxyCodeLine{8412 \textcolor{comment}{}}
\DoxyCodeLine{8413 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8414 \textcolor{comment}{    Info        -\/   return code, same as in MLPTrainLBFGS}}
\DoxyCodeLine{8415 \textcolor{comment}{    Rep         -\/   report, same as in MLPTrainLM/MLPTrainLBFGS}}
\DoxyCodeLine{8416 \textcolor{comment}{    CVRep       -\/   generalization error estimates}}
\DoxyCodeLine{8417 \textcolor{comment}{}}
\DoxyCodeLine{8418 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8419 \textcolor{comment}{     Copyright 09.12.2007 by Bochkanov Sergey}}
\DoxyCodeLine{8420 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8421 \textcolor{keywordtype}{void} mlpkfoldcvlm(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \textcolor{keywordtype}{double} decay, \textcolor{keyword}{const} ae\_int\_t restarts, \textcolor{keyword}{const} ae\_int\_t foldscount, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}} \&rep, \mbox{\hyperlink{classalglib_1_1mlpcvreport}{mlpcvreport}} \&cvrep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8422 }
\DoxyCodeLine{8423 }
\DoxyCodeLine{8424 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8425 \textcolor{comment}{This function estimates generalization error using cross-\/validation on the}}
\DoxyCodeLine{8426 \textcolor{comment}{current dataset with current training settings.}}
\DoxyCodeLine{8427 \textcolor{comment}{}}
\DoxyCodeLine{8428 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{8429 \textcolor{comment}{  !}}
\DoxyCodeLine{8430 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{8431 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{8432 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{8433 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{8434 \textcolor{comment}{  !}}
\DoxyCodeLine{8435 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{8436 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{8437 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{8438 \textcolor{comment}{}}
\DoxyCodeLine{8439 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8440 \textcolor{comment}{    S           -\/   trainer object}}
\DoxyCodeLine{8441 \textcolor{comment}{    Network     -\/   neural network. It must have same number of inputs and}}
\DoxyCodeLine{8442 \textcolor{comment}{                    output/classes as was specified during creation of the}}
\DoxyCodeLine{8443 \textcolor{comment}{                    trainer object. Network is not changed  during  cross-\/}}
\DoxyCodeLine{8444 \textcolor{comment}{                    validation and is not trained -\/ it  is  used  only  as}}
\DoxyCodeLine{8445 \textcolor{comment}{                    representative of its architecture. I.e., we  estimate}}
\DoxyCodeLine{8446 \textcolor{comment}{                    generalization properties of  ARCHITECTURE,  not  some}}
\DoxyCodeLine{8447 \textcolor{comment}{                    specific network.}}
\DoxyCodeLine{8448 \textcolor{comment}{    NRestarts   -\/   number of restarts, >=0:}}
\DoxyCodeLine{8449 \textcolor{comment}{                    * NRestarts>0  means  that  for  each cross-\/validation}}
\DoxyCodeLine{8450 \textcolor{comment}{                      round   specified  number   of  random  restarts  is}}
\DoxyCodeLine{8451 \textcolor{comment}{                      performed,  with  best  network  being  chosen after}}
\DoxyCodeLine{8452 \textcolor{comment}{                      training.}}
\DoxyCodeLine{8453 \textcolor{comment}{                    * NRestarts=0 is same as NRestarts=1}}
\DoxyCodeLine{8454 \textcolor{comment}{    FoldsCount  -\/   number of folds in k-\/fold cross-\/validation:}}
\DoxyCodeLine{8455 \textcolor{comment}{                    * 2<=FoldsCount<=size of dataset}}
\DoxyCodeLine{8456 \textcolor{comment}{                    * recommended value: 10.}}
\DoxyCodeLine{8457 \textcolor{comment}{                    * values larger than dataset size will be silently}}
\DoxyCodeLine{8458 \textcolor{comment}{                      truncated down to dataset size}}
\DoxyCodeLine{8459 \textcolor{comment}{}}
\DoxyCodeLine{8460 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8461 \textcolor{comment}{    Rep         -\/   structure which contains cross-\/validation estimates:}}
\DoxyCodeLine{8462 \textcolor{comment}{                    * Rep.RelCLSError -\/ fraction of misclassified cases.}}
\DoxyCodeLine{8463 \textcolor{comment}{                    * Rep.AvgCE -\/ acerage cross-\/entropy}}
\DoxyCodeLine{8464 \textcolor{comment}{                    * Rep.RMSError -\/ root-\/mean-\/square error}}
\DoxyCodeLine{8465 \textcolor{comment}{                    * Rep.AvgError -\/ average error}}
\DoxyCodeLine{8466 \textcolor{comment}{                    * Rep.AvgRelError -\/ average relative error}}
\DoxyCodeLine{8467 \textcolor{comment}{}}
\DoxyCodeLine{8468 \textcolor{comment}{NOTE: when no dataset was specified with MLPSetDataset/SetSparseDataset(),}}
\DoxyCodeLine{8469 \textcolor{comment}{      or subset with only one point  was  given,  zeros  are  returned  as}}
\DoxyCodeLine{8470 \textcolor{comment}{      estimates.}}
\DoxyCodeLine{8471 \textcolor{comment}{}}
\DoxyCodeLine{8472 \textcolor{comment}{NOTE: this method performs FoldsCount cross-\/validation  rounds,  each  one}}
\DoxyCodeLine{8473 \textcolor{comment}{      with NRestarts random starts.  Thus,  FoldsCount*NRestarts  networks}}
\DoxyCodeLine{8474 \textcolor{comment}{      are trained in total.}}
\DoxyCodeLine{8475 \textcolor{comment}{}}
\DoxyCodeLine{8476 \textcolor{comment}{NOTE: Rep.RelCLSError/Rep.AvgCE are zero on regression problems.}}
\DoxyCodeLine{8477 \textcolor{comment}{}}
\DoxyCodeLine{8478 \textcolor{comment}{NOTE: on classification problems Rep.RMSError/Rep.AvgError/Rep.AvgRelError}}
\DoxyCodeLine{8479 \textcolor{comment}{      contain errors in prediction of posterior probabilities.}}
\DoxyCodeLine{8480 \textcolor{comment}{}}
\DoxyCodeLine{8481 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8482 \textcolor{comment}{     Copyright 23.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{8483 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8484 \textcolor{keywordtype}{void} mlpkfoldcv(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} ae\_int\_t nrestarts, \textcolor{keyword}{const} ae\_int\_t foldscount, \mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8485 }
\DoxyCodeLine{8486 }
\DoxyCodeLine{8487 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8488 \textcolor{comment}{Creation of the network trainer object for regression networks}}
\DoxyCodeLine{8489 \textcolor{comment}{}}
\DoxyCodeLine{8490 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8491 \textcolor{comment}{    NIn         -\/   number of inputs, NIn>=1}}
\DoxyCodeLine{8492 \textcolor{comment}{    NOut        -\/   number of outputs, NOut>=1}}
\DoxyCodeLine{8493 \textcolor{comment}{}}
\DoxyCodeLine{8494 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8495 \textcolor{comment}{    S           -\/   neural network trainer object.}}
\DoxyCodeLine{8496 \textcolor{comment}{                    This structure can be used to train any regression}}
\DoxyCodeLine{8497 \textcolor{comment}{                    network with NIn inputs and NOut outputs.}}
\DoxyCodeLine{8498 \textcolor{comment}{}}
\DoxyCodeLine{8499 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8500 \textcolor{comment}{     Copyright 23.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{8501 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8502 \textcolor{keywordtype}{void} mlpcreatetrainer(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nout, \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8503 }
\DoxyCodeLine{8504 }
\DoxyCodeLine{8505 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8506 \textcolor{comment}{Creation of the network trainer object for classification networks}}
\DoxyCodeLine{8507 \textcolor{comment}{}}
\DoxyCodeLine{8508 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8509 \textcolor{comment}{    NIn         -\/   number of inputs, NIn>=1}}
\DoxyCodeLine{8510 \textcolor{comment}{    NClasses    -\/   number of classes, NClasses>=2}}
\DoxyCodeLine{8511 \textcolor{comment}{}}
\DoxyCodeLine{8512 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8513 \textcolor{comment}{    S           -\/   neural network trainer object.}}
\DoxyCodeLine{8514 \textcolor{comment}{                    This structure can be used to train any classification}}
\DoxyCodeLine{8515 \textcolor{comment}{                    network with NIn inputs and NOut outputs.}}
\DoxyCodeLine{8516 \textcolor{comment}{}}
\DoxyCodeLine{8517 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8518 \textcolor{comment}{     Copyright 23.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{8519 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8520 \textcolor{keywordtype}{void} mlpcreatetrainercls(\textcolor{keyword}{const} ae\_int\_t nin, \textcolor{keyword}{const} ae\_int\_t nclasses, \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8521 }
\DoxyCodeLine{8522 }
\DoxyCodeLine{8523 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8524 \textcolor{comment}{This function sets "{}current dataset"{} of the trainer object to  one  passed}}
\DoxyCodeLine{8525 \textcolor{comment}{by user.}}
\DoxyCodeLine{8526 \textcolor{comment}{}}
\DoxyCodeLine{8527 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8528 \textcolor{comment}{    S           -\/   trainer object}}
\DoxyCodeLine{8529 \textcolor{comment}{    XY          -\/   training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{8530 \textcolor{comment}{                    training set format. This function checks  correctness}}
\DoxyCodeLine{8531 \textcolor{comment}{                    of  the  dataset  (no  NANs/INFs,  class  numbers  are}}
\DoxyCodeLine{8532 \textcolor{comment}{                    correct) and throws exception when  incorrect  dataset}}
\DoxyCodeLine{8533 \textcolor{comment}{                    is passed.}}
\DoxyCodeLine{8534 \textcolor{comment}{    NPoints     -\/   points count, >=0.}}
\DoxyCodeLine{8535 \textcolor{comment}{}}
\DoxyCodeLine{8536 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{8537 \textcolor{comment}{}}
\DoxyCodeLine{8538 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{8539 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{8540 \textcolor{comment}{}}
\DoxyCodeLine{8541 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{8542 \textcolor{comment}{format is used:}}
\DoxyCodeLine{8543 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{8544 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{8545 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{8546 \textcolor{comment}{}}
\DoxyCodeLine{8547 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{8548 \textcolor{comment}{datasetformat is used:}}
\DoxyCodeLine{8549 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{8550 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{8551 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{8552 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{8553 \textcolor{comment}{}}
\DoxyCodeLine{8554 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8555 \textcolor{comment}{     Copyright 23.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{8556 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8557 \textcolor{keywordtype}{void} mlpsetdataset(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8558 }
\DoxyCodeLine{8559 }
\DoxyCodeLine{8560 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8561 \textcolor{comment}{This function sets "{}current dataset"{} of the trainer object to  one  passed}}
\DoxyCodeLine{8562 \textcolor{comment}{by user (sparse matrix is used to store dataset).}}
\DoxyCodeLine{8563 \textcolor{comment}{}}
\DoxyCodeLine{8564 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8565 \textcolor{comment}{    S           -\/   trainer object}}
\DoxyCodeLine{8566 \textcolor{comment}{    XY          -\/   training  set,  see  below  for  information  on   the}}
\DoxyCodeLine{8567 \textcolor{comment}{                    training set format. This function checks  correctness}}
\DoxyCodeLine{8568 \textcolor{comment}{                    of  the  dataset  (no  NANs/INFs,  class  numbers  are}}
\DoxyCodeLine{8569 \textcolor{comment}{                    correct) and throws exception when  incorrect  dataset}}
\DoxyCodeLine{8570 \textcolor{comment}{                    is passed. Any  sparse  storage  format  can be  used:}}
\DoxyCodeLine{8571 \textcolor{comment}{                    Hash-\/table, CRS...}}
\DoxyCodeLine{8572 \textcolor{comment}{    NPoints     -\/   points count, >=0}}
\DoxyCodeLine{8573 \textcolor{comment}{}}
\DoxyCodeLine{8574 \textcolor{comment}{DATASET FORMAT:}}
\DoxyCodeLine{8575 \textcolor{comment}{}}
\DoxyCodeLine{8576 \textcolor{comment}{This  function  uses  two  different  dataset formats -\/ one for regression}}
\DoxyCodeLine{8577 \textcolor{comment}{networks, another one for classification networks.}}
\DoxyCodeLine{8578 \textcolor{comment}{}}
\DoxyCodeLine{8579 \textcolor{comment}{For regression networks with NIn inputs and NOut outputs following dataset}}
\DoxyCodeLine{8580 \textcolor{comment}{format is used:}}
\DoxyCodeLine{8581 \textcolor{comment}{* dataset is given by NPoints*(NIn+NOut) matrix}}
\DoxyCodeLine{8582 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{8583 \textcolor{comment}{* first NIn columns are inputs, next NOut columns are outputs}}
\DoxyCodeLine{8584 \textcolor{comment}{}}
\DoxyCodeLine{8585 \textcolor{comment}{For classification networks with NIn inputs and NClasses clases  following}}
\DoxyCodeLine{8586 \textcolor{comment}{datasetformat is used:}}
\DoxyCodeLine{8587 \textcolor{comment}{* dataset is given by NPoints*(NIn+1) matrix}}
\DoxyCodeLine{8588 \textcolor{comment}{* each row corresponds to one example}}
\DoxyCodeLine{8589 \textcolor{comment}{* first NIn columns are inputs, last column stores class number (from 0 to}}
\DoxyCodeLine{8590 \textcolor{comment}{  NClasses-\/1).}}
\DoxyCodeLine{8591 \textcolor{comment}{}}
\DoxyCodeLine{8592 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8593 \textcolor{comment}{     Copyright 23.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{8594 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8595 \textcolor{keywordtype}{void} mlpsetsparsedataset(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1sparsematrix}{sparsematrix}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8596 }
\DoxyCodeLine{8597 }
\DoxyCodeLine{8598 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8599 \textcolor{comment}{This function sets weight decay coefficient which is used for training.}}
\DoxyCodeLine{8600 \textcolor{comment}{}}
\DoxyCodeLine{8601 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8602 \textcolor{comment}{    S           -\/   trainer object}}
\DoxyCodeLine{8603 \textcolor{comment}{    Decay       -\/   weight  decay  coefficient,  >=0.  Weight  decay  term}}
\DoxyCodeLine{8604 \textcolor{comment}{                    'Decay*||Weights||\string^2' is added to error  function.  If}}
\DoxyCodeLine{8605 \textcolor{comment}{                    you don't know what Decay to choose, use 1.0E-\/3.}}
\DoxyCodeLine{8606 \textcolor{comment}{                    Weight decay can be set to zero,  in this case network}}
\DoxyCodeLine{8607 \textcolor{comment}{                    is trained without weight decay.}}
\DoxyCodeLine{8608 \textcolor{comment}{}}
\DoxyCodeLine{8609 \textcolor{comment}{NOTE: by default network uses some small nonzero value for weight decay.}}
\DoxyCodeLine{8610 \textcolor{comment}{}}
\DoxyCodeLine{8611 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8612 \textcolor{comment}{     Copyright 23.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{8613 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8614 \textcolor{keywordtype}{void} mlpsetdecay(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}} \&s, \textcolor{keyword}{const} \textcolor{keywordtype}{double} decay, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8615 }
\DoxyCodeLine{8616 }
\DoxyCodeLine{8617 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8618 \textcolor{comment}{This function sets stopping criteria for the optimizer.}}
\DoxyCodeLine{8619 \textcolor{comment}{}}
\DoxyCodeLine{8620 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8621 \textcolor{comment}{    S           -\/   trainer object}}
\DoxyCodeLine{8622 \textcolor{comment}{    WStep       -\/   stopping criterion. Algorithm stops if  step  size  is}}
\DoxyCodeLine{8623 \textcolor{comment}{                    less than WStep. Recommended value -\/ 0.01.  Zero  step}}
\DoxyCodeLine{8624 \textcolor{comment}{                    size means stopping after MaxIts iterations.}}
\DoxyCodeLine{8625 \textcolor{comment}{                    WStep>=0.}}
\DoxyCodeLine{8626 \textcolor{comment}{    MaxIts      -\/   stopping   criterion.  Algorithm  stops  after  MaxIts}}
\DoxyCodeLine{8627 \textcolor{comment}{                    epochs (full passes over entire dataset).  Zero MaxIts}}
\DoxyCodeLine{8628 \textcolor{comment}{                    means stopping when step is sufficiently small.}}
\DoxyCodeLine{8629 \textcolor{comment}{                    MaxIts>=0.}}
\DoxyCodeLine{8630 \textcolor{comment}{}}
\DoxyCodeLine{8631 \textcolor{comment}{NOTE: by default, WStep=0.005 and MaxIts=0 are used. These values are also}}
\DoxyCodeLine{8632 \textcolor{comment}{      used when MLPSetCond() is called with WStep=0 and MaxIts=0.}}
\DoxyCodeLine{8633 \textcolor{comment}{}}
\DoxyCodeLine{8634 \textcolor{comment}{NOTE: these stopping criteria are used for all kinds of neural training  -\/}}
\DoxyCodeLine{8635 \textcolor{comment}{      from "{}conventional"{} networks to early stopping ensembles. When  used}}
\DoxyCodeLine{8636 \textcolor{comment}{      for "{}conventional"{} networks, they are  used  as  the  only  stopping}}
\DoxyCodeLine{8637 \textcolor{comment}{      criteria. When combined with early stopping, they used as ADDITIONAL}}
\DoxyCodeLine{8638 \textcolor{comment}{      stopping criteria which can terminate early stopping algorithm.}}
\DoxyCodeLine{8639 \textcolor{comment}{}}
\DoxyCodeLine{8640 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8641 \textcolor{comment}{     Copyright 23.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{8642 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8643 \textcolor{keywordtype}{void} mlpsetcond(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}} \&s, \textcolor{keyword}{const} \textcolor{keywordtype}{double} wstep, \textcolor{keyword}{const} ae\_int\_t maxits, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8644 }
\DoxyCodeLine{8645 }
\DoxyCodeLine{8646 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8647 \textcolor{comment}{This function sets training algorithm: batch training using L-\/BFGS will be}}
\DoxyCodeLine{8648 \textcolor{comment}{used.}}
\DoxyCodeLine{8649 \textcolor{comment}{}}
\DoxyCodeLine{8650 \textcolor{comment}{This algorithm:}}
\DoxyCodeLine{8651 \textcolor{comment}{* the most robust for small-\/scale problems, but may be too slow for  large}}
\DoxyCodeLine{8652 \textcolor{comment}{  scale ones.}}
\DoxyCodeLine{8653 \textcolor{comment}{* perfoms full pass through the dataset before performing step}}
\DoxyCodeLine{8654 \textcolor{comment}{* uses conditions specified by MLPSetCond() for stopping}}
\DoxyCodeLine{8655 \textcolor{comment}{* is default one used by trainer object}}
\DoxyCodeLine{8656 \textcolor{comment}{}}
\DoxyCodeLine{8657 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8658 \textcolor{comment}{    S           -\/   trainer object}}
\DoxyCodeLine{8659 \textcolor{comment}{}}
\DoxyCodeLine{8660 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8661 \textcolor{comment}{     Copyright 23.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{8662 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8663 \textcolor{keywordtype}{void} mlpsetalgobatch(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8664 }
\DoxyCodeLine{8665 }
\DoxyCodeLine{8666 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8667 \textcolor{comment}{This function trains neural network passed to this function, using current}}
\DoxyCodeLine{8668 \textcolor{comment}{dataset (one which was passed to MLPSetDataset() or MLPSetSparseDataset())}}
\DoxyCodeLine{8669 \textcolor{comment}{and current training settings. Training  from  NRestarts  random  starting}}
\DoxyCodeLine{8670 \textcolor{comment}{positions is performed, best network is chosen.}}
\DoxyCodeLine{8671 \textcolor{comment}{}}
\DoxyCodeLine{8672 \textcolor{comment}{Training is performed using current training algorithm.}}
\DoxyCodeLine{8673 \textcolor{comment}{}}
\DoxyCodeLine{8674 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{8675 \textcolor{comment}{  !}}
\DoxyCodeLine{8676 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{8677 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{8678 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{8679 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{8680 \textcolor{comment}{  !}}
\DoxyCodeLine{8681 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{8682 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{8683 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{8684 \textcolor{comment}{}}
\DoxyCodeLine{8685 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8686 \textcolor{comment}{    S           -\/   trainer object}}
\DoxyCodeLine{8687 \textcolor{comment}{    Network     -\/   neural network. It must have same number of inputs and}}
\DoxyCodeLine{8688 \textcolor{comment}{                    output/classes as was specified during creation of the}}
\DoxyCodeLine{8689 \textcolor{comment}{                    trainer object.}}
\DoxyCodeLine{8690 \textcolor{comment}{    NRestarts   -\/   number of restarts, >=0:}}
\DoxyCodeLine{8691 \textcolor{comment}{                    * NRestarts>0 means that specified  number  of  random}}
\DoxyCodeLine{8692 \textcolor{comment}{                      restarts are performed, best network is chosen after}}
\DoxyCodeLine{8693 \textcolor{comment}{                      training}}
\DoxyCodeLine{8694 \textcolor{comment}{                    * NRestarts=0 means that current state of the  network}}
\DoxyCodeLine{8695 \textcolor{comment}{                      is used for training.}}
\DoxyCodeLine{8696 \textcolor{comment}{}}
\DoxyCodeLine{8697 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8698 \textcolor{comment}{    Network     -\/   trained network}}
\DoxyCodeLine{8699 \textcolor{comment}{}}
\DoxyCodeLine{8700 \textcolor{comment}{NOTE: when no dataset was specified with MLPSetDataset/SetSparseDataset(),}}
\DoxyCodeLine{8701 \textcolor{comment}{      network  is  filled  by zero  values.  Same  behavior  for functions}}
\DoxyCodeLine{8702 \textcolor{comment}{      MLPStartTraining and MLPContinueTraining.}}
\DoxyCodeLine{8703 \textcolor{comment}{}}
\DoxyCodeLine{8704 \textcolor{comment}{NOTE: this method uses sum-\/of-\/squares error function for training.}}
\DoxyCodeLine{8705 \textcolor{comment}{}}
\DoxyCodeLine{8706 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8707 \textcolor{comment}{     Copyright 23.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{8708 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8709 \textcolor{keywordtype}{void} mlptrainnetwork(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} ae\_int\_t nrestarts, \mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8710 }
\DoxyCodeLine{8711 }
\DoxyCodeLine{8712 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8713 \textcolor{comment}{IMPORTANT: this is an "{}expert"{} version of the MLPTrain() function.  We  do}}
\DoxyCodeLine{8714 \textcolor{comment}{           not recommend you to use it unless you are pretty sure that you}}
\DoxyCodeLine{8715 \textcolor{comment}{           need ability to monitor training progress.}}
\DoxyCodeLine{8716 \textcolor{comment}{}}
\DoxyCodeLine{8717 \textcolor{comment}{This function performs step-\/by-\/step training of the neural  network.  Here}}
\DoxyCodeLine{8718 \textcolor{comment}{"{}step-\/by-\/step"{} means that training  starts  with  MLPStartTraining() call,}}
\DoxyCodeLine{8719 \textcolor{comment}{and then user subsequently calls MLPContinueTraining() to perform one more}}
\DoxyCodeLine{8720 \textcolor{comment}{iteration of the training.}}
\DoxyCodeLine{8721 \textcolor{comment}{}}
\DoxyCodeLine{8722 \textcolor{comment}{After call to this function trainer object remembers network and  is ready}}
\DoxyCodeLine{8723 \textcolor{comment}{to  train  it.  However,  no  training  is  performed  until first call to}}
\DoxyCodeLine{8724 \textcolor{comment}{MLPContinueTraining() function. Subsequent calls  to MLPContinueTraining()}}
\DoxyCodeLine{8725 \textcolor{comment}{will advance training progress one iteration further.}}
\DoxyCodeLine{8726 \textcolor{comment}{}}
\DoxyCodeLine{8727 \textcolor{comment}{EXAMPLE:}}
\DoxyCodeLine{8728 \textcolor{comment}{    >}}
\DoxyCodeLine{8729 \textcolor{comment}{    > ...initialize network and trainer object....}}
\DoxyCodeLine{8730 \textcolor{comment}{    >}}
\DoxyCodeLine{8731 \textcolor{comment}{    > MLPStartTraining(Trainer, Network, True)}}
\DoxyCodeLine{8732 \textcolor{comment}{    > while MLPContinueTraining(Trainer, Network) do}}
\DoxyCodeLine{8733 \textcolor{comment}{    >     ...visualize training progress...}}
\DoxyCodeLine{8734 \textcolor{comment}{    >}}
\DoxyCodeLine{8735 \textcolor{comment}{}}
\DoxyCodeLine{8736 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8737 \textcolor{comment}{    S           -\/   trainer object}}
\DoxyCodeLine{8738 \textcolor{comment}{    Network     -\/   neural network. It must have same number of inputs and}}
\DoxyCodeLine{8739 \textcolor{comment}{                    output/classes as was specified during creation of the}}
\DoxyCodeLine{8740 \textcolor{comment}{                    trainer object.}}
\DoxyCodeLine{8741 \textcolor{comment}{    RandomStart -\/   randomize network before training or not:}}
\DoxyCodeLine{8742 \textcolor{comment}{                    * True  means  that  network  is  randomized  and  its}}
\DoxyCodeLine{8743 \textcolor{comment}{                      initial state (one which was passed to  the  trainer}}
\DoxyCodeLine{8744 \textcolor{comment}{                      object) is lost.}}
\DoxyCodeLine{8745 \textcolor{comment}{                    * False  means  that  training  is  started  from  the}}
\DoxyCodeLine{8746 \textcolor{comment}{                      current state of the network}}
\DoxyCodeLine{8747 \textcolor{comment}{}}
\DoxyCodeLine{8748 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8749 \textcolor{comment}{    Network     -\/   neural network which is ready to training (weights are}}
\DoxyCodeLine{8750 \textcolor{comment}{                    initialized, preprocessor is initialized using current}}
\DoxyCodeLine{8751 \textcolor{comment}{                    training set)}}
\DoxyCodeLine{8752 \textcolor{comment}{}}
\DoxyCodeLine{8753 \textcolor{comment}{NOTE: this method uses sum-\/of-\/squares error function for training.}}
\DoxyCodeLine{8754 \textcolor{comment}{}}
\DoxyCodeLine{8755 \textcolor{comment}{NOTE: it is expected that trainer object settings are NOT  changed  during}}
\DoxyCodeLine{8756 \textcolor{comment}{      step-\/by-\/step training, i.e. no  one  changes  stopping  criteria  or}}
\DoxyCodeLine{8757 \textcolor{comment}{      training set during training. It is possible and there is no defense}}
\DoxyCodeLine{8758 \textcolor{comment}{      against  such  actions,  but  algorithm  behavior  in  such cases is}}
\DoxyCodeLine{8759 \textcolor{comment}{      undefined and can be unpredictable.}}
\DoxyCodeLine{8760 \textcolor{comment}{}}
\DoxyCodeLine{8761 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8762 \textcolor{comment}{     Copyright 23.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{8763 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8764 \textcolor{keywordtype}{void} mlpstarttraining(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \textcolor{keywordtype}{bool} randomstart, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8765 }
\DoxyCodeLine{8766 }
\DoxyCodeLine{8767 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8768 \textcolor{comment}{IMPORTANT: this is an "{}expert"{} version of the MLPTrain() function.  We  do}}
\DoxyCodeLine{8769 \textcolor{comment}{           not recommend you to use it unless you are pretty sure that you}}
\DoxyCodeLine{8770 \textcolor{comment}{           need ability to monitor training progress.}}
\DoxyCodeLine{8771 \textcolor{comment}{}}
\DoxyCodeLine{8772 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{8773 \textcolor{comment}{  !}}
\DoxyCodeLine{8774 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{8775 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{8776 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{8777 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{8778 \textcolor{comment}{  !}}
\DoxyCodeLine{8779 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{8780 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{8781 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{8782 \textcolor{comment}{}}
\DoxyCodeLine{8783 \textcolor{comment}{This function performs step-\/by-\/step training of the neural  network.  Here}}
\DoxyCodeLine{8784 \textcolor{comment}{"{}step-\/by-\/step"{} means that training starts  with  MLPStartTraining()  call,}}
\DoxyCodeLine{8785 \textcolor{comment}{and then user subsequently calls MLPContinueTraining() to perform one more}}
\DoxyCodeLine{8786 \textcolor{comment}{iteration of the training.}}
\DoxyCodeLine{8787 \textcolor{comment}{}}
\DoxyCodeLine{8788 \textcolor{comment}{This  function  performs  one  more  iteration of the training and returns}}
\DoxyCodeLine{8789 \textcolor{comment}{either True (training continues) or False (training stopped). In case True}}
\DoxyCodeLine{8790 \textcolor{comment}{was returned, Network weights are updated according to the  current  state}}
\DoxyCodeLine{8791 \textcolor{comment}{of the optimization progress. In case False was  returned,  no  additional}}
\DoxyCodeLine{8792 \textcolor{comment}{updates is performed (previous update of  the  network weights moved us to}}
\DoxyCodeLine{8793 \textcolor{comment}{the final point, and no additional updates is needed).}}
\DoxyCodeLine{8794 \textcolor{comment}{}}
\DoxyCodeLine{8795 \textcolor{comment}{EXAMPLE:}}
\DoxyCodeLine{8796 \textcolor{comment}{    >}}
\DoxyCodeLine{8797 \textcolor{comment}{    > [initialize network and trainer object]}}
\DoxyCodeLine{8798 \textcolor{comment}{    >}}
\DoxyCodeLine{8799 \textcolor{comment}{    > MLPStartTraining(Trainer, Network, True)}}
\DoxyCodeLine{8800 \textcolor{comment}{    > while MLPContinueTraining(Trainer, Network) do}}
\DoxyCodeLine{8801 \textcolor{comment}{    >     [visualize training progress]}}
\DoxyCodeLine{8802 \textcolor{comment}{    >}}
\DoxyCodeLine{8803 \textcolor{comment}{}}
\DoxyCodeLine{8804 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8805 \textcolor{comment}{    S           -\/   trainer object}}
\DoxyCodeLine{8806 \textcolor{comment}{    Network     -\/   neural  network  structure,  which  is  used to  store}}
\DoxyCodeLine{8807 \textcolor{comment}{                    current state of the training process.}}
\DoxyCodeLine{8808 \textcolor{comment}{}}
\DoxyCodeLine{8809 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8810 \textcolor{comment}{    Network     -\/   weights of the neural network  are  rewritten  by  the}}
\DoxyCodeLine{8811 \textcolor{comment}{                    current approximation.}}
\DoxyCodeLine{8812 \textcolor{comment}{}}
\DoxyCodeLine{8813 \textcolor{comment}{NOTE: this method uses sum-\/of-\/squares error function for training.}}
\DoxyCodeLine{8814 \textcolor{comment}{}}
\DoxyCodeLine{8815 \textcolor{comment}{NOTE: it is expected that trainer object settings are NOT  changed  during}}
\DoxyCodeLine{8816 \textcolor{comment}{      step-\/by-\/step training, i.e. no  one  changes  stopping  criteria  or}}
\DoxyCodeLine{8817 \textcolor{comment}{      training set during training. It is possible and there is no defense}}
\DoxyCodeLine{8818 \textcolor{comment}{      against  such  actions,  but  algorithm  behavior  in  such cases is}}
\DoxyCodeLine{8819 \textcolor{comment}{      undefined and can be unpredictable.}}
\DoxyCodeLine{8820 \textcolor{comment}{}}
\DoxyCodeLine{8821 \textcolor{comment}{NOTE: It  is  expected that Network is the same one which  was  passed  to}}
\DoxyCodeLine{8822 \textcolor{comment}{      MLPStartTraining() function.  However,  THIS  function  checks  only}}
\DoxyCodeLine{8823 \textcolor{comment}{      following:}}
\DoxyCodeLine{8824 \textcolor{comment}{      * that number of network inputs is consistent with trainer object}}
\DoxyCodeLine{8825 \textcolor{comment}{        settings}}
\DoxyCodeLine{8826 \textcolor{comment}{      * that number of network outputs/classes is consistent with  trainer}}
\DoxyCodeLine{8827 \textcolor{comment}{        object settings}}
\DoxyCodeLine{8828 \textcolor{comment}{      * that number of network weights is the same as number of weights in}}
\DoxyCodeLine{8829 \textcolor{comment}{        the network passed to MLPStartTraining() function}}
\DoxyCodeLine{8830 \textcolor{comment}{      Exception is thrown when these conditions are violated.}}
\DoxyCodeLine{8831 \textcolor{comment}{}}
\DoxyCodeLine{8832 \textcolor{comment}{      It is also expected that you do not change state of the  network  on}}
\DoxyCodeLine{8833 \textcolor{comment}{      your own -\/ the only party who has right to change network during its}}
\DoxyCodeLine{8834 \textcolor{comment}{      training is a trainer object. Any attempt to interfere with  trainer}}
\DoxyCodeLine{8835 \textcolor{comment}{      may lead to unpredictable results.}}
\DoxyCodeLine{8836 \textcolor{comment}{}}
\DoxyCodeLine{8837 \textcolor{comment}{}}
\DoxyCodeLine{8838 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8839 \textcolor{comment}{     Copyright 23.07.2012 by Bochkanov Sergey}}
\DoxyCodeLine{8840 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8841 \textcolor{keywordtype}{bool} mlpcontinuetraining(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1multilayerperceptron}{multilayerperceptron}} \&network, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8842 }
\DoxyCodeLine{8843 }
\DoxyCodeLine{8844 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8845 \textcolor{comment}{Training neural networks ensemble using  bootstrap  aggregating (bagging).}}
\DoxyCodeLine{8846 \textcolor{comment}{Modified Levenberg-\/Marquardt algorithm is used as base training method.}}
\DoxyCodeLine{8847 \textcolor{comment}{}}
\DoxyCodeLine{8848 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8849 \textcolor{comment}{    Ensemble    -\/   model with initialized geometry}}
\DoxyCodeLine{8850 \textcolor{comment}{    XY          -\/   training set}}
\DoxyCodeLine{8851 \textcolor{comment}{    NPoints     -\/   training set size}}
\DoxyCodeLine{8852 \textcolor{comment}{    Decay       -\/   weight decay coefficient, >=0.001}}
\DoxyCodeLine{8853 \textcolor{comment}{    Restarts    -\/   restarts, >0.}}
\DoxyCodeLine{8854 \textcolor{comment}{}}
\DoxyCodeLine{8855 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8856 \textcolor{comment}{    Ensemble    -\/   trained model}}
\DoxyCodeLine{8857 \textcolor{comment}{    Info        -\/   return code:}}
\DoxyCodeLine{8858 \textcolor{comment}{                    * -\/2, if there is a point with class number}}
\DoxyCodeLine{8859 \textcolor{comment}{                          outside of [0..NClasses-\/1].}}
\DoxyCodeLine{8860 \textcolor{comment}{                    * -\/1, if incorrect parameters was passed}}
\DoxyCodeLine{8861 \textcolor{comment}{                          (NPoints<0, Restarts<1).}}
\DoxyCodeLine{8862 \textcolor{comment}{                    *  2, if task has been solved.}}
\DoxyCodeLine{8863 \textcolor{comment}{    Rep         -\/   training report.}}
\DoxyCodeLine{8864 \textcolor{comment}{    OOBErrors   -\/   out-\/of-\/bag generalization error estimate}}
\DoxyCodeLine{8865 \textcolor{comment}{}}
\DoxyCodeLine{8866 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8867 \textcolor{comment}{     Copyright 17.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{8868 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8869 \textcolor{keywordtype}{void} mlpebagginglm(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \textcolor{keywordtype}{double} decay, \textcolor{keyword}{const} ae\_int\_t restarts, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}} \&rep, \mbox{\hyperlink{classalglib_1_1mlpcvreport}{mlpcvreport}} \&ooberrors, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8870 }
\DoxyCodeLine{8871 }
\DoxyCodeLine{8872 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8873 \textcolor{comment}{Training neural networks ensemble using  bootstrap  aggregating (bagging).}}
\DoxyCodeLine{8874 \textcolor{comment}{L-\/BFGS algorithm is used as base training method.}}
\DoxyCodeLine{8875 \textcolor{comment}{}}
\DoxyCodeLine{8876 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8877 \textcolor{comment}{    Ensemble    -\/   model with initialized geometry}}
\DoxyCodeLine{8878 \textcolor{comment}{    XY          -\/   training set}}
\DoxyCodeLine{8879 \textcolor{comment}{    NPoints     -\/   training set size}}
\DoxyCodeLine{8880 \textcolor{comment}{    Decay       -\/   weight decay coefficient, >=0.001}}
\DoxyCodeLine{8881 \textcolor{comment}{    Restarts    -\/   restarts, >0.}}
\DoxyCodeLine{8882 \textcolor{comment}{    WStep       -\/   stopping criterion, same as in MLPTrainLBFGS}}
\DoxyCodeLine{8883 \textcolor{comment}{    MaxIts      -\/   stopping criterion, same as in MLPTrainLBFGS}}
\DoxyCodeLine{8884 \textcolor{comment}{}}
\DoxyCodeLine{8885 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8886 \textcolor{comment}{    Ensemble    -\/   trained model}}
\DoxyCodeLine{8887 \textcolor{comment}{    Info        -\/   return code:}}
\DoxyCodeLine{8888 \textcolor{comment}{                    * -\/8, if both WStep=0 and MaxIts=0}}
\DoxyCodeLine{8889 \textcolor{comment}{                    * -\/2, if there is a point with class number}}
\DoxyCodeLine{8890 \textcolor{comment}{                          outside of [0..NClasses-\/1].}}
\DoxyCodeLine{8891 \textcolor{comment}{                    * -\/1, if incorrect parameters was passed}}
\DoxyCodeLine{8892 \textcolor{comment}{                          (NPoints<0, Restarts<1).}}
\DoxyCodeLine{8893 \textcolor{comment}{                    *  2, if task has been solved.}}
\DoxyCodeLine{8894 \textcolor{comment}{    Rep         -\/   training report.}}
\DoxyCodeLine{8895 \textcolor{comment}{    OOBErrors   -\/   out-\/of-\/bag generalization error estimate}}
\DoxyCodeLine{8896 \textcolor{comment}{}}
\DoxyCodeLine{8897 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8898 \textcolor{comment}{     Copyright 17.02.2009 by Bochkanov Sergey}}
\DoxyCodeLine{8899 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8900 \textcolor{keywordtype}{void} mlpebagginglbfgs(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \textcolor{keywordtype}{double} decay, \textcolor{keyword}{const} ae\_int\_t restarts, \textcolor{keyword}{const} \textcolor{keywordtype}{double} wstep, \textcolor{keyword}{const} ae\_int\_t maxits, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}} \&rep, \mbox{\hyperlink{classalglib_1_1mlpcvreport}{mlpcvreport}} \&ooberrors, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8901 }
\DoxyCodeLine{8902 }
\DoxyCodeLine{8903 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8904 \textcolor{comment}{Training neural networks ensemble using early stopping.}}
\DoxyCodeLine{8905 \textcolor{comment}{}}
\DoxyCodeLine{8906 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8907 \textcolor{comment}{    Ensemble    -\/   model with initialized geometry}}
\DoxyCodeLine{8908 \textcolor{comment}{    XY          -\/   training set}}
\DoxyCodeLine{8909 \textcolor{comment}{    NPoints     -\/   training set size}}
\DoxyCodeLine{8910 \textcolor{comment}{    Decay       -\/   weight decay coefficient, >=0.001}}
\DoxyCodeLine{8911 \textcolor{comment}{    Restarts    -\/   restarts, >0.}}
\DoxyCodeLine{8912 \textcolor{comment}{}}
\DoxyCodeLine{8913 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8914 \textcolor{comment}{    Ensemble    -\/   trained model}}
\DoxyCodeLine{8915 \textcolor{comment}{    Info        -\/   return code:}}
\DoxyCodeLine{8916 \textcolor{comment}{                    * -\/2, if there is a point with class number}}
\DoxyCodeLine{8917 \textcolor{comment}{                          outside of [0..NClasses-\/1].}}
\DoxyCodeLine{8918 \textcolor{comment}{                    * -\/1, if incorrect parameters was passed}}
\DoxyCodeLine{8919 \textcolor{comment}{                          (NPoints<0, Restarts<1).}}
\DoxyCodeLine{8920 \textcolor{comment}{                    *  6, if task has been solved.}}
\DoxyCodeLine{8921 \textcolor{comment}{    Rep         -\/   training report.}}
\DoxyCodeLine{8922 \textcolor{comment}{    OOBErrors   -\/   out-\/of-\/bag generalization error estimate}}
\DoxyCodeLine{8923 \textcolor{comment}{}}
\DoxyCodeLine{8924 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8925 \textcolor{comment}{     Copyright 10.03.2009 by Bochkanov Sergey}}
\DoxyCodeLine{8926 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8927 \textcolor{keywordtype}{void} mlpetraines(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} \textcolor{keywordtype}{double} decay, \textcolor{keyword}{const} ae\_int\_t restarts, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8928 }
\DoxyCodeLine{8929 }
\DoxyCodeLine{8930 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8931 \textcolor{comment}{This function trains neural network ensemble passed to this function using}}
\DoxyCodeLine{8932 \textcolor{comment}{current dataset and early stopping training algorithm. Each early stopping}}
\DoxyCodeLine{8933 \textcolor{comment}{round performs NRestarts  random  restarts  (thus,  EnsembleSize*NRestarts}}
\DoxyCodeLine{8934 \textcolor{comment}{training rounds is performed in total).}}
\DoxyCodeLine{8935 \textcolor{comment}{}}
\DoxyCodeLine{8936 \textcolor{comment}{  ! COMMERCIAL EDITION OF ALGLIB:}}
\DoxyCodeLine{8937 \textcolor{comment}{  !}}
\DoxyCodeLine{8938 \textcolor{comment}{  ! Commercial Edition of ALGLIB includes following important improvements}}
\DoxyCodeLine{8939 \textcolor{comment}{  ! of this function:}}
\DoxyCodeLine{8940 \textcolor{comment}{  ! * high-\/performance native backend with same C\# interface (C\# version)}}
\DoxyCodeLine{8941 \textcolor{comment}{  ! * multithreading support (C++ and C\# versions)}}
\DoxyCodeLine{8942 \textcolor{comment}{  !}}
\DoxyCodeLine{8943 \textcolor{comment}{  ! We recommend you to read 'Working with commercial version' section  of}}
\DoxyCodeLine{8944 \textcolor{comment}{  ! ALGLIB Reference Manual in order to find out how to  use  performance-\/}}
\DoxyCodeLine{8945 \textcolor{comment}{  ! related features provided by commercial edition of ALGLIB.}}
\DoxyCodeLine{8946 \textcolor{comment}{}}
\DoxyCodeLine{8947 \textcolor{comment}{INPUT PARAMETERS:}}
\DoxyCodeLine{8948 \textcolor{comment}{    S           -\/   trainer object;}}
\DoxyCodeLine{8949 \textcolor{comment}{    Ensemble    -\/   neural network ensemble. It must have same  number  of}}
\DoxyCodeLine{8950 \textcolor{comment}{                    inputs and outputs/classes  as  was  specified  during}}
\DoxyCodeLine{8951 \textcolor{comment}{                    creation of the trainer object.}}
\DoxyCodeLine{8952 \textcolor{comment}{    NRestarts   -\/   number of restarts, >=0:}}
\DoxyCodeLine{8953 \textcolor{comment}{                    * NRestarts>0 means that specified  number  of  random}}
\DoxyCodeLine{8954 \textcolor{comment}{                      restarts are performed during each ES round;}}
\DoxyCodeLine{8955 \textcolor{comment}{                    * NRestarts=0 is silently replaced by 1.}}
\DoxyCodeLine{8956 \textcolor{comment}{}}
\DoxyCodeLine{8957 \textcolor{comment}{OUTPUT PARAMETERS:}}
\DoxyCodeLine{8958 \textcolor{comment}{    Ensemble    -\/   trained ensemble;}}
\DoxyCodeLine{8959 \textcolor{comment}{    Rep         -\/   it contains all type of errors.}}
\DoxyCodeLine{8960 \textcolor{comment}{}}
\DoxyCodeLine{8961 \textcolor{comment}{NOTE: this training method uses BOTH early stopping and weight decay!  So,}}
\DoxyCodeLine{8962 \textcolor{comment}{      you should select weight decay before starting training just as  you}}
\DoxyCodeLine{8963 \textcolor{comment}{      select it before training "{}conventional"{} networks.}}
\DoxyCodeLine{8964 \textcolor{comment}{}}
\DoxyCodeLine{8965 \textcolor{comment}{NOTE: when no dataset was specified with MLPSetDataset/SetSparseDataset(),}}
\DoxyCodeLine{8966 \textcolor{comment}{      or  single-\/point  dataset  was  passed,  ensemble  is filled by zero}}
\DoxyCodeLine{8967 \textcolor{comment}{      values.}}
\DoxyCodeLine{8968 \textcolor{comment}{}}
\DoxyCodeLine{8969 \textcolor{comment}{NOTE: this method uses sum-\/of-\/squares error function for training.}}
\DoxyCodeLine{8970 \textcolor{comment}{}}
\DoxyCodeLine{8971 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8972 \textcolor{comment}{     Copyright 22.08.2012 by Bochkanov Sergey}}
\DoxyCodeLine{8973 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8974 \textcolor{keywordtype}{void} mlptrainensemblees(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlptrainer}{mlptrainer}} \&s, \textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1mlpensemble}{mlpensemble}} \&ensemble, \textcolor{keyword}{const} ae\_int\_t nrestarts, \mbox{\hyperlink{classalglib_1_1mlpreport}{mlpreport}} \&rep, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8975 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{8976 }
\DoxyCodeLine{8977 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_DATACOMP) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{8978 \textcolor{comment}{/*************************************************************************}}
\DoxyCodeLine{8979 \textcolor{comment}{k-\/means++ clusterization.}}
\DoxyCodeLine{8980 \textcolor{comment}{Backward compatibility function, we recommend to use CLUSTERING subpackage}}
\DoxyCodeLine{8981 \textcolor{comment}{as better replacement.}}
\DoxyCodeLine{8982 \textcolor{comment}{}}
\DoxyCodeLine{8983 \textcolor{comment}{  -\/-\/ ALGLIB -\/-\/}}
\DoxyCodeLine{8984 \textcolor{comment}{     Copyright 21.03.2009 by Bochkanov Sergey}}
\DoxyCodeLine{8985 \textcolor{comment}{*************************************************************************/}}
\DoxyCodeLine{8986 \textcolor{keywordtype}{void} kmeansgenerate(\textcolor{keyword}{const} \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&xy, \textcolor{keyword}{const} ae\_int\_t npoints, \textcolor{keyword}{const} ae\_int\_t nvars, \textcolor{keyword}{const} ae\_int\_t k, \textcolor{keyword}{const} ae\_int\_t restarts, ae\_int\_t \&info, \mbox{\hyperlink{classalglib_1_1real__2d__array}{real\_2d\_array}} \&c, \mbox{\hyperlink{classalglib_1_1integer__1d__array}{integer\_1d\_array}} \&xyc, \textcolor{keyword}{const} \mbox{\hyperlink{structalglib_1_1xparams}{xparams}} \_xparams = alglib::xdefault);}
\DoxyCodeLine{8987 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{8988 \}}
\DoxyCodeLine{8989 }
\DoxyCodeLine{8991 \textcolor{comment}{//}}
\DoxyCodeLine{8992 \textcolor{comment}{// THIS SECTION CONTAINS COMPUTATIONAL CORE DECLARATIONS (FUNCTIONS)}}
\DoxyCodeLine{8993 \textcolor{comment}{//}}
\DoxyCodeLine{8995 \textcolor{comment}{}\textcolor{keyword}{namespace }alglib\_impl}
\DoxyCodeLine{8996 \{}
\DoxyCodeLine{8997 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_PCA) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{8998 \textcolor{keywordtype}{void} pcabuildbasis(\textcolor{comment}{/* Real    */} ae\_matrix* x,}
\DoxyCodeLine{8999      ae\_int\_t npoints,}
\DoxyCodeLine{9000      ae\_int\_t nvars,}
\DoxyCodeLine{9001      ae\_int\_t* info,}
\DoxyCodeLine{9002      \textcolor{comment}{/* Real    */} ae\_vector* s2,}
\DoxyCodeLine{9003      \textcolor{comment}{/* Real    */} ae\_matrix* v,}
\DoxyCodeLine{9004      ae\_state *\_state);}
\DoxyCodeLine{9005 \textcolor{keywordtype}{void} pcatruncatedsubspace(\textcolor{comment}{/* Real    */} ae\_matrix* x,}
\DoxyCodeLine{9006      ae\_int\_t npoints,}
\DoxyCodeLine{9007      ae\_int\_t nvars,}
\DoxyCodeLine{9008      ae\_int\_t nneeded,}
\DoxyCodeLine{9009      \textcolor{keywordtype}{double} eps,}
\DoxyCodeLine{9010      ae\_int\_t maxits,}
\DoxyCodeLine{9011      \textcolor{comment}{/* Real    */} ae\_vector* s2,}
\DoxyCodeLine{9012      \textcolor{comment}{/* Real    */} ae\_matrix* v,}
\DoxyCodeLine{9013      ae\_state *\_state);}
\DoxyCodeLine{9014 \textcolor{keywordtype}{void} pcatruncatedsubspacesparse(sparsematrix* x,}
\DoxyCodeLine{9015      ae\_int\_t npoints,}
\DoxyCodeLine{9016      ae\_int\_t nvars,}
\DoxyCodeLine{9017      ae\_int\_t nneeded,}
\DoxyCodeLine{9018      \textcolor{keywordtype}{double} eps,}
\DoxyCodeLine{9019      ae\_int\_t maxits,}
\DoxyCodeLine{9020      \textcolor{comment}{/* Real    */} ae\_vector* s2,}
\DoxyCodeLine{9021      \textcolor{comment}{/* Real    */} ae\_matrix* v,}
\DoxyCodeLine{9022      ae\_state *\_state);}
\DoxyCodeLine{9023 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{9024 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_BDSS) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{9025 \textcolor{keywordtype}{void} dserrallocate(ae\_int\_t nclasses,}
\DoxyCodeLine{9026      \textcolor{comment}{/* Real    */} ae\_vector* buf,}
\DoxyCodeLine{9027      ae\_state *\_state);}
\DoxyCodeLine{9028 \textcolor{keywordtype}{void} dserraccumulate(\textcolor{comment}{/* Real    */} ae\_vector* buf,}
\DoxyCodeLine{9029      \textcolor{comment}{/* Real    */} ae\_vector* y,}
\DoxyCodeLine{9030      \textcolor{comment}{/* Real    */} ae\_vector* desiredy,}
\DoxyCodeLine{9031      ae\_state *\_state);}
\DoxyCodeLine{9032 \textcolor{keywordtype}{void} dserrfinish(\textcolor{comment}{/* Real    */} ae\_vector* buf, ae\_state *\_state);}
\DoxyCodeLine{9033 \textcolor{keywordtype}{void} dsnormalize(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9034      ae\_int\_t npoints,}
\DoxyCodeLine{9035      ae\_int\_t nvars,}
\DoxyCodeLine{9036      ae\_int\_t* info,}
\DoxyCodeLine{9037      \textcolor{comment}{/* Real    */} ae\_vector* means,}
\DoxyCodeLine{9038      \textcolor{comment}{/* Real    */} ae\_vector* sigmas,}
\DoxyCodeLine{9039      ae\_state *\_state);}
\DoxyCodeLine{9040 \textcolor{keywordtype}{void} dsnormalizec(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9041      ae\_int\_t npoints,}
\DoxyCodeLine{9042      ae\_int\_t nvars,}
\DoxyCodeLine{9043      ae\_int\_t* info,}
\DoxyCodeLine{9044      \textcolor{comment}{/* Real    */} ae\_vector* means,}
\DoxyCodeLine{9045      \textcolor{comment}{/* Real    */} ae\_vector* sigmas,}
\DoxyCodeLine{9046      ae\_state *\_state);}
\DoxyCodeLine{9047 \textcolor{keywordtype}{double} dsgetmeanmindistance(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9048      ae\_int\_t npoints,}
\DoxyCodeLine{9049      ae\_int\_t nvars,}
\DoxyCodeLine{9050      ae\_state *\_state);}
\DoxyCodeLine{9051 \textcolor{keywordtype}{void} dstie(\textcolor{comment}{/* Real    */} ae\_vector* a,}
\DoxyCodeLine{9052      ae\_int\_t n,}
\DoxyCodeLine{9053      \textcolor{comment}{/* Integer */} ae\_vector* ties,}
\DoxyCodeLine{9054      ae\_int\_t* tiecount,}
\DoxyCodeLine{9055      \textcolor{comment}{/* Integer */} ae\_vector* p1,}
\DoxyCodeLine{9056      \textcolor{comment}{/* Integer */} ae\_vector* p2,}
\DoxyCodeLine{9057      ae\_state *\_state);}
\DoxyCodeLine{9058 \textcolor{keywordtype}{void} dstiefasti(\textcolor{comment}{/* Real    */} ae\_vector* a,}
\DoxyCodeLine{9059      \textcolor{comment}{/* Integer */} ae\_vector* b,}
\DoxyCodeLine{9060      ae\_int\_t n,}
\DoxyCodeLine{9061      \textcolor{comment}{/* Integer */} ae\_vector* ties,}
\DoxyCodeLine{9062      ae\_int\_t* tiecount,}
\DoxyCodeLine{9063      \textcolor{comment}{/* Real    */} ae\_vector* bufr,}
\DoxyCodeLine{9064      \textcolor{comment}{/* Integer */} ae\_vector* bufi,}
\DoxyCodeLine{9065      ae\_state *\_state);}
\DoxyCodeLine{9066 \textcolor{keywordtype}{void} dsoptimalsplit2(\textcolor{comment}{/* Real    */} ae\_vector* a,}
\DoxyCodeLine{9067      \textcolor{comment}{/* Integer */} ae\_vector* c,}
\DoxyCodeLine{9068      ae\_int\_t n,}
\DoxyCodeLine{9069      ae\_int\_t* info,}
\DoxyCodeLine{9070      \textcolor{keywordtype}{double}* threshold,}
\DoxyCodeLine{9071      \textcolor{keywordtype}{double}* pal,}
\DoxyCodeLine{9072      \textcolor{keywordtype}{double}* pbl,}
\DoxyCodeLine{9073      \textcolor{keywordtype}{double}* par,}
\DoxyCodeLine{9074      \textcolor{keywordtype}{double}* pbr,}
\DoxyCodeLine{9075      \textcolor{keywordtype}{double}* cve,}
\DoxyCodeLine{9076      ae\_state *\_state);}
\DoxyCodeLine{9077 \textcolor{keywordtype}{void} dsoptimalsplit2fast(\textcolor{comment}{/* Real    */} ae\_vector* a,}
\DoxyCodeLine{9078      \textcolor{comment}{/* Integer */} ae\_vector* c,}
\DoxyCodeLine{9079      \textcolor{comment}{/* Integer */} ae\_vector* tiesbuf,}
\DoxyCodeLine{9080      \textcolor{comment}{/* Integer */} ae\_vector* cntbuf,}
\DoxyCodeLine{9081      \textcolor{comment}{/* Real    */} ae\_vector* bufr,}
\DoxyCodeLine{9082      \textcolor{comment}{/* Integer */} ae\_vector* bufi,}
\DoxyCodeLine{9083      ae\_int\_t n,}
\DoxyCodeLine{9084      ae\_int\_t nc,}
\DoxyCodeLine{9085      \textcolor{keywordtype}{double} alpha,}
\DoxyCodeLine{9086      ae\_int\_t* info,}
\DoxyCodeLine{9087      \textcolor{keywordtype}{double}* threshold,}
\DoxyCodeLine{9088      \textcolor{keywordtype}{double}* rms,}
\DoxyCodeLine{9089      \textcolor{keywordtype}{double}* cvrms,}
\DoxyCodeLine{9090      ae\_state *\_state);}
\DoxyCodeLine{9091 \textcolor{keywordtype}{void} dssplitk(\textcolor{comment}{/* Real    */} ae\_vector* a,}
\DoxyCodeLine{9092      \textcolor{comment}{/* Integer */} ae\_vector* c,}
\DoxyCodeLine{9093      ae\_int\_t n,}
\DoxyCodeLine{9094      ae\_int\_t nc,}
\DoxyCodeLine{9095      ae\_int\_t kmax,}
\DoxyCodeLine{9096      ae\_int\_t* info,}
\DoxyCodeLine{9097      \textcolor{comment}{/* Real    */} ae\_vector* thresholds,}
\DoxyCodeLine{9098      ae\_int\_t* ni,}
\DoxyCodeLine{9099      \textcolor{keywordtype}{double}* cve,}
\DoxyCodeLine{9100      ae\_state *\_state);}
\DoxyCodeLine{9101 \textcolor{keywordtype}{void} dsoptimalsplitk(\textcolor{comment}{/* Real    */} ae\_vector* a,}
\DoxyCodeLine{9102      \textcolor{comment}{/* Integer */} ae\_vector* c,}
\DoxyCodeLine{9103      ae\_int\_t n,}
\DoxyCodeLine{9104      ae\_int\_t nc,}
\DoxyCodeLine{9105      ae\_int\_t kmax,}
\DoxyCodeLine{9106      ae\_int\_t* info,}
\DoxyCodeLine{9107      \textcolor{comment}{/* Real    */} ae\_vector* thresholds,}
\DoxyCodeLine{9108      ae\_int\_t* ni,}
\DoxyCodeLine{9109      \textcolor{keywordtype}{double}* cve,}
\DoxyCodeLine{9110      ae\_state *\_state);}
\DoxyCodeLine{9111 \textcolor{keywordtype}{void} \_cvreport\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9112 \textcolor{keywordtype}{void} \_cvreport\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9113 \textcolor{keywordtype}{void} \_cvreport\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9114 \textcolor{keywordtype}{void} \_cvreport\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9115 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{9116 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_MLPBASE) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{9117 ae\_int\_t mlpgradsplitcost(ae\_state *\_state);}
\DoxyCodeLine{9118 ae\_int\_t mlpgradsplitsize(ae\_state *\_state);}
\DoxyCodeLine{9119 \textcolor{keywordtype}{void} mlpcreate0(ae\_int\_t nin,}
\DoxyCodeLine{9120      ae\_int\_t nout,}
\DoxyCodeLine{9121      multilayerperceptron* network,}
\DoxyCodeLine{9122      ae\_state *\_state);}
\DoxyCodeLine{9123 \textcolor{keywordtype}{void} mlpcreate1(ae\_int\_t nin,}
\DoxyCodeLine{9124      ae\_int\_t nhid,}
\DoxyCodeLine{9125      ae\_int\_t nout,}
\DoxyCodeLine{9126      multilayerperceptron* network,}
\DoxyCodeLine{9127      ae\_state *\_state);}
\DoxyCodeLine{9128 \textcolor{keywordtype}{void} mlpcreate2(ae\_int\_t nin,}
\DoxyCodeLine{9129      ae\_int\_t nhid1,}
\DoxyCodeLine{9130      ae\_int\_t nhid2,}
\DoxyCodeLine{9131      ae\_int\_t nout,}
\DoxyCodeLine{9132      multilayerperceptron* network,}
\DoxyCodeLine{9133      ae\_state *\_state);}
\DoxyCodeLine{9134 \textcolor{keywordtype}{void} mlpcreateb0(ae\_int\_t nin,}
\DoxyCodeLine{9135      ae\_int\_t nout,}
\DoxyCodeLine{9136      \textcolor{keywordtype}{double} b,}
\DoxyCodeLine{9137      \textcolor{keywordtype}{double} d,}
\DoxyCodeLine{9138      multilayerperceptron* network,}
\DoxyCodeLine{9139      ae\_state *\_state);}
\DoxyCodeLine{9140 \textcolor{keywordtype}{void} mlpcreateb1(ae\_int\_t nin,}
\DoxyCodeLine{9141      ae\_int\_t nhid,}
\DoxyCodeLine{9142      ae\_int\_t nout,}
\DoxyCodeLine{9143      \textcolor{keywordtype}{double} b,}
\DoxyCodeLine{9144      \textcolor{keywordtype}{double} d,}
\DoxyCodeLine{9145      multilayerperceptron* network,}
\DoxyCodeLine{9146      ae\_state *\_state);}
\DoxyCodeLine{9147 \textcolor{keywordtype}{void} mlpcreateb2(ae\_int\_t nin,}
\DoxyCodeLine{9148      ae\_int\_t nhid1,}
\DoxyCodeLine{9149      ae\_int\_t nhid2,}
\DoxyCodeLine{9150      ae\_int\_t nout,}
\DoxyCodeLine{9151      \textcolor{keywordtype}{double} b,}
\DoxyCodeLine{9152      \textcolor{keywordtype}{double} d,}
\DoxyCodeLine{9153      multilayerperceptron* network,}
\DoxyCodeLine{9154      ae\_state *\_state);}
\DoxyCodeLine{9155 \textcolor{keywordtype}{void} mlpcreater0(ae\_int\_t nin,}
\DoxyCodeLine{9156      ae\_int\_t nout,}
\DoxyCodeLine{9157      \textcolor{keywordtype}{double} a,}
\DoxyCodeLine{9158      \textcolor{keywordtype}{double} b,}
\DoxyCodeLine{9159      multilayerperceptron* network,}
\DoxyCodeLine{9160      ae\_state *\_state);}
\DoxyCodeLine{9161 \textcolor{keywordtype}{void} mlpcreater1(ae\_int\_t nin,}
\DoxyCodeLine{9162      ae\_int\_t nhid,}
\DoxyCodeLine{9163      ae\_int\_t nout,}
\DoxyCodeLine{9164      \textcolor{keywordtype}{double} a,}
\DoxyCodeLine{9165      \textcolor{keywordtype}{double} b,}
\DoxyCodeLine{9166      multilayerperceptron* network,}
\DoxyCodeLine{9167      ae\_state *\_state);}
\DoxyCodeLine{9168 \textcolor{keywordtype}{void} mlpcreater2(ae\_int\_t nin,}
\DoxyCodeLine{9169      ae\_int\_t nhid1,}
\DoxyCodeLine{9170      ae\_int\_t nhid2,}
\DoxyCodeLine{9171      ae\_int\_t nout,}
\DoxyCodeLine{9172      \textcolor{keywordtype}{double} a,}
\DoxyCodeLine{9173      \textcolor{keywordtype}{double} b,}
\DoxyCodeLine{9174      multilayerperceptron* network,}
\DoxyCodeLine{9175      ae\_state *\_state);}
\DoxyCodeLine{9176 \textcolor{keywordtype}{void} mlpcreatec0(ae\_int\_t nin,}
\DoxyCodeLine{9177      ae\_int\_t nout,}
\DoxyCodeLine{9178      multilayerperceptron* network,}
\DoxyCodeLine{9179      ae\_state *\_state);}
\DoxyCodeLine{9180 \textcolor{keywordtype}{void} mlpcreatec1(ae\_int\_t nin,}
\DoxyCodeLine{9181      ae\_int\_t nhid,}
\DoxyCodeLine{9182      ae\_int\_t nout,}
\DoxyCodeLine{9183      multilayerperceptron* network,}
\DoxyCodeLine{9184      ae\_state *\_state);}
\DoxyCodeLine{9185 \textcolor{keywordtype}{void} mlpcreatec2(ae\_int\_t nin,}
\DoxyCodeLine{9186      ae\_int\_t nhid1,}
\DoxyCodeLine{9187      ae\_int\_t nhid2,}
\DoxyCodeLine{9188      ae\_int\_t nout,}
\DoxyCodeLine{9189      multilayerperceptron* network,}
\DoxyCodeLine{9190      ae\_state *\_state);}
\DoxyCodeLine{9191 \textcolor{keywordtype}{void} mlpcopy(multilayerperceptron* network1,}
\DoxyCodeLine{9192      multilayerperceptron* network2,}
\DoxyCodeLine{9193      ae\_state *\_state);}
\DoxyCodeLine{9194 \textcolor{keywordtype}{void} mlpcopyshared(multilayerperceptron* network1,}
\DoxyCodeLine{9195      multilayerperceptron* network2,}
\DoxyCodeLine{9196      ae\_state *\_state);}
\DoxyCodeLine{9197 ae\_bool mlpsamearchitecture(multilayerperceptron* network1,}
\DoxyCodeLine{9198      multilayerperceptron* network2,}
\DoxyCodeLine{9199      ae\_state *\_state);}
\DoxyCodeLine{9200 \textcolor{keywordtype}{void} mlpcopytunableparameters(multilayerperceptron* network1,}
\DoxyCodeLine{9201      multilayerperceptron* network2,}
\DoxyCodeLine{9202      ae\_state *\_state);}
\DoxyCodeLine{9203 \textcolor{keywordtype}{void} mlpexporttunableparameters(multilayerperceptron* network,}
\DoxyCodeLine{9204      \textcolor{comment}{/* Real    */} ae\_vector* p,}
\DoxyCodeLine{9205      ae\_int\_t* pcount,}
\DoxyCodeLine{9206      ae\_state *\_state);}
\DoxyCodeLine{9207 \textcolor{keywordtype}{void} mlpimporttunableparameters(multilayerperceptron* network,}
\DoxyCodeLine{9208      \textcolor{comment}{/* Real    */} ae\_vector* p,}
\DoxyCodeLine{9209      ae\_state *\_state);}
\DoxyCodeLine{9210 \textcolor{keywordtype}{void} mlpserializeold(multilayerperceptron* network,}
\DoxyCodeLine{9211      \textcolor{comment}{/* Real    */} ae\_vector* ra,}
\DoxyCodeLine{9212      ae\_int\_t* rlen,}
\DoxyCodeLine{9213      ae\_state *\_state);}
\DoxyCodeLine{9214 \textcolor{keywordtype}{void} mlpunserializeold(\textcolor{comment}{/* Real    */} ae\_vector* ra,}
\DoxyCodeLine{9215      multilayerperceptron* network,}
\DoxyCodeLine{9216      ae\_state *\_state);}
\DoxyCodeLine{9217 \textcolor{keywordtype}{void} mlprandomize(multilayerperceptron* network, ae\_state *\_state);}
\DoxyCodeLine{9218 \textcolor{keywordtype}{void} mlprandomizefull(multilayerperceptron* network, ae\_state *\_state);}
\DoxyCodeLine{9219 \textcolor{keywordtype}{void} mlpinitpreprocessor(multilayerperceptron* network,}
\DoxyCodeLine{9220      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9221      ae\_int\_t ssize,}
\DoxyCodeLine{9222      ae\_state *\_state);}
\DoxyCodeLine{9223 \textcolor{keywordtype}{void} mlpinitpreprocessorsparse(multilayerperceptron* network,}
\DoxyCodeLine{9224      sparsematrix* xy,}
\DoxyCodeLine{9225      ae\_int\_t ssize,}
\DoxyCodeLine{9226      ae\_state *\_state);}
\DoxyCodeLine{9227 \textcolor{keywordtype}{void} mlpinitpreprocessorsubset(multilayerperceptron* network,}
\DoxyCodeLine{9228      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9229      ae\_int\_t setsize,}
\DoxyCodeLine{9230      \textcolor{comment}{/* Integer */} ae\_vector* idx,}
\DoxyCodeLine{9231      ae\_int\_t subsetsize,}
\DoxyCodeLine{9232      ae\_state *\_state);}
\DoxyCodeLine{9233 \textcolor{keywordtype}{void} mlpinitpreprocessorsparsesubset(multilayerperceptron* network,}
\DoxyCodeLine{9234      sparsematrix* xy,}
\DoxyCodeLine{9235      ae\_int\_t setsize,}
\DoxyCodeLine{9236      \textcolor{comment}{/* Integer */} ae\_vector* idx,}
\DoxyCodeLine{9237      ae\_int\_t subsetsize,}
\DoxyCodeLine{9238      ae\_state *\_state);}
\DoxyCodeLine{9239 \textcolor{keywordtype}{void} mlpproperties(multilayerperceptron* network,}
\DoxyCodeLine{9240      ae\_int\_t* nin,}
\DoxyCodeLine{9241      ae\_int\_t* nout,}
\DoxyCodeLine{9242      ae\_int\_t* wcount,}
\DoxyCodeLine{9243      ae\_state *\_state);}
\DoxyCodeLine{9244 ae\_int\_t mlpntotal(multilayerperceptron* network, ae\_state *\_state);}
\DoxyCodeLine{9245 ae\_int\_t mlpgetinputscount(multilayerperceptron* network,}
\DoxyCodeLine{9246      ae\_state *\_state);}
\DoxyCodeLine{9247 ae\_int\_t mlpgetoutputscount(multilayerperceptron* network,}
\DoxyCodeLine{9248      ae\_state *\_state);}
\DoxyCodeLine{9249 ae\_int\_t mlpgetweightscount(multilayerperceptron* network,}
\DoxyCodeLine{9250      ae\_state *\_state);}
\DoxyCodeLine{9251 ae\_bool mlpissoftmax(multilayerperceptron* network, ae\_state *\_state);}
\DoxyCodeLine{9252 ae\_int\_t mlpgetlayerscount(multilayerperceptron* network,}
\DoxyCodeLine{9253      ae\_state *\_state);}
\DoxyCodeLine{9254 ae\_int\_t mlpgetlayersize(multilayerperceptron* network,}
\DoxyCodeLine{9255      ae\_int\_t k,}
\DoxyCodeLine{9256      ae\_state *\_state);}
\DoxyCodeLine{9257 \textcolor{keywordtype}{void} mlpgetinputscaling(multilayerperceptron* network,}
\DoxyCodeLine{9258      ae\_int\_t i,}
\DoxyCodeLine{9259      \textcolor{keywordtype}{double}* mean,}
\DoxyCodeLine{9260      \textcolor{keywordtype}{double}* sigma,}
\DoxyCodeLine{9261      ae\_state *\_state);}
\DoxyCodeLine{9262 \textcolor{keywordtype}{void} mlpgetoutputscaling(multilayerperceptron* network,}
\DoxyCodeLine{9263      ae\_int\_t i,}
\DoxyCodeLine{9264      \textcolor{keywordtype}{double}* mean,}
\DoxyCodeLine{9265      \textcolor{keywordtype}{double}* sigma,}
\DoxyCodeLine{9266      ae\_state *\_state);}
\DoxyCodeLine{9267 \textcolor{keywordtype}{void} mlpgetneuroninfo(multilayerperceptron* network,}
\DoxyCodeLine{9268      ae\_int\_t k,}
\DoxyCodeLine{9269      ae\_int\_t i,}
\DoxyCodeLine{9270      ae\_int\_t* fkind,}
\DoxyCodeLine{9271      \textcolor{keywordtype}{double}* threshold,}
\DoxyCodeLine{9272      ae\_state *\_state);}
\DoxyCodeLine{9273 \textcolor{keywordtype}{double} mlpgetweight(multilayerperceptron* network,}
\DoxyCodeLine{9274      ae\_int\_t k0,}
\DoxyCodeLine{9275      ae\_int\_t i0,}
\DoxyCodeLine{9276      ae\_int\_t k1,}
\DoxyCodeLine{9277      ae\_int\_t i1,}
\DoxyCodeLine{9278      ae\_state *\_state);}
\DoxyCodeLine{9279 \textcolor{keywordtype}{void} mlpsetinputscaling(multilayerperceptron* network,}
\DoxyCodeLine{9280      ae\_int\_t i,}
\DoxyCodeLine{9281      \textcolor{keywordtype}{double} mean,}
\DoxyCodeLine{9282      \textcolor{keywordtype}{double} sigma,}
\DoxyCodeLine{9283      ae\_state *\_state);}
\DoxyCodeLine{9284 \textcolor{keywordtype}{void} mlpsetoutputscaling(multilayerperceptron* network,}
\DoxyCodeLine{9285      ae\_int\_t i,}
\DoxyCodeLine{9286      \textcolor{keywordtype}{double} mean,}
\DoxyCodeLine{9287      \textcolor{keywordtype}{double} sigma,}
\DoxyCodeLine{9288      ae\_state *\_state);}
\DoxyCodeLine{9289 \textcolor{keywordtype}{void} mlpsetneuroninfo(multilayerperceptron* network,}
\DoxyCodeLine{9290      ae\_int\_t k,}
\DoxyCodeLine{9291      ae\_int\_t i,}
\DoxyCodeLine{9292      ae\_int\_t fkind,}
\DoxyCodeLine{9293      \textcolor{keywordtype}{double} threshold,}
\DoxyCodeLine{9294      ae\_state *\_state);}
\DoxyCodeLine{9295 \textcolor{keywordtype}{void} mlpsetweight(multilayerperceptron* network,}
\DoxyCodeLine{9296      ae\_int\_t k0,}
\DoxyCodeLine{9297      ae\_int\_t i0,}
\DoxyCodeLine{9298      ae\_int\_t k1,}
\DoxyCodeLine{9299      ae\_int\_t i1,}
\DoxyCodeLine{9300      \textcolor{keywordtype}{double} w,}
\DoxyCodeLine{9301      ae\_state *\_state);}
\DoxyCodeLine{9302 \textcolor{keywordtype}{void} mlpactivationfunction(\textcolor{keywordtype}{double} net,}
\DoxyCodeLine{9303      ae\_int\_t k,}
\DoxyCodeLine{9304      \textcolor{keywordtype}{double}* f,}
\DoxyCodeLine{9305      \textcolor{keywordtype}{double}* df,}
\DoxyCodeLine{9306      \textcolor{keywordtype}{double}* d2f,}
\DoxyCodeLine{9307      ae\_state *\_state);}
\DoxyCodeLine{9308 \textcolor{keywordtype}{void} mlpprocess(multilayerperceptron* network,}
\DoxyCodeLine{9309      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{9310      \textcolor{comment}{/* Real    */} ae\_vector* y,}
\DoxyCodeLine{9311      ae\_state *\_state);}
\DoxyCodeLine{9312 \textcolor{keywordtype}{void} mlpprocessi(multilayerperceptron* network,}
\DoxyCodeLine{9313      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{9314      \textcolor{comment}{/* Real    */} ae\_vector* y,}
\DoxyCodeLine{9315      ae\_state *\_state);}
\DoxyCodeLine{9316 \textcolor{keywordtype}{double} mlperror(multilayerperceptron* network,}
\DoxyCodeLine{9317      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9318      ae\_int\_t npoints,}
\DoxyCodeLine{9319      ae\_state *\_state);}
\DoxyCodeLine{9320 \textcolor{keywordtype}{double} mlperrorsparse(multilayerperceptron* network,}
\DoxyCodeLine{9321      sparsematrix* xy,}
\DoxyCodeLine{9322      ae\_int\_t npoints,}
\DoxyCodeLine{9323      ae\_state *\_state);}
\DoxyCodeLine{9324 \textcolor{keywordtype}{double} mlperrorn(multilayerperceptron* network,}
\DoxyCodeLine{9325      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9326      ae\_int\_t ssize,}
\DoxyCodeLine{9327      ae\_state *\_state);}
\DoxyCodeLine{9328 ae\_int\_t mlpclserror(multilayerperceptron* network,}
\DoxyCodeLine{9329      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9330      ae\_int\_t npoints,}
\DoxyCodeLine{9331      ae\_state *\_state);}
\DoxyCodeLine{9332 \textcolor{keywordtype}{double} mlprelclserror(multilayerperceptron* network,}
\DoxyCodeLine{9333      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9334      ae\_int\_t npoints,}
\DoxyCodeLine{9335      ae\_state *\_state);}
\DoxyCodeLine{9336 \textcolor{keywordtype}{double} mlprelclserrorsparse(multilayerperceptron* network,}
\DoxyCodeLine{9337      sparsematrix* xy,}
\DoxyCodeLine{9338      ae\_int\_t npoints,}
\DoxyCodeLine{9339      ae\_state *\_state);}
\DoxyCodeLine{9340 \textcolor{keywordtype}{double} mlpavgce(multilayerperceptron* network,}
\DoxyCodeLine{9341      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9342      ae\_int\_t npoints,}
\DoxyCodeLine{9343      ae\_state *\_state);}
\DoxyCodeLine{9344 \textcolor{keywordtype}{double} mlpavgcesparse(multilayerperceptron* network,}
\DoxyCodeLine{9345      sparsematrix* xy,}
\DoxyCodeLine{9346      ae\_int\_t npoints,}
\DoxyCodeLine{9347      ae\_state *\_state);}
\DoxyCodeLine{9348 \textcolor{keywordtype}{double} mlprmserror(multilayerperceptron* network,}
\DoxyCodeLine{9349      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9350      ae\_int\_t npoints,}
\DoxyCodeLine{9351      ae\_state *\_state);}
\DoxyCodeLine{9352 \textcolor{keywordtype}{double} mlprmserrorsparse(multilayerperceptron* network,}
\DoxyCodeLine{9353      sparsematrix* xy,}
\DoxyCodeLine{9354      ae\_int\_t npoints,}
\DoxyCodeLine{9355      ae\_state *\_state);}
\DoxyCodeLine{9356 \textcolor{keywordtype}{double} mlpavgerror(multilayerperceptron* network,}
\DoxyCodeLine{9357      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9358      ae\_int\_t npoints,}
\DoxyCodeLine{9359      ae\_state *\_state);}
\DoxyCodeLine{9360 \textcolor{keywordtype}{double} mlpavgerrorsparse(multilayerperceptron* network,}
\DoxyCodeLine{9361      sparsematrix* xy,}
\DoxyCodeLine{9362      ae\_int\_t npoints,}
\DoxyCodeLine{9363      ae\_state *\_state);}
\DoxyCodeLine{9364 \textcolor{keywordtype}{double} mlpavgrelerror(multilayerperceptron* network,}
\DoxyCodeLine{9365      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9366      ae\_int\_t npoints,}
\DoxyCodeLine{9367      ae\_state *\_state);}
\DoxyCodeLine{9368 \textcolor{keywordtype}{double} mlpavgrelerrorsparse(multilayerperceptron* network,}
\DoxyCodeLine{9369      sparsematrix* xy,}
\DoxyCodeLine{9370      ae\_int\_t npoints,}
\DoxyCodeLine{9371      ae\_state *\_state);}
\DoxyCodeLine{9372 \textcolor{keywordtype}{void} mlpgrad(multilayerperceptron* network,}
\DoxyCodeLine{9373      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{9374      \textcolor{comment}{/* Real    */} ae\_vector* desiredy,}
\DoxyCodeLine{9375      \textcolor{keywordtype}{double}* e,}
\DoxyCodeLine{9376      \textcolor{comment}{/* Real    */} ae\_vector* grad,}
\DoxyCodeLine{9377      ae\_state *\_state);}
\DoxyCodeLine{9378 \textcolor{keywordtype}{void} mlpgradn(multilayerperceptron* network,}
\DoxyCodeLine{9379      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{9380      \textcolor{comment}{/* Real    */} ae\_vector* desiredy,}
\DoxyCodeLine{9381      \textcolor{keywordtype}{double}* e,}
\DoxyCodeLine{9382      \textcolor{comment}{/* Real    */} ae\_vector* grad,}
\DoxyCodeLine{9383      ae\_state *\_state);}
\DoxyCodeLine{9384 \textcolor{keywordtype}{void} mlpgradbatch(multilayerperceptron* network,}
\DoxyCodeLine{9385      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9386      ae\_int\_t ssize,}
\DoxyCodeLine{9387      \textcolor{keywordtype}{double}* e,}
\DoxyCodeLine{9388      \textcolor{comment}{/* Real    */} ae\_vector* grad,}
\DoxyCodeLine{9389      ae\_state *\_state);}
\DoxyCodeLine{9390 \textcolor{keywordtype}{void} mlpgradbatchsparse(multilayerperceptron* network,}
\DoxyCodeLine{9391      sparsematrix* xy,}
\DoxyCodeLine{9392      ae\_int\_t ssize,}
\DoxyCodeLine{9393      \textcolor{keywordtype}{double}* e,}
\DoxyCodeLine{9394      \textcolor{comment}{/* Real    */} ae\_vector* grad,}
\DoxyCodeLine{9395      ae\_state *\_state);}
\DoxyCodeLine{9396 \textcolor{keywordtype}{void} mlpgradbatchsubset(multilayerperceptron* network,}
\DoxyCodeLine{9397      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9398      ae\_int\_t setsize,}
\DoxyCodeLine{9399      \textcolor{comment}{/* Integer */} ae\_vector* idx,}
\DoxyCodeLine{9400      ae\_int\_t subsetsize,}
\DoxyCodeLine{9401      \textcolor{keywordtype}{double}* e,}
\DoxyCodeLine{9402      \textcolor{comment}{/* Real    */} ae\_vector* grad,}
\DoxyCodeLine{9403      ae\_state *\_state);}
\DoxyCodeLine{9404 \textcolor{keywordtype}{void} mlpgradbatchsparsesubset(multilayerperceptron* network,}
\DoxyCodeLine{9405      sparsematrix* xy,}
\DoxyCodeLine{9406      ae\_int\_t setsize,}
\DoxyCodeLine{9407      \textcolor{comment}{/* Integer */} ae\_vector* idx,}
\DoxyCodeLine{9408      ae\_int\_t subsetsize,}
\DoxyCodeLine{9409      \textcolor{keywordtype}{double}* e,}
\DoxyCodeLine{9410      \textcolor{comment}{/* Real    */} ae\_vector* grad,}
\DoxyCodeLine{9411      ae\_state *\_state);}
\DoxyCodeLine{9412 \textcolor{keywordtype}{void} mlpgradbatchx(multilayerperceptron* network,}
\DoxyCodeLine{9413      \textcolor{comment}{/* Real    */} ae\_matrix* densexy,}
\DoxyCodeLine{9414      sparsematrix* sparsexy,}
\DoxyCodeLine{9415      ae\_int\_t datasetsize,}
\DoxyCodeLine{9416      ae\_int\_t datasettype,}
\DoxyCodeLine{9417      \textcolor{comment}{/* Integer */} ae\_vector* idx,}
\DoxyCodeLine{9418      ae\_int\_t subset0,}
\DoxyCodeLine{9419      ae\_int\_t subset1,}
\DoxyCodeLine{9420      ae\_int\_t subsettype,}
\DoxyCodeLine{9421      ae\_shared\_pool* buf,}
\DoxyCodeLine{9422      ae\_shared\_pool* gradbuf,}
\DoxyCodeLine{9423      ae\_state *\_state);}
\DoxyCodeLine{9424 ae\_bool \_trypexec\_mlpgradbatchx(multilayerperceptron* network,}
\DoxyCodeLine{9425     \textcolor{comment}{/* Real    */} ae\_matrix* densexy,}
\DoxyCodeLine{9426     sparsematrix* sparsexy,}
\DoxyCodeLine{9427     ae\_int\_t datasetsize,}
\DoxyCodeLine{9428     ae\_int\_t datasettype,}
\DoxyCodeLine{9429     \textcolor{comment}{/* Integer */} ae\_vector* idx,}
\DoxyCodeLine{9430     ae\_int\_t subset0,}
\DoxyCodeLine{9431     ae\_int\_t subset1,}
\DoxyCodeLine{9432     ae\_int\_t subsettype,}
\DoxyCodeLine{9433     ae\_shared\_pool* buf,}
\DoxyCodeLine{9434     ae\_shared\_pool* gradbuf, ae\_state *\_state);}
\DoxyCodeLine{9435 \textcolor{keywordtype}{void} mlpgradnbatch(multilayerperceptron* network,}
\DoxyCodeLine{9436      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9437      ae\_int\_t ssize,}
\DoxyCodeLine{9438      \textcolor{keywordtype}{double}* e,}
\DoxyCodeLine{9439      \textcolor{comment}{/* Real    */} ae\_vector* grad,}
\DoxyCodeLine{9440      ae\_state *\_state);}
\DoxyCodeLine{9441 \textcolor{keywordtype}{void} mlphessiannbatch(multilayerperceptron* network,}
\DoxyCodeLine{9442      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9443      ae\_int\_t ssize,}
\DoxyCodeLine{9444      \textcolor{keywordtype}{double}* e,}
\DoxyCodeLine{9445      \textcolor{comment}{/* Real    */} ae\_vector* grad,}
\DoxyCodeLine{9446      \textcolor{comment}{/* Real    */} ae\_matrix* h,}
\DoxyCodeLine{9447      ae\_state *\_state);}
\DoxyCodeLine{9448 \textcolor{keywordtype}{void} mlphessianbatch(multilayerperceptron* network,}
\DoxyCodeLine{9449      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9450      ae\_int\_t ssize,}
\DoxyCodeLine{9451      \textcolor{keywordtype}{double}* e,}
\DoxyCodeLine{9452      \textcolor{comment}{/* Real    */} ae\_vector* grad,}
\DoxyCodeLine{9453      \textcolor{comment}{/* Real    */} ae\_matrix* h,}
\DoxyCodeLine{9454      ae\_state *\_state);}
\DoxyCodeLine{9455 \textcolor{keywordtype}{void} mlpinternalprocessvector(\textcolor{comment}{/* Integer */} ae\_vector* structinfo,}
\DoxyCodeLine{9456      \textcolor{comment}{/* Real    */} ae\_vector* weights,}
\DoxyCodeLine{9457      \textcolor{comment}{/* Real    */} ae\_vector* columnmeans,}
\DoxyCodeLine{9458      \textcolor{comment}{/* Real    */} ae\_vector* columnsigmas,}
\DoxyCodeLine{9459      \textcolor{comment}{/* Real    */} ae\_vector* neurons,}
\DoxyCodeLine{9460      \textcolor{comment}{/* Real    */} ae\_vector* dfdnet,}
\DoxyCodeLine{9461      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{9462      \textcolor{comment}{/* Real    */} ae\_vector* y,}
\DoxyCodeLine{9463      ae\_state *\_state);}
\DoxyCodeLine{9464 \textcolor{keywordtype}{void} mlpalloc(ae\_serializer* s,}
\DoxyCodeLine{9465      multilayerperceptron* network,}
\DoxyCodeLine{9466      ae\_state *\_state);}
\DoxyCodeLine{9467 \textcolor{keywordtype}{void} mlpserialize(ae\_serializer* s,}
\DoxyCodeLine{9468      multilayerperceptron* network,}
\DoxyCodeLine{9469      ae\_state *\_state);}
\DoxyCodeLine{9470 \textcolor{keywordtype}{void} mlpunserialize(ae\_serializer* s,}
\DoxyCodeLine{9471      multilayerperceptron* network,}
\DoxyCodeLine{9472      ae\_state *\_state);}
\DoxyCodeLine{9473 \textcolor{keywordtype}{void} mlpallerrorssubset(multilayerperceptron* network,}
\DoxyCodeLine{9474      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9475      ae\_int\_t setsize,}
\DoxyCodeLine{9476      \textcolor{comment}{/* Integer */} ae\_vector* subset,}
\DoxyCodeLine{9477      ae\_int\_t subsetsize,}
\DoxyCodeLine{9478      modelerrors* rep,}
\DoxyCodeLine{9479      ae\_state *\_state);}
\DoxyCodeLine{9480 \textcolor{keywordtype}{void} mlpallerrorssparsesubset(multilayerperceptron* network,}
\DoxyCodeLine{9481      sparsematrix* xy,}
\DoxyCodeLine{9482      ae\_int\_t setsize,}
\DoxyCodeLine{9483      \textcolor{comment}{/* Integer */} ae\_vector* subset,}
\DoxyCodeLine{9484      ae\_int\_t subsetsize,}
\DoxyCodeLine{9485      modelerrors* rep,}
\DoxyCodeLine{9486      ae\_state *\_state);}
\DoxyCodeLine{9487 \textcolor{keywordtype}{double} mlperrorsubset(multilayerperceptron* network,}
\DoxyCodeLine{9488      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9489      ae\_int\_t setsize,}
\DoxyCodeLine{9490      \textcolor{comment}{/* Integer */} ae\_vector* subset,}
\DoxyCodeLine{9491      ae\_int\_t subsetsize,}
\DoxyCodeLine{9492      ae\_state *\_state);}
\DoxyCodeLine{9493 \textcolor{keywordtype}{double} mlperrorsparsesubset(multilayerperceptron* network,}
\DoxyCodeLine{9494      sparsematrix* xy,}
\DoxyCodeLine{9495      ae\_int\_t setsize,}
\DoxyCodeLine{9496      \textcolor{comment}{/* Integer */} ae\_vector* subset,}
\DoxyCodeLine{9497      ae\_int\_t subsetsize,}
\DoxyCodeLine{9498      ae\_state *\_state);}
\DoxyCodeLine{9499 \textcolor{keywordtype}{void} mlpallerrorsx(multilayerperceptron* network,}
\DoxyCodeLine{9500      \textcolor{comment}{/* Real    */} ae\_matrix* densexy,}
\DoxyCodeLine{9501      sparsematrix* sparsexy,}
\DoxyCodeLine{9502      ae\_int\_t datasetsize,}
\DoxyCodeLine{9503      ae\_int\_t datasettype,}
\DoxyCodeLine{9504      \textcolor{comment}{/* Integer */} ae\_vector* idx,}
\DoxyCodeLine{9505      ae\_int\_t subset0,}
\DoxyCodeLine{9506      ae\_int\_t subset1,}
\DoxyCodeLine{9507      ae\_int\_t subsettype,}
\DoxyCodeLine{9508      ae\_shared\_pool* buf,}
\DoxyCodeLine{9509      modelerrors* rep,}
\DoxyCodeLine{9510      ae\_state *\_state);}
\DoxyCodeLine{9511 ae\_bool \_trypexec\_mlpallerrorsx(multilayerperceptron* network,}
\DoxyCodeLine{9512     \textcolor{comment}{/* Real    */} ae\_matrix* densexy,}
\DoxyCodeLine{9513     sparsematrix* sparsexy,}
\DoxyCodeLine{9514     ae\_int\_t datasetsize,}
\DoxyCodeLine{9515     ae\_int\_t datasettype,}
\DoxyCodeLine{9516     \textcolor{comment}{/* Integer */} ae\_vector* idx,}
\DoxyCodeLine{9517     ae\_int\_t subset0,}
\DoxyCodeLine{9518     ae\_int\_t subset1,}
\DoxyCodeLine{9519     ae\_int\_t subsettype,}
\DoxyCodeLine{9520     ae\_shared\_pool* buf,}
\DoxyCodeLine{9521     modelerrors* rep, ae\_state *\_state);}
\DoxyCodeLine{9522 \textcolor{keywordtype}{void} \_modelerrors\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9523 \textcolor{keywordtype}{void} \_modelerrors\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9524 \textcolor{keywordtype}{void} \_modelerrors\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9525 \textcolor{keywordtype}{void} \_modelerrors\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9526 \textcolor{keywordtype}{void} \_smlpgrad\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9527 \textcolor{keywordtype}{void} \_smlpgrad\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9528 \textcolor{keywordtype}{void} \_smlpgrad\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9529 \textcolor{keywordtype}{void} \_smlpgrad\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9530 \textcolor{keywordtype}{void} \_multilayerperceptron\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9531 \textcolor{keywordtype}{void} \_multilayerperceptron\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9532 \textcolor{keywordtype}{void} \_multilayerperceptron\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9533 \textcolor{keywordtype}{void} \_multilayerperceptron\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9534 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{9535 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_MLPE) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{9536 \textcolor{keywordtype}{void} mlpecreate0(ae\_int\_t nin,}
\DoxyCodeLine{9537      ae\_int\_t nout,}
\DoxyCodeLine{9538      ae\_int\_t ensemblesize,}
\DoxyCodeLine{9539      mlpensemble* ensemble,}
\DoxyCodeLine{9540      ae\_state *\_state);}
\DoxyCodeLine{9541 \textcolor{keywordtype}{void} mlpecreate1(ae\_int\_t nin,}
\DoxyCodeLine{9542      ae\_int\_t nhid,}
\DoxyCodeLine{9543      ae\_int\_t nout,}
\DoxyCodeLine{9544      ae\_int\_t ensemblesize,}
\DoxyCodeLine{9545      mlpensemble* ensemble,}
\DoxyCodeLine{9546      ae\_state *\_state);}
\DoxyCodeLine{9547 \textcolor{keywordtype}{void} mlpecreate2(ae\_int\_t nin,}
\DoxyCodeLine{9548      ae\_int\_t nhid1,}
\DoxyCodeLine{9549      ae\_int\_t nhid2,}
\DoxyCodeLine{9550      ae\_int\_t nout,}
\DoxyCodeLine{9551      ae\_int\_t ensemblesize,}
\DoxyCodeLine{9552      mlpensemble* ensemble,}
\DoxyCodeLine{9553      ae\_state *\_state);}
\DoxyCodeLine{9554 \textcolor{keywordtype}{void} mlpecreateb0(ae\_int\_t nin,}
\DoxyCodeLine{9555      ae\_int\_t nout,}
\DoxyCodeLine{9556      \textcolor{keywordtype}{double} b,}
\DoxyCodeLine{9557      \textcolor{keywordtype}{double} d,}
\DoxyCodeLine{9558      ae\_int\_t ensemblesize,}
\DoxyCodeLine{9559      mlpensemble* ensemble,}
\DoxyCodeLine{9560      ae\_state *\_state);}
\DoxyCodeLine{9561 \textcolor{keywordtype}{void} mlpecreateb1(ae\_int\_t nin,}
\DoxyCodeLine{9562      ae\_int\_t nhid,}
\DoxyCodeLine{9563      ae\_int\_t nout,}
\DoxyCodeLine{9564      \textcolor{keywordtype}{double} b,}
\DoxyCodeLine{9565      \textcolor{keywordtype}{double} d,}
\DoxyCodeLine{9566      ae\_int\_t ensemblesize,}
\DoxyCodeLine{9567      mlpensemble* ensemble,}
\DoxyCodeLine{9568      ae\_state *\_state);}
\DoxyCodeLine{9569 \textcolor{keywordtype}{void} mlpecreateb2(ae\_int\_t nin,}
\DoxyCodeLine{9570      ae\_int\_t nhid1,}
\DoxyCodeLine{9571      ae\_int\_t nhid2,}
\DoxyCodeLine{9572      ae\_int\_t nout,}
\DoxyCodeLine{9573      \textcolor{keywordtype}{double} b,}
\DoxyCodeLine{9574      \textcolor{keywordtype}{double} d,}
\DoxyCodeLine{9575      ae\_int\_t ensemblesize,}
\DoxyCodeLine{9576      mlpensemble* ensemble,}
\DoxyCodeLine{9577      ae\_state *\_state);}
\DoxyCodeLine{9578 \textcolor{keywordtype}{void} mlpecreater0(ae\_int\_t nin,}
\DoxyCodeLine{9579      ae\_int\_t nout,}
\DoxyCodeLine{9580      \textcolor{keywordtype}{double} a,}
\DoxyCodeLine{9581      \textcolor{keywordtype}{double} b,}
\DoxyCodeLine{9582      ae\_int\_t ensemblesize,}
\DoxyCodeLine{9583      mlpensemble* ensemble,}
\DoxyCodeLine{9584      ae\_state *\_state);}
\DoxyCodeLine{9585 \textcolor{keywordtype}{void} mlpecreater1(ae\_int\_t nin,}
\DoxyCodeLine{9586      ae\_int\_t nhid,}
\DoxyCodeLine{9587      ae\_int\_t nout,}
\DoxyCodeLine{9588      \textcolor{keywordtype}{double} a,}
\DoxyCodeLine{9589      \textcolor{keywordtype}{double} b,}
\DoxyCodeLine{9590      ae\_int\_t ensemblesize,}
\DoxyCodeLine{9591      mlpensemble* ensemble,}
\DoxyCodeLine{9592      ae\_state *\_state);}
\DoxyCodeLine{9593 \textcolor{keywordtype}{void} mlpecreater2(ae\_int\_t nin,}
\DoxyCodeLine{9594      ae\_int\_t nhid1,}
\DoxyCodeLine{9595      ae\_int\_t nhid2,}
\DoxyCodeLine{9596      ae\_int\_t nout,}
\DoxyCodeLine{9597      \textcolor{keywordtype}{double} a,}
\DoxyCodeLine{9598      \textcolor{keywordtype}{double} b,}
\DoxyCodeLine{9599      ae\_int\_t ensemblesize,}
\DoxyCodeLine{9600      mlpensemble* ensemble,}
\DoxyCodeLine{9601      ae\_state *\_state);}
\DoxyCodeLine{9602 \textcolor{keywordtype}{void} mlpecreatec0(ae\_int\_t nin,}
\DoxyCodeLine{9603      ae\_int\_t nout,}
\DoxyCodeLine{9604      ae\_int\_t ensemblesize,}
\DoxyCodeLine{9605      mlpensemble* ensemble,}
\DoxyCodeLine{9606      ae\_state *\_state);}
\DoxyCodeLine{9607 \textcolor{keywordtype}{void} mlpecreatec1(ae\_int\_t nin,}
\DoxyCodeLine{9608      ae\_int\_t nhid,}
\DoxyCodeLine{9609      ae\_int\_t nout,}
\DoxyCodeLine{9610      ae\_int\_t ensemblesize,}
\DoxyCodeLine{9611      mlpensemble* ensemble,}
\DoxyCodeLine{9612      ae\_state *\_state);}
\DoxyCodeLine{9613 \textcolor{keywordtype}{void} mlpecreatec2(ae\_int\_t nin,}
\DoxyCodeLine{9614      ae\_int\_t nhid1,}
\DoxyCodeLine{9615      ae\_int\_t nhid2,}
\DoxyCodeLine{9616      ae\_int\_t nout,}
\DoxyCodeLine{9617      ae\_int\_t ensemblesize,}
\DoxyCodeLine{9618      mlpensemble* ensemble,}
\DoxyCodeLine{9619      ae\_state *\_state);}
\DoxyCodeLine{9620 \textcolor{keywordtype}{void} mlpecreatefromnetwork(multilayerperceptron* network,}
\DoxyCodeLine{9621      ae\_int\_t ensemblesize,}
\DoxyCodeLine{9622      mlpensemble* ensemble,}
\DoxyCodeLine{9623      ae\_state *\_state);}
\DoxyCodeLine{9624 \textcolor{keywordtype}{void} mlpecopy(mlpensemble* ensemble1,}
\DoxyCodeLine{9625      mlpensemble* ensemble2,}
\DoxyCodeLine{9626      ae\_state *\_state);}
\DoxyCodeLine{9627 \textcolor{keywordtype}{void} mlperandomize(mlpensemble* ensemble, ae\_state *\_state);}
\DoxyCodeLine{9628 \textcolor{keywordtype}{void} mlpeproperties(mlpensemble* ensemble,}
\DoxyCodeLine{9629      ae\_int\_t* nin,}
\DoxyCodeLine{9630      ae\_int\_t* nout,}
\DoxyCodeLine{9631      ae\_state *\_state);}
\DoxyCodeLine{9632 ae\_bool mlpeissoftmax(mlpensemble* ensemble, ae\_state *\_state);}
\DoxyCodeLine{9633 \textcolor{keywordtype}{void} mlpeprocess(mlpensemble* ensemble,}
\DoxyCodeLine{9634      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{9635      \textcolor{comment}{/* Real    */} ae\_vector* y,}
\DoxyCodeLine{9636      ae\_state *\_state);}
\DoxyCodeLine{9637 \textcolor{keywordtype}{void} mlpeprocessi(mlpensemble* ensemble,}
\DoxyCodeLine{9638      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{9639      \textcolor{comment}{/* Real    */} ae\_vector* y,}
\DoxyCodeLine{9640      ae\_state *\_state);}
\DoxyCodeLine{9641 \textcolor{keywordtype}{void} mlpeallerrorsx(mlpensemble* ensemble,}
\DoxyCodeLine{9642      \textcolor{comment}{/* Real    */} ae\_matrix* densexy,}
\DoxyCodeLine{9643      sparsematrix* sparsexy,}
\DoxyCodeLine{9644      ae\_int\_t datasetsize,}
\DoxyCodeLine{9645      ae\_int\_t datasettype,}
\DoxyCodeLine{9646      \textcolor{comment}{/* Integer */} ae\_vector* idx,}
\DoxyCodeLine{9647      ae\_int\_t subset0,}
\DoxyCodeLine{9648      ae\_int\_t subset1,}
\DoxyCodeLine{9649      ae\_int\_t subsettype,}
\DoxyCodeLine{9650      ae\_shared\_pool* buf,}
\DoxyCodeLine{9651      modelerrors* rep,}
\DoxyCodeLine{9652      ae\_state *\_state);}
\DoxyCodeLine{9653 \textcolor{keywordtype}{void} mlpeallerrorssparse(mlpensemble* ensemble,}
\DoxyCodeLine{9654      sparsematrix* xy,}
\DoxyCodeLine{9655      ae\_int\_t npoints,}
\DoxyCodeLine{9656      \textcolor{keywordtype}{double}* relcls,}
\DoxyCodeLine{9657      \textcolor{keywordtype}{double}* avgce,}
\DoxyCodeLine{9658      \textcolor{keywordtype}{double}* rms,}
\DoxyCodeLine{9659      \textcolor{keywordtype}{double}* avg,}
\DoxyCodeLine{9660      \textcolor{keywordtype}{double}* avgrel,}
\DoxyCodeLine{9661      ae\_state *\_state);}
\DoxyCodeLine{9662 \textcolor{keywordtype}{double} mlperelclserror(mlpensemble* ensemble,}
\DoxyCodeLine{9663      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9664      ae\_int\_t npoints,}
\DoxyCodeLine{9665      ae\_state *\_state);}
\DoxyCodeLine{9666 \textcolor{keywordtype}{double} mlpeavgce(mlpensemble* ensemble,}
\DoxyCodeLine{9667      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9668      ae\_int\_t npoints,}
\DoxyCodeLine{9669      ae\_state *\_state);}
\DoxyCodeLine{9670 \textcolor{keywordtype}{double} mlpermserror(mlpensemble* ensemble,}
\DoxyCodeLine{9671      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9672      ae\_int\_t npoints,}
\DoxyCodeLine{9673      ae\_state *\_state);}
\DoxyCodeLine{9674 \textcolor{keywordtype}{double} mlpeavgerror(mlpensemble* ensemble,}
\DoxyCodeLine{9675      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9676      ae\_int\_t npoints,}
\DoxyCodeLine{9677      ae\_state *\_state);}
\DoxyCodeLine{9678 \textcolor{keywordtype}{double} mlpeavgrelerror(mlpensemble* ensemble,}
\DoxyCodeLine{9679      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9680      ae\_int\_t npoints,}
\DoxyCodeLine{9681      ae\_state *\_state);}
\DoxyCodeLine{9682 \textcolor{keywordtype}{void} mlpealloc(ae\_serializer* s, mlpensemble* ensemble, ae\_state *\_state);}
\DoxyCodeLine{9683 \textcolor{keywordtype}{void} mlpeserialize(ae\_serializer* s,}
\DoxyCodeLine{9684      mlpensemble* ensemble,}
\DoxyCodeLine{9685      ae\_state *\_state);}
\DoxyCodeLine{9686 \textcolor{keywordtype}{void} mlpeunserialize(ae\_serializer* s,}
\DoxyCodeLine{9687      mlpensemble* ensemble,}
\DoxyCodeLine{9688      ae\_state *\_state);}
\DoxyCodeLine{9689 \textcolor{keywordtype}{void} \_mlpensemble\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9690 \textcolor{keywordtype}{void} \_mlpensemble\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9691 \textcolor{keywordtype}{void} \_mlpensemble\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9692 \textcolor{keywordtype}{void} \_mlpensemble\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9693 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{9694 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_CLUSTERING) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{9695 \textcolor{keywordtype}{void} clusterizercreate(clusterizerstate* s, ae\_state *\_state);}
\DoxyCodeLine{9696 \textcolor{keywordtype}{void} clusterizersetpoints(clusterizerstate* s,}
\DoxyCodeLine{9697      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9698      ae\_int\_t npoints,}
\DoxyCodeLine{9699      ae\_int\_t nfeatures,}
\DoxyCodeLine{9700      ae\_int\_t disttype,}
\DoxyCodeLine{9701      ae\_state *\_state);}
\DoxyCodeLine{9702 \textcolor{keywordtype}{void} clusterizersetdistances(clusterizerstate* s,}
\DoxyCodeLine{9703      \textcolor{comment}{/* Real    */} ae\_matrix* d,}
\DoxyCodeLine{9704      ae\_int\_t npoints,}
\DoxyCodeLine{9705      ae\_bool isupper,}
\DoxyCodeLine{9706      ae\_state *\_state);}
\DoxyCodeLine{9707 \textcolor{keywordtype}{void} clusterizersetahcalgo(clusterizerstate* s,}
\DoxyCodeLine{9708      ae\_int\_t algo,}
\DoxyCodeLine{9709      ae\_state *\_state);}
\DoxyCodeLine{9710 \textcolor{keywordtype}{void} clusterizersetkmeanslimits(clusterizerstate* s,}
\DoxyCodeLine{9711      ae\_int\_t restarts,}
\DoxyCodeLine{9712      ae\_int\_t maxits,}
\DoxyCodeLine{9713      ae\_state *\_state);}
\DoxyCodeLine{9714 \textcolor{keywordtype}{void} clusterizersetkmeansinit(clusterizerstate* s,}
\DoxyCodeLine{9715      ae\_int\_t initalgo,}
\DoxyCodeLine{9716      ae\_state *\_state);}
\DoxyCodeLine{9717 \textcolor{keywordtype}{void} clusterizersetseed(clusterizerstate* s,}
\DoxyCodeLine{9718      ae\_int\_t seed,}
\DoxyCodeLine{9719      ae\_state *\_state);}
\DoxyCodeLine{9720 \textcolor{keywordtype}{void} clusterizerrunahc(clusterizerstate* s,}
\DoxyCodeLine{9721      ahcreport* rep,}
\DoxyCodeLine{9722      ae\_state *\_state);}
\DoxyCodeLine{9723 \textcolor{keywordtype}{void} clusterizerrunkmeans(clusterizerstate* s,}
\DoxyCodeLine{9724      ae\_int\_t k,}
\DoxyCodeLine{9725      kmeansreport* rep,}
\DoxyCodeLine{9726      ae\_state *\_state);}
\DoxyCodeLine{9727 \textcolor{keywordtype}{void} clusterizergetdistances(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9728      ae\_int\_t npoints,}
\DoxyCodeLine{9729      ae\_int\_t nfeatures,}
\DoxyCodeLine{9730      ae\_int\_t disttype,}
\DoxyCodeLine{9731      \textcolor{comment}{/* Real    */} ae\_matrix* d,}
\DoxyCodeLine{9732      ae\_state *\_state);}
\DoxyCodeLine{9733 \textcolor{keywordtype}{void} clusterizergetdistancesbuf(apbuffers* buf,}
\DoxyCodeLine{9734      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9735      ae\_int\_t npoints,}
\DoxyCodeLine{9736      ae\_int\_t nfeatures,}
\DoxyCodeLine{9737      ae\_int\_t disttype,}
\DoxyCodeLine{9738      \textcolor{comment}{/* Real    */} ae\_matrix* d,}
\DoxyCodeLine{9739      ae\_state *\_state);}
\DoxyCodeLine{9740 \textcolor{keywordtype}{void} clusterizergetkclusters(ahcreport* rep,}
\DoxyCodeLine{9741      ae\_int\_t k,}
\DoxyCodeLine{9742      \textcolor{comment}{/* Integer */} ae\_vector* cidx,}
\DoxyCodeLine{9743      \textcolor{comment}{/* Integer */} ae\_vector* cz,}
\DoxyCodeLine{9744      ae\_state *\_state);}
\DoxyCodeLine{9745 \textcolor{keywordtype}{void} clusterizerseparatedbydist(ahcreport* rep,}
\DoxyCodeLine{9746      \textcolor{keywordtype}{double} r,}
\DoxyCodeLine{9747      ae\_int\_t* k,}
\DoxyCodeLine{9748      \textcolor{comment}{/* Integer */} ae\_vector* cidx,}
\DoxyCodeLine{9749      \textcolor{comment}{/* Integer */} ae\_vector* cz,}
\DoxyCodeLine{9750      ae\_state *\_state);}
\DoxyCodeLine{9751 \textcolor{keywordtype}{void} clusterizerseparatedbycorr(ahcreport* rep,}
\DoxyCodeLine{9752      \textcolor{keywordtype}{double} r,}
\DoxyCodeLine{9753      ae\_int\_t* k,}
\DoxyCodeLine{9754      \textcolor{comment}{/* Integer */} ae\_vector* cidx,}
\DoxyCodeLine{9755      \textcolor{comment}{/* Integer */} ae\_vector* cz,}
\DoxyCodeLine{9756      ae\_state *\_state);}
\DoxyCodeLine{9757 \textcolor{keywordtype}{void} kmeansinitbuf(kmeansbuffers* buf, ae\_state *\_state);}
\DoxyCodeLine{9758 \textcolor{keywordtype}{void} kmeansgenerateinternal(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9759      ae\_int\_t npoints,}
\DoxyCodeLine{9760      ae\_int\_t nvars,}
\DoxyCodeLine{9761      ae\_int\_t k,}
\DoxyCodeLine{9762      ae\_int\_t initalgo,}
\DoxyCodeLine{9763      ae\_int\_t seed,}
\DoxyCodeLine{9764      ae\_int\_t maxits,}
\DoxyCodeLine{9765      ae\_int\_t restarts,}
\DoxyCodeLine{9766      ae\_bool kmeansdbgnoits,}
\DoxyCodeLine{9767      ae\_int\_t* info,}
\DoxyCodeLine{9768      ae\_int\_t* iterationscount,}
\DoxyCodeLine{9769      \textcolor{comment}{/* Real    */} ae\_matrix* ccol,}
\DoxyCodeLine{9770      ae\_bool needccol,}
\DoxyCodeLine{9771      \textcolor{comment}{/* Real    */} ae\_matrix* crow,}
\DoxyCodeLine{9772      ae\_bool needcrow,}
\DoxyCodeLine{9773      \textcolor{comment}{/* Integer */} ae\_vector* xyc,}
\DoxyCodeLine{9774      \textcolor{keywordtype}{double}* energy,}
\DoxyCodeLine{9775      kmeansbuffers* buf,}
\DoxyCodeLine{9776      ae\_state *\_state);}
\DoxyCodeLine{9777 \textcolor{keywordtype}{void} kmeansupdatedistances(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9778      ae\_int\_t idx0,}
\DoxyCodeLine{9779      ae\_int\_t idx1,}
\DoxyCodeLine{9780      ae\_int\_t nvars,}
\DoxyCodeLine{9781      \textcolor{comment}{/* Real    */} ae\_matrix* ct,}
\DoxyCodeLine{9782      ae\_int\_t cidx0,}
\DoxyCodeLine{9783      ae\_int\_t cidx1,}
\DoxyCodeLine{9784      \textcolor{comment}{/* Integer */} ae\_vector* xyc,}
\DoxyCodeLine{9785      \textcolor{comment}{/* Real    */} ae\_vector* xydist2,}
\DoxyCodeLine{9786      ae\_shared\_pool* bufferpool,}
\DoxyCodeLine{9787      ae\_state *\_state);}
\DoxyCodeLine{9788 ae\_bool \_trypexec\_kmeansupdatedistances(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9789     ae\_int\_t idx0,}
\DoxyCodeLine{9790     ae\_int\_t idx1,}
\DoxyCodeLine{9791     ae\_int\_t nvars,}
\DoxyCodeLine{9792     \textcolor{comment}{/* Real    */} ae\_matrix* ct,}
\DoxyCodeLine{9793     ae\_int\_t cidx0,}
\DoxyCodeLine{9794     ae\_int\_t cidx1,}
\DoxyCodeLine{9795     \textcolor{comment}{/* Integer */} ae\_vector* xyc,}
\DoxyCodeLine{9796     \textcolor{comment}{/* Real    */} ae\_vector* xydist2,}
\DoxyCodeLine{9797     ae\_shared\_pool* bufferpool, ae\_state *\_state);}
\DoxyCodeLine{9798 \textcolor{keywordtype}{void} \_kmeansbuffers\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9799 \textcolor{keywordtype}{void} \_kmeansbuffers\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9800 \textcolor{keywordtype}{void} \_kmeansbuffers\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9801 \textcolor{keywordtype}{void} \_kmeansbuffers\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9802 \textcolor{keywordtype}{void} \_clusterizerstate\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9803 \textcolor{keywordtype}{void} \_clusterizerstate\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9804 \textcolor{keywordtype}{void} \_clusterizerstate\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9805 \textcolor{keywordtype}{void} \_clusterizerstate\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9806 \textcolor{keywordtype}{void} \_ahcreport\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9807 \textcolor{keywordtype}{void} \_ahcreport\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9808 \textcolor{keywordtype}{void} \_ahcreport\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9809 \textcolor{keywordtype}{void} \_ahcreport\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9810 \textcolor{keywordtype}{void} \_kmeansreport\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9811 \textcolor{keywordtype}{void} \_kmeansreport\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9812 \textcolor{keywordtype}{void} \_kmeansreport\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9813 \textcolor{keywordtype}{void} \_kmeansreport\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9814 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{9815 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_DFOREST) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{9816 \textcolor{keywordtype}{void} dfcreatebuffer(decisionforest* model,}
\DoxyCodeLine{9817      decisionforestbuffer* buf,}
\DoxyCodeLine{9818      ae\_state *\_state);}
\DoxyCodeLine{9819 \textcolor{keywordtype}{void} dfbuildercreate(decisionforestbuilder* s, ae\_state *\_state);}
\DoxyCodeLine{9820 \textcolor{keywordtype}{void} dfbuildersetdataset(decisionforestbuilder* s,}
\DoxyCodeLine{9821      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9822      ae\_int\_t npoints,}
\DoxyCodeLine{9823      ae\_int\_t nvars,}
\DoxyCodeLine{9824      ae\_int\_t nclasses,}
\DoxyCodeLine{9825      ae\_state *\_state);}
\DoxyCodeLine{9826 \textcolor{keywordtype}{void} dfbuildersetrndvars(decisionforestbuilder* s,}
\DoxyCodeLine{9827      ae\_int\_t rndvars,}
\DoxyCodeLine{9828      ae\_state *\_state);}
\DoxyCodeLine{9829 \textcolor{keywordtype}{void} dfbuildersetrndvarsratio(decisionforestbuilder* s,}
\DoxyCodeLine{9830      \textcolor{keywordtype}{double} f,}
\DoxyCodeLine{9831      ae\_state *\_state);}
\DoxyCodeLine{9832 \textcolor{keywordtype}{void} dfbuildersetrndvarsauto(decisionforestbuilder* s, ae\_state *\_state);}
\DoxyCodeLine{9833 \textcolor{keywordtype}{void} dfbuildersetsubsampleratio(decisionforestbuilder* s,}
\DoxyCodeLine{9834      \textcolor{keywordtype}{double} f,}
\DoxyCodeLine{9835      ae\_state *\_state);}
\DoxyCodeLine{9836 \textcolor{keywordtype}{void} dfbuildersetseed(decisionforestbuilder* s,}
\DoxyCodeLine{9837      ae\_int\_t seedval,}
\DoxyCodeLine{9838      ae\_state *\_state);}
\DoxyCodeLine{9839 \textcolor{keywordtype}{void} dfbuildersetrdfalgo(decisionforestbuilder* s,}
\DoxyCodeLine{9840      ae\_int\_t algotype,}
\DoxyCodeLine{9841      ae\_state *\_state);}
\DoxyCodeLine{9842 \textcolor{keywordtype}{void} dfbuildersetrdfsplitstrength(decisionforestbuilder* s,}
\DoxyCodeLine{9843      ae\_int\_t splitstrength,}
\DoxyCodeLine{9844      ae\_state *\_state);}
\DoxyCodeLine{9845 \textcolor{keywordtype}{void} dfbuildersetimportancetrngini(decisionforestbuilder* s,}
\DoxyCodeLine{9846      ae\_state *\_state);}
\DoxyCodeLine{9847 \textcolor{keywordtype}{void} dfbuildersetimportanceoobgini(decisionforestbuilder* s,}
\DoxyCodeLine{9848      ae\_state *\_state);}
\DoxyCodeLine{9849 \textcolor{keywordtype}{void} dfbuildersetimportancepermutation(decisionforestbuilder* s,}
\DoxyCodeLine{9850      ae\_state *\_state);}
\DoxyCodeLine{9851 \textcolor{keywordtype}{void} dfbuildersetimportancenone(decisionforestbuilder* s,}
\DoxyCodeLine{9852      ae\_state *\_state);}
\DoxyCodeLine{9853 \textcolor{keywordtype}{double} dfbuildergetprogress(decisionforestbuilder* s, ae\_state *\_state);}
\DoxyCodeLine{9854 \textcolor{keywordtype}{double} dfbuilderpeekprogress(decisionforestbuilder* s, ae\_state *\_state);}
\DoxyCodeLine{9855 \textcolor{keywordtype}{void} dfbuilderbuildrandomforest(decisionforestbuilder* s,}
\DoxyCodeLine{9856      ae\_int\_t ntrees,}
\DoxyCodeLine{9857      decisionforest* df,}
\DoxyCodeLine{9858      dfreport* rep,}
\DoxyCodeLine{9859      ae\_state *\_state);}
\DoxyCodeLine{9860 \textcolor{keywordtype}{double} dfbinarycompression(decisionforest* df, ae\_state *\_state);}
\DoxyCodeLine{9861 \textcolor{keywordtype}{double} dfbinarycompression8(decisionforest* df, ae\_state *\_state);}
\DoxyCodeLine{9862 \textcolor{keywordtype}{void} dfprocess(decisionforest* df,}
\DoxyCodeLine{9863      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{9864      \textcolor{comment}{/* Real    */} ae\_vector* y,}
\DoxyCodeLine{9865      ae\_state *\_state);}
\DoxyCodeLine{9866 \textcolor{keywordtype}{void} dfprocessi(decisionforest* df,}
\DoxyCodeLine{9867      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{9868      \textcolor{comment}{/* Real    */} ae\_vector* y,}
\DoxyCodeLine{9869      ae\_state *\_state);}
\DoxyCodeLine{9870 \textcolor{keywordtype}{double} dfprocess0(decisionforest* model,}
\DoxyCodeLine{9871      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{9872      ae\_state *\_state);}
\DoxyCodeLine{9873 ae\_int\_t dfclassify(decisionforest* model,}
\DoxyCodeLine{9874      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{9875      ae\_state *\_state);}
\DoxyCodeLine{9876 \textcolor{keywordtype}{void} dftsprocess(decisionforest* df,}
\DoxyCodeLine{9877      decisionforestbuffer* buf,}
\DoxyCodeLine{9878      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{9879      \textcolor{comment}{/* Real    */} ae\_vector* y,}
\DoxyCodeLine{9880      ae\_state *\_state);}
\DoxyCodeLine{9881 \textcolor{keywordtype}{double} dfrelclserror(decisionforest* df,}
\DoxyCodeLine{9882      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9883      ae\_int\_t npoints,}
\DoxyCodeLine{9884      ae\_state *\_state);}
\DoxyCodeLine{9885 \textcolor{keywordtype}{double} dfavgce(decisionforest* df,}
\DoxyCodeLine{9886      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9887      ae\_int\_t npoints,}
\DoxyCodeLine{9888      ae\_state *\_state);}
\DoxyCodeLine{9889 \textcolor{keywordtype}{double} dfrmserror(decisionforest* df,}
\DoxyCodeLine{9890      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9891      ae\_int\_t npoints,}
\DoxyCodeLine{9892      ae\_state *\_state);}
\DoxyCodeLine{9893 \textcolor{keywordtype}{double} dfavgerror(decisionforest* df,}
\DoxyCodeLine{9894      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9895      ae\_int\_t npoints,}
\DoxyCodeLine{9896      ae\_state *\_state);}
\DoxyCodeLine{9897 \textcolor{keywordtype}{double} dfavgrelerror(decisionforest* df,}
\DoxyCodeLine{9898      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9899      ae\_int\_t npoints,}
\DoxyCodeLine{9900      ae\_state *\_state);}
\DoxyCodeLine{9901 \textcolor{keywordtype}{void} dfcopy(decisionforest* df1, decisionforest* df2, ae\_state *\_state);}
\DoxyCodeLine{9902 \textcolor{keywordtype}{void} dfalloc(ae\_serializer* s, decisionforest* forest, ae\_state *\_state);}
\DoxyCodeLine{9903 \textcolor{keywordtype}{void} dfserialize(ae\_serializer* s,}
\DoxyCodeLine{9904      decisionforest* forest,}
\DoxyCodeLine{9905      ae\_state *\_state);}
\DoxyCodeLine{9906 \textcolor{keywordtype}{void} dfunserialize(ae\_serializer* s,}
\DoxyCodeLine{9907      decisionforest* forest,}
\DoxyCodeLine{9908      ae\_state *\_state);}
\DoxyCodeLine{9909 \textcolor{keywordtype}{void} dfbuildrandomdecisionforest(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9910      ae\_int\_t npoints,}
\DoxyCodeLine{9911      ae\_int\_t nvars,}
\DoxyCodeLine{9912      ae\_int\_t nclasses,}
\DoxyCodeLine{9913      ae\_int\_t ntrees,}
\DoxyCodeLine{9914      \textcolor{keywordtype}{double} r,}
\DoxyCodeLine{9915      ae\_int\_t* info,}
\DoxyCodeLine{9916      decisionforest* df,}
\DoxyCodeLine{9917      dfreport* rep,}
\DoxyCodeLine{9918      ae\_state *\_state);}
\DoxyCodeLine{9919 \textcolor{keywordtype}{void} dfbuildrandomdecisionforestx1(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9920      ae\_int\_t npoints,}
\DoxyCodeLine{9921      ae\_int\_t nvars,}
\DoxyCodeLine{9922      ae\_int\_t nclasses,}
\DoxyCodeLine{9923      ae\_int\_t ntrees,}
\DoxyCodeLine{9924      ae\_int\_t nrndvars,}
\DoxyCodeLine{9925      \textcolor{keywordtype}{double} r,}
\DoxyCodeLine{9926      ae\_int\_t* info,}
\DoxyCodeLine{9927      decisionforest* df,}
\DoxyCodeLine{9928      dfreport* rep,}
\DoxyCodeLine{9929      ae\_state *\_state);}
\DoxyCodeLine{9930 \textcolor{keywordtype}{void} dfbuildinternal(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9931      ae\_int\_t npoints,}
\DoxyCodeLine{9932      ae\_int\_t nvars,}
\DoxyCodeLine{9933      ae\_int\_t nclasses,}
\DoxyCodeLine{9934      ae\_int\_t ntrees,}
\DoxyCodeLine{9935      ae\_int\_t samplesize,}
\DoxyCodeLine{9936      ae\_int\_t nfeatures,}
\DoxyCodeLine{9937      ae\_int\_t flags,}
\DoxyCodeLine{9938      ae\_int\_t* info,}
\DoxyCodeLine{9939      decisionforest* df,}
\DoxyCodeLine{9940      dfreport* rep,}
\DoxyCodeLine{9941      ae\_state *\_state);}
\DoxyCodeLine{9942 \textcolor{keywordtype}{void} \_decisionforestbuilder\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9943 \textcolor{keywordtype}{void} \_decisionforestbuilder\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9944 \textcolor{keywordtype}{void} \_decisionforestbuilder\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9945 \textcolor{keywordtype}{void} \_decisionforestbuilder\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9946 \textcolor{keywordtype}{void} \_dfworkbuf\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9947 \textcolor{keywordtype}{void} \_dfworkbuf\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9948 \textcolor{keywordtype}{void} \_dfworkbuf\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9949 \textcolor{keywordtype}{void} \_dfworkbuf\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9950 \textcolor{keywordtype}{void} \_dfvotebuf\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9951 \textcolor{keywordtype}{void} \_dfvotebuf\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9952 \textcolor{keywordtype}{void} \_dfvotebuf\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9953 \textcolor{keywordtype}{void} \_dfvotebuf\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9954 \textcolor{keywordtype}{void} \_dfpermimpbuf\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9955 \textcolor{keywordtype}{void} \_dfpermimpbuf\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9956 \textcolor{keywordtype}{void} \_dfpermimpbuf\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9957 \textcolor{keywordtype}{void} \_dfpermimpbuf\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9958 \textcolor{keywordtype}{void} \_dftreebuf\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9959 \textcolor{keywordtype}{void} \_dftreebuf\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9960 \textcolor{keywordtype}{void} \_dftreebuf\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9961 \textcolor{keywordtype}{void} \_dftreebuf\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9962 \textcolor{keywordtype}{void} \_decisionforestbuffer\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9963 \textcolor{keywordtype}{void} \_decisionforestbuffer\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9964 \textcolor{keywordtype}{void} \_decisionforestbuffer\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9965 \textcolor{keywordtype}{void} \_decisionforestbuffer\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9966 \textcolor{keywordtype}{void} \_decisionforest\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9967 \textcolor{keywordtype}{void} \_decisionforest\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9968 \textcolor{keywordtype}{void} \_decisionforest\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9969 \textcolor{keywordtype}{void} \_decisionforest\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9970 \textcolor{keywordtype}{void} \_dfreport\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9971 \textcolor{keywordtype}{void} \_dfreport\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9972 \textcolor{keywordtype}{void} \_dfreport\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9973 \textcolor{keywordtype}{void} \_dfreport\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9974 \textcolor{keywordtype}{void} \_dfinternalbuffers\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9975 \textcolor{keywordtype}{void} \_dfinternalbuffers\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{9976 \textcolor{keywordtype}{void} \_dfinternalbuffers\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9977 \textcolor{keywordtype}{void} \_dfinternalbuffers\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{9978 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{9979 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_LINREG) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{9980 \textcolor{keywordtype}{void} lrbuild(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9981      ae\_int\_t npoints,}
\DoxyCodeLine{9982      ae\_int\_t nvars,}
\DoxyCodeLine{9983      ae\_int\_t* info,}
\DoxyCodeLine{9984      linearmodel* lm,}
\DoxyCodeLine{9985      lrreport* ar,}
\DoxyCodeLine{9986      ae\_state *\_state);}
\DoxyCodeLine{9987 \textcolor{keywordtype}{void} lrbuilds(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9988      \textcolor{comment}{/* Real    */} ae\_vector* s,}
\DoxyCodeLine{9989      ae\_int\_t npoints,}
\DoxyCodeLine{9990      ae\_int\_t nvars,}
\DoxyCodeLine{9991      ae\_int\_t* info,}
\DoxyCodeLine{9992      linearmodel* lm,}
\DoxyCodeLine{9993      lrreport* ar,}
\DoxyCodeLine{9994      ae\_state *\_state);}
\DoxyCodeLine{9995 \textcolor{keywordtype}{void} lrbuildzs(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{9996      \textcolor{comment}{/* Real    */} ae\_vector* s,}
\DoxyCodeLine{9997      ae\_int\_t npoints,}
\DoxyCodeLine{9998      ae\_int\_t nvars,}
\DoxyCodeLine{9999      ae\_int\_t* info,}
\DoxyCodeLine{10000      linearmodel* lm,}
\DoxyCodeLine{10001      lrreport* ar,}
\DoxyCodeLine{10002      ae\_state *\_state);}
\DoxyCodeLine{10003 \textcolor{keywordtype}{void} lrbuildz(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10004      ae\_int\_t npoints,}
\DoxyCodeLine{10005      ae\_int\_t nvars,}
\DoxyCodeLine{10006      ae\_int\_t* info,}
\DoxyCodeLine{10007      linearmodel* lm,}
\DoxyCodeLine{10008      lrreport* ar,}
\DoxyCodeLine{10009      ae\_state *\_state);}
\DoxyCodeLine{10010 \textcolor{keywordtype}{void} lrunpack(linearmodel* lm,}
\DoxyCodeLine{10011      \textcolor{comment}{/* Real    */} ae\_vector* v,}
\DoxyCodeLine{10012      ae\_int\_t* nvars,}
\DoxyCodeLine{10013      ae\_state *\_state);}
\DoxyCodeLine{10014 \textcolor{keywordtype}{void} lrpack(\textcolor{comment}{/* Real    */} ae\_vector* v,}
\DoxyCodeLine{10015      ae\_int\_t nvars,}
\DoxyCodeLine{10016      linearmodel* lm,}
\DoxyCodeLine{10017      ae\_state *\_state);}
\DoxyCodeLine{10018 \textcolor{keywordtype}{double} lrprocess(linearmodel* lm,}
\DoxyCodeLine{10019      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{10020      ae\_state *\_state);}
\DoxyCodeLine{10021 \textcolor{keywordtype}{double} lrrmserror(linearmodel* lm,}
\DoxyCodeLine{10022      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10023      ae\_int\_t npoints,}
\DoxyCodeLine{10024      ae\_state *\_state);}
\DoxyCodeLine{10025 \textcolor{keywordtype}{double} lravgerror(linearmodel* lm,}
\DoxyCodeLine{10026      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10027      ae\_int\_t npoints,}
\DoxyCodeLine{10028      ae\_state *\_state);}
\DoxyCodeLine{10029 \textcolor{keywordtype}{double} lravgrelerror(linearmodel* lm,}
\DoxyCodeLine{10030      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10031      ae\_int\_t npoints,}
\DoxyCodeLine{10032      ae\_state *\_state);}
\DoxyCodeLine{10033 \textcolor{keywordtype}{void} lrcopy(linearmodel* lm1, linearmodel* lm2, ae\_state *\_state);}
\DoxyCodeLine{10034 \textcolor{keywordtype}{void} lrlines(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10035      \textcolor{comment}{/* Real    */} ae\_vector* s,}
\DoxyCodeLine{10036      ae\_int\_t n,}
\DoxyCodeLine{10037      ae\_int\_t* info,}
\DoxyCodeLine{10038      \textcolor{keywordtype}{double}* a,}
\DoxyCodeLine{10039      \textcolor{keywordtype}{double}* b,}
\DoxyCodeLine{10040      \textcolor{keywordtype}{double}* vara,}
\DoxyCodeLine{10041      \textcolor{keywordtype}{double}* varb,}
\DoxyCodeLine{10042      \textcolor{keywordtype}{double}* covab,}
\DoxyCodeLine{10043      \textcolor{keywordtype}{double}* corrab,}
\DoxyCodeLine{10044      \textcolor{keywordtype}{double}* p,}
\DoxyCodeLine{10045      ae\_state *\_state);}
\DoxyCodeLine{10046 \textcolor{keywordtype}{void} lrline(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10047      ae\_int\_t n,}
\DoxyCodeLine{10048      ae\_int\_t* info,}
\DoxyCodeLine{10049      \textcolor{keywordtype}{double}* a,}
\DoxyCodeLine{10050      \textcolor{keywordtype}{double}* b,}
\DoxyCodeLine{10051      ae\_state *\_state);}
\DoxyCodeLine{10052 \textcolor{keywordtype}{void} \_linearmodel\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10053 \textcolor{keywordtype}{void} \_linearmodel\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10054 \textcolor{keywordtype}{void} \_linearmodel\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10055 \textcolor{keywordtype}{void} \_linearmodel\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10056 \textcolor{keywordtype}{void} \_lrreport\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10057 \textcolor{keywordtype}{void} \_lrreport\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10058 \textcolor{keywordtype}{void} \_lrreport\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10059 \textcolor{keywordtype}{void} \_lrreport\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10060 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{10061 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_FILTERS) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{10062 \textcolor{keywordtype}{void} filtersma(\textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{10063      ae\_int\_t n,}
\DoxyCodeLine{10064      ae\_int\_t k,}
\DoxyCodeLine{10065      ae\_state *\_state);}
\DoxyCodeLine{10066 \textcolor{keywordtype}{void} filterema(\textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{10067      ae\_int\_t n,}
\DoxyCodeLine{10068      \textcolor{keywordtype}{double} alpha,}
\DoxyCodeLine{10069      ae\_state *\_state);}
\DoxyCodeLine{10070 \textcolor{keywordtype}{void} filterlrma(\textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{10071      ae\_int\_t n,}
\DoxyCodeLine{10072      ae\_int\_t k,}
\DoxyCodeLine{10073      ae\_state *\_state);}
\DoxyCodeLine{10074 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{10075 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_SSA) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{10076 \textcolor{keywordtype}{void} ssacreate(ssamodel* s, ae\_state *\_state);}
\DoxyCodeLine{10077 \textcolor{keywordtype}{void} ssasetwindow(ssamodel* s, ae\_int\_t windowwidth, ae\_state *\_state);}
\DoxyCodeLine{10078 \textcolor{keywordtype}{void} ssasetseed(ssamodel* s, ae\_int\_t seed, ae\_state *\_state);}
\DoxyCodeLine{10079 \textcolor{keywordtype}{void} ssasetpoweruplength(ssamodel* s, ae\_int\_t pwlen, ae\_state *\_state);}
\DoxyCodeLine{10080 \textcolor{keywordtype}{void} ssasetmemorylimit(ssamodel* s, ae\_int\_t memlimit, ae\_state *\_state);}
\DoxyCodeLine{10081 \textcolor{keywordtype}{void} ssaaddsequence(ssamodel* s,}
\DoxyCodeLine{10082      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{10083      ae\_int\_t n,}
\DoxyCodeLine{10084      ae\_state *\_state);}
\DoxyCodeLine{10085 \textcolor{keywordtype}{void} ssaappendpointandupdate(ssamodel* s,}
\DoxyCodeLine{10086      \textcolor{keywordtype}{double} x,}
\DoxyCodeLine{10087      \textcolor{keywordtype}{double} updateits,}
\DoxyCodeLine{10088      ae\_state *\_state);}
\DoxyCodeLine{10089 \textcolor{keywordtype}{void} ssaappendsequenceandupdate(ssamodel* s,}
\DoxyCodeLine{10090      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{10091      ae\_int\_t nticks,}
\DoxyCodeLine{10092      \textcolor{keywordtype}{double} updateits,}
\DoxyCodeLine{10093      ae\_state *\_state);}
\DoxyCodeLine{10094 \textcolor{keywordtype}{void} ssasetalgoprecomputed(ssamodel* s,}
\DoxyCodeLine{10095      \textcolor{comment}{/* Real    */} ae\_matrix* a,}
\DoxyCodeLine{10096      ae\_int\_t windowwidth,}
\DoxyCodeLine{10097      ae\_int\_t nbasis,}
\DoxyCodeLine{10098      ae\_state *\_state);}
\DoxyCodeLine{10099 \textcolor{keywordtype}{void} ssasetalgotopkdirect(ssamodel* s, ae\_int\_t topk, ae\_state *\_state);}
\DoxyCodeLine{10100 \textcolor{keywordtype}{void} ssasetalgotopkrealtime(ssamodel* s, ae\_int\_t topk, ae\_state *\_state);}
\DoxyCodeLine{10101 \textcolor{keywordtype}{void} ssacleardata(ssamodel* s, ae\_state *\_state);}
\DoxyCodeLine{10102 \textcolor{keywordtype}{void} ssagetbasis(ssamodel* s,}
\DoxyCodeLine{10103      \textcolor{comment}{/* Real    */} ae\_matrix* a,}
\DoxyCodeLine{10104      \textcolor{comment}{/* Real    */} ae\_vector* sv,}
\DoxyCodeLine{10105      ae\_int\_t* windowwidth,}
\DoxyCodeLine{10106      ae\_int\_t* nbasis,}
\DoxyCodeLine{10107      ae\_state *\_state);}
\DoxyCodeLine{10108 \textcolor{keywordtype}{void} ssagetlrr(ssamodel* s,}
\DoxyCodeLine{10109      \textcolor{comment}{/* Real    */} ae\_vector* a,}
\DoxyCodeLine{10110      ae\_int\_t* windowwidth,}
\DoxyCodeLine{10111      ae\_state *\_state);}
\DoxyCodeLine{10112 \textcolor{keywordtype}{void} ssaanalyzelastwindow(ssamodel* s,}
\DoxyCodeLine{10113      \textcolor{comment}{/* Real    */} ae\_vector* trend,}
\DoxyCodeLine{10114      \textcolor{comment}{/* Real    */} ae\_vector* noise,}
\DoxyCodeLine{10115      ae\_int\_t* nticks,}
\DoxyCodeLine{10116      ae\_state *\_state);}
\DoxyCodeLine{10117 \textcolor{keywordtype}{void} ssaanalyzelast(ssamodel* s,}
\DoxyCodeLine{10118      ae\_int\_t nticks,}
\DoxyCodeLine{10119      \textcolor{comment}{/* Real    */} ae\_vector* trend,}
\DoxyCodeLine{10120      \textcolor{comment}{/* Real    */} ae\_vector* noise,}
\DoxyCodeLine{10121      ae\_state *\_state);}
\DoxyCodeLine{10122 \textcolor{keywordtype}{void} ssaanalyzesequence(ssamodel* s,}
\DoxyCodeLine{10123      \textcolor{comment}{/* Real    */} ae\_vector* data,}
\DoxyCodeLine{10124      ae\_int\_t nticks,}
\DoxyCodeLine{10125      \textcolor{comment}{/* Real    */} ae\_vector* trend,}
\DoxyCodeLine{10126      \textcolor{comment}{/* Real    */} ae\_vector* noise,}
\DoxyCodeLine{10127      ae\_state *\_state);}
\DoxyCodeLine{10128 \textcolor{keywordtype}{void} ssaforecastlast(ssamodel* s,}
\DoxyCodeLine{10129      ae\_int\_t nticks,}
\DoxyCodeLine{10130      \textcolor{comment}{/* Real    */} ae\_vector* trend,}
\DoxyCodeLine{10131      ae\_state *\_state);}
\DoxyCodeLine{10132 \textcolor{keywordtype}{void} ssaforecastsequence(ssamodel* s,}
\DoxyCodeLine{10133      \textcolor{comment}{/* Real    */} ae\_vector* data,}
\DoxyCodeLine{10134      ae\_int\_t datalen,}
\DoxyCodeLine{10135      ae\_int\_t forecastlen,}
\DoxyCodeLine{10136      ae\_bool applysmoothing,}
\DoxyCodeLine{10137      \textcolor{comment}{/* Real    */} ae\_vector* trend,}
\DoxyCodeLine{10138      ae\_state *\_state);}
\DoxyCodeLine{10139 \textcolor{keywordtype}{void} ssaforecastavglast(ssamodel* s,}
\DoxyCodeLine{10140      ae\_int\_t m,}
\DoxyCodeLine{10141      ae\_int\_t nticks,}
\DoxyCodeLine{10142      \textcolor{comment}{/* Real    */} ae\_vector* trend,}
\DoxyCodeLine{10143      ae\_state *\_state);}
\DoxyCodeLine{10144 \textcolor{keywordtype}{void} ssaforecastavgsequence(ssamodel* s,}
\DoxyCodeLine{10145      \textcolor{comment}{/* Real    */} ae\_vector* data,}
\DoxyCodeLine{10146      ae\_int\_t datalen,}
\DoxyCodeLine{10147      ae\_int\_t m,}
\DoxyCodeLine{10148      ae\_int\_t forecastlen,}
\DoxyCodeLine{10149      ae\_bool applysmoothing,}
\DoxyCodeLine{10150      \textcolor{comment}{/* Real    */} ae\_vector* trend,}
\DoxyCodeLine{10151      ae\_state *\_state);}
\DoxyCodeLine{10152 \textcolor{keywordtype}{void} \_ssamodel\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10153 \textcolor{keywordtype}{void} \_ssamodel\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10154 \textcolor{keywordtype}{void} \_ssamodel\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10155 \textcolor{keywordtype}{void} \_ssamodel\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10156 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{10157 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_LDA) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{10158 \textcolor{keywordtype}{void} fisherlda(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10159      ae\_int\_t npoints,}
\DoxyCodeLine{10160      ae\_int\_t nvars,}
\DoxyCodeLine{10161      ae\_int\_t nclasses,}
\DoxyCodeLine{10162      ae\_int\_t* info,}
\DoxyCodeLine{10163      \textcolor{comment}{/* Real    */} ae\_vector* w,}
\DoxyCodeLine{10164      ae\_state *\_state);}
\DoxyCodeLine{10165 \textcolor{keywordtype}{void} fisherldan(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10166      ae\_int\_t npoints,}
\DoxyCodeLine{10167      ae\_int\_t nvars,}
\DoxyCodeLine{10168      ae\_int\_t nclasses,}
\DoxyCodeLine{10169      ae\_int\_t* info,}
\DoxyCodeLine{10170      \textcolor{comment}{/* Real    */} ae\_matrix* w,}
\DoxyCodeLine{10171      ae\_state *\_state);}
\DoxyCodeLine{10172 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{10173 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_MCPD) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{10174 \textcolor{keywordtype}{void} mcpdcreate(ae\_int\_t n, mcpdstate* s, ae\_state *\_state);}
\DoxyCodeLine{10175 \textcolor{keywordtype}{void} mcpdcreateentry(ae\_int\_t n,}
\DoxyCodeLine{10176      ae\_int\_t entrystate,}
\DoxyCodeLine{10177      mcpdstate* s,}
\DoxyCodeLine{10178      ae\_state *\_state);}
\DoxyCodeLine{10179 \textcolor{keywordtype}{void} mcpdcreateexit(ae\_int\_t n,}
\DoxyCodeLine{10180      ae\_int\_t exitstate,}
\DoxyCodeLine{10181      mcpdstate* s,}
\DoxyCodeLine{10182      ae\_state *\_state);}
\DoxyCodeLine{10183 \textcolor{keywordtype}{void} mcpdcreateentryexit(ae\_int\_t n,}
\DoxyCodeLine{10184      ae\_int\_t entrystate,}
\DoxyCodeLine{10185      ae\_int\_t exitstate,}
\DoxyCodeLine{10186      mcpdstate* s,}
\DoxyCodeLine{10187      ae\_state *\_state);}
\DoxyCodeLine{10188 \textcolor{keywordtype}{void} mcpdaddtrack(mcpdstate* s,}
\DoxyCodeLine{10189      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10190      ae\_int\_t k,}
\DoxyCodeLine{10191      ae\_state *\_state);}
\DoxyCodeLine{10192 \textcolor{keywordtype}{void} mcpdsetec(mcpdstate* s,}
\DoxyCodeLine{10193      \textcolor{comment}{/* Real    */} ae\_matrix* ec,}
\DoxyCodeLine{10194      ae\_state *\_state);}
\DoxyCodeLine{10195 \textcolor{keywordtype}{void} mcpdaddec(mcpdstate* s,}
\DoxyCodeLine{10196      ae\_int\_t i,}
\DoxyCodeLine{10197      ae\_int\_t j,}
\DoxyCodeLine{10198      \textcolor{keywordtype}{double} c,}
\DoxyCodeLine{10199      ae\_state *\_state);}
\DoxyCodeLine{10200 \textcolor{keywordtype}{void} mcpdsetbc(mcpdstate* s,}
\DoxyCodeLine{10201      \textcolor{comment}{/* Real    */} ae\_matrix* bndl,}
\DoxyCodeLine{10202      \textcolor{comment}{/* Real    */} ae\_matrix* bndu,}
\DoxyCodeLine{10203      ae\_state *\_state);}
\DoxyCodeLine{10204 \textcolor{keywordtype}{void} mcpdaddbc(mcpdstate* s,}
\DoxyCodeLine{10205      ae\_int\_t i,}
\DoxyCodeLine{10206      ae\_int\_t j,}
\DoxyCodeLine{10207      \textcolor{keywordtype}{double} bndl,}
\DoxyCodeLine{10208      \textcolor{keywordtype}{double} bndu,}
\DoxyCodeLine{10209      ae\_state *\_state);}
\DoxyCodeLine{10210 \textcolor{keywordtype}{void} mcpdsetlc(mcpdstate* s,}
\DoxyCodeLine{10211      \textcolor{comment}{/* Real    */} ae\_matrix* c,}
\DoxyCodeLine{10212      \textcolor{comment}{/* Integer */} ae\_vector* ct,}
\DoxyCodeLine{10213      ae\_int\_t k,}
\DoxyCodeLine{10214      ae\_state *\_state);}
\DoxyCodeLine{10215 \textcolor{keywordtype}{void} mcpdsettikhonovregularizer(mcpdstate* s, \textcolor{keywordtype}{double} v, ae\_state *\_state);}
\DoxyCodeLine{10216 \textcolor{keywordtype}{void} mcpdsetprior(mcpdstate* s,}
\DoxyCodeLine{10217      \textcolor{comment}{/* Real    */} ae\_matrix* pp,}
\DoxyCodeLine{10218      ae\_state *\_state);}
\DoxyCodeLine{10219 \textcolor{keywordtype}{void} mcpdsetpredictionweights(mcpdstate* s,}
\DoxyCodeLine{10220      \textcolor{comment}{/* Real    */} ae\_vector* pw,}
\DoxyCodeLine{10221      ae\_state *\_state);}
\DoxyCodeLine{10222 \textcolor{keywordtype}{void} mcpdsolve(mcpdstate* s, ae\_state *\_state);}
\DoxyCodeLine{10223 \textcolor{keywordtype}{void} mcpdresults(mcpdstate* s,}
\DoxyCodeLine{10224      \textcolor{comment}{/* Real    */} ae\_matrix* p,}
\DoxyCodeLine{10225      mcpdreport* rep,}
\DoxyCodeLine{10226      ae\_state *\_state);}
\DoxyCodeLine{10227 \textcolor{keywordtype}{void} \_mcpdstate\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10228 \textcolor{keywordtype}{void} \_mcpdstate\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10229 \textcolor{keywordtype}{void} \_mcpdstate\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10230 \textcolor{keywordtype}{void} \_mcpdstate\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10231 \textcolor{keywordtype}{void} \_mcpdreport\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10232 \textcolor{keywordtype}{void} \_mcpdreport\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10233 \textcolor{keywordtype}{void} \_mcpdreport\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10234 \textcolor{keywordtype}{void} \_mcpdreport\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10235 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{10236 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_LOGIT) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{10237 \textcolor{keywordtype}{void} mnltrainh(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10238      ae\_int\_t npoints,}
\DoxyCodeLine{10239      ae\_int\_t nvars,}
\DoxyCodeLine{10240      ae\_int\_t nclasses,}
\DoxyCodeLine{10241      ae\_int\_t* info,}
\DoxyCodeLine{10242      logitmodel* lm,}
\DoxyCodeLine{10243      mnlreport* rep,}
\DoxyCodeLine{10244      ae\_state *\_state);}
\DoxyCodeLine{10245 \textcolor{keywordtype}{void} mnlprocess(logitmodel* lm,}
\DoxyCodeLine{10246      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{10247      \textcolor{comment}{/* Real    */} ae\_vector* y,}
\DoxyCodeLine{10248      ae\_state *\_state);}
\DoxyCodeLine{10249 \textcolor{keywordtype}{void} mnlprocessi(logitmodel* lm,}
\DoxyCodeLine{10250      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{10251      \textcolor{comment}{/* Real    */} ae\_vector* y,}
\DoxyCodeLine{10252      ae\_state *\_state);}
\DoxyCodeLine{10253 \textcolor{keywordtype}{void} mnlunpack(logitmodel* lm,}
\DoxyCodeLine{10254      \textcolor{comment}{/* Real    */} ae\_matrix* a,}
\DoxyCodeLine{10255      ae\_int\_t* nvars,}
\DoxyCodeLine{10256      ae\_int\_t* nclasses,}
\DoxyCodeLine{10257      ae\_state *\_state);}
\DoxyCodeLine{10258 \textcolor{keywordtype}{void} mnlpack(\textcolor{comment}{/* Real    */} ae\_matrix* a,}
\DoxyCodeLine{10259      ae\_int\_t nvars,}
\DoxyCodeLine{10260      ae\_int\_t nclasses,}
\DoxyCodeLine{10261      logitmodel* lm,}
\DoxyCodeLine{10262      ae\_state *\_state);}
\DoxyCodeLine{10263 \textcolor{keywordtype}{void} mnlcopy(logitmodel* lm1, logitmodel* lm2, ae\_state *\_state);}
\DoxyCodeLine{10264 \textcolor{keywordtype}{double} mnlavgce(logitmodel* lm,}
\DoxyCodeLine{10265      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10266      ae\_int\_t npoints,}
\DoxyCodeLine{10267      ae\_state *\_state);}
\DoxyCodeLine{10268 \textcolor{keywordtype}{double} mnlrelclserror(logitmodel* lm,}
\DoxyCodeLine{10269      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10270      ae\_int\_t npoints,}
\DoxyCodeLine{10271      ae\_state *\_state);}
\DoxyCodeLine{10272 \textcolor{keywordtype}{double} mnlrmserror(logitmodel* lm,}
\DoxyCodeLine{10273      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10274      ae\_int\_t npoints,}
\DoxyCodeLine{10275      ae\_state *\_state);}
\DoxyCodeLine{10276 \textcolor{keywordtype}{double} mnlavgerror(logitmodel* lm,}
\DoxyCodeLine{10277      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10278      ae\_int\_t npoints,}
\DoxyCodeLine{10279      ae\_state *\_state);}
\DoxyCodeLine{10280 \textcolor{keywordtype}{double} mnlavgrelerror(logitmodel* lm,}
\DoxyCodeLine{10281      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10282      ae\_int\_t ssize,}
\DoxyCodeLine{10283      ae\_state *\_state);}
\DoxyCodeLine{10284 ae\_int\_t mnlclserror(logitmodel* lm,}
\DoxyCodeLine{10285      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10286      ae\_int\_t npoints,}
\DoxyCodeLine{10287      ae\_state *\_state);}
\DoxyCodeLine{10288 \textcolor{keywordtype}{void} \_logitmodel\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10289 \textcolor{keywordtype}{void} \_logitmodel\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10290 \textcolor{keywordtype}{void} \_logitmodel\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10291 \textcolor{keywordtype}{void} \_logitmodel\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10292 \textcolor{keywordtype}{void} \_logitmcstate\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10293 \textcolor{keywordtype}{void} \_logitmcstate\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10294 \textcolor{keywordtype}{void} \_logitmcstate\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10295 \textcolor{keywordtype}{void} \_logitmcstate\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10296 \textcolor{keywordtype}{void} \_mnlreport\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10297 \textcolor{keywordtype}{void} \_mnlreport\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10298 \textcolor{keywordtype}{void} \_mnlreport\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10299 \textcolor{keywordtype}{void} \_mnlreport\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10300 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{10301 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_KNN) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{10302 \textcolor{keywordtype}{void} knncreatebuffer(knnmodel* model, knnbuffer* buf, ae\_state *\_state);}
\DoxyCodeLine{10303 \textcolor{keywordtype}{void} knnbuildercreate(knnbuilder* s, ae\_state *\_state);}
\DoxyCodeLine{10304 \textcolor{keywordtype}{void} knnbuildersetdatasetreg(knnbuilder* s,}
\DoxyCodeLine{10305      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10306      ae\_int\_t npoints,}
\DoxyCodeLine{10307      ae\_int\_t nvars,}
\DoxyCodeLine{10308      ae\_int\_t nout,}
\DoxyCodeLine{10309      ae\_state *\_state);}
\DoxyCodeLine{10310 \textcolor{keywordtype}{void} knnbuildersetdatasetcls(knnbuilder* s,}
\DoxyCodeLine{10311      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10312      ae\_int\_t npoints,}
\DoxyCodeLine{10313      ae\_int\_t nvars,}
\DoxyCodeLine{10314      ae\_int\_t nclasses,}
\DoxyCodeLine{10315      ae\_state *\_state);}
\DoxyCodeLine{10316 \textcolor{keywordtype}{void} knnbuildersetnorm(knnbuilder* s, ae\_int\_t nrmtype, ae\_state *\_state);}
\DoxyCodeLine{10317 \textcolor{keywordtype}{void} knnbuilderbuildknnmodel(knnbuilder* s,}
\DoxyCodeLine{10318      ae\_int\_t k,}
\DoxyCodeLine{10319      \textcolor{keywordtype}{double} eps,}
\DoxyCodeLine{10320      knnmodel* model,}
\DoxyCodeLine{10321      knnreport* rep,}
\DoxyCodeLine{10322      ae\_state *\_state);}
\DoxyCodeLine{10323 \textcolor{keywordtype}{void} knnrewritekeps(knnmodel* model,}
\DoxyCodeLine{10324      ae\_int\_t k,}
\DoxyCodeLine{10325      \textcolor{keywordtype}{double} eps,}
\DoxyCodeLine{10326      ae\_state *\_state);}
\DoxyCodeLine{10327 \textcolor{keywordtype}{void} knnprocess(knnmodel* model,}
\DoxyCodeLine{10328      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{10329      \textcolor{comment}{/* Real    */} ae\_vector* y,}
\DoxyCodeLine{10330      ae\_state *\_state);}
\DoxyCodeLine{10331 \textcolor{keywordtype}{double} knnprocess0(knnmodel* model,}
\DoxyCodeLine{10332      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{10333      ae\_state *\_state);}
\DoxyCodeLine{10334 ae\_int\_t knnclassify(knnmodel* model,}
\DoxyCodeLine{10335      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{10336      ae\_state *\_state);}
\DoxyCodeLine{10337 \textcolor{keywordtype}{void} knnprocessi(knnmodel* model,}
\DoxyCodeLine{10338      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{10339      \textcolor{comment}{/* Real    */} ae\_vector* y,}
\DoxyCodeLine{10340      ae\_state *\_state);}
\DoxyCodeLine{10341 \textcolor{keywordtype}{void} knntsprocess(knnmodel* model,}
\DoxyCodeLine{10342      knnbuffer* buf,}
\DoxyCodeLine{10343      \textcolor{comment}{/* Real    */} ae\_vector* x,}
\DoxyCodeLine{10344      \textcolor{comment}{/* Real    */} ae\_vector* y,}
\DoxyCodeLine{10345      ae\_state *\_state);}
\DoxyCodeLine{10346 \textcolor{keywordtype}{double} knnrelclserror(knnmodel* model,}
\DoxyCodeLine{10347      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10348      ae\_int\_t npoints,}
\DoxyCodeLine{10349      ae\_state *\_state);}
\DoxyCodeLine{10350 \textcolor{keywordtype}{double} knnavgce(knnmodel* model,}
\DoxyCodeLine{10351      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10352      ae\_int\_t npoints,}
\DoxyCodeLine{10353      ae\_state *\_state);}
\DoxyCodeLine{10354 \textcolor{keywordtype}{double} knnrmserror(knnmodel* model,}
\DoxyCodeLine{10355      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10356      ae\_int\_t npoints,}
\DoxyCodeLine{10357      ae\_state *\_state);}
\DoxyCodeLine{10358 \textcolor{keywordtype}{double} knnavgerror(knnmodel* model,}
\DoxyCodeLine{10359      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10360      ae\_int\_t npoints,}
\DoxyCodeLine{10361      ae\_state *\_state);}
\DoxyCodeLine{10362 \textcolor{keywordtype}{double} knnavgrelerror(knnmodel* model,}
\DoxyCodeLine{10363      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10364      ae\_int\_t npoints,}
\DoxyCodeLine{10365      ae\_state *\_state);}
\DoxyCodeLine{10366 \textcolor{keywordtype}{void} knnallerrors(knnmodel* model,}
\DoxyCodeLine{10367      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10368      ae\_int\_t npoints,}
\DoxyCodeLine{10369      knnreport* rep,}
\DoxyCodeLine{10370      ae\_state *\_state);}
\DoxyCodeLine{10371 \textcolor{keywordtype}{void} knnalloc(ae\_serializer* s, knnmodel* model, ae\_state *\_state);}
\DoxyCodeLine{10372 \textcolor{keywordtype}{void} knnserialize(ae\_serializer* s, knnmodel* model, ae\_state *\_state);}
\DoxyCodeLine{10373 \textcolor{keywordtype}{void} knnunserialize(ae\_serializer* s, knnmodel* model, ae\_state *\_state);}
\DoxyCodeLine{10374 \textcolor{keywordtype}{void} \_knnbuffer\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10375 \textcolor{keywordtype}{void} \_knnbuffer\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10376 \textcolor{keywordtype}{void} \_knnbuffer\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10377 \textcolor{keywordtype}{void} \_knnbuffer\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10378 \textcolor{keywordtype}{void} \_knnbuilder\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10379 \textcolor{keywordtype}{void} \_knnbuilder\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10380 \textcolor{keywordtype}{void} \_knnbuilder\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10381 \textcolor{keywordtype}{void} \_knnbuilder\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10382 \textcolor{keywordtype}{void} \_knnmodel\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10383 \textcolor{keywordtype}{void} \_knnmodel\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10384 \textcolor{keywordtype}{void} \_knnmodel\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10385 \textcolor{keywordtype}{void} \_knnmodel\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10386 \textcolor{keywordtype}{void} \_knnreport\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10387 \textcolor{keywordtype}{void} \_knnreport\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10388 \textcolor{keywordtype}{void} \_knnreport\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10389 \textcolor{keywordtype}{void} \_knnreport\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10390 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{10391 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_MLPTRAIN) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{10392 \textcolor{keywordtype}{void} mlptrainlm(multilayerperceptron* network,}
\DoxyCodeLine{10393      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10394      ae\_int\_t npoints,}
\DoxyCodeLine{10395      \textcolor{keywordtype}{double} decay,}
\DoxyCodeLine{10396      ae\_int\_t restarts,}
\DoxyCodeLine{10397      ae\_int\_t* info,}
\DoxyCodeLine{10398      mlpreport* rep,}
\DoxyCodeLine{10399      ae\_state *\_state);}
\DoxyCodeLine{10400 \textcolor{keywordtype}{void} mlptrainlbfgs(multilayerperceptron* network,}
\DoxyCodeLine{10401      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10402      ae\_int\_t npoints,}
\DoxyCodeLine{10403      \textcolor{keywordtype}{double} decay,}
\DoxyCodeLine{10404      ae\_int\_t restarts,}
\DoxyCodeLine{10405      \textcolor{keywordtype}{double} wstep,}
\DoxyCodeLine{10406      ae\_int\_t maxits,}
\DoxyCodeLine{10407      ae\_int\_t* info,}
\DoxyCodeLine{10408      mlpreport* rep,}
\DoxyCodeLine{10409      ae\_state *\_state);}
\DoxyCodeLine{10410 \textcolor{keywordtype}{void} mlptraines(multilayerperceptron* network,}
\DoxyCodeLine{10411      \textcolor{comment}{/* Real    */} ae\_matrix* trnxy,}
\DoxyCodeLine{10412      ae\_int\_t trnsize,}
\DoxyCodeLine{10413      \textcolor{comment}{/* Real    */} ae\_matrix* valxy,}
\DoxyCodeLine{10414      ae\_int\_t valsize,}
\DoxyCodeLine{10415      \textcolor{keywordtype}{double} decay,}
\DoxyCodeLine{10416      ae\_int\_t restarts,}
\DoxyCodeLine{10417      ae\_int\_t* info,}
\DoxyCodeLine{10418      mlpreport* rep,}
\DoxyCodeLine{10419      ae\_state *\_state);}
\DoxyCodeLine{10420 \textcolor{keywordtype}{void} mlpkfoldcvlbfgs(multilayerperceptron* network,}
\DoxyCodeLine{10421      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10422      ae\_int\_t npoints,}
\DoxyCodeLine{10423      \textcolor{keywordtype}{double} decay,}
\DoxyCodeLine{10424      ae\_int\_t restarts,}
\DoxyCodeLine{10425      \textcolor{keywordtype}{double} wstep,}
\DoxyCodeLine{10426      ae\_int\_t maxits,}
\DoxyCodeLine{10427      ae\_int\_t foldscount,}
\DoxyCodeLine{10428      ae\_int\_t* info,}
\DoxyCodeLine{10429      mlpreport* rep,}
\DoxyCodeLine{10430      mlpcvreport* cvrep,}
\DoxyCodeLine{10431      ae\_state *\_state);}
\DoxyCodeLine{10432 \textcolor{keywordtype}{void} mlpkfoldcvlm(multilayerperceptron* network,}
\DoxyCodeLine{10433      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10434      ae\_int\_t npoints,}
\DoxyCodeLine{10435      \textcolor{keywordtype}{double} decay,}
\DoxyCodeLine{10436      ae\_int\_t restarts,}
\DoxyCodeLine{10437      ae\_int\_t foldscount,}
\DoxyCodeLine{10438      ae\_int\_t* info,}
\DoxyCodeLine{10439      mlpreport* rep,}
\DoxyCodeLine{10440      mlpcvreport* cvrep,}
\DoxyCodeLine{10441      ae\_state *\_state);}
\DoxyCodeLine{10442 \textcolor{keywordtype}{void} mlpkfoldcv(mlptrainer* s,}
\DoxyCodeLine{10443      multilayerperceptron* network,}
\DoxyCodeLine{10444      ae\_int\_t nrestarts,}
\DoxyCodeLine{10445      ae\_int\_t foldscount,}
\DoxyCodeLine{10446      mlpreport* rep,}
\DoxyCodeLine{10447      ae\_state *\_state);}
\DoxyCodeLine{10448 \textcolor{keywordtype}{void} mlpcreatetrainer(ae\_int\_t nin,}
\DoxyCodeLine{10449      ae\_int\_t nout,}
\DoxyCodeLine{10450      mlptrainer* s,}
\DoxyCodeLine{10451      ae\_state *\_state);}
\DoxyCodeLine{10452 \textcolor{keywordtype}{void} mlpcreatetrainercls(ae\_int\_t nin,}
\DoxyCodeLine{10453      ae\_int\_t nclasses,}
\DoxyCodeLine{10454      mlptrainer* s,}
\DoxyCodeLine{10455      ae\_state *\_state);}
\DoxyCodeLine{10456 \textcolor{keywordtype}{void} mlpsetdataset(mlptrainer* s,}
\DoxyCodeLine{10457      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10458      ae\_int\_t npoints,}
\DoxyCodeLine{10459      ae\_state *\_state);}
\DoxyCodeLine{10460 \textcolor{keywordtype}{void} mlpsetsparsedataset(mlptrainer* s,}
\DoxyCodeLine{10461      sparsematrix* xy,}
\DoxyCodeLine{10462      ae\_int\_t npoints,}
\DoxyCodeLine{10463      ae\_state *\_state);}
\DoxyCodeLine{10464 \textcolor{keywordtype}{void} mlpsetdecay(mlptrainer* s, \textcolor{keywordtype}{double} decay, ae\_state *\_state);}
\DoxyCodeLine{10465 \textcolor{keywordtype}{void} mlpsetcond(mlptrainer* s,}
\DoxyCodeLine{10466      \textcolor{keywordtype}{double} wstep,}
\DoxyCodeLine{10467      ae\_int\_t maxits,}
\DoxyCodeLine{10468      ae\_state *\_state);}
\DoxyCodeLine{10469 \textcolor{keywordtype}{void} mlpsetalgobatch(mlptrainer* s, ae\_state *\_state);}
\DoxyCodeLine{10470 \textcolor{keywordtype}{void} mlptrainnetwork(mlptrainer* s,}
\DoxyCodeLine{10471      multilayerperceptron* network,}
\DoxyCodeLine{10472      ae\_int\_t nrestarts,}
\DoxyCodeLine{10473      mlpreport* rep,}
\DoxyCodeLine{10474      ae\_state *\_state);}
\DoxyCodeLine{10475 \textcolor{keywordtype}{void} mlpstarttraining(mlptrainer* s,}
\DoxyCodeLine{10476      multilayerperceptron* network,}
\DoxyCodeLine{10477      ae\_bool randomstart,}
\DoxyCodeLine{10478      ae\_state *\_state);}
\DoxyCodeLine{10479 ae\_bool mlpcontinuetraining(mlptrainer* s,}
\DoxyCodeLine{10480      multilayerperceptron* network,}
\DoxyCodeLine{10481      ae\_state *\_state);}
\DoxyCodeLine{10482 \textcolor{keywordtype}{void} mlpebagginglm(mlpensemble* ensemble,}
\DoxyCodeLine{10483      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10484      ae\_int\_t npoints,}
\DoxyCodeLine{10485      \textcolor{keywordtype}{double} decay,}
\DoxyCodeLine{10486      ae\_int\_t restarts,}
\DoxyCodeLine{10487      ae\_int\_t* info,}
\DoxyCodeLine{10488      mlpreport* rep,}
\DoxyCodeLine{10489      mlpcvreport* ooberrors,}
\DoxyCodeLine{10490      ae\_state *\_state);}
\DoxyCodeLine{10491 \textcolor{keywordtype}{void} mlpebagginglbfgs(mlpensemble* ensemble,}
\DoxyCodeLine{10492      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10493      ae\_int\_t npoints,}
\DoxyCodeLine{10494      \textcolor{keywordtype}{double} decay,}
\DoxyCodeLine{10495      ae\_int\_t restarts,}
\DoxyCodeLine{10496      \textcolor{keywordtype}{double} wstep,}
\DoxyCodeLine{10497      ae\_int\_t maxits,}
\DoxyCodeLine{10498      ae\_int\_t* info,}
\DoxyCodeLine{10499      mlpreport* rep,}
\DoxyCodeLine{10500      mlpcvreport* ooberrors,}
\DoxyCodeLine{10501      ae\_state *\_state);}
\DoxyCodeLine{10502 \textcolor{keywordtype}{void} mlpetraines(mlpensemble* ensemble,}
\DoxyCodeLine{10503      \textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10504      ae\_int\_t npoints,}
\DoxyCodeLine{10505      \textcolor{keywordtype}{double} decay,}
\DoxyCodeLine{10506      ae\_int\_t restarts,}
\DoxyCodeLine{10507      ae\_int\_t* info,}
\DoxyCodeLine{10508      mlpreport* rep,}
\DoxyCodeLine{10509      ae\_state *\_state);}
\DoxyCodeLine{10510 \textcolor{keywordtype}{void} mlptrainensemblees(mlptrainer* s,}
\DoxyCodeLine{10511      mlpensemble* ensemble,}
\DoxyCodeLine{10512      ae\_int\_t nrestarts,}
\DoxyCodeLine{10513      mlpreport* rep,}
\DoxyCodeLine{10514      ae\_state *\_state);}
\DoxyCodeLine{10515 \textcolor{keywordtype}{void} \_mlpreport\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10516 \textcolor{keywordtype}{void} \_mlpreport\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10517 \textcolor{keywordtype}{void} \_mlpreport\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10518 \textcolor{keywordtype}{void} \_mlpreport\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10519 \textcolor{keywordtype}{void} \_mlpcvreport\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10520 \textcolor{keywordtype}{void} \_mlpcvreport\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10521 \textcolor{keywordtype}{void} \_mlpcvreport\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10522 \textcolor{keywordtype}{void} \_mlpcvreport\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10523 \textcolor{keywordtype}{void} \_smlptrnsession\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10524 \textcolor{keywordtype}{void} \_smlptrnsession\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10525 \textcolor{keywordtype}{void} \_smlptrnsession\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10526 \textcolor{keywordtype}{void} \_smlptrnsession\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10527 \textcolor{keywordtype}{void} \_mlpetrnsession\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10528 \textcolor{keywordtype}{void} \_mlpetrnsession\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10529 \textcolor{keywordtype}{void} \_mlpetrnsession\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10530 \textcolor{keywordtype}{void} \_mlpetrnsession\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10531 \textcolor{keywordtype}{void} \_mlptrainer\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10532 \textcolor{keywordtype}{void} \_mlptrainer\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10533 \textcolor{keywordtype}{void} \_mlptrainer\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10534 \textcolor{keywordtype}{void} \_mlptrainer\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10535 \textcolor{keywordtype}{void} \_mlpparallelizationcv\_init(\textcolor{keywordtype}{void}* \_p, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10536 \textcolor{keywordtype}{void} \_mlpparallelizationcv\_init\_copy(\textcolor{keywordtype}{void}* \_dst, \textcolor{keywordtype}{void}* \_src, ae\_state *\_state, ae\_bool make\_automatic);}
\DoxyCodeLine{10537 \textcolor{keywordtype}{void} \_mlpparallelizationcv\_clear(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10538 \textcolor{keywordtype}{void} \_mlpparallelizationcv\_destroy(\textcolor{keywordtype}{void}* \_p);}
\DoxyCodeLine{10539 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{10540 \textcolor{preprocessor}{\#if defined(AE\_COMPILE\_DATACOMP) || !defined(AE\_PARTIAL\_BUILD)}}
\DoxyCodeLine{10541 \textcolor{keywordtype}{void} kmeansgenerate(\textcolor{comment}{/* Real    */} ae\_matrix* xy,}
\DoxyCodeLine{10542      ae\_int\_t npoints,}
\DoxyCodeLine{10543      ae\_int\_t nvars,}
\DoxyCodeLine{10544      ae\_int\_t k,}
\DoxyCodeLine{10545      ae\_int\_t restarts,}
\DoxyCodeLine{10546      ae\_int\_t* info,}
\DoxyCodeLine{10547      \textcolor{comment}{/* Real    */} ae\_matrix* c,}
\DoxyCodeLine{10548      \textcolor{comment}{/* Integer */} ae\_vector* xyc,}
\DoxyCodeLine{10549      ae\_state *\_state);}
\DoxyCodeLine{10550 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{10551 }
\DoxyCodeLine{10552 \}}
\DoxyCodeLine{10553 \textcolor{preprocessor}{\#endif}}
\DoxyCodeLine{10554 }

\end{DoxyCode}
